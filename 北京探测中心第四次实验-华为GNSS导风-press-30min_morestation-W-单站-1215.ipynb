{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52136ab1-fb69-49f7-99dd-fd137796b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载原始数据文件...\n",
      "文件加载完毕。\n",
      "正在对原始数据进行预处理...\n",
      "预处理完成。\n",
      "\n",
      "--- 开始筛选站点 (新逻辑) ---\n",
      "目标风场站点: 58557\n",
      "使用预设的目标站点经纬度: Lon=120.0717, Lat=29.3619\n",
      "在GNSS数据文件中找到 1215 个可用站点。\n",
      "在CSV和GNSS数据文件中共有 1215 个共同站点。\n",
      "找到的最近 1215 个GNSS站点: ['H992830', 'H998276', 'H11705423', 'H11705435', 'H792737', 'H892451', 'H992254', 'H11705447', 'H11705440', 'H892504', 'H998585', 'H997648', 'H992221', 'H998596', 'H11705442', 'H11705404', 'H798684', 'H997915', 'H997714', 'H11705408', 'H892866', 'H992792', 'H992154', 'H991217', 'H998172', 'H997618', 'H992023', 'H756621', 'H999268', 'H990477', 'H999166', 'H756021', 'H996453', 'H990638', 'H998429', 'H990413', 'H999194', 'H991454', 'H999941', 'H999072', 'H990004', 'H799390', 'H990379', 'H999070', 'H990896', 'H796752', 'H756990', 'H990312', 'H999634', 'H990100', 'H999409', 'H999227', 'H890501', 'H999651', 'H796767', 'H990819', 'H992352', 'H993271', 'H994528', 'H796788', 'H993233', 'H990014', 'H799263', 'H799424', 'H994427', 'H999342', 'H891649', 'H997770', 'H999401', 'H899701', 'H854592', 'H756069', 'H756507', 'H990435', 'H956637', 'H956050', 'H999174', 'H993527', 'H956776', 'H999425', 'H994430', 'H799188', 'H754810', 'H758362', 'H754825', 'H990287', 'H754964', 'H994827', 'H754070', 'H990589', 'H956437', 'H11705362', 'H999137', 'H754047', 'H756643', 'H994535', 'H899502', 'H799069', 'H999036', 'H899953', 'H899447', 'H994080', 'H999195', 'H999208', 'H997384', 'H756089', 'H999192', 'H790349', 'H990300', 'H999220', 'H996009', 'H990270', 'H756613', 'H990220', 'H999926', 'H11705360', 'H799361', 'H990658', 'H890734', 'H999753', 'H752190', 'H990362', 'H999080', 'H790044', 'H990791', 'H890125', 'H11705511', 'H890930', 'H991672', 'H990356', 'H990975', 'H891646', 'H990933', 'H990805', 'H990390', 'H999508', 'H999127', 'H990029', 'H799256', 'H994615', 'H990208', 'H990790', 'H991684', 'H11705376', 'H999099', 'H990665', 'H11705375', 'H995070', 'H990785', 'H990635', 'H754576', 'H994622', 'H890721', 'H999660', 'H752327', 'H990247', 'H990936', 'H995674', 'H899154', 'H756366', 'H890990', 'H999153', 'H999664', 'H990190', 'H999237', 'H11705381', 'H11705382', 'H999672', 'H11705371', 'H752344', 'H899851', 'H996184', 'H754323', 'H11705373', 'H990225', 'H996542', 'H990520', 'H756680', 'H11705384', 'H996903', 'H752178', 'H990544', 'H890545', 'H754077', 'H890236', 'H990148', 'H996176', 'H754458', 'H899660', 'H990098', 'H752439', 'H996150', 'H991654', 'H996402', 'H756649', 'H996284', 'H713716', 'H752478', 'H990211', 'H996016', 'H754497', 'H990815', 'H996587', 'H752365', 'H756451', 'H899223', 'H799497', 'H996177', 'H913879', 'H990318', 'H996085', 'H996408', 'H999197', 'H752355', 'H996276', 'H899700', 'H996162', 'H790122', 'H713099', 'H999289', 'H752598', 'H996172', 'H752993', 'H752561', 'H752080', 'H712795', 'H990656', 'H952235', 'H752312', 'H999033', 'H752172', 'H854560', 'H990385', 'H996058', 'H999251', 'H815529', 'H752612', 'H996458', 'H991682', 'H812229', 'H999001', 'H999337', 'H999670', 'H812364', 'H717664', 'H918333', 'H917541', 'H712500', 'H996073', 'H990826', 'H952754', 'H996406', 'H790852', 'H815368', 'H916985', 'H899680', 'H799026', 'H999079', 'H917558', 'H713454', 'H990363', 'H712465', 'H999784', 'H717503', 'H752972', 'H852847', 'H812830', 'H890309', 'H990326', 'H752784', 'H996078', 'H996202', 'H910437', 'H852873', 'H818012', 'H713420', 'H752051', 'H995552', 'H996091', 'H952696', 'H752654', 'H815373', 'H813115', 'H996419', 'H816290', 'H790844', 'H894896', 'H990814', 'H713333', 'H752371', 'H752363', 'H990842', 'H990450', 'H912930', 'H813277', 'H752360', 'H752331', 'H812960', 'H911031', 'H812339', 'H912330', 'H817058', 'H917272', 'H913901', 'H814890', 'H713104', 'H712231', 'H811399', 'H911080', 'H752329', 'H912596', 'H752321', 'H914283', 'H910993', 'H914268', 'H812472', 'H719197', 'H711205', 'H711417', 'H712372', 'H815654', 'H815683', 'H717490', 'H911092', 'H917915', 'H913045', 'H717441', 'H516440', 'H711437', 'H811053', 'H714575', 'H414954', 'H913997', 'H913183', 'H811100', 'H416412', 'H779871', 'H711370', 'H714024', 'H717064', 'H912003', 'H779869', 'H712277', 'H819770', 'H714675', 'H912015', 'H418645', 'H711288', 'H475383', 'H714836', 'H711897', 'H711196', 'H776415', 'H812051', 'H944935', 'H515808', 'H717342', 'H913143', 'H719139', 'H944929', 'H717753', 'H715046', 'H813668', 'H944916', 'H944885', 'H710894', 'H944927', 'H944200', 'H444117', 'H944389', 'H873456', 'H944436', 'H776146', 'H776173', 'H544723', 'H944686', 'H944411', 'H944811', 'H944312', 'H11681931', 'H771248', 'H944329', 'H544715', 'H770190', 'H444168', 'H771268', 'H874165', 'H771828', 'H877273', 'H944190', 'H876753', 'H940874', 'H771123', 'H944285', 'H944148', 'H11682037', 'H944812', 'H947727', 'H940937', 'H940208', 'H949348', 'H940153', 'H776679', 'H940152', 'H941086', 'H776680', 'H949201', 'H941719', 'H947393', 'H777359', 'H779860', 'H949076', 'H779864', 'H873410', 'H775525', 'H949002', 'H871938', 'H943744', 'H940288', 'H440142', 'H773894', 'H943717', 'H945116', 'H943840', 'H945643', 'H945596', 'H945338', 'H948168', 'H949087', 'H475613', 'H948161', 'H945701', 'H949152', 'H945789', 'H943783', 'H949198', 'H943739', 'H949035', 'H445201', 'H949600', 'H949051', 'H771839', 'H949037', 'H943424', 'H11682008', 'H945631', 'H876616', 'H943849', 'H948239', 'H941838', 'H11682007', 'H779345', 'H445169', 'H945933', 'H771727', 'H875870', 'H948586', 'H947392', 'H777361', 'H773975', 'H11678387', 'H773959', 'H477543', 'H475201', 'H771227', 'H872486', 'H11682022', 'H971814', 'H943096', 'H778483', 'H877659', 'H11682000', 'H945117', 'H874967', 'H877863', 'H941425', 'H771463', 'H873916', 'H778478', 'H11682031', 'H670431', 'H945249', 'H776798', 'H978076', 'H778780', 'H945253', 'H943701', 'H943032', 'H779531', 'H872324', 'H945081', 'H11682020', 'H945785', 'H945548', 'H470820', 'H945732', 'H977455', 'H941421', 'H940758', 'H973268', 'H778510', 'H777878', 'H943712', 'H875021', 'H945768', 'H776029', 'H945056', 'H948159', 'H872490', 'H477835', 'H974225', 'H947494', 'H945779', 'H947423', 'H478496', 'H945195', 'H777754', 'H943012', 'H949137', 'H771956', 'H941723', 'H943753', 'H778636', 'H973065', 'H943897', 'H11681811', 'H945094', 'H949139', 'H473477', 'H472113', 'H943473', 'H448399', 'H545716', 'H943863', 'H774016', 'H479294', 'H479646', 'H946337', 'H876191', 'H775628', 'H947346', 'H770953', 'H548894', 'H778402', 'H879557', 'H946945', 'H875715', 'H11547837', 'H943738', 'H479685', 'H946187', 'H770271', 'H947324', 'H872968', 'H941871', 'H973363', 'H873821', 'H877203', 'H479731', 'H472671', 'H973194', 'H977670', 'H11558032', 'H776239', 'H879771', 'H972521', 'H772569', 'H772718', 'H946334', 'H779838', 'H879448', 'H872768', 'H872341', 'H774944', 'H872745', 'H872036', 'H946872', 'H946637', 'H774788', 'H448389', 'H877140', 'H771291', 'H774339', 'H872734', 'H877091', 'H772131', 'H877093', 'H777022', 'H973582', 'H946835', 'H476441', 'H476827', 'H878110', 'H876948', 'H946786', 'H771599', 'H773789', 'H774384', 'H875467', 'H774416', 'H771366', 'H773543', 'H479151', 'H973407', 'H874881', 'H477930', 'H974157', 'H774752', 'H779692', 'H875000', 'H976520', 'H470188', 'H906303', 'H906292', 'H11548254', 'H706213', 'H906161', 'H706249', 'H708810', 'H706665', 'H970399', 'H706842', 'H706136', 'H706294', 'H976578', 'H706417', 'H906103', 'H906378', 'H706207', 'H706540', 'H706390', 'H706393', 'H706566', 'H706415', 'H706713', 'H706866', 'H706231', 'H906301', 'H906758', 'H706432', 'H906229', 'H906747', 'H706197', 'H11681888', 'H706228', 'H706352', 'H706183', 'H709301', 'H11681892', 'H709611', 'H706285', 'H906671', 'H709481', 'H706481', 'H775193', 'H709181', 'H709177', 'H776883', 'H709421', 'H709166', 'H706122', 'H709483', 'H706321', 'H709241', 'H709512', 'H877856', 'H706289', 'H709168', 'H709211', 'H709518', 'H906166', 'H709484', 'H706482', 'H906240', 'H709204', 'H706194', 'H706433', 'H709296', 'H706278', 'H709234', 'H706348', 'H706120', 'H709171', 'H909437', 'H806108', 'H706522', 'H706726', 'H906130', 'H906140', 'H709829', 'H708804', 'H906158', 'H709316', 'H706476', 'H706443', 'H709435', 'H706642', 'H709184', 'H708014', 'H709480', 'H706590', 'H706587', 'H909212', 'H709125', 'H706201', 'H709456', 'H706379', 'H706740', 'H909443', 'H706318', 'H709190', 'H706212', 'H709881', 'H906808', 'H709295', 'H708800', 'H908806', 'H706405', 'H709341', 'H709120', 'H706250', 'H706851', 'H706794', 'H708817', 'H706573', 'H906172', 'H706102', 'H906633', 'H706406', 'H709658', 'H706480', 'H706351', 'H906844', 'H709391', 'H709160', 'H706143', 'H709342', 'H706409', 'H706465', 'H709195', 'H709108', 'H709571', 'H706419', 'H706891', 'H709281', 'H906519', 'H706402', 'H706392', 'H706690', 'H706486', 'H706448', 'H706164', 'H706890', 'H909349', 'H706752', 'H706883', 'H906261', 'H706020', 'H706612', 'H706182', 'H709197', 'H709385', 'H706702', 'H706291', 'H706428', 'H706467', 'H709249', 'H706551', 'H906441', 'H706261', 'H706295', 'H906319', 'H906468', 'H706337', 'H706271', 'H806515', 'H706537', 'H706632', 'H706911', 'H706741', 'H706812', 'H706581', 'H706594', 'H706639', 'H706634', 'H706450', 'H706329', 'H906327', 'H706268', 'H706899', 'H706189', 'H708700', 'H706407', 'H706886', 'H706418', 'H909206', 'H706472', 'H906169', 'H907500', 'H706288', 'H706498', 'H906247', 'H706061', 'H909180', 'H706361', 'H706644', 'H706550', 'H706416', 'H906181', 'H706731', 'H707060', 'H706846', 'H706704', 'H909464', 'H907553', 'H706580', 'H706728', 'H706129', 'H706827', 'H706223', 'H906280', 'H709238', 'H706403', 'H709361', 'H706395', 'H906435', 'H709320', 'H909323', 'H706918', 'H806050', 'H709415', 'H706344', 'H706499', 'H706715', 'H909265', 'H806030', 'H709321', 'H709304', 'H706748', 'H708823', 'H706394', 'H776824', 'H909247', 'H709157', 'H706269', 'H706816', 'H708733', 'H706743', 'H706469', 'H706188', 'H706755', 'H706325', 'H706265', 'H706651', 'H706758', 'H706286', 'H709416', 'H706105', 'H708042', 'H706092', 'H706681', 'H706111', 'H706679', 'H706154', 'H706479', 'H706484', 'H706487', 'H706101', 'H706998', 'H706938', 'H706263', 'H706473', 'H706977', 'H906373', 'H706323', 'H706248', 'H708842', 'H708711', 'H907551', 'H706374', 'H709273', 'H906827', 'H709657', 'H906177', 'H709221', 'H906422', 'H907162', 'H706927', 'H706760', 'H706253', 'H709521', 'H906297', 'H709538', 'H706421', 'H707219', 'H707408', 'H709276', 'H706674', 'H708808', 'H706152', 'H707373', 'H706820', 'H706350', 'H706501', 'H707378', 'H706369', 'H906389', 'H706186', 'H707282', 'H709949', 'H706708', 'H709497', 'H707380', 'H706246', 'H706338', 'H706709', 'H707377', 'H907270', 'H706762', 'H809240', 'H709673', 'H707382', 'H708011', 'H706493', 'H706399', 'H909488', 'H709546', 'H706751', 'H709145', 'H709486', 'H709446', 'H706830', 'H907376', 'H909259', 'H709193', 'H709014', 'H709243', 'H709001', 'H706828', 'H709372', 'H706749', 'H709173', 'H706192', 'H707484', 'H706722', 'H707220', 'H709309', 'H706397', 'H707381', 'H706696', 'H709185', 'H709351', 'H709151', 'H707325', 'H709136', 'H706306', 'H709401', 'H709042', 'H709418', 'H706398', 'H707274', 'H709143', 'H907429', 'H709882', 'H709154', 'H709989', 'H906459', 'H709340', 'H707956', 'H909136', 'H709051', 'H909675', 'H709399', 'H807573', 'H709860', 'H809818', 'H707375', 'H708866', 'H909083', 'H709096', 'H709559', 'H907496', 'H707206', 'H709280', 'H707496', 'H709116', 'H709012', 'H907316', 'H707409', 'H707312', 'H709387', 'H709915', 'H709285', 'H707350', 'H709445', 'H709608', 'H707279', 'H709692', 'H909293', 'H709388', 'H709147', 'H707349', 'H709182', 'H709878', 'H709382', 'H707286', 'H707275', 'H707320', 'H709196', 'H709471', 'H709408', 'H709409', 'H709144', 'H709472', 'H709643', 'H707452', 'H709492', 'H709359', 'H707430', 'H709346', 'H709709', 'H709470', 'H907024', 'H709912', 'H707348', 'H707280', 'H707323', 'H707433', 'H709530', 'H909671', 'H707236', 'H707267', 'H909139', 'H709381', 'H709811', 'H709395', 'H707346', 'H707177', 'H709655', 'H907171', 'H707234', 'H709815', 'H709070', 'H909961', 'H707402', 'H707264', 'H707339', 'H707244', 'H907453', 'H709010', 'H709419', 'H707337', 'H707213', 'H909261', 'H707247', 'H709561', 'H909216', 'H709501', 'H707398', 'H909993', 'H907522', 'H707237', 'H707243', 'H707207', 'H709299', 'H707494', 'H709367', 'H707265', 'H709347', 'H707142', 'H707973', 'H707933', 'H709333', 'H709498', 'H709572', 'H909291', 'H709693', 'H707424', 'H707257', 'H909138', 'H709378', 'H707511', 'H709511', 'H709887', 'H709493', 'H707260', 'H707170', 'H709105', 'H709163', 'H707399', 'H709308', 'H907261', 'H709260', 'H709659', 'H709269', 'H709618', 'H707544', 'H709095', 'H709663', 'H709312', 'H709685', 'H909314', 'H709389', 'H907524', 'H709283', 'H709584', 'H809522', 'H709365', 'H709462', 'H909318', 'H709477', 'H707545', 'H709358', 'H709984', 'H709278', 'H908208', 'H708306', 'H709941', 'H909167', 'H909149', 'H909218', 'H909119', 'H908142', 'H707548', 'H709111', 'H907383', 'H708300', 'H909324', 'H708124', 'H707396', 'H708210', 'H707391', 'H708197', 'H907166', 'H909159', 'H709816', 'H770091', 'H708105', 'H707127', 'H707299', 'H707310', 'H707357', 'H707354', 'H907599', 'H707451', 'H707168', 'H707209', 'H707138', 'H707326', 'H807013', 'H707358', 'H907364', 'H707372', 'H707210', 'H707434', 'H707335', 'H807130', 'H707370', 'H707174', 'H907211', 'H707196', 'H707369', 'H707158', 'H907169', 'H707441', 'H707610', 'H707136', 'H907122', 'H807572', 'H707116', 'H707609', 'H707214', 'H907190', 'H708176', 'H809879', 'H908120', 'H708263', 'H908260', 'H708236', 'H708529', 'H908136', 'H708193', 'H908496', 'H908502', 'H708248', 'H708189', 'H808249', 'H708217', 'H708305', 'H908230', 'H908161', 'H708227', 'H908237', 'H908240', 'H708264', 'H908239', 'H908158', 'H708159', 'H708195', 'H808519', 'H808516', 'H908132', 'H708301', 'H908148', 'H908155', 'H908111', 'H908164', 'H908498', 'H708130', 'H908201', 'H708154', 'H708202', 'H708206', 'H708258', 'H908138']\n",
      "站点筛选完成。\n",
      "\n",
      "--- 正在根据筛选结果过滤数据集 ---\n",
      "数据集过滤完成。\n",
      "  - 过滤后GNSS数据站点数: 1215\n",
      "  - 过滤后风场数据站点数: 1\n",
      "\n",
      "--- 开始调用数据准备函数 ---\n",
      "Pass 1: 正在扫描有效的连续序列 (稳健模式)...\n",
      "GNSS 时间 dtype: datetime64[ns], Wind 时间 dtype: datetime64[ns]\n",
      "Pass 1 完成. 共找到 17594 个有效样本。耗时: 20.57 秒。\n",
      "正在预分配内存...\n",
      "Pass 2: 正在填充数据...\n",
      "Pass 2 完成. 数据填充完毕。耗时: 12.49 秒。\n",
      "正在创建最终的 xarray.DataArray...\n",
      "所有处理完成！总耗时: 33.07 秒。\n",
      "\n",
      "--- 处理后结果 ---\n",
      "输入变量 vx:\n",
      "  - 形状: (17594, 6, 1215)\n",
      "  - 维度: ('sample', 'timesteps', 'station')\n",
      "  - 站点: ['H992830' 'H998276' 'H11705423' ... 'H708206' 'H708258' 'H908138']\n",
      "  - 内存占用: 513.04 MB\n",
      "\n",
      "目标变量 vy:\n",
      "  - 形状: (17594, 7)\n",
      "  - 维度: ('sample', 'station_press_flat')\n",
      "  - 站点: [58557]\n",
      "  - 内存占用: 0.49 MB\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    使用Haversine公式计算两个经纬度点之间的距离（单位：公里）。\n",
    "    \"\"\"\n",
    "    # 将十进制度数转化为弧度\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine公式\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371 # 地球平均半径，单位为公里\n",
    "    return c * r\n",
    "\n",
    "def prepare_transformer_inputs_mem_efficient_robust(gnss_ds: xr.Dataset, wind_ds: xr.Dataset):\n",
    "    \"\"\"\n",
    "    更稳健的版本，处理时间戳 dtype 不匹配的问题。\n",
    "    (此函数无需任何修改)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gnss_ztd = gnss_ds['ztd']\n",
    "    wind_u = wind_ds['W']\n",
    "    \n",
    "    sequence_length = 6\n",
    "    time_step = pd.to_timedelta('5min')\n",
    "    expected_duration = time_step * (sequence_length - 1)\n",
    "\n",
    "    num_gnss_times = len(gnss_ztd.time)\n",
    "    \n",
    "    # --- Pass 1: 扫描并找到所有有效样本的起始索引 ---\n",
    "    print(\"Pass 1: 正在扫描有效的连续序列 (稳健模式)...\")\n",
    "    \n",
    "    gnss_dtype = gnss_ztd.time.dtype\n",
    "    wind_dtype = wind_u.Datetime.dtype\n",
    "    print(f\"GNSS 时间 dtype: {gnss_dtype}, Wind 时间 dtype: {wind_dtype}\")\n",
    "    wind_dtype_unit = np.datetime_data(wind_dtype)[0]\n",
    "\n",
    "    valid_start_indices = []\n",
    "    wind_times_set = set(wind_u.Datetime.values)\n",
    "\n",
    "    for i in range(num_gnss_times - sequence_length + 1):\n",
    "        window_times = gnss_ztd.time[i : i + sequence_length]\n",
    "        \n",
    "        actual_duration = window_times[-1].values - window_times[0].values\n",
    "        if np.abs(actual_duration - expected_duration) < pd.to_timedelta('1s'):\n",
    "            \n",
    "            target_wind_time_raw = window_times[-1].values + 6*time_step\n",
    "            target_wind_time_converted = np.datetime64(target_wind_time_raw, wind_dtype_unit)\n",
    "\n",
    "            if target_wind_time_converted in wind_times_set:\n",
    "                valid_start_indices.append(i)\n",
    "    \n",
    "    num_samples = len(valid_start_indices)\n",
    "    print(f\"Pass 1 完成. 共找到 {num_samples} 个有效样本。耗时: {time.time() - start_time:.2f} 秒。\")\n",
    "\n",
    "    if num_samples == 0:\n",
    "        print(\"在稳健模式下仍然未找到任何有效序列。请检查数据本身，例如风场数据是否覆盖了GNSS数据的时间范围。\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 内存分配 (Pass 2) ---\n",
    "    print(\"正在预分配内存...\")\n",
    "    num_stations_gnss = len(gnss_ztd.station)\n",
    "    num_stations_wind = len(wind_u.station)\n",
    "    num_press_levels = len(wind_u.PRESS)\n",
    "    \n",
    "    vx_data = np.empty((num_samples, sequence_length, num_stations_gnss), dtype=np.float32)\n",
    "    vy_data = np.empty((num_samples, num_stations_wind * num_press_levels), dtype=np.float32)\n",
    "\n",
    "    print(\"Pass 2: 正在填充数据...\")\n",
    "    fill_start_time = time.time()\n",
    "    gnss_ztd_values = gnss_ztd.values\n",
    "    \n",
    "    for k, start_idx in enumerate(valid_start_indices):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        vx_data[k, :, :] = gnss_ztd_values[start_idx:end_idx, :]\n",
    "        \n",
    "        last_gnss_time = gnss_ztd.time[end_idx - 1]\n",
    "        target_wind_time = last_gnss_time.values + 6*time_step\n",
    "        \n",
    "        target_wind_time_converted = np.datetime64(target_wind_time, wind_dtype_unit)\n",
    "        vy_slice_values = wind_u.sel(Datetime=target_wind_time_converted).values\n",
    "        vy_data[k, :] = vy_slice_values.flatten()\n",
    "        \n",
    "    print(f\"Pass 2 完成. 数据填充完毕。耗时: {time.time() - fill_start_time:.2f} 秒。\")\n",
    "\n",
    "    print(\"正在创建最终的 xarray.DataArray...\")\n",
    "    sample_coords = gnss_ztd.time.values[valid_start_indices]\n",
    "    vx = xr.DataArray(\n",
    "        vx_data,\n",
    "        dims=('sample', 'timesteps', 'station'),\n",
    "        coords={'sample': sample_coords, 'timesteps': np.arange(sequence_length), 'station': gnss_ztd.station.values}\n",
    "    )\n",
    "\n",
    "    vy_flat_coords = wind_u.stack(station_press_flat=('station', 'PRESS')).coords['station_press_flat']\n",
    "    vy = xr.DataArray(\n",
    "        vy_data,\n",
    "        dims=('sample', 'station_press_flat'),\n",
    "        coords={'sample': sample_coords, 'station_press_flat': vy_flat_coords}\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"所有处理完成！总耗时: {total_time:.2f} 秒。\")\n",
    "    return vx, vy\n",
    "\n",
    "# --- 主程序 ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. 定义文件路径和目标站点信息\n",
    "    gnss_nc_path = r'E:/gnss_ztd_combined_robust_morestation.nc'\n",
    "    wind_nc_path = r'E:/merged_stations_6min_common_period_float32_no_nan_press.nc'\n",
    "    gnss_info_path = r'E:\\huawei_gnss_morestation\\zj_allid.csv'\n",
    "    \n",
    "    target_wind_station_id = 58557 \n",
    "    target_wind_station_lon = 120.0717\n",
    "    target_wind_station_lat = 29.3619\n",
    "    \n",
    "    num_nearest_stations = 1215 \n",
    "\n",
    "    # 2. 加载原始数据文件\n",
    "    print(\"正在加载原始数据文件...\")\n",
    "    gnss_file = xr.open_dataset(gnss_nc_path)\n",
    "    wind_file = xr.open_dataset(wind_nc_path)\n",
    "    gnss_info_df = pd.read_csv(gnss_info_path)\n",
    "    print(\"文件加载完毕。\")\n",
    "\n",
    "    # 3. 对原始数据进行预处理（插值、填充等）\n",
    "    print(\"正在对原始数据进行预处理...\")\n",
    "    wind_new_time = pd.date_range(wind_file.Datetime.values[0], wind_file.Datetime.values[-1], freq='5min')\n",
    "    wind_file = wind_file.interp(Datetime=wind_new_time)\n",
    "    gnss_file = gnss_file.interpolate_na(dim='time')\n",
    "    gnss_file = gnss_file.ffill(dim='time').bfill(dim='time')\n",
    "    print(\"预处理完成。\")\n",
    "\n",
    "    # 4. MODIFIED LOGIC: 寻找实际存在于数据中的最近10个GNSS站点\n",
    "    print(\"\\n--- 开始筛选站点 (新逻辑) ---\")\n",
    "    print(f\"目标风场站点: {target_wind_station_id}\")\n",
    "    print(f\"使用预设的目标站点经纬度: Lon={target_wind_station_lon}, Lat={target_wind_station_lat}\")\n",
    "\n",
    "    # 步骤 4.1: 获取gnss数据文件中实际存在的所有站点ID\n",
    "    available_gnss_in_nc = gnss_file.station.values\n",
    "    print(f\"在GNSS数据文件中找到 {len(available_gnss_in_nc)} 个可用站点。\")\n",
    "\n",
    "    # 步骤 4.2: 从CSV站点信息中，只保留那些实际存在于gnss数据文件中的站点\n",
    "    gnss_info_df['id'] = gnss_info_df['id'].astype(str)\n",
    "    # 使用.copy()避免SettingWithCopyWarning\n",
    "    valid_stations_info_df = gnss_info_df[gnss_info_df['id'].isin(available_gnss_in_nc)].copy()\n",
    "    if valid_stations_info_df.empty:\n",
    "        raise ValueError(\"CSV站点信息文件和GNSS数据文件之间没有共同的站点。\")\n",
    "    print(f\"在CSV和GNSS数据文件中共有 {len(valid_stations_info_df)} 个共同站点。\")\n",
    "\n",
    "\n",
    "    # 步骤 4.3: 在这个有效站点子集上计算到目标的距离\n",
    "    valid_stations_info_df['distance_km'] = valid_stations_info_df.apply(\n",
    "        lambda row: haversine(target_wind_station_lon, target_wind_station_lat, row['lon'], row['lat']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 步骤 4.4: 按距离排序并选出最近的N个\n",
    "    # 检查可用站点是否少于期望数量\n",
    "    if len(valid_stations_info_df) < num_nearest_stations:\n",
    "        print(f\"警告: 可用站点总数 ({len(valid_stations_info_df)}) 小于期望的数量 ({num_nearest_stations})。将使用所有可用的站点。\")\n",
    "        num_to_select = len(valid_stations_info_df)\n",
    "    else:\n",
    "        num_to_select = num_nearest_stations\n",
    "\n",
    "    nearest_stations_df = valid_stations_info_df.sort_values(by='distance_km').head(num_to_select)\n",
    "    final_gnss_selection = nearest_stations_df['id'].tolist()\n",
    "    \n",
    "    print(f\"找到的最近 {len(final_gnss_selection)} 个GNSS站点: {final_gnss_selection}\")\n",
    "    print(\"站点筛选完成。\")\n",
    "\n",
    "\n",
    "    # 5. 根据筛选出的站点ID来过滤xarray数据集\n",
    "    print(\"\\n--- 正在根据筛选结果过滤数据集 ---\")\n",
    "    \n",
    "    # 确保目标站点存在于wind_file中\n",
    "    if target_wind_station_id not in wind_file.station.values:\n",
    "        raise ValueError(f\"目标站点 {target_wind_station_id} 在风场数据中未找到!\")\n",
    "\n",
    "    gnss_file_filtered = gnss_file.sel(station=final_gnss_selection)\n",
    "    wind_file_filtered = wind_file.sel(station=[target_wind_station_id])\n",
    "\n",
    "    print(\"数据集过滤完成。\")\n",
    "    print(f\"  - 过滤后GNSS数据站点数: {len(gnss_file_filtered.station)}\")\n",
    "    print(f\"  - 过滤后风场数据站点数: {len(wind_file_filtered.station)}\")\n",
    "\n",
    "    # 6. 调用核心处理函数\n",
    "    print(\"\\n--- 开始调用数据准备函数 ---\")\n",
    "    vx, vy = prepare_transformer_inputs_mem_efficient_robust(gnss_file_filtered, wind_file_filtered)\n",
    "\n",
    "    # 7. 打印最终结果\n",
    "    if vx is not None and vy is not None:\n",
    "        print(\"\\n--- 处理后结果 ---\")\n",
    "        print(\"输入变量 vx:\")\n",
    "        print(f\"  - 形状: {vx.shape}\")\n",
    "        print(f\"  - 维度: {vx.dims}\")\n",
    "        print(f\"  - 站点: {vx.station.values}\")\n",
    "        print(f\"  - 内存占用: {vx.nbytes / 1e6:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n目标变量 vy:\")\n",
    "        print(f\"  - 形状: {vy.shape}\")\n",
    "        print(f\"  - 维度: {vy.dims}\")\n",
    "        vy_station = vy.station_press_flat.to_index().get_level_values('station').unique().to_list()\n",
    "        print(f\"  - 站点: {vy_station}\")\n",
    "        print(f\"  - 内存占用: {vy.nbytes / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28420690-6159-40b4-97b6-977a409e4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer网络\n",
    "def Auto_Transformer(vy,vx,timestep,model_list,test_size=0.2,valid_size=0.1,k_fold=None,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=2,key_dim=2,ifdropout='no',trans_dropout_rate=0.0,trans_units=64,trans_activation='sigmoid',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='SGD',metrics='default',if_early_stopping=None,learning_rate=0.01,epochs=2000,batch_size=20,ifrandom_split='yes',ifweight='yes',ifmute='no',ifsave='no',savepath=None,device='cpu'):\n",
    "    import tensorflow as tf\n",
    "    if device=='gpu':\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                # 设置只使用 GPU 0\n",
    "                tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "                # 设置 GPU 0 的内存动态增长\n",
    "                tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    from keras.models import Sequential,Model\n",
    "    from keras.layers.core import Activation,Dropout,Dense\n",
    "    from keras.layers import Input,BatchNormalization,LayerNormalization,Embedding,Add,MultiHeadAttention,Flatten\n",
    "    from keras.initializers import TruncatedNormal,RandomNormal,RandomUniform\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import KFold\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.optimizers import SGD,Adam\n",
    "    import keras\n",
    "    from scipy.stats import pearsonr\n",
    "    import os\n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "    from keras.models import load_model\n",
    "    import sklearn\n",
    "    import copy\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from tensorflow.keras import backend as K\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    if embedding_num==None:\n",
    "        embedding_num=timestep+1\n",
    "    if task_mode=='regression':\n",
    "        if loss_function=='default' or loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanAbsoluteError':\n",
    "            loss=tf.keras.losses.MeanAbsoluteError()\n",
    "        elif loss_function=='MeanAbsolutePercentageError':\n",
    "            loss=tf.keras.losses.MeanAbsolutePercentageError()\n",
    "        elif loss_function=='MeanSquaredLogarithmicError':\n",
    "            loss=tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "        elif loss_function=='CosineSimilarity':\n",
    "            loss=tf.keras.losses.CosineSimilarity()\n",
    "        elif loss_function=='Huber':\n",
    "            loss=tf.keras.losses.Huber()\n",
    "        elif loss_function=='LogCosh':\n",
    "            loss=tf.keras.losses.LogCosh()\n",
    "        elif loss_function=='Pearsonr':\n",
    "            def loss_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            loss=loss_pearsonr\n",
    "        if metrics=='default' or metrics=='MeanSquaredError':\n",
    "            metric=tf.keras.metrics.MeanSquaredError()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='MeanAbsolutePercentageError':\n",
    "            metric=tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "        elif metrics=='MeanSquaredLogarithmicError':\n",
    "            metric=tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        elif metrics=='CosineSimilarity':\n",
    "            metric=tf.keras.metrics.CosineSimilarity()\n",
    "        elif metrics=='LogCoshError':\n",
    "            metric=tf.keras.metrics.LogCoshError()\n",
    "        elif metrics=='Pearsonr':\n",
    "            def metrics_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            metric=metrics_pearsonr\n",
    "    elif task_mode=='binary_classify':\n",
    "        if loss_function=='default' or loss_function=='BinaryCrossentropy':\n",
    "            loss=tf.keras.losses.BinaryCrossentropy()\n",
    "        elif loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        elif loss_function=='f1':\n",
    "            def loss_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return 1 - f1\n",
    "            loss=loss_f1\n",
    "        if metrics=='default' or metrics=='BinaryAccuracy':\n",
    "            metric=tf.keras.metrics.BinaryAccuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='BinaryCrossentropy':\n",
    "            metric=tf.keras.metrics.BinaryCrossentropy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "        elif metrics=='AUC':\n",
    "            metric=tf.keras.metrics.AUC()\n",
    "        elif metrics=='Precision':\n",
    "            metric=tf.keras.metrics.Precision()\n",
    "        elif metrics=='Recall':\n",
    "            metric=tf.keras.metrics.Recall()\n",
    "        elif metrics=='TruePositives':\n",
    "            metric=tf.keras.metrics.TruePositives()\n",
    "        elif metrics=='TrueNegatives':\n",
    "            metric=tf.keras.metrics.TrueNegatives()\n",
    "        elif metrics=='FalsePositives':\n",
    "            metric=tf.keras.metrics.FalsePositives()\n",
    "        elif metrics=='FalseNegatives':\n",
    "            metric=tf.keras.metrics.FalseNegatives()\n",
    "        elif metrics=='PrecisionAtRecall':\n",
    "            metric=tf.keras.metrics.PrecisionAtRecall()\n",
    "        elif metrics=='SensitivityAtSpecificity':\n",
    "            metric=tf.keras.metrics.SensitivityAtSpecificity()\n",
    "        elif metrics=='SpecificityAtSensitivity':\n",
    "            metric=tf.keras.metrics.SpecificityAtSensitivity()\n",
    "        elif metrics=='f1':\n",
    "            def metric_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return f1\n",
    "            metric=metric_f1\n",
    "    elif task_mode=='multi_classify':\n",
    "        if loss_function=='default' or loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        if metrics=='default' or metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "    weights=0\n",
    "    model=0\n",
    "    if vy.ndim==1:\n",
    "        vy=vy.reshape(vy.shape[0],1)\n",
    "    if ifrandom_split=='yes':\n",
    "        trainy,testy,trainx,testx = train_test_split(vy,vx,test_size=test_size,random_state=25)\n",
    "    else:\n",
    "        index=int((1-test_size)*vy.shape[0])\n",
    "        trainy=vy[:index]\n",
    "        testy=vy[index:]\n",
    "        trainx=vx[:index,:,:]\n",
    "        testx=vx[index:,:,:]\n",
    "    train_position=np.zeros((trainx.shape[0],trainx.shape[1]))\n",
    "    test_position=np.zeros((testx.shape[0],testx.shape[1]))\n",
    "    for i in range(trainx.shape[0]):\n",
    "        train_position[i,:]=np.arange(0,timestep,1)\n",
    "    for i in range(testx.shape[0]):\n",
    "        test_position[i,:]=np.arange(0,timestep,1)\n",
    "    if task_mode!='regression':\n",
    "        def create_sample_weights_for_batch_multitask(y_batch_multitask, list_of_task_weights_dicts):\n",
    "            batch_size, num_tasks = y_batch_multitask.shape\n",
    "            \n",
    "            if len(list_of_task_weights_dicts) != num_tasks:\n",
    "                raise ValueError(f\"Number of tasks in y_batch_multitask ({num_tasks}) \"\n",
    "                                 f\"must match length of list_of_task_weights_dicts ({len(list_of_task_weights_dicts)}).\")\n",
    "        \n",
    "            sample_weight_batch = np.ones_like(y_batch_multitask, dtype=np.float32)\n",
    "        \n",
    "            for i in range(num_tasks):\n",
    "                task_labels_current_channel = y_batch_multitask[:, i] \n",
    "                weights_dict_for_task_i = list_of_task_weights_dicts[i]\n",
    "                \n",
    "                weight_for_0 = weights_dict_for_task_i.get(0, 1.0)\n",
    "                weight_for_1 = weights_dict_for_task_i.get(1, 1.0)\n",
    "                \n",
    "                current_task_weights = sample_weight_batch[:, i] \n",
    "                current_task_weights[task_labels_current_channel == 0] = weight_for_0\n",
    "                current_task_weights[task_labels_current_channel == 1] = weight_for_1\n",
    "                sample_weight_batch[:, i] = current_task_weights\n",
    "                \n",
    "            return sample_weight_batch\n",
    "        def compute_unified_class_weights(y, task_mode=task_mode):\n",
    "            if task_mode == 'binary_classify':\n",
    "                if y.ndim == 2 and y.shape[-1] > 1:\n",
    "                    num_tasks = y.shape[-1]\n",
    "                    list_of_task_weights_dicts = []\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    for i in range(num_tasks):\n",
    "                        y_task_i_flat = y[:, i].ravel()\n",
    "                        if len(y_task_i_flat) == 0:\n",
    "                            weights_dict_task_i = {0: 1.0, 1: 1.0} \n",
    "                        else:\n",
    "                            valid_labels_mask = np.isin(y_task_i_flat, possible_binary_classes)\n",
    "                            if not np.all(valid_labels_mask) and np.any(valid_labels_mask): \n",
    "                                y_task_i_flat_filtered = y_task_i_flat[valid_labels_mask]\n",
    "                                if len(y_task_i_flat_filtered) == 0 : y_task_i_flat_filtered = np.array([0]) \n",
    "                            elif not np.any(valid_labels_mask): \n",
    "                                 y_task_i_flat_filtered = np.array([0]) \n",
    "                            else:\n",
    "                                y_task_i_flat_filtered = y_task_i_flat\n",
    "                            class_weights_arr = compute_class_weight(\n",
    "                                class_weight='balanced',\n",
    "                                classes=possible_binary_classes, \n",
    "                                y=y_task_i_flat_filtered\n",
    "                            )\n",
    "                            weights_dict_task_i = dict(zip(possible_binary_classes, class_weights_arr))\n",
    "                        list_of_task_weights_dicts.append(weights_dict_task_i)\n",
    "                    return list_of_task_weights_dicts \n",
    "        \n",
    "                else: \n",
    "                    y_flat = y.ravel()\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    valid_labels_mask = np.isin(y_flat, possible_binary_classes)\n",
    "                    if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                        y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                        if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0])\n",
    "                    elif not np.any(valid_labels_mask):\n",
    "                         y_flat_filtered = np.array([0])\n",
    "                    else:\n",
    "                        y_flat_filtered = y_flat\n",
    "        \n",
    "                    class_weights_arr = compute_class_weight(\n",
    "                        class_weight='balanced',\n",
    "                        classes=possible_binary_classes,\n",
    "                        y=y_flat_filtered\n",
    "                    )\n",
    "                    return dict(zip(possible_binary_classes, class_weights_arr)) \n",
    "        \n",
    "            elif task_mode == 'multi_classify':\n",
    "                y_flat = y.ravel()\n",
    "                possible_multiclass_classes = np.arange(int(np.max(y)+1))\n",
    "                valid_labels_mask = np.isin(y_flat, possible_multiclass_classes)\n",
    "                if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                    if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0]) \n",
    "                elif not np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = np.array([0]) \n",
    "                else:\n",
    "                    y_flat_filtered = y_flat\n",
    "                class_weights_arr = compute_class_weight(\n",
    "                    class_weight='balanced',\n",
    "                    classes=possible_multiclass_classes,\n",
    "                    y=y_flat_filtered\n",
    "                )\n",
    "                return dict(zip(possible_multiclass_classes, class_weights_arr)) \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported task_mode: {task_mode}\")\n",
    "        def create_unified_sample_weights_for_batch(y_batch, unified_class_weights):\n",
    "            if isinstance(unified_class_weights, list):\n",
    "                if not (y_batch.ndim == 2 and y_batch.shape[-1] == len(unified_class_weights)):\n",
    "                     raise ValueError(f\"Shape mismatch for multi-task binary weights. \"\n",
    "                                      f\"y_batch shape: {y_batch.shape}, num_weight_dicts: {len(unified_class_weights)}\")\n",
    "                return create_sample_weights_for_batch_multitask(y_batch, unified_class_weights)\n",
    "            elif isinstance(unified_class_weights, dict):\n",
    "                y_int_labels_for_weights = y_batch\n",
    "                if y_batch.ndim == 2 and y_batch.shape[-1] == 1: \n",
    "                    y_int_labels_for_weights = np.squeeze(y_batch, axis=-1)\n",
    "                sample_weight_for_batch = np.ones_like(y_int_labels_for_weights, dtype=np.float32)\n",
    "                for class_label, weight in unified_class_weights.items():\n",
    "                    sample_weight_for_batch[y_int_labels_for_weights == class_label] = weight\n",
    "                \n",
    "                return sample_weight_for_batch\n",
    "            else:\n",
    "                raise TypeError(f\"unified_class_weights has unexpected type: {type(unified_class_weights)}. Expected dict or list.\")\n",
    "        def train_data_generator(x,position, y, batch_size, task_mode=task_mode):\n",
    "            num_samples = x.shape[0]\n",
    "            global_unified_weights = compute_unified_class_weights(y, task_mode)\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    if len(batch_indices) == 0:\n",
    "                        continue\n",
    "        \n",
    "                    x_batch = x[batch_indices]\n",
    "                    position_batch = position[batch_indices]\n",
    "                    y_batch = y[batch_indices] \n",
    "                    sample_weight_batch = create_unified_sample_weights_for_batch(\n",
    "                        y_batch, \n",
    "                        global_unified_weights\n",
    "                    )\n",
    "                    yield {\"input_1\": x_batch, \"input_2\": position_batch}, y_batch, sample_weight_batch\n",
    "    else:\n",
    "        def train_data_generator(x, position, y, batch_size):\n",
    "            num_samples = x.shape[0]\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    x_batch = x[batch_indices]  \n",
    "                    position_batch = position[batch_indices]   \n",
    "                    y_batch = y[batch_indices]      \n",
    "                    \n",
    "                    yield ({\"input_1\": x_batch, \"input_2\": position_batch}, y_batch)\n",
    "    def test_data_generator(x, position, batch_size):\n",
    "        num_samples = x.shape[0]\n",
    "        while True:\n",
    "            indices = np.arange(num_samples)\n",
    "            \n",
    "            for start in range(0, num_samples, batch_size):\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                x_batch = x[batch_indices]  # 第一个输入特征\n",
    "                position_batch = position[batch_indices]\n",
    "                \n",
    "                yield ({\"input_1\": x_batch, \"input_2\": position_batch})\n",
    "    if if_best_mode=='no':\n",
    "        inputshape1=(None,timestep,trainx.shape[2])\n",
    "        inputshape2=(None,timestep)\n",
    "        inputs1=Input(shape=(timestep,trainx.shape[2]))\n",
    "        inputs2=Input(shape=(timestep))\n",
    "        for i in range(len(model_list)):\n",
    "            if model_list[i][0] == 'transformer':\n",
    "                position_embedding=Embedding(embedding_num,trainx.shape[2],input_length=timestep,input_shape=inputshape2)(inputs2)\n",
    "                add=Add(input_shape=inputshape1)([inputs1,position_embedding])\n",
    "                for j in range(encoder_deep):\n",
    "                    if j ==0:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(add,add,add)')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([add,en_multihead'+str(j+1)+'])')\n",
    "                    else:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(en_layernormalization'+str(j)+',en_layernormalization'+str(j)+',en_layernormalization'+str(j)+')')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([en_layernormalization'+str(j)+',en_multihead'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                    if ifdropout=='yes':\n",
    "                        exec('en_dropout'+str(j+1)+'=Dropout(trans_dropout_rate)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_dropout'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    else:\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    exec('en_add'+str(j+1)+'=Add()([en_fc'+str(j+1)+',en_layernormalization'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                exec('en_fla=Flatten()(en_layernormalization'+str(j+1)+')')\n",
    "            elif model_list[i][0] == 'batchnormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'layernormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'activation':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'flatten':\n",
    "                if model_list[i-1][0]=='transformer':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(en_fla)')\n",
    "                elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(norm'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='activation':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(act'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='dropout':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(drop'+str(i)+')')\n",
    "            elif model_list[i][0] =='fc':\n",
    "                if if_weight_initialize=='no':\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            outputs=eval('Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            outputs=eval('Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            outputs=eval('Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            outputs=eval('Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'dropout':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "        if optimizer == 'SGD':\n",
    "            opt = SGD(lr = learning_rate)\n",
    "        elif optimizer == 'Adam':\n",
    "            opt = Adam(lr = learning_rate)\n",
    "        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "    elif if_best_mode=='yes' or if_best_mode=='load':\n",
    "        if k_fold!=None:\n",
    "            models=[]\n",
    "            for i in range(k_fold):\n",
    "                models.append(load_model(modelpath+'_'+str(i+1)))\n",
    "        else:\n",
    "            model=load_model(modelpath)\n",
    "    if if_print_model=='yes':\n",
    "        if k_fold!=None:\n",
    "            if if_best_mode=='yes' or if_best_mode=='load':\n",
    "                print(models[0].summary())\n",
    "            else:\n",
    "                print(model.summary())\n",
    "        else:\n",
    "            print(model.summary())\n",
    "    if epochs!=0:\n",
    "        if valid_size!=None or k_fold !=None:\n",
    "            if k_fold!=None:\n",
    "                if if_best_mode=='no' :\n",
    "                    models = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "                        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models.append(model)\n",
    "                else:\n",
    "                    models_new = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models_new.append(models[fold_no])\n",
    "                    models=models_new\n",
    "            else:\n",
    "                if ifrandom_split=='yes':\n",
    "                    trainy,validy,trainx,validx,train_position,valid_position = train_test_split(trainy,trainx,train_position,test_size=valid_size/(1-test_size),random_state=25)\n",
    "                else:\n",
    "                    index=int((1-valid_size/(1-test_size))*trainy.shape[0])\n",
    "                    validy=trainy[index:]\n",
    "                    trainy=trainy[:index]\n",
    "                    validx=trainx[index:]\n",
    "                    trainx=trainx[:index]\n",
    "                    valid_position=train_position[index:]\n",
    "                    train_position=train_position[:index]\n",
    "                if if_early_stopping!=None:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                else:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "        else:\n",
    "            if if_early_stopping!=None:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "            else:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "    if k_fold!=None:\n",
    "        predicty = [model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0))) for model in models]\n",
    "        predicty=np.nanmean(predicty,axis=0)\n",
    "    else:\n",
    "        predicty = model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)))\n",
    "    predicty = np.nan_to_num(predicty,nan=0)\n",
    "    if task_mode=='regression':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        p=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i],p[i] = pearsonr(predicty[:,i],testy[:,i])\n",
    "            r=np.nan_to_num(r,nan=0)\n",
    "    elif task_mode=='binary_classify':\n",
    "        accuracy=np.zeros((testy.shape[1]))\n",
    "        recall=np.zeros((testy.shape[1]))\n",
    "        precision=np.zeros((testy.shape[1]))\n",
    "        f1=np.zeros((testy.shape[1]))\n",
    "        for i in range(predicty.shape[1]):\n",
    "            predicty[:,i]=[int(round(predicty[j,i],0)) for j in range(predicty.shape[0])]\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            if metrics=='Recall':\n",
    "                r[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            elif metrics=='Precision':\n",
    "                r[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            else:\n",
    "                r[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            recall[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            precision[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            accuracy[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            f1[i]=f1_score(testy[:,i], predicty[:,i])\n",
    "        p=0\n",
    "    elif task_mode=='multi_classify':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i]=accuracy_score(testy[:,i], np.argmax(predicty,axis=1))\n",
    "        p=0\n",
    "    if ifmute == 'no':\n",
    "        if task_mode=='regression':\n",
    "            print('相关系数',np.nanmean(r))\n",
    "        elif task_mode=='binary_classify':\n",
    "            print('召回率+精确率',np.nanmean(f1),'准确率',np.nanmean(accuracy),'召回率',np.nanmean(recall),'精确率',np.nanmean(precision))\n",
    "        elif task_mode=='multi_classify':\n",
    "            print('准确率',np.nanmean(r))\n",
    "    if ifweight=='yes':\n",
    "        weights=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        weight_more=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                testx_new=copy.deepcopy(testx)\n",
    "                weight=[]\n",
    "                for k in range(10):\n",
    "                    per=np.random.permutation(testx.shape[0])\n",
    "                    testx_shuffle=testx[per,:,j]\n",
    "                    testx_new[:,:,j]=testx_shuffle\n",
    "                    if k_fold!=None:\n",
    "                        predicty_new = [model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0))) for model in models]\n",
    "                        predicty_new=np.nanmean(predicty_new,axis=0)\n",
    "                    else:\n",
    "                        predicty_new = model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0)))\n",
    "                    if task_mode=='regression':\n",
    "                        weight.append(sklearn.metrics.mean_squared_error(testy[:,i],predicty_new[:,i])-sklearn.metrics.mean_squared_error(testy[:,i],predicty[:,i]))\n",
    "                    elif task_mode=='multi_classify':\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,:])-sklearn.metrics.log_loss(testy[:,i],predicty[:,:]))\n",
    "                    else:\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,i])-sklearn.metrics.log_loss(testy[:,i],predicty[:,i]))\n",
    "                weight_more[i,j]=np.nanmean(weight)\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                weights[i,j]=(weight_more[i,j]/np.nansum(weight_more[i,:]))*100\n",
    "                print('预报因子',j+1,'对预报值',i+1,'的贡献：',np.array(weights[i,j]),'％')\n",
    "            print('\\n')\n",
    "    if ifsave=='yes':\n",
    "        if k_fold!=None:\n",
    "            for i, model in enumerate(models):\n",
    "                model.save(savepath+'_'+str(i+1))\n",
    "        else:\n",
    "            model.save(savepath)\n",
    "    if k_fold!=None:\n",
    "        return models,predicty,testy,r,p,weights\n",
    "    else:\n",
    "        return model,predicty,testy,r,p,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5694aac2-581f-4745-8d73-80163b988f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0114 - metrics_pearsonr: 2.2148e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8830e-04\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0114 - metrics_pearsonr: 2.2141e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8841e-04\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0114 - metrics_pearsonr: 2.2125e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8835e-04\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0114 - metrics_pearsonr: 2.2115e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8848e-04\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0114 - metrics_pearsonr: 2.2104e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8844e-04\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0114 - metrics_pearsonr: 2.2097e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8857e-04\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0114 - metrics_pearsonr: 2.2085e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8854e-04\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0114 - metrics_pearsonr: 2.2078e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8878e-04\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0114 - metrics_pearsonr: 2.2066e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8880e-04\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0114 - metrics_pearsonr: 2.2057e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8905e-04\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0114 - metrics_pearsonr: 2.2044e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.8916e-04\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0114 - metrics_pearsonr: 2.2036e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.8949e-04\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0114 - metrics_pearsonr: 2.2024e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.8959e-04\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0114 - metrics_pearsonr: 2.2013e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.8982e-04\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0114 - metrics_pearsonr: 2.1999e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.8985e-04\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0114 - metrics_pearsonr: 2.1990e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9007e-04\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0114 - metrics_pearsonr: 2.1978e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.8998e-04\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0114 - metrics_pearsonr: 2.1969e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9008e-04\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0113 - metrics_pearsonr: 2.1957e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.8994e-04\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0113 - metrics_pearsonr: 2.1950e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.9013e-04\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0113 - metrics_pearsonr: 2.1940e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.9005e-04\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0113 - metrics_pearsonr: 2.1935e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9019e-04\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0113 - metrics_pearsonr: 2.1924e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9013e-04\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0113 - metrics_pearsonr: 2.1918e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9039e-04\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0113 - metrics_pearsonr: 2.1908e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9048e-04\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0113 - metrics_pearsonr: 2.1902e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9076e-04\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0114 - metrics_pearsonr: 2.1890e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9093e-04\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0114 - metrics_pearsonr: 2.1882e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9146e-04\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0115 - metrics_pearsonr: 2.1870e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.9175e-04\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0115 - metrics_pearsonr: 2.1862e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.9226e-04\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0116 - metrics_pearsonr: 2.1852e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.9251e-04\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0115 - metrics_pearsonr: 2.1842e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.9276e-04\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0115 - metrics_pearsonr: 2.1834e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.9275e-04\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0115 - metrics_pearsonr: 2.1827e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9270e-04\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0114 - metrics_pearsonr: 2.1818e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9242e-04\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0114 - metrics_pearsonr: 2.1819e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.9257e-04\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0115 - metrics_pearsonr: 2.1823e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9254e-04\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0116 - metrics_pearsonr: 2.1835e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.9306e-04\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0117 - metrics_pearsonr: 2.1842e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9320e-04\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0119 - metrics_pearsonr: 2.1852e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 4.9374e-04\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0119 - metrics_pearsonr: 2.1857e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 4.9392e-04\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0119 - metrics_pearsonr: 2.1872e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9410e-04\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0118 - metrics_pearsonr: 2.1881e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.9391e-04\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0117 - metrics_pearsonr: 2.1903e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9397e-04\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0119 - metrics_pearsonr: 2.1924e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9426e-04\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0122 - metrics_pearsonr: 2.1963e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.9566e-04\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0129 - metrics_pearsonr: 2.2004e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 4.9799e-04\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0138 - metrics_pearsonr: 2.2050e-04 - val_loss: 0.0216 - val_metrics_pearsonr: 5.0142e-04\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0148 - metrics_pearsonr: 2.2098e-04 - val_loss: 0.0240 - val_metrics_pearsonr: 5.0544e-04\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0156 - metrics_pearsonr: 2.2174e-04 - val_loss: 0.0260 - val_metrics_pearsonr: 5.0972e-04\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0161 - metrics_pearsonr: 2.2277e-04 - val_loss: 0.0266 - val_metrics_pearsonr: 5.1259e-04\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0158 - metrics_pearsonr: 2.2391e-04 - val_loss: 0.0250 - val_metrics_pearsonr: 5.1385e-04\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0152 - metrics_pearsonr: 2.2499e-04 - val_loss: 0.0216 - val_metrics_pearsonr: 5.1182e-04\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0146 - metrics_pearsonr: 2.2575e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0995e-04\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0150 - metrics_pearsonr: 2.2775e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.1043e-04\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0172 - metrics_pearsonr: 2.3123e-04 - val_loss: 0.0240 - val_metrics_pearsonr: 5.1656e-04\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0205 - metrics_pearsonr: 2.3407e-04 - val_loss: 0.0326 - val_metrics_pearsonr: 5.2574e-04\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0233 - metrics_pearsonr: 2.3549e-04 - val_loss: 0.0391 - val_metrics_pearsonr: 5.3406e-04\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0240 - metrics_pearsonr: 2.3757e-04 - val_loss: 0.0365 - val_metrics_pearsonr: 5.3870e-04\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0222 - metrics_pearsonr: 2.4123e-04 - val_loss: 0.0252 - val_metrics_pearsonr: 5.3411e-04\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0200 - metrics_pearsonr: 2.4493e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.3035e-04\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0207 - metrics_pearsonr: 2.4791e-04 - val_loss: 0.0276 - val_metrics_pearsonr: 5.4214e-04\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0238 - metrics_pearsonr: 2.4510e-04 - val_loss: 0.0401 - val_metrics_pearsonr: 5.5308e-04\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0254 - metrics_pearsonr: 2.4636e-04 - val_loss: 0.0362 - val_metrics_pearsonr: 5.4993e-04\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0225 - metrics_pearsonr: 2.4713e-04 - val_loss: 0.0214 - val_metrics_pearsonr: 5.3186e-04\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0185 - metrics_pearsonr: 2.4121e-04 - val_loss: 0.0206 - val_metrics_pearsonr: 5.2303e-04\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0183 - metrics_pearsonr: 2.3794e-04 - val_loss: 0.0279 - val_metrics_pearsonr: 5.2678e-04\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0182 - metrics_pearsonr: 2.3491e-04 - val_loss: 0.0245 - val_metrics_pearsonr: 5.2661e-04\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0159 - metrics_pearsonr: 2.3450e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1318e-04\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0144 - metrics_pearsonr: 2.3149e-04 - val_loss: 0.0208 - val_metrics_pearsonr: 5.1070e-04\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0145 - metrics_pearsonr: 2.2866e-04 - val_loss: 0.0227 - val_metrics_pearsonr: 5.1208e-04\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0140 - metrics_pearsonr: 2.2673e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.2370e-04\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0130 - metrics_pearsonr: 2.2778e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.1572e-04\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0127 - metrics_pearsonr: 2.2471e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.0553e-04\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0127 - metrics_pearsonr: 2.2148e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.0613e-04\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0122 - metrics_pearsonr: 2.2242e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0467e-04\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0121 - metrics_pearsonr: 2.2373e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0614e-04\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0122 - metrics_pearsonr: 2.2152e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.0486e-04\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0120 - metrics_pearsonr: 2.1924e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0159e-04\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0117 - metrics_pearsonr: 2.1799e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0033e-04\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0116 - metrics_pearsonr: 2.1780e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0025e-04\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0116 - metrics_pearsonr: 2.1726e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.9916e-04\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0115 - metrics_pearsonr: 2.1628e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9689e-04\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0114 - metrics_pearsonr: 2.1597e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.9696e-04\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0114 - metrics_pearsonr: 2.1608e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.9815e-04\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0114 - metrics_pearsonr: 2.1572e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0050e-04\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0113 - metrics_pearsonr: 2.1533e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9950e-04\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0113 - metrics_pearsonr: 2.1480e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9803e-04\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0112 - metrics_pearsonr: 2.1444e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9753e-04\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0112 - metrics_pearsonr: 2.1448e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9755e-04\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0112 - metrics_pearsonr: 2.1460e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9789e-04\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0112 - metrics_pearsonr: 2.1439e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9819e-04\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0112 - metrics_pearsonr: 2.1383e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.9796e-04\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0112 - metrics_pearsonr: 2.1341e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9810e-04\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0112 - metrics_pearsonr: 2.1330e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9824e-04\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0111 - metrics_pearsonr: 2.1328e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9823e-04\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0111 - metrics_pearsonr: 2.1314e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9792e-04\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0111 - metrics_pearsonr: 2.1294e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9765e-04\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0111 - metrics_pearsonr: 2.1283e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9771e-04\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0111 - metrics_pearsonr: 2.1269e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9801e-04\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0111 - metrics_pearsonr: 2.1246e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9835e-04\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0111 - metrics_pearsonr: 2.1221e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9840e-04\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0111 - metrics_pearsonr: 2.1203e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9847e-04\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0111 - metrics_pearsonr: 2.1195e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9857e-04\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0111 - metrics_pearsonr: 2.1191e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9859e-04\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0111 - metrics_pearsonr: 2.1182e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9847e-04\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0111 - metrics_pearsonr: 2.1170e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.9834e-04\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0111 - metrics_pearsonr: 2.1159e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9835e-04\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0111 - metrics_pearsonr: 2.1145e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9848e-04\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0111 - metrics_pearsonr: 2.1134e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9881e-04\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0111 - metrics_pearsonr: 2.1124e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9907e-04\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0111 - metrics_pearsonr: 2.1114e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9930e-04\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0111 - metrics_pearsonr: 2.1104e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9929e-04\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0110 - metrics_pearsonr: 2.1094e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9935e-04\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0110 - metrics_pearsonr: 2.1084e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9923e-04\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0110 - metrics_pearsonr: 2.1076e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9927e-04\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0110 - metrics_pearsonr: 2.1065e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9917e-04\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0110 - metrics_pearsonr: 2.1056e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9935e-04\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0110 - metrics_pearsonr: 2.1045e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9944e-04\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0110 - metrics_pearsonr: 2.1038e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9973e-04\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0110 - metrics_pearsonr: 2.1028e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.9986e-04\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0110 - metrics_pearsonr: 2.1018e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0008e-04\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0110 - metrics_pearsonr: 2.1006e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0010e-04\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0110 - metrics_pearsonr: 2.0996e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0021e-04\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0110 - metrics_pearsonr: 2.0985e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0014e-04\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0110 - metrics_pearsonr: 2.0976e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0020e-04\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0110 - metrics_pearsonr: 2.0965e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0015e-04\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0110 - metrics_pearsonr: 2.0958e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0026e-04\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0110 - metrics_pearsonr: 2.0948e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0024e-04\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0110 - metrics_pearsonr: 2.0941e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0040e-04\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0110 - metrics_pearsonr: 2.0930e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0044e-04\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0110 - metrics_pearsonr: 2.0922e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0071e-04\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0110 - metrics_pearsonr: 2.0910e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0081e-04\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0110 - metrics_pearsonr: 2.0902e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0107e-04\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0110 - metrics_pearsonr: 2.0890e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0111e-04\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0110 - metrics_pearsonr: 2.0881e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0127e-04\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0110 - metrics_pearsonr: 2.0869e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0121e-04\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0110 - metrics_pearsonr: 2.0862e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0130e-04\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0110 - metrics_pearsonr: 2.0851e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0121e-04\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0109 - metrics_pearsonr: 2.0844e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0130e-04\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0109 - metrics_pearsonr: 2.0834e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 5.0121e-04\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0109 - metrics_pearsonr: 2.0828e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0139e-04\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0109 - metrics_pearsonr: 2.0818e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0135e-04\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0109 - metrics_pearsonr: 2.0812e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0160e-04\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0109 - metrics_pearsonr: 2.0800e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0165e-04\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0110 - metrics_pearsonr: 2.0792e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0201e-04\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0110 - metrics_pearsonr: 2.0781e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0213e-04\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0110 - metrics_pearsonr: 2.0772e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0246e-04\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0110 - metrics_pearsonr: 2.0760e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0249e-04\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0110 - metrics_pearsonr: 2.0751e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0272e-04\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0110 - metrics_pearsonr: 2.0740e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0261e-04\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0109 - metrics_pearsonr: 2.0733e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0272e-04\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0109 - metrics_pearsonr: 2.0723e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0253e-04\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0109 - metrics_pearsonr: 2.0718e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0264e-04\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0109 - metrics_pearsonr: 2.0709e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0248e-04\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0109 - metrics_pearsonr: 2.0706e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0264e-04\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0109 - metrics_pearsonr: 2.0697e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0249e-04\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0109 - metrics_pearsonr: 2.0693e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0271e-04\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0109 - metrics_pearsonr: 2.0684e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0265e-04\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0109 - metrics_pearsonr: 2.0680e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 5.0299e-04\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0110 - metrics_pearsonr: 2.0670e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0316e-04\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0110 - metrics_pearsonr: 2.0664e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0375e-04\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0111 - metrics_pearsonr: 2.0656e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.0420e-04\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0112 - metrics_pearsonr: 2.0648e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0484e-04\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0112 - metrics_pearsonr: 2.0639e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0517e-04\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0112 - metrics_pearsonr: 2.0634e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0559e-04\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0112 - metrics_pearsonr: 2.0627e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0548e-04\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0111 - metrics_pearsonr: 2.0624e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.0556e-04\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0111 - metrics_pearsonr: 2.0623e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0511e-04\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0111 - metrics_pearsonr: 2.0626e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0525e-04\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0112 - metrics_pearsonr: 2.0635e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0510e-04\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0113 - metrics_pearsonr: 2.0651e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0559e-04\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0116 - metrics_pearsonr: 2.0665e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.0594e-04\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0117 - metrics_pearsonr: 2.0685e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.0658e-04\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0118 - metrics_pearsonr: 2.0698e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.0678e-04\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0118 - metrics_pearsonr: 2.0720e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.0677e-04\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0116 - metrics_pearsonr: 2.0733e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0638e-04\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0116 - metrics_pearsonr: 2.0768e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0630e-04\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0117 - metrics_pearsonr: 2.0800e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0680e-04\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0123 - metrics_pearsonr: 2.0857e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.0917e-04\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0132 - metrics_pearsonr: 2.0912e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.1260e-04\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0145 - metrics_pearsonr: 2.0972e-04 - val_loss: 0.0241 - val_metrics_pearsonr: 5.1759e-04\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0157 - metrics_pearsonr: 2.1047e-04 - val_loss: 0.0272 - val_metrics_pearsonr: 5.2282e-04\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0166 - metrics_pearsonr: 2.1159e-04 - val_loss: 0.0289 - val_metrics_pearsonr: 5.2684e-04\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0167 - metrics_pearsonr: 2.1322e-04 - val_loss: 0.0278 - val_metrics_pearsonr: 5.2869e-04\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0160 - metrics_pearsonr: 2.1463e-04 - val_loss: 0.0237 - val_metrics_pearsonr: 5.2614e-04\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0150 - metrics_pearsonr: 2.1537e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.2284e-04\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0152 - metrics_pearsonr: 2.1692e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2292e-04\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0173 - metrics_pearsonr: 2.2053e-04 - val_loss: 0.0252 - val_metrics_pearsonr: 5.2998e-04\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0208 - metrics_pearsonr: 2.2347e-04 - val_loss: 0.0346 - val_metrics_pearsonr: 5.3948e-04\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0233 - metrics_pearsonr: 2.2436e-04 - val_loss: 0.0396 - val_metrics_pearsonr: 5.4495e-04\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0233 - metrics_pearsonr: 2.2614e-04 - val_loss: 0.0332 - val_metrics_pearsonr: 5.4433e-04\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0209 - metrics_pearsonr: 2.2868e-04 - val_loss: 0.0214 - val_metrics_pearsonr: 5.3622e-04\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0191 - metrics_pearsonr: 2.3124e-04 - val_loss: 0.0206 - val_metrics_pearsonr: 5.3742e-04\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0206 - metrics_pearsonr: 2.3266e-04 - val_loss: 0.0327 - val_metrics_pearsonr: 5.5607e-04\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0230 - metrics_pearsonr: 2.3054e-04 - val_loss: 0.0382 - val_metrics_pearsonr: 5.6522e-04\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0224 - metrics_pearsonr: 2.3410e-04 - val_loss: 0.0271 - val_metrics_pearsonr: 5.5104e-04\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0186 - metrics_pearsonr: 2.3173e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.3781e-04\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0167 - metrics_pearsonr: 2.2664e-04 - val_loss: 0.0243 - val_metrics_pearsonr: 5.3257e-04\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0171 - metrics_pearsonr: 2.2464e-04 - val_loss: 0.0263 - val_metrics_pearsonr: 5.4347e-04\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0158 - metrics_pearsonr: 2.2447e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.3403e-04\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0139 - metrics_pearsonr: 2.2054e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1877e-04\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0135 - metrics_pearsonr: 2.1558e-04 - val_loss: 0.0220 - val_metrics_pearsonr: 5.2267e-04\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0135 - metrics_pearsonr: 2.1452e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.2342e-04\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0126 - metrics_pearsonr: 2.1366e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.3488e-04\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0121 - metrics_pearsonr: 2.1426e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.1980e-04\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0120 - metrics_pearsonr: 2.1025e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.1577e-04\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0118 - metrics_pearsonr: 2.0929e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1730e-04\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0115 - metrics_pearsonr: 2.1139e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 5.1630e-04\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0116 - metrics_pearsonr: 2.1119e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.1672e-04\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0116 - metrics_pearsonr: 2.0810e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1450e-04\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0114 - metrics_pearsonr: 2.0618e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1170e-04\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0111 - metrics_pearsonr: 2.0548e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1059e-04\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0111 - metrics_pearsonr: 2.0524e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 5.1032e-04\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0111 - metrics_pearsonr: 2.0439e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.0865e-04\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0110 - metrics_pearsonr: 2.0373e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 5.0803e-04\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0109 - metrics_pearsonr: 2.0392e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0861e-04\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0110 - metrics_pearsonr: 2.0404e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 5.1025e-04\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0109 - metrics_pearsonr: 2.0357e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1131e-04\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0109 - metrics_pearsonr: 2.0310e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0971e-04\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0108 - metrics_pearsonr: 2.0266e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0897e-04\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0108 - metrics_pearsonr: 2.0256e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0874e-04\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0108 - metrics_pearsonr: 2.0260e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0870e-04\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0108 - metrics_pearsonr: 2.0257e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0884e-04\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0108 - metrics_pearsonr: 2.0229e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0883e-04\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0108 - metrics_pearsonr: 2.0186e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0894e-04\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0108 - metrics_pearsonr: 2.0160e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0915e-04\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0108 - metrics_pearsonr: 2.0152e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0941e-04\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0107 - metrics_pearsonr: 2.0143e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0925e-04\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0107 - metrics_pearsonr: 2.0128e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0885e-04\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0107 - metrics_pearsonr: 2.0115e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0876e-04\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0107 - metrics_pearsonr: 2.0115e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0889e-04\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0107 - metrics_pearsonr: 2.0110e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0894e-04\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0107 - metrics_pearsonr: 2.0090e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0894e-04\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0107 - metrics_pearsonr: 2.0067e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0915e-04\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0107 - metrics_pearsonr: 2.0057e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.0953e-04\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0107 - metrics_pearsonr: 2.0052e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0969e-04\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0107 - metrics_pearsonr: 2.0046e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0960e-04\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0107 - metrics_pearsonr: 2.0035e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0940e-04\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0107 - metrics_pearsonr: 2.0027e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0938e-04\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0107 - metrics_pearsonr: 2.0019e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0925e-04\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0107 - metrics_pearsonr: 2.0011e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0936e-04\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0107 - metrics_pearsonr: 1.9999e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0945e-04\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0107 - metrics_pearsonr: 1.9989e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.0987e-04\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0107 - metrics_pearsonr: 1.9981e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1005e-04\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0107 - metrics_pearsonr: 1.9973e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1027e-04\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0107 - metrics_pearsonr: 1.9962e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1018e-04\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0106 - metrics_pearsonr: 1.9952e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1022e-04\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0106 - metrics_pearsonr: 1.9942e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1010e-04\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0106 - metrics_pearsonr: 1.9936e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1016e-04\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0106 - metrics_pearsonr: 1.9925e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1007e-04\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0106 - metrics_pearsonr: 1.9917e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1020e-04\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0106 - metrics_pearsonr: 1.9908e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1021e-04\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0106 - metrics_pearsonr: 1.9902e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1050e-04\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0106 - metrics_pearsonr: 1.9893e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1058e-04\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0106 - metrics_pearsonr: 1.9885e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1085e-04\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0106 - metrics_pearsonr: 1.9874e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1088e-04\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0106 - metrics_pearsonr: 1.9865e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1105e-04\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0106 - metrics_pearsonr: 1.9855e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1100e-04\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0106 - metrics_pearsonr: 1.9847e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1106e-04\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0106 - metrics_pearsonr: 1.9837e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1095e-04\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0106 - metrics_pearsonr: 1.9830e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1106e-04\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0106 - metrics_pearsonr: 1.9821e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1097e-04\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0106 - metrics_pearsonr: 1.9815e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1114e-04\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0106 - metrics_pearsonr: 1.9807e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 5.1108e-04\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0106 - metrics_pearsonr: 1.9800e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1136e-04\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0106 - metrics_pearsonr: 1.9790e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1145e-04\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0106 - metrics_pearsonr: 1.9782e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1178e-04\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0106 - metrics_pearsonr: 1.9772e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1186e-04\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0106 - metrics_pearsonr: 1.9763e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1211e-04\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0106 - metrics_pearsonr: 1.9752e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1211e-04\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0106 - metrics_pearsonr: 1.9744e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1225e-04\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0106 - metrics_pearsonr: 1.9735e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1211e-04\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0106 - metrics_pearsonr: 1.9728e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1219e-04\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0106 - metrics_pearsonr: 1.9719e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1201e-04\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0106 - metrics_pearsonr: 1.9714e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1217e-04\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0106 - metrics_pearsonr: 1.9707e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1200e-04\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0106 - metrics_pearsonr: 1.9703e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1221e-04\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0106 - metrics_pearsonr: 1.9694e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1213e-04\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0106 - metrics_pearsonr: 1.9688e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1246e-04\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0106 - metrics_pearsonr: 1.9679e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1255e-04\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0106 - metrics_pearsonr: 1.9672e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1300e-04\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0106 - metrics_pearsonr: 1.9663e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 5.1323e-04\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0107 - metrics_pearsonr: 1.9654e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1367e-04\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0107 - metrics_pearsonr: 1.9645e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1380e-04\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0107 - metrics_pearsonr: 1.9638e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1405e-04\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0106 - metrics_pearsonr: 1.9629e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 5.1385e-04\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0106 - metrics_pearsonr: 1.9623e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1390e-04\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0106 - metrics_pearsonr: 1.9617e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1360e-04\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0106 - metrics_pearsonr: 1.9615e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1375e-04\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0106 - metrics_pearsonr: 1.9613e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1350e-04\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0107 - metrics_pearsonr: 1.9615e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1379e-04\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0107 - metrics_pearsonr: 1.9615e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.1362e-04\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0107 - metrics_pearsonr: 1.9618e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1384e-04\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0107 - metrics_pearsonr: 1.9615e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 5.1358e-04\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0107 - metrics_pearsonr: 1.9618e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 5.1387e-04\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0107 - metrics_pearsonr: 1.9618e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 5.1397e-04\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0108 - metrics_pearsonr: 1.9624e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.1482e-04\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0111 - metrics_pearsonr: 1.9627e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1574e-04\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0114 - metrics_pearsonr: 1.9633e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.1741e-04\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0117 - metrics_pearsonr: 1.9641e-04 - val_loss: 0.0206 - val_metrics_pearsonr: 5.1897e-04\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0120 - metrics_pearsonr: 1.9652e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 5.2052e-04\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0120 - metrics_pearsonr: 1.9670e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 5.2124e-04\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0119 - metrics_pearsonr: 1.9688e-04 - val_loss: 0.0204 - val_metrics_pearsonr: 5.2133e-04\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0116 - metrics_pearsonr: 1.9713e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.2048e-04\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0115 - metrics_pearsonr: 1.9735e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.2002e-04\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0117 - metrics_pearsonr: 1.9791e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.1968e-04\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0123 - metrics_pearsonr: 1.9877e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.2124e-04\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0134 - metrics_pearsonr: 1.9983e-04 - val_loss: 0.0226 - val_metrics_pearsonr: 5.2367e-04\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0146 - metrics_pearsonr: 2.0086e-04 - val_loss: 0.0254 - val_metrics_pearsonr: 5.2736e-04\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0155 - metrics_pearsonr: 2.0189e-04 - val_loss: 0.0271 - val_metrics_pearsonr: 5.3096e-04\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0156 - metrics_pearsonr: 2.0304e-04 - val_loss: 0.0262 - val_metrics_pearsonr: 5.3153e-04\n",
      "Epoch 1/5000\n",
      "3/3 [==============================] - 2s 372ms/step - loss: 0.0263 - metrics_pearsonr: 4.7420e-04 - val_loss: 0.0145 - val_metrics_pearsonr: 3.5659e-04\n",
      "Epoch 2/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0243 - metrics_pearsonr: 5.1304e-04 - val_loss: 0.0136 - val_metrics_pearsonr: 3.3567e-04\n",
      "Epoch 3/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0224 - metrics_pearsonr: 5.0000e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 3.4203e-04\n",
      "Epoch 4/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0244 - metrics_pearsonr: 4.9045e-04 - val_loss: 0.0229 - val_metrics_pearsonr: 3.4324e-04\n",
      "Epoch 5/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0285 - metrics_pearsonr: 4.7797e-04 - val_loss: 0.0347 - val_metrics_pearsonr: 3.6517e-04\n",
      "Epoch 6/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0331 - metrics_pearsonr: 4.7948e-04 - val_loss: 0.0492 - val_metrics_pearsonr: 4.2681e-04\n",
      "Epoch 7/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0382 - metrics_pearsonr: 5.3185e-04 - val_loss: 0.0543 - val_metrics_pearsonr: 4.3549e-04\n",
      "Epoch 8/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0384 - metrics_pearsonr: 5.1284e-04 - val_loss: 0.0390 - val_metrics_pearsonr: 4.0737e-04\n",
      "Epoch 9/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0362 - metrics_pearsonr: 5.0605e-04 - val_loss: 0.0172 - val_metrics_pearsonr: 3.7626e-04\n",
      "Epoch 10/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0354 - metrics_pearsonr: 4.8640e-04 - val_loss: 0.0270 - val_metrics_pearsonr: 3.8122e-04\n",
      "Epoch 11/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0428 - metrics_pearsonr: 4.9234e-04 - val_loss: 0.0588 - val_metrics_pearsonr: 4.4169e-04\n",
      "Epoch 12/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0465 - metrics_pearsonr: 4.9746e-04 - val_loss: 0.0508 - val_metrics_pearsonr: 4.4720e-04\n",
      "Epoch 13/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0400 - metrics_pearsonr: 5.0527e-04 - val_loss: 0.0169 - val_metrics_pearsonr: 3.7578e-04\n",
      "Epoch 14/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0286 - metrics_pearsonr: 4.5137e-04 - val_loss: 0.0257 - val_metrics_pearsonr: 3.8479e-04\n",
      "Epoch 15/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0265 - metrics_pearsonr: 4.4007e-04 - val_loss: 0.0265 - val_metrics_pearsonr: 3.8285e-04\n",
      "Epoch 16/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0241 - metrics_pearsonr: 4.3879e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.9086e-04\n",
      "Epoch 17/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0223 - metrics_pearsonr: 4.4503e-04 - val_loss: 0.0228 - val_metrics_pearsonr: 3.7466e-04\n",
      "Epoch 18/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0226 - metrics_pearsonr: 4.3493e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 3.7488e-04\n",
      "Epoch 19/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0201 - metrics_pearsonr: 4.2166e-04 - val_loss: 0.0148 - val_metrics_pearsonr: 3.6611e-04\n",
      "Epoch 20/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0183 - metrics_pearsonr: 4.1231e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 3.6858e-04\n",
      "Epoch 21/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0186 - metrics_pearsonr: 4.0696e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 3.6133e-04\n",
      "Epoch 22/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0179 - metrics_pearsonr: 3.9945e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.6385e-04\n",
      "Epoch 23/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0179 - metrics_pearsonr: 3.9822e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 3.7021e-04\n",
      "Epoch 24/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0179 - metrics_pearsonr: 3.9837e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.5890e-04\n",
      "Epoch 25/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0167 - metrics_pearsonr: 3.8963e-04 - val_loss: 0.0146 - val_metrics_pearsonr: 3.5889e-04\n",
      "Epoch 26/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0162 - metrics_pearsonr: 3.8541e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.6112e-04\n",
      "Epoch 27/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0163 - metrics_pearsonr: 3.8366e-04 - val_loss: 0.0146 - val_metrics_pearsonr: 3.5968e-04\n",
      "Epoch 28/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0163 - metrics_pearsonr: 3.8166e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.6063e-04\n",
      "Epoch 29/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0163 - metrics_pearsonr: 3.7998e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.5960e-04\n",
      "Epoch 30/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0161 - metrics_pearsonr: 3.7735e-04 - val_loss: 0.0147 - val_metrics_pearsonr: 3.5959e-04\n",
      "Epoch 31/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0157 - metrics_pearsonr: 3.7467e-04 - val_loss: 0.0146 - val_metrics_pearsonr: 3.6052e-04\n",
      "Epoch 32/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0156 - metrics_pearsonr: 3.7271e-04 - val_loss: 0.0147 - val_metrics_pearsonr: 3.6206e-04\n",
      "Epoch 33/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0156 - metrics_pearsonr: 3.7163e-04 - val_loss: 0.0146 - val_metrics_pearsonr: 3.6331e-04\n",
      "Epoch 34/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0156 - metrics_pearsonr: 3.7087e-04 - val_loss: 0.0147 - val_metrics_pearsonr: 3.6261e-04\n",
      "Epoch 35/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0156 - metrics_pearsonr: 3.6931e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.6350e-04\n",
      "Epoch 36/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0156 - metrics_pearsonr: 3.6795e-04 - val_loss: 0.0148 - val_metrics_pearsonr: 3.6614e-04\n",
      "Epoch 37/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0154 - metrics_pearsonr: 3.6666e-04 - val_loss: 0.0147 - val_metrics_pearsonr: 3.6684e-04\n",
      "Epoch 38/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0153 - metrics_pearsonr: 3.6537e-04 - val_loss: 0.0147 - val_metrics_pearsonr: 3.6731e-04\n",
      "Epoch 39/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0153 - metrics_pearsonr: 3.6420e-04 - val_loss: 0.0147 - val_metrics_pearsonr: 3.6783e-04\n",
      "Epoch 40/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0153 - metrics_pearsonr: 3.6315e-04 - val_loss: 0.0148 - val_metrics_pearsonr: 3.6859e-04\n",
      "Epoch 41/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0153 - metrics_pearsonr: 3.6222e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.6966e-04\n",
      "Epoch 42/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0153 - metrics_pearsonr: 3.6129e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.7017e-04\n",
      "Epoch 43/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0152 - metrics_pearsonr: 3.6021e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.7072e-04\n",
      "Epoch 44/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0152 - metrics_pearsonr: 3.5909e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.7185e-04\n",
      "Epoch 45/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0151 - metrics_pearsonr: 3.5818e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.7260e-04\n",
      "Epoch 46/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0151 - metrics_pearsonr: 3.5725e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.7307e-04\n",
      "Epoch 47/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0151 - metrics_pearsonr: 3.5644e-04 - val_loss: 0.0149 - val_metrics_pearsonr: 3.7364e-04\n",
      "Epoch 48/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0151 - metrics_pearsonr: 3.5564e-04 - val_loss: 0.0150 - val_metrics_pearsonr: 3.7422e-04\n",
      "Epoch 49/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0151 - metrics_pearsonr: 3.5475e-04 - val_loss: 0.0150 - val_metrics_pearsonr: 3.7502e-04\n",
      "Epoch 50/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0151 - metrics_pearsonr: 3.5389e-04 - val_loss: 0.0150 - val_metrics_pearsonr: 3.7591e-04\n",
      "Epoch 51/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0150 - metrics_pearsonr: 3.5305e-04 - val_loss: 0.0150 - val_metrics_pearsonr: 3.7663e-04\n",
      "Epoch 52/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0150 - metrics_pearsonr: 3.5223e-04 - val_loss: 0.0150 - val_metrics_pearsonr: 3.7731e-04\n",
      "Epoch 53/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0150 - metrics_pearsonr: 3.5145e-04 - val_loss: 0.0151 - val_metrics_pearsonr: 3.7786e-04\n",
      "Epoch 54/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0150 - metrics_pearsonr: 3.5066e-04 - val_loss: 0.0151 - val_metrics_pearsonr: 3.7845e-04\n",
      "Epoch 55/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0149 - metrics_pearsonr: 3.4990e-04 - val_loss: 0.0151 - val_metrics_pearsonr: 3.7912e-04\n",
      "Epoch 56/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0149 - metrics_pearsonr: 3.4919e-04 - val_loss: 0.0151 - val_metrics_pearsonr: 3.7971e-04\n",
      "Epoch 57/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0149 - metrics_pearsonr: 3.4843e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.8030e-04\n",
      "Epoch 58/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0149 - metrics_pearsonr: 3.4768e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.8105e-04\n",
      "Epoch 59/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0149 - metrics_pearsonr: 3.4696e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.8179e-04\n",
      "Epoch 60/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0148 - metrics_pearsonr: 3.4626e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.8245e-04\n",
      "Epoch 61/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0148 - metrics_pearsonr: 3.4555e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.8307e-04\n",
      "Epoch 62/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0148 - metrics_pearsonr: 3.4487e-04 - val_loss: 0.0152 - val_metrics_pearsonr: 3.8364e-04\n",
      "Epoch 63/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0148 - metrics_pearsonr: 3.4418e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.8421e-04\n",
      "Epoch 64/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0148 - metrics_pearsonr: 3.4350e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.8483e-04\n",
      "Epoch 65/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0148 - metrics_pearsonr: 3.4285e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.8541e-04\n",
      "Epoch 66/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0147 - metrics_pearsonr: 3.4221e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.8601e-04\n",
      "Epoch 67/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0147 - metrics_pearsonr: 3.4158e-04 - val_loss: 0.0153 - val_metrics_pearsonr: 3.8665e-04\n",
      "Epoch 68/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0147 - metrics_pearsonr: 3.4094e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.8727e-04\n",
      "Epoch 69/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0147 - metrics_pearsonr: 3.4031e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.8793e-04\n",
      "Epoch 70/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0147 - metrics_pearsonr: 3.3969e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.8852e-04\n",
      "Epoch 71/5000\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0146 - metrics_pearsonr: 3.3906e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.8911e-04\n",
      "Epoch 72/5000\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0146 - metrics_pearsonr: 3.3843e-04 - val_loss: 0.0154 - val_metrics_pearsonr: 3.8964e-04\n",
      "Epoch 73/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0146 - metrics_pearsonr: 3.3785e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9013e-04\n",
      "Epoch 74/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0146 - metrics_pearsonr: 3.3726e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9066e-04\n",
      "Epoch 75/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0146 - metrics_pearsonr: 3.3666e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9118e-04\n",
      "Epoch 76/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0146 - metrics_pearsonr: 3.3610e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9173e-04\n",
      "Epoch 77/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0145 - metrics_pearsonr: 3.3553e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9230e-04\n",
      "Epoch 78/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0145 - metrics_pearsonr: 3.3495e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9284e-04\n",
      "Epoch 79/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0145 - metrics_pearsonr: 3.3440e-04 - val_loss: 0.0155 - val_metrics_pearsonr: 3.9339e-04\n",
      "Epoch 80/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0145 - metrics_pearsonr: 3.3384e-04 - val_loss: 0.0156 - val_metrics_pearsonr: 3.9396e-04\n",
      "Epoch 81/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0145 - metrics_pearsonr: 3.3329e-04 - val_loss: 0.0156 - val_metrics_pearsonr: 3.9450e-04\n",
      "Epoch 82/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0145 - metrics_pearsonr: 3.3276e-04 - val_loss: 0.0156 - val_metrics_pearsonr: 3.9502e-04\n",
      "Epoch 83/5000\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.0145 - metrics_pearsonr: 3.3222e-04 - val_loss: 0.0156 - val_metrics_pearsonr: 3.9556e-04\n",
      "Epoch 84/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0144 - metrics_pearsonr: 3.3169e-04 - val_loss: 0.0156 - val_metrics_pearsonr: 3.9606e-04\n",
      "Epoch 85/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0144 - metrics_pearsonr: 3.3117e-04 - val_loss: 0.0156 - val_metrics_pearsonr: 3.9658e-04\n",
      "Epoch 86/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0144 - metrics_pearsonr: 3.3065e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 3.9710e-04\n",
      "Epoch 87/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0144 - metrics_pearsonr: 3.3013e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 3.9759e-04\n",
      "Epoch 88/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0144 - metrics_pearsonr: 3.2961e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 3.9810e-04\n",
      "Epoch 89/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0144 - metrics_pearsonr: 3.2911e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 3.9860e-04\n",
      "Epoch 90/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0144 - metrics_pearsonr: 3.2861e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 3.9910e-04\n",
      "Epoch 91/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0143 - metrics_pearsonr: 3.2811e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 3.9959e-04\n",
      "Epoch 92/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0143 - metrics_pearsonr: 3.2762e-04 - val_loss: 0.0157 - val_metrics_pearsonr: 4.0009e-04\n",
      "Epoch 93/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0143 - metrics_pearsonr: 3.2713e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 4.0058e-04\n",
      "Epoch 94/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0143 - metrics_pearsonr: 3.2664e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 4.0108e-04\n",
      "Epoch 95/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0143 - metrics_pearsonr: 3.2616e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 4.0156e-04\n",
      "Epoch 96/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0143 - metrics_pearsonr: 3.2568e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 4.0205e-04\n",
      "Epoch 97/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0143 - metrics_pearsonr: 3.2521e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 4.0253e-04\n",
      "Epoch 98/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0143 - metrics_pearsonr: 3.2474e-04 - val_loss: 0.0158 - val_metrics_pearsonr: 4.0301e-04\n",
      "Epoch 99/5000\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0142 - metrics_pearsonr: 3.2428e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0349e-04\n",
      "Epoch 100/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0142 - metrics_pearsonr: 3.2381e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0397e-04\n",
      "Epoch 101/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0142 - metrics_pearsonr: 3.2335e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0444e-04\n",
      "Epoch 102/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0142 - metrics_pearsonr: 3.2290e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0492e-04\n",
      "Epoch 103/5000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0142 - metrics_pearsonr: 3.2244e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0539e-04\n",
      "Epoch 104/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0142 - metrics_pearsonr: 3.2200e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0587e-04\n",
      "Epoch 105/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0142 - metrics_pearsonr: 3.2155e-04 - val_loss: 0.0159 - val_metrics_pearsonr: 4.0634e-04\n",
      "Epoch 106/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0142 - metrics_pearsonr: 3.2111e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0679e-04\n",
      "Epoch 107/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0141 - metrics_pearsonr: 3.2067e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0726e-04\n",
      "Epoch 108/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0141 - metrics_pearsonr: 3.2024e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0772e-04\n",
      "Epoch 109/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0141 - metrics_pearsonr: 3.1981e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0818e-04\n",
      "Epoch 110/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0141 - metrics_pearsonr: 3.1938e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0863e-04\n",
      "Epoch 111/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0141 - metrics_pearsonr: 3.1896e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0908e-04\n",
      "Epoch 112/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0141 - metrics_pearsonr: 3.1853e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0953e-04\n",
      "Epoch 113/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0141 - metrics_pearsonr: 3.1812e-04 - val_loss: 0.0160 - val_metrics_pearsonr: 4.0997e-04\n",
      "Epoch 114/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0141 - metrics_pearsonr: 3.1768e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1042e-04\n",
      "Epoch 115/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0140 - metrics_pearsonr: 3.1728e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1085e-04\n",
      "Epoch 116/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0140 - metrics_pearsonr: 3.1686e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1130e-04\n",
      "Epoch 117/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0140 - metrics_pearsonr: 3.1646e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1174e-04\n",
      "Epoch 118/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0140 - metrics_pearsonr: 3.1604e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1219e-04\n",
      "Epoch 119/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0140 - metrics_pearsonr: 3.1565e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1262e-04\n",
      "Epoch 120/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0140 - metrics_pearsonr: 3.1523e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1308e-04\n",
      "Epoch 121/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0140 - metrics_pearsonr: 3.1485e-04 - val_loss: 0.0161 - val_metrics_pearsonr: 4.1352e-04\n",
      "Epoch 122/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0140 - metrics_pearsonr: 3.1444e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1398e-04\n",
      "Epoch 123/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0140 - metrics_pearsonr: 3.1407e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1445e-04\n",
      "Epoch 124/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0139 - metrics_pearsonr: 3.1366e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1491e-04\n",
      "Epoch 125/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0139 - metrics_pearsonr: 3.1329e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1540e-04\n",
      "Epoch 126/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0139 - metrics_pearsonr: 3.1288e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1589e-04\n",
      "Epoch 127/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0139 - metrics_pearsonr: 3.1252e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1640e-04\n",
      "Epoch 128/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0139 - metrics_pearsonr: 3.1211e-04 - val_loss: 0.0162 - val_metrics_pearsonr: 4.1688e-04\n",
      "Epoch 129/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0139 - metrics_pearsonr: 3.1175e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1736e-04\n",
      "Epoch 130/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0139 - metrics_pearsonr: 3.1135e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1783e-04\n",
      "Epoch 131/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0139 - metrics_pearsonr: 3.1097e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1825e-04\n",
      "Epoch 132/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0139 - metrics_pearsonr: 3.1062e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1867e-04\n",
      "Epoch 133/5000\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0138 - metrics_pearsonr: 3.1024e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1910e-04\n",
      "Epoch 134/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0138 - metrics_pearsonr: 3.0985e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1949e-04\n",
      "Epoch 135/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0138 - metrics_pearsonr: 3.0948e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.1988e-04\n",
      "Epoch 136/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0138 - metrics_pearsonr: 3.0914e-04 - val_loss: 0.0163 - val_metrics_pearsonr: 4.2031e-04\n",
      "Epoch 137/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0138 - metrics_pearsonr: 3.0881e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2072e-04\n",
      "Epoch 138/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0138 - metrics_pearsonr: 3.0840e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2108e-04\n",
      "Epoch 139/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0138 - metrics_pearsonr: 3.0806e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2150e-04\n",
      "Epoch 140/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0138 - metrics_pearsonr: 3.0773e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2185e-04\n",
      "Epoch 141/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0138 - metrics_pearsonr: 3.0734e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2220e-04\n",
      "Epoch 142/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0138 - metrics_pearsonr: 3.0703e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2264e-04\n",
      "Epoch 143/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0138 - metrics_pearsonr: 3.0667e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2302e-04\n",
      "Epoch 144/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0138 - metrics_pearsonr: 3.0631e-04 - val_loss: 0.0164 - val_metrics_pearsonr: 4.2336e-04\n",
      "Epoch 145/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0137 - metrics_pearsonr: 3.0599e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2370e-04\n",
      "Epoch 146/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0137 - metrics_pearsonr: 3.0565e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2407e-04\n",
      "Epoch 147/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0137 - metrics_pearsonr: 3.0530e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2444e-04\n",
      "Epoch 148/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0137 - metrics_pearsonr: 3.0494e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2483e-04\n",
      "Epoch 149/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0137 - metrics_pearsonr: 3.0457e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2526e-04\n",
      "Epoch 150/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0137 - metrics_pearsonr: 3.0423e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2567e-04\n",
      "Epoch 151/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0137 - metrics_pearsonr: 3.0385e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2597e-04\n",
      "Epoch 152/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0136 - metrics_pearsonr: 3.0348e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2638e-04\n",
      "Epoch 153/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0136 - metrics_pearsonr: 3.0316e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2677e-04\n",
      "Epoch 154/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0136 - metrics_pearsonr: 3.0280e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2712e-04\n",
      "Epoch 155/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0136 - metrics_pearsonr: 3.0245e-04 - val_loss: 0.0165 - val_metrics_pearsonr: 4.2752e-04\n",
      "Epoch 156/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0136 - metrics_pearsonr: 3.0212e-04 - val_loss: 0.0166 - val_metrics_pearsonr: 4.2790e-04\n",
      "Epoch 157/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0136 - metrics_pearsonr: 3.0180e-04 - val_loss: 0.0166 - val_metrics_pearsonr: 4.2834e-04\n",
      "Epoch 158/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0136 - metrics_pearsonr: 3.0147e-04 - val_loss: 0.0166 - val_metrics_pearsonr: 4.2883e-04\n",
      "Epoch 159/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0136 - metrics_pearsonr: 3.0115e-04 - val_loss: 0.0166 - val_metrics_pearsonr: 4.2925e-04\n",
      "Epoch 160/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0136 - metrics_pearsonr: 3.0086e-04 - val_loss: 0.0166 - val_metrics_pearsonr: 4.2972e-04\n",
      "Epoch 161/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0136 - metrics_pearsonr: 3.0057e-04 - val_loss: 0.0166 - val_metrics_pearsonr: 4.3018e-04\n",
      "Epoch 162/5000\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0136 - metrics_pearsonr: 3.0029e-04 - val_loss: 0.0167 - val_metrics_pearsonr: 4.3079e-04\n",
      "Epoch 163/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0136 - metrics_pearsonr: 3.0002e-04 - val_loss: 0.0167 - val_metrics_pearsonr: 4.3065e-04\n",
      "Epoch 164/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0137 - metrics_pearsonr: 2.9983e-04 - val_loss: 0.0168 - val_metrics_pearsonr: 4.3095e-04\n",
      "Epoch 165/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0137 - metrics_pearsonr: 2.9957e-04 - val_loss: 0.0168 - val_metrics_pearsonr: 4.3149e-04\n",
      "Epoch 166/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0137 - metrics_pearsonr: 2.9937e-04 - val_loss: 0.0169 - val_metrics_pearsonr: 4.3232e-04\n",
      "Epoch 167/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0138 - metrics_pearsonr: 2.9914e-04 - val_loss: 0.0170 - val_metrics_pearsonr: 4.3296e-04\n",
      "Epoch 168/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0138 - metrics_pearsonr: 2.9891e-04 - val_loss: 0.0171 - val_metrics_pearsonr: 4.3336e-04\n",
      "Epoch 169/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0138 - metrics_pearsonr: 2.9869e-04 - val_loss: 0.0171 - val_metrics_pearsonr: 4.3403e-04\n",
      "Epoch 170/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0138 - metrics_pearsonr: 2.9841e-04 - val_loss: 0.0172 - val_metrics_pearsonr: 4.3440e-04\n",
      "Epoch 171/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0138 - metrics_pearsonr: 2.9815e-04 - val_loss: 0.0172 - val_metrics_pearsonr: 4.3495e-04\n",
      "Epoch 172/5000\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0138 - metrics_pearsonr: 2.9783e-04 - val_loss: 0.0172 - val_metrics_pearsonr: 4.3527e-04\n",
      "Epoch 173/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0137 - metrics_pearsonr: 2.9750e-04 - val_loss: 0.0171 - val_metrics_pearsonr: 4.3549e-04\n",
      "Epoch 174/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0137 - metrics_pearsonr: 2.9722e-04 - val_loss: 0.0171 - val_metrics_pearsonr: 4.3586e-04\n",
      "Epoch 175/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0136 - metrics_pearsonr: 2.9685e-04 - val_loss: 0.0170 - val_metrics_pearsonr: 4.3591e-04\n",
      "Epoch 176/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0136 - metrics_pearsonr: 2.9649e-04 - val_loss: 0.0169 - val_metrics_pearsonr: 4.3605e-04\n",
      "Epoch 177/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0135 - metrics_pearsonr: 2.9622e-04 - val_loss: 0.0168 - val_metrics_pearsonr: 4.3643e-04\n",
      "Epoch 178/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0136 - metrics_pearsonr: 2.9591e-04 - val_loss: 0.0168 - val_metrics_pearsonr: 4.3654e-04\n",
      "Epoch 179/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0136 - metrics_pearsonr: 2.9568e-04 - val_loss: 0.0169 - val_metrics_pearsonr: 4.3708e-04\n",
      "Epoch 180/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0138 - metrics_pearsonr: 2.9557e-04 - val_loss: 0.0170 - val_metrics_pearsonr: 4.3773e-04\n",
      "Epoch 181/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0140 - metrics_pearsonr: 2.9553e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.3865e-04\n",
      "Epoch 182/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0143 - metrics_pearsonr: 2.9560e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.3991e-04\n",
      "Epoch 183/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0147 - metrics_pearsonr: 2.9577e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.4144e-04\n",
      "Epoch 184/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0151 - metrics_pearsonr: 2.9603e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 4.4330e-04\n",
      "Epoch 185/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0156 - metrics_pearsonr: 2.9638e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 4.4558e-04\n",
      "Epoch 186/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0161 - metrics_pearsonr: 2.9680e-04 - val_loss: 0.0213 - val_metrics_pearsonr: 4.4806e-04\n",
      "Epoch 187/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0166 - metrics_pearsonr: 2.9725e-04 - val_loss: 0.0226 - val_metrics_pearsonr: 4.5089e-04\n",
      "Epoch 188/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0170 - metrics_pearsonr: 2.9780e-04 - val_loss: 0.0238 - val_metrics_pearsonr: 4.5409e-04\n",
      "Epoch 189/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0172 - metrics_pearsonr: 2.9848e-04 - val_loss: 0.0247 - val_metrics_pearsonr: 4.5670e-04\n",
      "Epoch 190/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0173 - metrics_pearsonr: 2.9920e-04 - val_loss: 0.0250 - val_metrics_pearsonr: 4.5857e-04\n",
      "Epoch 191/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0172 - metrics_pearsonr: 3.0019e-04 - val_loss: 0.0244 - val_metrics_pearsonr: 4.5889e-04\n",
      "Epoch 192/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0168 - metrics_pearsonr: 3.0110e-04 - val_loss: 0.0227 - val_metrics_pearsonr: 4.5827e-04\n",
      "Epoch 193/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0166 - metrics_pearsonr: 3.0233e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 4.5642e-04\n",
      "Epoch 194/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0169 - metrics_pearsonr: 3.0384e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.5531e-04\n",
      "Epoch 195/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0183 - metrics_pearsonr: 3.0714e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.5798e-04\n",
      "Epoch 196/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0218 - metrics_pearsonr: 3.1328e-04 - val_loss: 0.0227 - val_metrics_pearsonr: 4.6853e-04\n",
      "Epoch 197/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0276 - metrics_pearsonr: 3.2180e-04 - val_loss: 0.0351 - val_metrics_pearsonr: 4.8868e-04\n",
      "Epoch 198/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0348 - metrics_pearsonr: 3.3151e-04 - val_loss: 0.0543 - val_metrics_pearsonr: 5.1550e-04\n",
      "Epoch 199/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0410 - metrics_pearsonr: 3.4287e-04 - val_loss: 0.0678 - val_metrics_pearsonr: 5.3695e-04\n",
      "Epoch 200/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0419 - metrics_pearsonr: 3.5218e-04 - val_loss: 0.0537 - val_metrics_pearsonr: 5.3714e-04\n",
      "Epoch 201/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0365 - metrics_pearsonr: 3.5921e-04 - val_loss: 0.0232 - val_metrics_pearsonr: 5.1013e-04\n",
      "Epoch 202/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0313 - metrics_pearsonr: 3.5506e-04 - val_loss: 0.0275 - val_metrics_pearsonr: 5.0693e-04\n",
      "Epoch 203/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0337 - metrics_pearsonr: 3.4635e-04 - val_loss: 0.0537 - val_metrics_pearsonr: 5.2937e-04\n",
      "Epoch 204/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0353 - metrics_pearsonr: 3.4263e-04 - val_loss: 0.0378 - val_metrics_pearsonr: 5.2723e-04\n",
      "Epoch 205/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0285 - metrics_pearsonr: 3.4666e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 4.9745e-04\n",
      "Epoch 206/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0231 - metrics_pearsonr: 3.3698e-04 - val_loss: 0.0307 - val_metrics_pearsonr: 4.8165e-04\n",
      "Epoch 207/5000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0227 - metrics_pearsonr: 3.2593e-04 - val_loss: 0.0246 - val_metrics_pearsonr: 4.8218e-04\n",
      "Epoch 208/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0195 - metrics_pearsonr: 3.2123e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 4.8188e-04\n",
      "Epoch 209/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0178 - metrics_pearsonr: 3.2066e-04 - val_loss: 0.0249 - val_metrics_pearsonr: 4.8446e-04\n",
      "Epoch 210/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0178 - metrics_pearsonr: 3.1569e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 4.6856e-04\n",
      "Epoch 211/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0160 - metrics_pearsonr: 3.0576e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 4.6533e-04\n",
      "Epoch 212/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0159 - metrics_pearsonr: 3.0503e-04 - val_loss: 0.0217 - val_metrics_pearsonr: 4.7506e-04\n",
      "Epoch 213/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0160 - metrics_pearsonr: 3.0483e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.6058e-04\n",
      "Epoch 214/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0148 - metrics_pearsonr: 2.9900e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.6006e-04\n",
      "Epoch 215/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0145 - metrics_pearsonr: 2.9721e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 4.6183e-04\n",
      "Epoch 216/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0144 - metrics_pearsonr: 2.9615e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6543e-04\n",
      "Epoch 217/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0140 - metrics_pearsonr: 2.9582e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.5738e-04\n",
      "Epoch 218/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0140 - metrics_pearsonr: 2.9326e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.5855e-04\n",
      "Epoch 219/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0139 - metrics_pearsonr: 2.9265e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5531e-04\n",
      "Epoch 220/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0136 - metrics_pearsonr: 2.9109e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.5639e-04\n",
      "Epoch 221/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0135 - metrics_pearsonr: 2.9000e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.5613e-04\n",
      "Epoch 222/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0134 - metrics_pearsonr: 2.8889e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5409e-04\n",
      "Epoch 223/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0133 - metrics_pearsonr: 2.8772e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5437e-04\n",
      "Epoch 224/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0134 - metrics_pearsonr: 2.8752e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.5491e-04\n",
      "Epoch 225/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0133 - metrics_pearsonr: 2.8718e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5370e-04\n",
      "Epoch 226/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0132 - metrics_pearsonr: 2.8616e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5358e-04\n",
      "Epoch 227/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0132 - metrics_pearsonr: 2.8554e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5470e-04\n",
      "Epoch 228/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0132 - metrics_pearsonr: 2.8537e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5493e-04\n",
      "Epoch 229/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0132 - metrics_pearsonr: 2.8502e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5391e-04\n",
      "Epoch 230/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0132 - metrics_pearsonr: 2.8457e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5405e-04\n",
      "Epoch 231/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0131 - metrics_pearsonr: 2.8439e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5432e-04\n",
      "Epoch 232/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0131 - metrics_pearsonr: 2.8404e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5492e-04\n",
      "Epoch 233/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0131 - metrics_pearsonr: 2.8363e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5501e-04\n",
      "Epoch 234/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0131 - metrics_pearsonr: 2.8319e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5488e-04\n",
      "Epoch 235/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0131 - metrics_pearsonr: 2.8287e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5506e-04\n",
      "Epoch 236/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0131 - metrics_pearsonr: 2.8270e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5528e-04\n",
      "Epoch 237/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0131 - metrics_pearsonr: 2.8246e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5542e-04\n",
      "Epoch 238/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0130 - metrics_pearsonr: 2.8213e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5556e-04\n",
      "Epoch 239/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0130 - metrics_pearsonr: 2.8185e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5590e-04\n",
      "Epoch 240/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0130 - metrics_pearsonr: 2.8156e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5624e-04\n",
      "Epoch 241/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0130 - metrics_pearsonr: 2.8130e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5631e-04\n",
      "Epoch 242/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0130 - metrics_pearsonr: 2.8108e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5645e-04\n",
      "Epoch 243/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0130 - metrics_pearsonr: 2.8083e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5664e-04\n",
      "Epoch 244/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0130 - metrics_pearsonr: 2.8059e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5691e-04\n",
      "Epoch 245/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0130 - metrics_pearsonr: 2.8032e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5710e-04\n",
      "Epoch 246/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0130 - metrics_pearsonr: 2.8010e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5726e-04\n",
      "Epoch 247/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0130 - metrics_pearsonr: 2.7986e-04 - val_loss: 0.0173 - val_metrics_pearsonr: 4.5756e-04\n",
      "Epoch 248/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0130 - metrics_pearsonr: 2.7958e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5775e-04\n",
      "Epoch 249/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0129 - metrics_pearsonr: 2.7938e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5794e-04\n",
      "Epoch 250/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0129 - metrics_pearsonr: 2.7914e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5812e-04\n",
      "Epoch 251/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0129 - metrics_pearsonr: 2.7889e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5821e-04\n",
      "Epoch 252/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0129 - metrics_pearsonr: 2.7868e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5844e-04\n",
      "Epoch 253/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0129 - metrics_pearsonr: 2.7848e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5871e-04\n",
      "Epoch 254/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0129 - metrics_pearsonr: 2.7823e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5899e-04\n",
      "Epoch 255/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0129 - metrics_pearsonr: 2.7798e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5916e-04\n",
      "Epoch 256/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0129 - metrics_pearsonr: 2.7777e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5937e-04\n",
      "Epoch 257/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0129 - metrics_pearsonr: 2.7752e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5964e-04\n",
      "Epoch 258/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0129 - metrics_pearsonr: 2.7729e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5976e-04\n",
      "Epoch 259/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0129 - metrics_pearsonr: 2.7711e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.5996e-04\n",
      "Epoch 260/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0129 - metrics_pearsonr: 2.7690e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.6024e-04\n",
      "Epoch 261/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0129 - metrics_pearsonr: 2.7666e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.6048e-04\n",
      "Epoch 262/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0129 - metrics_pearsonr: 2.7644e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.6068e-04\n",
      "Epoch 263/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0129 - metrics_pearsonr: 2.7621e-04 - val_loss: 0.0174 - val_metrics_pearsonr: 4.6082e-04\n",
      "Epoch 264/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0128 - metrics_pearsonr: 2.7606e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6102e-04\n",
      "Epoch 265/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0128 - metrics_pearsonr: 2.7581e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6121e-04\n",
      "Epoch 266/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0128 - metrics_pearsonr: 2.7559e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6143e-04\n",
      "Epoch 267/5000\n",
      "3/3 [==============================] - 0s 186ms/step - loss: 0.0128 - metrics_pearsonr: 2.7540e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6164e-04\n",
      "Epoch 268/5000\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0128 - metrics_pearsonr: 2.7518e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6188e-04\n",
      "Epoch 269/5000\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0128 - metrics_pearsonr: 2.7496e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6212e-04\n",
      "Epoch 270/5000\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0128 - metrics_pearsonr: 2.7475e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6235e-04\n",
      "Epoch 271/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0128 - metrics_pearsonr: 2.7452e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6259e-04\n",
      "Epoch 272/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0128 - metrics_pearsonr: 2.7431e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6285e-04\n",
      "Epoch 273/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0128 - metrics_pearsonr: 2.7408e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6311e-04\n",
      "Epoch 274/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0128 - metrics_pearsonr: 2.7385e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6334e-04\n",
      "Epoch 275/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0128 - metrics_pearsonr: 2.7364e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6350e-04\n",
      "Epoch 276/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0128 - metrics_pearsonr: 2.7345e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6369e-04\n",
      "Epoch 277/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0128 - metrics_pearsonr: 2.7324e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6397e-04\n",
      "Epoch 278/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0128 - metrics_pearsonr: 2.7303e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6411e-04\n",
      "Epoch 279/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0127 - metrics_pearsonr: 2.7282e-04 - val_loss: 0.0175 - val_metrics_pearsonr: 4.6428e-04\n",
      "Epoch 280/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0127 - metrics_pearsonr: 2.7260e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6460e-04\n",
      "Epoch 281/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0127 - metrics_pearsonr: 2.7241e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6476e-04\n",
      "Epoch 282/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0127 - metrics_pearsonr: 2.7220e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6496e-04\n",
      "Epoch 283/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0127 - metrics_pearsonr: 2.7200e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6526e-04\n",
      "Epoch 284/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0127 - metrics_pearsonr: 2.7178e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6545e-04\n",
      "Epoch 285/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0127 - metrics_pearsonr: 2.7156e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6563e-04\n",
      "Epoch 286/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0127 - metrics_pearsonr: 2.7138e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6587e-04\n",
      "Epoch 287/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0127 - metrics_pearsonr: 2.7118e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6610e-04\n",
      "Epoch 288/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0127 - metrics_pearsonr: 2.7095e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6624e-04\n",
      "Epoch 289/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0127 - metrics_pearsonr: 2.7073e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6644e-04\n",
      "Epoch 290/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0127 - metrics_pearsonr: 2.7051e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6673e-04\n",
      "Epoch 291/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0127 - metrics_pearsonr: 2.7031e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6697e-04\n",
      "Epoch 292/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0127 - metrics_pearsonr: 2.7012e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6716e-04\n",
      "Epoch 293/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0127 - metrics_pearsonr: 2.6991e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6747e-04\n",
      "Epoch 294/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0127 - metrics_pearsonr: 2.6972e-04 - val_loss: 0.0176 - val_metrics_pearsonr: 4.6767e-04\n",
      "Epoch 295/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0126 - metrics_pearsonr: 2.6949e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6789e-04\n",
      "Epoch 296/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0126 - metrics_pearsonr: 2.6930e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6819e-04\n",
      "Epoch 297/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0126 - metrics_pearsonr: 2.6910e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6830e-04\n",
      "Epoch 298/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0126 - metrics_pearsonr: 2.6895e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6856e-04\n",
      "Epoch 299/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0126 - metrics_pearsonr: 2.6873e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6882e-04\n",
      "Epoch 300/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0126 - metrics_pearsonr: 2.6855e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6908e-04\n",
      "Epoch 301/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0126 - metrics_pearsonr: 2.6831e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6922e-04\n",
      "Epoch 302/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0126 - metrics_pearsonr: 2.6810e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6960e-04\n",
      "Epoch 303/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0126 - metrics_pearsonr: 2.6791e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.6985e-04\n",
      "Epoch 304/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0126 - metrics_pearsonr: 2.6776e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.7012e-04\n",
      "Epoch 305/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0126 - metrics_pearsonr: 2.6752e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.7042e-04\n",
      "Epoch 306/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0126 - metrics_pearsonr: 2.6731e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.7074e-04\n",
      "Epoch 307/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0126 - metrics_pearsonr: 2.6716e-04 - val_loss: 0.0177 - val_metrics_pearsonr: 4.7099e-04\n",
      "Epoch 308/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0126 - metrics_pearsonr: 2.6693e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.7143e-04\n",
      "Epoch 309/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0126 - metrics_pearsonr: 2.6675e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.7200e-04\n",
      "Epoch 310/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0126 - metrics_pearsonr: 2.6656e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.7230e-04\n",
      "Epoch 311/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0125 - metrics_pearsonr: 2.6628e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.7307e-04\n",
      "Epoch 312/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0125 - metrics_pearsonr: 2.6600e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.7348e-04\n",
      "Epoch 313/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0125 - metrics_pearsonr: 2.6587e-04 - val_loss: 0.0178 - val_metrics_pearsonr: 4.7383e-04\n",
      "Epoch 314/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0125 - metrics_pearsonr: 2.6566e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7400e-04\n",
      "Epoch 315/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0125 - metrics_pearsonr: 2.6549e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7416e-04\n",
      "Epoch 316/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0125 - metrics_pearsonr: 2.6530e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7420e-04\n",
      "Epoch 317/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0125 - metrics_pearsonr: 2.6510e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7431e-04\n",
      "Epoch 318/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0125 - metrics_pearsonr: 2.6489e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7448e-04\n",
      "Epoch 319/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0125 - metrics_pearsonr: 2.6471e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7479e-04\n",
      "Epoch 320/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0125 - metrics_pearsonr: 2.6455e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7489e-04\n",
      "Epoch 321/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0125 - metrics_pearsonr: 2.6431e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7509e-04\n",
      "Epoch 322/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0125 - metrics_pearsonr: 2.6412e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7539e-04\n",
      "Epoch 323/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0125 - metrics_pearsonr: 2.6393e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7551e-04\n",
      "Epoch 324/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0125 - metrics_pearsonr: 2.6377e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7577e-04\n",
      "Epoch 325/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0125 - metrics_pearsonr: 2.6359e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7605e-04\n",
      "Epoch 326/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0125 - metrics_pearsonr: 2.6340e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7631e-04\n",
      "Epoch 327/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0125 - metrics_pearsonr: 2.6320e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7643e-04\n",
      "Epoch 328/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0125 - metrics_pearsonr: 2.6301e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7663e-04\n",
      "Epoch 329/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0125 - metrics_pearsonr: 2.6286e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7680e-04\n",
      "Epoch 330/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0125 - metrics_pearsonr: 2.6273e-04 - val_loss: 0.0179 - val_metrics_pearsonr: 4.7712e-04\n",
      "Epoch 331/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0124 - metrics_pearsonr: 2.6253e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7722e-04\n",
      "Epoch 332/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0124 - metrics_pearsonr: 2.6235e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7755e-04\n",
      "Epoch 333/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0124 - metrics_pearsonr: 2.6216e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7773e-04\n",
      "Epoch 334/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0124 - metrics_pearsonr: 2.6206e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7800e-04\n",
      "Epoch 335/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0124 - metrics_pearsonr: 2.6176e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7820e-04\n",
      "Epoch 336/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0124 - metrics_pearsonr: 2.6162e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7819e-04\n",
      "Epoch 337/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0124 - metrics_pearsonr: 2.6140e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7820e-04\n",
      "Epoch 338/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0124 - metrics_pearsonr: 2.6122e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7846e-04\n",
      "Epoch 339/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0124 - metrics_pearsonr: 2.6100e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7862e-04\n",
      "Epoch 340/5000\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0124 - metrics_pearsonr: 2.6080e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7891e-04\n",
      "Epoch 341/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0124 - metrics_pearsonr: 2.6060e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7915e-04\n",
      "Epoch 342/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0124 - metrics_pearsonr: 2.6045e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7950e-04\n",
      "Epoch 343/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0124 - metrics_pearsonr: 2.6025e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.7960e-04\n",
      "Epoch 344/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0124 - metrics_pearsonr: 2.6011e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.8003e-04\n",
      "Epoch 345/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0124 - metrics_pearsonr: 2.5988e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.8017e-04\n",
      "Epoch 346/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0124 - metrics_pearsonr: 2.5974e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.8047e-04\n",
      "Epoch 347/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0124 - metrics_pearsonr: 2.5957e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.8051e-04\n",
      "Epoch 348/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0124 - metrics_pearsonr: 2.5944e-04 - val_loss: 0.0180 - val_metrics_pearsonr: 4.8083e-04\n",
      "Epoch 349/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0124 - metrics_pearsonr: 2.5927e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.8105e-04\n",
      "Epoch 350/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0124 - metrics_pearsonr: 2.5920e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.8138e-04\n",
      "Epoch 351/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0125 - metrics_pearsonr: 2.5905e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.8149e-04\n",
      "Epoch 352/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0125 - metrics_pearsonr: 2.5894e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.8197e-04\n",
      "Epoch 353/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0126 - metrics_pearsonr: 2.5888e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.8221e-04\n",
      "Epoch 354/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0126 - metrics_pearsonr: 2.5883e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.8261e-04\n",
      "Epoch 355/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0126 - metrics_pearsonr: 2.5873e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.8285e-04\n",
      "Epoch 356/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0126 - metrics_pearsonr: 2.5855e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.8305e-04\n",
      "Epoch 357/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0125 - metrics_pearsonr: 2.5842e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.8348e-04\n",
      "Epoch 358/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0125 - metrics_pearsonr: 2.5824e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.8347e-04\n",
      "Epoch 359/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0124 - metrics_pearsonr: 2.5802e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.8377e-04\n",
      "Epoch 360/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0124 - metrics_pearsonr: 2.5782e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.8398e-04\n",
      "Epoch 361/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0124 - metrics_pearsonr: 2.5764e-04 - val_loss: 0.0181 - val_metrics_pearsonr: 4.8425e-04\n",
      "Epoch 362/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0125 - metrics_pearsonr: 2.5757e-04 - val_loss: 0.0182 - val_metrics_pearsonr: 4.8473e-04\n",
      "Epoch 363/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0127 - metrics_pearsonr: 2.5749e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.8548e-04\n",
      "Epoch 364/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0129 - metrics_pearsonr: 2.5755e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 4.8643e-04\n",
      "Epoch 365/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0132 - metrics_pearsonr: 2.5771e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 4.8772e-04\n",
      "Epoch 366/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0136 - metrics_pearsonr: 2.5791e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 4.8932e-04\n",
      "Epoch 367/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0139 - metrics_pearsonr: 2.5815e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 4.9090e-04\n",
      "Epoch 368/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0142 - metrics_pearsonr: 2.5842e-04 - val_loss: 0.0219 - val_metrics_pearsonr: 4.9264e-04\n",
      "Epoch 369/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0144 - metrics_pearsonr: 2.5878e-04 - val_loss: 0.0225 - val_metrics_pearsonr: 4.9404e-04\n",
      "Epoch 370/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0145 - metrics_pearsonr: 2.5913e-04 - val_loss: 0.0227 - val_metrics_pearsonr: 4.9499e-04\n",
      "Epoch 371/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0144 - metrics_pearsonr: 2.5949e-04 - val_loss: 0.0224 - val_metrics_pearsonr: 4.9527e-04\n",
      "Epoch 372/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0142 - metrics_pearsonr: 2.5993e-04 - val_loss: 0.0214 - val_metrics_pearsonr: 4.9477e-04\n",
      "Epoch 373/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0140 - metrics_pearsonr: 2.6023e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 4.9397e-04\n",
      "Epoch 374/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0140 - metrics_pearsonr: 2.6062e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 4.9305e-04\n",
      "Epoch 375/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0146 - metrics_pearsonr: 2.6197e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9343e-04\n",
      "Epoch 376/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0162 - metrics_pearsonr: 2.6416e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 4.9597e-04\n",
      "Epoch 377/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0190 - metrics_pearsonr: 2.6838e-04 - val_loss: 0.0249 - val_metrics_pearsonr: 5.0461e-04\n",
      "Epoch 378/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0228 - metrics_pearsonr: 2.7342e-04 - val_loss: 0.0331 - val_metrics_pearsonr: 5.1537e-04\n",
      "Epoch 379/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0270 - metrics_pearsonr: 2.7850e-04 - val_loss: 0.0438 - val_metrics_pearsonr: 5.3106e-04\n",
      "Epoch 380/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0303 - metrics_pearsonr: 2.8483e-04 - val_loss: 0.0512 - val_metrics_pearsonr: 5.4862e-04\n",
      "Epoch 381/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0308 - metrics_pearsonr: 2.9095e-04 - val_loss: 0.0461 - val_metrics_pearsonr: 5.5544e-04\n",
      "Epoch 382/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0281 - metrics_pearsonr: 2.9646e-04 - val_loss: 0.0291 - val_metrics_pearsonr: 5.4850e-04\n",
      "Epoch 383/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0252 - metrics_pearsonr: 3.0139e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.3342e-04\n",
      "Epoch 384/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0265 - metrics_pearsonr: 2.9818e-04 - val_loss: 0.0360 - val_metrics_pearsonr: 5.4301e-04\n",
      "Epoch 385/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0320 - metrics_pearsonr: 2.9758e-04 - val_loss: 0.0547 - val_metrics_pearsonr: 5.6261e-04\n",
      "Epoch 386/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0335 - metrics_pearsonr: 2.9944e-04 - val_loss: 0.0418 - val_metrics_pearsonr: 5.6626e-04\n",
      "Epoch 387/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0280 - metrics_pearsonr: 3.0489e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.3478e-04\n",
      "Epoch 388/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0226 - metrics_pearsonr: 2.9700e-04 - val_loss: 0.0281 - val_metrics_pearsonr: 5.1844e-04\n",
      "Epoch 389/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0225 - metrics_pearsonr: 2.8785e-04 - val_loss: 0.0324 - val_metrics_pearsonr: 5.3411e-04\n",
      "Epoch 390/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0207 - metrics_pearsonr: 2.8681e-04 - val_loss: 0.0212 - val_metrics_pearsonr: 5.4878e-04\n",
      "Epoch 391/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0177 - metrics_pearsonr: 2.9396e-04 - val_loss: 0.0217 - val_metrics_pearsonr: 5.2278e-04\n",
      "Epoch 392/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0167 - metrics_pearsonr: 2.8375e-04 - val_loss: 0.0250 - val_metrics_pearsonr: 5.2184e-04\n",
      "Epoch 393/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0161 - metrics_pearsonr: 2.7639e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.0754e-04\n",
      "Epoch 394/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0145 - metrics_pearsonr: 2.7051e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.0861e-04\n",
      "Epoch 395/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0146 - metrics_pearsonr: 2.7097e-04 - val_loss: 0.0216 - val_metrics_pearsonr: 5.1467e-04\n",
      "Epoch 396/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0143 - metrics_pearsonr: 2.6783e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 4.9998e-04\n",
      "Epoch 397/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0135 - metrics_pearsonr: 2.6431e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.0706e-04\n",
      "Epoch 398/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0134 - metrics_pearsonr: 2.6547e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.0215e-04\n",
      "Epoch 399/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0133 - metrics_pearsonr: 2.6340e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.1235e-04\n",
      "Epoch 400/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0129 - metrics_pearsonr: 2.6380e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9564e-04\n",
      "Epoch 401/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0128 - metrics_pearsonr: 2.5959e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 4.9743e-04\n",
      "Epoch 402/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0128 - metrics_pearsonr: 2.5812e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 4.9679e-04\n",
      "Epoch 403/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0126 - metrics_pearsonr: 2.5671e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9821e-04\n",
      "Epoch 404/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0125 - metrics_pearsonr: 2.5636e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 4.9626e-04\n",
      "Epoch 405/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0125 - metrics_pearsonr: 2.5483e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 4.9392e-04\n",
      "Epoch 406/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0123 - metrics_pearsonr: 2.5332e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9179e-04\n",
      "Epoch 407/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0123 - metrics_pearsonr: 2.5266e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9293e-04\n",
      "Epoch 408/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0123 - metrics_pearsonr: 2.5276e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9310e-04\n",
      "Epoch 409/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0123 - metrics_pearsonr: 2.5228e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9246e-04\n",
      "Epoch 410/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0122 - metrics_pearsonr: 2.5186e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9209e-04\n",
      "Epoch 411/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0122 - metrics_pearsonr: 2.5169e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9314e-04\n",
      "Epoch 412/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0122 - metrics_pearsonr: 2.5161e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9363e-04\n",
      "Epoch 413/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0121 - metrics_pearsonr: 2.5126e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9211e-04\n",
      "Epoch 414/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0121 - metrics_pearsonr: 2.5068e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9224e-04\n",
      "Epoch 415/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0121 - metrics_pearsonr: 2.5048e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9248e-04\n",
      "Epoch 416/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0121 - metrics_pearsonr: 2.5032e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9246e-04\n",
      "Epoch 417/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0121 - metrics_pearsonr: 2.5009e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9232e-04\n",
      "Epoch 418/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0121 - metrics_pearsonr: 2.4976e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9230e-04\n",
      "Epoch 419/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0121 - metrics_pearsonr: 2.4943e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9242e-04\n",
      "Epoch 420/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0120 - metrics_pearsonr: 2.4922e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9262e-04\n",
      "Epoch 421/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0120 - metrics_pearsonr: 2.4910e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9276e-04\n",
      "Epoch 422/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0120 - metrics_pearsonr: 2.4895e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9277e-04\n",
      "Epoch 423/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0120 - metrics_pearsonr: 2.4876e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9280e-04\n",
      "Epoch 424/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0120 - metrics_pearsonr: 2.4857e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9303e-04\n",
      "Epoch 425/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0120 - metrics_pearsonr: 2.4841e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9342e-04\n",
      "Epoch 426/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0120 - metrics_pearsonr: 2.4823e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9357e-04\n",
      "Epoch 427/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0120 - metrics_pearsonr: 2.4802e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9361e-04\n",
      "Epoch 428/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0120 - metrics_pearsonr: 2.4785e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9369e-04\n",
      "Epoch 429/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0120 - metrics_pearsonr: 2.4770e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9383e-04\n",
      "Epoch 430/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0120 - metrics_pearsonr: 2.4755e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9398e-04\n",
      "Epoch 431/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0120 - metrics_pearsonr: 2.4739e-04 - val_loss: 0.0183 - val_metrics_pearsonr: 4.9415e-04\n",
      "Epoch 432/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0120 - metrics_pearsonr: 2.4722e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9437e-04\n",
      "Epoch 433/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0120 - metrics_pearsonr: 2.4705e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9465e-04\n",
      "Epoch 434/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0120 - metrics_pearsonr: 2.4689e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9489e-04\n",
      "Epoch 435/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0120 - metrics_pearsonr: 2.4674e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9502e-04\n",
      "Epoch 436/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0119 - metrics_pearsonr: 2.4659e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9510e-04\n",
      "Epoch 437/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0119 - metrics_pearsonr: 2.4643e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9522e-04\n",
      "Epoch 438/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0119 - metrics_pearsonr: 2.4628e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9540e-04\n",
      "Epoch 439/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0119 - metrics_pearsonr: 2.4613e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9560e-04\n",
      "Epoch 440/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0119 - metrics_pearsonr: 2.4598e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9579e-04\n",
      "Epoch 441/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0119 - metrics_pearsonr: 2.4582e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9596e-04\n",
      "Epoch 442/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0119 - metrics_pearsonr: 2.4566e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9611e-04\n",
      "Epoch 443/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0119 - metrics_pearsonr: 2.4551e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9626e-04\n",
      "Epoch 444/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0119 - metrics_pearsonr: 2.4536e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9640e-04\n",
      "Epoch 445/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0119 - metrics_pearsonr: 2.4521e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9653e-04\n",
      "Epoch 446/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0119 - metrics_pearsonr: 2.4506e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9667e-04\n",
      "Epoch 447/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0119 - metrics_pearsonr: 2.4491e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9681e-04\n",
      "Epoch 448/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0119 - metrics_pearsonr: 2.4476e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9696e-04\n",
      "Epoch 449/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0119 - metrics_pearsonr: 2.4462e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9710e-04\n",
      "Epoch 450/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0119 - metrics_pearsonr: 2.4447e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9725e-04\n",
      "Epoch 451/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0119 - metrics_pearsonr: 2.4432e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9739e-04\n",
      "Epoch 452/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0119 - metrics_pearsonr: 2.4417e-04 - val_loss: 0.0184 - val_metrics_pearsonr: 4.9754e-04\n",
      "Epoch 453/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0119 - metrics_pearsonr: 2.4402e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9768e-04\n",
      "Epoch 454/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0119 - metrics_pearsonr: 2.4387e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9780e-04\n",
      "Epoch 455/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0119 - metrics_pearsonr: 2.4373e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9792e-04\n",
      "Epoch 456/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0118 - metrics_pearsonr: 2.4358e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9804e-04\n",
      "Epoch 457/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0118 - metrics_pearsonr: 2.4343e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9815e-04\n",
      "Epoch 458/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0118 - metrics_pearsonr: 2.4328e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9826e-04\n",
      "Epoch 459/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0118 - metrics_pearsonr: 2.4314e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9837e-04\n",
      "Epoch 460/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0118 - metrics_pearsonr: 2.4299e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9847e-04\n",
      "Epoch 461/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0118 - metrics_pearsonr: 2.4284e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9857e-04\n",
      "Epoch 462/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0118 - metrics_pearsonr: 2.4270e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9868e-04\n",
      "Epoch 463/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0118 - metrics_pearsonr: 2.4255e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9880e-04\n",
      "Epoch 464/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0118 - metrics_pearsonr: 2.4241e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9894e-04\n",
      "Epoch 465/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0118 - metrics_pearsonr: 2.4226e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9909e-04\n",
      "Epoch 466/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0118 - metrics_pearsonr: 2.4212e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9923e-04\n",
      "Epoch 467/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0118 - metrics_pearsonr: 2.4197e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9938e-04\n",
      "Epoch 468/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0118 - metrics_pearsonr: 2.4183e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9951e-04\n",
      "Epoch 469/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0118 - metrics_pearsonr: 2.4169e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9965e-04\n",
      "Epoch 470/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0118 - metrics_pearsonr: 2.4155e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9979e-04\n",
      "Epoch 471/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0118 - metrics_pearsonr: 2.4140e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 4.9994e-04\n",
      "Epoch 472/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0118 - metrics_pearsonr: 2.4126e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0009e-04\n",
      "Epoch 473/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0118 - metrics_pearsonr: 2.4112e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0023e-04\n",
      "Epoch 474/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0118 - metrics_pearsonr: 2.4097e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0038e-04\n",
      "Epoch 475/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0118 - metrics_pearsonr: 2.4083e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0051e-04\n",
      "Epoch 476/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0118 - metrics_pearsonr: 2.4069e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0066e-04\n",
      "Epoch 477/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0118 - metrics_pearsonr: 2.4054e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0081e-04\n",
      "Epoch 478/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0117 - metrics_pearsonr: 2.4040e-04 - val_loss: 0.0185 - val_metrics_pearsonr: 5.0095e-04\n",
      "Epoch 479/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0117 - metrics_pearsonr: 2.4025e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0110e-04\n",
      "Epoch 480/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0117 - metrics_pearsonr: 2.4011e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0124e-04\n",
      "Epoch 481/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0117 - metrics_pearsonr: 2.3997e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0138e-04\n",
      "Epoch 482/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0117 - metrics_pearsonr: 2.3983e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0151e-04\n",
      "Epoch 483/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0117 - metrics_pearsonr: 2.3969e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0164e-04\n",
      "Epoch 484/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0117 - metrics_pearsonr: 2.3955e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0176e-04\n",
      "Epoch 485/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0117 - metrics_pearsonr: 2.3941e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0190e-04\n",
      "Epoch 486/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0117 - metrics_pearsonr: 2.3928e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0205e-04\n",
      "Epoch 487/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0117 - metrics_pearsonr: 2.3914e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0220e-04\n",
      "Epoch 488/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0117 - metrics_pearsonr: 2.3900e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0235e-04\n",
      "Epoch 489/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0117 - metrics_pearsonr: 2.3886e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0250e-04\n",
      "Epoch 490/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0117 - metrics_pearsonr: 2.3872e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0265e-04\n",
      "Epoch 491/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0117 - metrics_pearsonr: 2.3857e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0280e-04\n",
      "Epoch 492/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0117 - metrics_pearsonr: 2.3843e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0297e-04\n",
      "Epoch 493/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0117 - metrics_pearsonr: 2.3828e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0314e-04\n",
      "Epoch 494/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0117 - metrics_pearsonr: 2.3814e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0331e-04\n",
      "Epoch 495/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0117 - metrics_pearsonr: 2.3800e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0347e-04\n",
      "Epoch 496/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0117 - metrics_pearsonr: 2.3786e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0363e-04\n",
      "Epoch 497/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0117 - metrics_pearsonr: 2.3772e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0378e-04\n",
      "Epoch 498/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0117 - metrics_pearsonr: 2.3759e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0392e-04\n",
      "Epoch 499/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0117 - metrics_pearsonr: 2.3746e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0406e-04\n",
      "Epoch 500/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0117 - metrics_pearsonr: 2.3733e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0419e-04\n",
      "Epoch 501/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0117 - metrics_pearsonr: 2.3720e-04 - val_loss: 0.0186 - val_metrics_pearsonr: 5.0432e-04\n",
      "Epoch 502/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0117 - metrics_pearsonr: 2.3707e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0447e-04\n",
      "Epoch 503/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0117 - metrics_pearsonr: 2.3695e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0462e-04\n",
      "Epoch 504/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0117 - metrics_pearsonr: 2.3682e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0478e-04\n",
      "Epoch 505/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0117 - metrics_pearsonr: 2.3670e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0494e-04\n",
      "Epoch 506/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0117 - metrics_pearsonr: 2.3656e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0511e-04\n",
      "Epoch 507/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0116 - metrics_pearsonr: 2.3642e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0529e-04\n",
      "Epoch 508/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0116 - metrics_pearsonr: 2.3627e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0549e-04\n",
      "Epoch 509/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0116 - metrics_pearsonr: 2.3612e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0573e-04\n",
      "Epoch 510/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0116 - metrics_pearsonr: 2.3597e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0600e-04\n",
      "Epoch 511/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0116 - metrics_pearsonr: 2.3583e-04 - val_loss: 0.0187 - val_metrics_pearsonr: 5.0632e-04\n",
      "Epoch 512/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0116 - metrics_pearsonr: 2.3569e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.0665e-04\n",
      "Epoch 513/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0116 - metrics_pearsonr: 2.3556e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0699e-04\n",
      "Epoch 514/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0117 - metrics_pearsonr: 2.3544e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0729e-04\n",
      "Epoch 515/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0117 - metrics_pearsonr: 2.3533e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0755e-04\n",
      "Epoch 516/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0117 - metrics_pearsonr: 2.3521e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0774e-04\n",
      "Epoch 517/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0117 - metrics_pearsonr: 2.3510e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0784e-04\n",
      "Epoch 518/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0116 - metrics_pearsonr: 2.3499e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.0789e-04\n",
      "Epoch 519/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0116 - metrics_pearsonr: 2.3490e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.0792e-04\n",
      "Epoch 520/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0117 - metrics_pearsonr: 2.3482e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.0800e-04\n",
      "Epoch 521/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0117 - metrics_pearsonr: 2.3478e-04 - val_loss: 0.0188 - val_metrics_pearsonr: 5.0812e-04\n",
      "Epoch 522/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0118 - metrics_pearsonr: 2.3479e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.0836e-04\n",
      "Epoch 523/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0119 - metrics_pearsonr: 2.3485e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.0882e-04\n",
      "Epoch 524/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0121 - metrics_pearsonr: 2.3495e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.0943e-04\n",
      "Epoch 525/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0123 - metrics_pearsonr: 2.3509e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.1016e-04\n",
      "Epoch 526/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0124 - metrics_pearsonr: 2.3521e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.1086e-04\n",
      "Epoch 527/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0124 - metrics_pearsonr: 2.3530e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.1141e-04\n",
      "Epoch 528/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0124 - metrics_pearsonr: 2.3533e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.1177e-04\n",
      "Epoch 529/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0123 - metrics_pearsonr: 2.3529e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.1191e-04\n",
      "Epoch 530/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0122 - metrics_pearsonr: 2.3520e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.1198e-04\n",
      "Epoch 531/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0120 - metrics_pearsonr: 2.3511e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.1205e-04\n",
      "Epoch 532/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0121 - metrics_pearsonr: 2.3512e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1243e-04\n",
      "Epoch 533/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0123 - metrics_pearsonr: 2.3534e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.1328e-04\n",
      "Epoch 534/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0129 - metrics_pearsonr: 2.3582e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.1501e-04\n",
      "Epoch 535/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0138 - metrics_pearsonr: 2.3666e-04 - val_loss: 0.0216 - val_metrics_pearsonr: 5.1794e-04\n",
      "Epoch 536/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0149 - metrics_pearsonr: 2.3768e-04 - val_loss: 0.0240 - val_metrics_pearsonr: 5.2208e-04\n",
      "Epoch 537/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0161 - metrics_pearsonr: 2.3893e-04 - val_loss: 0.0269 - val_metrics_pearsonr: 5.2689e-04\n",
      "Epoch 538/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0172 - metrics_pearsonr: 2.4048e-04 - val_loss: 0.0298 - val_metrics_pearsonr: 5.3200e-04\n",
      "Epoch 539/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0180 - metrics_pearsonr: 2.4254e-04 - val_loss: 0.0315 - val_metrics_pearsonr: 5.3599e-04\n",
      "Epoch 540/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0181 - metrics_pearsonr: 2.4499e-04 - val_loss: 0.0307 - val_metrics_pearsonr: 5.3695e-04\n",
      "Epoch 541/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0174 - metrics_pearsonr: 2.4687e-04 - val_loss: 0.0268 - val_metrics_pearsonr: 5.3375e-04\n",
      "Epoch 542/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0165 - metrics_pearsonr: 2.4702e-04 - val_loss: 0.0215 - val_metrics_pearsonr: 5.2849e-04\n",
      "Epoch 543/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0165 - metrics_pearsonr: 2.4712e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.2702e-04\n",
      "Epoch 544/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.0190 - metrics_pearsonr: 2.5108e-04 - val_loss: 0.0251 - val_metrics_pearsonr: 5.3564e-04\n",
      "Epoch 545/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0240 - metrics_pearsonr: 2.5833e-04 - val_loss: 0.0382 - val_metrics_pearsonr: 5.5382e-04\n",
      "Epoch 546/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0292 - metrics_pearsonr: 2.6257e-04 - val_loss: 0.0508 - val_metrics_pearsonr: 5.7029e-04\n",
      "Epoch 547/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0313 - metrics_pearsonr: 2.6538e-04 - val_loss: 0.0491 - val_metrics_pearsonr: 5.7831e-04\n",
      "Epoch 548/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0288 - metrics_pearsonr: 2.7045e-04 - val_loss: 0.0306 - val_metrics_pearsonr: 5.7161e-04\n",
      "Epoch 549/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0240 - metrics_pearsonr: 2.7202e-04 - val_loss: 0.0204 - val_metrics_pearsonr: 5.5529e-04\n",
      "Epoch 550/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0231 - metrics_pearsonr: 2.6935e-04 - val_loss: 0.0346 - val_metrics_pearsonr: 5.6313e-04\n",
      "Epoch 551/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0259 - metrics_pearsonr: 2.6693e-04 - val_loss: 0.0435 - val_metrics_pearsonr: 5.8285e-04\n",
      "Epoch 552/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0251 - metrics_pearsonr: 2.7006e-04 - val_loss: 0.0292 - val_metrics_pearsonr: 5.8214e-04\n",
      "Epoch 553/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0209 - metrics_pearsonr: 2.7581e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.3977e-04\n",
      "Epoch 554/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0182 - metrics_pearsonr: 2.6267e-04 - val_loss: 0.0280 - val_metrics_pearsonr: 5.4107e-04\n",
      "Epoch 555/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0184 - metrics_pearsonr: 2.5788e-04 - val_loss: 0.0261 - val_metrics_pearsonr: 5.5603e-04\n",
      "Epoch 556/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0165 - metrics_pearsonr: 2.6030e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.6571e-04\n",
      "Epoch 557/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0147 - metrics_pearsonr: 2.6224e-04 - val_loss: 0.0217 - val_metrics_pearsonr: 5.3681e-04\n",
      "Epoch 558/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0144 - metrics_pearsonr: 2.5250e-04 - val_loss: 0.0228 - val_metrics_pearsonr: 5.4212e-04\n",
      "Epoch 559/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0137 - metrics_pearsonr: 2.4717e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.2653e-04\n",
      "Epoch 560/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0129 - metrics_pearsonr: 2.4354e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.3450e-04\n",
      "Epoch 561/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0131 - metrics_pearsonr: 2.4449e-04 - val_loss: 0.0209 - val_metrics_pearsonr: 5.3182e-04\n",
      "Epoch 562/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0128 - metrics_pearsonr: 2.4095e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.2597e-04\n",
      "Epoch 563/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0123 - metrics_pearsonr: 2.3991e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2593e-04\n",
      "Epoch 564/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0121 - metrics_pearsonr: 2.3972e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.2267e-04\n",
      "Epoch 565/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0121 - metrics_pearsonr: 2.3790e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.3040e-04\n",
      "Epoch 566/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0119 - metrics_pearsonr: 2.3783e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1795e-04\n",
      "Epoch 567/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0118 - metrics_pearsonr: 2.3485e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.1970e-04\n",
      "Epoch 568/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0119 - metrics_pearsonr: 2.3397e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.1924e-04\n",
      "Epoch 569/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0118 - metrics_pearsonr: 2.3299e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1900e-04\n",
      "Epoch 570/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0116 - metrics_pearsonr: 2.3238e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1741e-04\n",
      "Epoch 571/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0116 - metrics_pearsonr: 2.3138e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.1638e-04\n",
      "Epoch 572/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0116 - metrics_pearsonr: 2.3039e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.1575e-04\n",
      "Epoch 573/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0115 - metrics_pearsonr: 2.2996e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1655e-04\n",
      "Epoch 574/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0115 - metrics_pearsonr: 2.3016e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1649e-04\n",
      "Epoch 575/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0115 - metrics_pearsonr: 2.2985e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1572e-04\n",
      "Epoch 576/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0115 - metrics_pearsonr: 2.2942e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1550e-04\n",
      "Epoch 577/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0114 - metrics_pearsonr: 2.2932e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1577e-04\n",
      "Epoch 578/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0114 - metrics_pearsonr: 2.2916e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1677e-04\n",
      "Epoch 579/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0114 - metrics_pearsonr: 2.2894e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1628e-04\n",
      "Epoch 580/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0114 - metrics_pearsonr: 2.2859e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1604e-04\n",
      "Epoch 581/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0114 - metrics_pearsonr: 2.2837e-04 - val_loss: 0.0189 - val_metrics_pearsonr: 5.1636e-04\n",
      "Epoch 582/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0114 - metrics_pearsonr: 2.2826e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1672e-04\n",
      "Epoch 583/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0114 - metrics_pearsonr: 2.2810e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1692e-04\n",
      "Epoch 584/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0114 - metrics_pearsonr: 2.2788e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1700e-04\n",
      "Epoch 585/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0114 - metrics_pearsonr: 2.2766e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1726e-04\n",
      "Epoch 586/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0113 - metrics_pearsonr: 2.2749e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1758e-04\n",
      "Epoch 587/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0113 - metrics_pearsonr: 2.2739e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1774e-04\n",
      "Epoch 588/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0113 - metrics_pearsonr: 2.2729e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1769e-04\n",
      "Epoch 589/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0113 - metrics_pearsonr: 2.2715e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1754e-04\n",
      "Epoch 590/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0113 - metrics_pearsonr: 2.2698e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1755e-04\n",
      "Epoch 591/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0113 - metrics_pearsonr: 2.2685e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1780e-04\n",
      "Epoch 592/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0113 - metrics_pearsonr: 2.2673e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1816e-04\n",
      "Epoch 593/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0113 - metrics_pearsonr: 2.2660e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1836e-04\n",
      "Epoch 594/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0113 - metrics_pearsonr: 2.2644e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1835e-04\n",
      "Epoch 595/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0113 - metrics_pearsonr: 2.2629e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1837e-04\n",
      "Epoch 596/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0113 - metrics_pearsonr: 2.2617e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1845e-04\n",
      "Epoch 597/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0113 - metrics_pearsonr: 2.2606e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1846e-04\n",
      "Epoch 598/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0113 - metrics_pearsonr: 2.2594e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1853e-04\n",
      "Epoch 599/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0113 - metrics_pearsonr: 2.2581e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1869e-04\n",
      "Epoch 600/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0113 - metrics_pearsonr: 2.2569e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1878e-04\n",
      "Epoch 601/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0113 - metrics_pearsonr: 2.2557e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1886e-04\n",
      "Epoch 602/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0113 - metrics_pearsonr: 2.2545e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1895e-04\n",
      "Epoch 603/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0113 - metrics_pearsonr: 2.2532e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1901e-04\n",
      "Epoch 604/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0113 - metrics_pearsonr: 2.2519e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1908e-04\n",
      "Epoch 605/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0113 - metrics_pearsonr: 2.2506e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1920e-04\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0113 - metrics_pearsonr: 2.2494e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1928e-04\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0113 - metrics_pearsonr: 2.2482e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1937e-04\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0113 - metrics_pearsonr: 2.2470e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1946e-04\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0112 - metrics_pearsonr: 2.2458e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1956e-04\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0112 - metrics_pearsonr: 2.2447e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1966e-04\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0112 - metrics_pearsonr: 2.2435e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1974e-04\n",
      "Epoch 612/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0112 - metrics_pearsonr: 2.2423e-04 - val_loss: 0.0190 - val_metrics_pearsonr: 5.1986e-04\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0112 - metrics_pearsonr: 2.2411e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2000e-04\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0112 - metrics_pearsonr: 2.2397e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2010e-04\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0112 - metrics_pearsonr: 2.2385e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2022e-04\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0112 - metrics_pearsonr: 2.2374e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2028e-04\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0112 - metrics_pearsonr: 2.2362e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2036e-04\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0112 - metrics_pearsonr: 2.2350e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2046e-04\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0112 - metrics_pearsonr: 2.2339e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2055e-04\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0112 - metrics_pearsonr: 2.2328e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2065e-04\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0112 - metrics_pearsonr: 2.2316e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2073e-04\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0112 - metrics_pearsonr: 2.2304e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2081e-04\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0112 - metrics_pearsonr: 2.2293e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2087e-04\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0112 - metrics_pearsonr: 2.2281e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2094e-04\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0112 - metrics_pearsonr: 2.2268e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2103e-04\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0112 - metrics_pearsonr: 2.2257e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2112e-04\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0112 - metrics_pearsonr: 2.2245e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2121e-04\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0112 - metrics_pearsonr: 2.2233e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2130e-04\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0112 - metrics_pearsonr: 2.2221e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2140e-04\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0112 - metrics_pearsonr: 2.2210e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2150e-04\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0112 - metrics_pearsonr: 2.2198e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2161e-04\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0112 - metrics_pearsonr: 2.2187e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2173e-04\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0112 - metrics_pearsonr: 2.2176e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2183e-04\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0112 - metrics_pearsonr: 2.2165e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2193e-04\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0112 - metrics_pearsonr: 2.2153e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2205e-04\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0111 - metrics_pearsonr: 2.2142e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2216e-04\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0111 - metrics_pearsonr: 2.2130e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2229e-04\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0111 - metrics_pearsonr: 2.2119e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2241e-04\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0111 - metrics_pearsonr: 2.2106e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2254e-04\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0111 - metrics_pearsonr: 2.2095e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2268e-04\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0111 - metrics_pearsonr: 2.2083e-04 - val_loss: 0.0191 - val_metrics_pearsonr: 5.2283e-04\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0111 - metrics_pearsonr: 2.2071e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2296e-04\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0111 - metrics_pearsonr: 2.2060e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2309e-04\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0111 - metrics_pearsonr: 2.2049e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2322e-04\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0111 - metrics_pearsonr: 2.2038e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2333e-04\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0111 - metrics_pearsonr: 2.2027e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2343e-04\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0111 - metrics_pearsonr: 2.2016e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2353e-04\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0111 - metrics_pearsonr: 2.2006e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2364e-04\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0111 - metrics_pearsonr: 2.1995e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2375e-04\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0111 - metrics_pearsonr: 2.1984e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2386e-04\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0111 - metrics_pearsonr: 2.1973e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2396e-04\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0111 - metrics_pearsonr: 2.1962e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2407e-04\n",
      "Epoch 653/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0111 - metrics_pearsonr: 2.1950e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2418e-04\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0111 - metrics_pearsonr: 2.1937e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2432e-04\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0111 - metrics_pearsonr: 2.1925e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2446e-04\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0111 - metrics_pearsonr: 2.1912e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2463e-04\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0111 - metrics_pearsonr: 2.1901e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2481e-04\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0111 - metrics_pearsonr: 2.1890e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2502e-04\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0111 - metrics_pearsonr: 2.1879e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2521e-04\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0111 - metrics_pearsonr: 2.1869e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2534e-04\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0111 - metrics_pearsonr: 2.1859e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2542e-04\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0111 - metrics_pearsonr: 2.1849e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2546e-04\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0111 - metrics_pearsonr: 2.1841e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2551e-04\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0111 - metrics_pearsonr: 2.1833e-04 - val_loss: 0.0192 - val_metrics_pearsonr: 5.2561e-04\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0111 - metrics_pearsonr: 2.1826e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2574e-04\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0111 - metrics_pearsonr: 2.1821e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2594e-04\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0112 - metrics_pearsonr: 2.1817e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.2615e-04\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0112 - metrics_pearsonr: 2.1813e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.2639e-04\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0113 - metrics_pearsonr: 2.1807e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.2658e-04\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0112 - metrics_pearsonr: 2.1800e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.2672e-04\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0112 - metrics_pearsonr: 2.1790e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.2681e-04\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0112 - metrics_pearsonr: 2.1778e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2688e-04\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0111 - metrics_pearsonr: 2.1765e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2705e-04\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0111 - metrics_pearsonr: 2.1754e-04 - val_loss: 0.0193 - val_metrics_pearsonr: 5.2737e-04\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0112 - metrics_pearsonr: 2.1748e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.2788e-04\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0114 - metrics_pearsonr: 2.1748e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.2860e-04\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0116 - metrics_pearsonr: 2.1754e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.2955e-04\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0118 - metrics_pearsonr: 2.1765e-04 - val_loss: 0.0209 - val_metrics_pearsonr: 5.3061e-04\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0120 - metrics_pearsonr: 2.1780e-04 - val_loss: 0.0214 - val_metrics_pearsonr: 5.3163e-04\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0121 - metrics_pearsonr: 2.1799e-04 - val_loss: 0.0217 - val_metrics_pearsonr: 5.3241e-04\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0121 - metrics_pearsonr: 2.1818e-04 - val_loss: 0.0216 - val_metrics_pearsonr: 5.3277e-04\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0120 - metrics_pearsonr: 2.1832e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 5.3258e-04\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0119 - metrics_pearsonr: 2.1841e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.3203e-04\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0118 - metrics_pearsonr: 2.1853e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3147e-04\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0120 - metrics_pearsonr: 2.1884e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3154e-04\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0127 - metrics_pearsonr: 2.1962e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.3299e-04\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0138 - metrics_pearsonr: 2.2093e-04 - val_loss: 0.0224 - val_metrics_pearsonr: 5.3611e-04\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0155 - metrics_pearsonr: 2.2270e-04 - val_loss: 0.0257 - val_metrics_pearsonr: 5.4139e-04\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0172 - metrics_pearsonr: 2.2486e-04 - val_loss: 0.0296 - val_metrics_pearsonr: 5.4758e-04\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0186 - metrics_pearsonr: 2.2688e-04 - val_loss: 0.0326 - val_metrics_pearsonr: 5.5412e-04\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0190 - metrics_pearsonr: 2.2851e-04 - val_loss: 0.0328 - val_metrics_pearsonr: 5.5773e-04\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0182 - metrics_pearsonr: 2.2982e-04 - val_loss: 0.0290 - val_metrics_pearsonr: 5.5744e-04\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0169 - metrics_pearsonr: 2.3124e-04 - val_loss: 0.0230 - val_metrics_pearsonr: 5.5352e-04\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0163 - metrics_pearsonr: 2.3277e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4929e-04\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0179 - metrics_pearsonr: 2.3403e-04 - val_loss: 0.0251 - val_metrics_pearsonr: 5.5264e-04\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0220 - metrics_pearsonr: 2.3604e-04 - val_loss: 0.0384 - val_metrics_pearsonr: 5.6660e-04\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0265 - metrics_pearsonr: 2.3899e-04 - val_loss: 0.0493 - val_metrics_pearsonr: 5.8348e-04\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0280 - metrics_pearsonr: 2.4511e-04 - val_loss: 0.0444 - val_metrics_pearsonr: 5.9194e-04\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0254 - metrics_pearsonr: 2.5419e-04 - val_loss: 0.0262 - val_metrics_pearsonr: 5.6996e-04\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0213 - metrics_pearsonr: 2.4969e-04 - val_loss: 0.0218 - val_metrics_pearsonr: 5.5980e-04\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0219 - metrics_pearsonr: 2.4966e-04 - val_loss: 0.0358 - val_metrics_pearsonr: 5.7703e-04\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0244 - metrics_pearsonr: 2.5423e-04 - val_loss: 0.0384 - val_metrics_pearsonr: 6.1693e-04\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0225 - metrics_pearsonr: 2.6300e-04 - val_loss: 0.0261 - val_metrics_pearsonr: 6.1576e-04\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0185 - metrics_pearsonr: 2.5986e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.5952e-04\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0166 - metrics_pearsonr: 2.4310e-04 - val_loss: 0.0277 - val_metrics_pearsonr: 5.7370e-04\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0165 - metrics_pearsonr: 2.3905e-04 - val_loss: 0.0252 - val_metrics_pearsonr: 5.5557e-04\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0148 - metrics_pearsonr: 2.3915e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.9608e-04\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0138 - metrics_pearsonr: 2.5040e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 5.6032e-04\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0133 - metrics_pearsonr: 2.4418e-04 - val_loss: 0.0224 - val_metrics_pearsonr: 5.6782e-04\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0129 - metrics_pearsonr: 2.4085e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.6302e-04\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0122 - metrics_pearsonr: 2.3704e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.5895e-04\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0121 - metrics_pearsonr: 2.3100e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 5.5072e-04\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0120 - metrics_pearsonr: 2.2404e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.4149e-04\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0116 - metrics_pearsonr: 2.1970e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3672e-04\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0115 - metrics_pearsonr: 2.1876e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4271e-04\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0115 - metrics_pearsonr: 2.1910e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.3737e-04\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0114 - metrics_pearsonr: 2.1755e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3806e-04\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0112 - metrics_pearsonr: 2.1748e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3541e-04\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0112 - metrics_pearsonr: 2.1661e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.3832e-04\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0112 - metrics_pearsonr: 2.1617e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.3575e-04\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0111 - metrics_pearsonr: 2.1518e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3425e-04\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0110 - metrics_pearsonr: 2.1472e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3482e-04\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0110 - metrics_pearsonr: 2.1447e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3604e-04\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0110 - metrics_pearsonr: 2.1438e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3532e-04\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0110 - metrics_pearsonr: 2.1401e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3496e-04\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0109 - metrics_pearsonr: 2.1355e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3490e-04\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0109 - metrics_pearsonr: 2.1317e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3502e-04\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0109 - metrics_pearsonr: 2.1308e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3497e-04\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0109 - metrics_pearsonr: 2.1304e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3439e-04\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0109 - metrics_pearsonr: 2.1278e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3429e-04\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0109 - metrics_pearsonr: 2.1261e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3470e-04\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0109 - metrics_pearsonr: 2.1255e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3492e-04\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0109 - metrics_pearsonr: 2.1238e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3469e-04\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0109 - metrics_pearsonr: 2.1210e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3472e-04\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0109 - metrics_pearsonr: 2.1194e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3503e-04\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0109 - metrics_pearsonr: 2.1189e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3493e-04\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0108 - metrics_pearsonr: 2.1177e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3472e-04\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0108 - metrics_pearsonr: 2.1162e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3481e-04\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0108 - metrics_pearsonr: 2.1150e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3505e-04\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0108 - metrics_pearsonr: 2.1140e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3519e-04\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0108 - metrics_pearsonr: 2.1127e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3525e-04\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0108 - metrics_pearsonr: 2.1113e-04 - val_loss: 0.0194 - val_metrics_pearsonr: 5.3532e-04\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0108 - metrics_pearsonr: 2.1100e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3537e-04\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0108 - metrics_pearsonr: 2.1089e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3544e-04\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0108 - metrics_pearsonr: 2.1079e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3552e-04\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0108 - metrics_pearsonr: 2.1069e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3558e-04\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0108 - metrics_pearsonr: 2.1058e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3568e-04\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0108 - metrics_pearsonr: 2.1047e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3581e-04\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0108 - metrics_pearsonr: 2.1037e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3595e-04\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0108 - metrics_pearsonr: 2.1026e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3604e-04\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0108 - metrics_pearsonr: 2.1014e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3613e-04\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0108 - metrics_pearsonr: 2.1003e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3625e-04\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0108 - metrics_pearsonr: 2.0993e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3639e-04\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0108 - metrics_pearsonr: 2.0982e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3650e-04\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0108 - metrics_pearsonr: 2.0971e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3658e-04\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0108 - metrics_pearsonr: 2.0961e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3669e-04\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0108 - metrics_pearsonr: 2.0951e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3680e-04\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0108 - metrics_pearsonr: 2.0940e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3686e-04\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0108 - metrics_pearsonr: 2.0930e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3694e-04\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0108 - metrics_pearsonr: 2.0919e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3703e-04\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0107 - metrics_pearsonr: 2.0909e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3709e-04\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0107 - metrics_pearsonr: 2.0897e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3716e-04\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0107 - metrics_pearsonr: 2.0886e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3754e-04\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0107 - metrics_pearsonr: 2.0874e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3759e-04\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0107 - metrics_pearsonr: 2.0865e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3767e-04\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0107 - metrics_pearsonr: 2.0855e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3773e-04\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0107 - metrics_pearsonr: 2.0843e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3782e-04\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0107 - metrics_pearsonr: 2.0833e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3793e-04\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0107 - metrics_pearsonr: 2.0824e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3804e-04\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0107 - metrics_pearsonr: 2.0815e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3815e-04\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0107 - metrics_pearsonr: 2.0803e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3826e-04\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0107 - metrics_pearsonr: 2.0794e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3841e-04\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0107 - metrics_pearsonr: 2.0785e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3851e-04\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0107 - metrics_pearsonr: 2.0774e-04 - val_loss: 0.0195 - val_metrics_pearsonr: 5.3862e-04\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0107 - metrics_pearsonr: 2.0763e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3875e-04\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0107 - metrics_pearsonr: 2.0752e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3884e-04\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0107 - metrics_pearsonr: 2.0742e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3897e-04\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0107 - metrics_pearsonr: 2.0732e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3909e-04\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0107 - metrics_pearsonr: 2.0722e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3919e-04\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0107 - metrics_pearsonr: 2.0713e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3931e-04\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0107 - metrics_pearsonr: 2.0702e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3939e-04\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0107 - metrics_pearsonr: 2.0693e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3951e-04\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0107 - metrics_pearsonr: 2.0684e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3963e-04\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0107 - metrics_pearsonr: 2.0674e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3974e-04\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0107 - metrics_pearsonr: 2.0665e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3988e-04\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0107 - metrics_pearsonr: 2.0655e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.3998e-04\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0107 - metrics_pearsonr: 2.0645e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4010e-04\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0107 - metrics_pearsonr: 2.0635e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4020e-04\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0107 - metrics_pearsonr: 2.0625e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4032e-04\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0106 - metrics_pearsonr: 2.0614e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4043e-04\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0106 - metrics_pearsonr: 2.0604e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4056e-04\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0107 - metrics_pearsonr: 2.0594e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4067e-04\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0107 - metrics_pearsonr: 2.0584e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4078e-04\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0107 - metrics_pearsonr: 2.0575e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4087e-04\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0106 - metrics_pearsonr: 2.0566e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4097e-04\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0106 - metrics_pearsonr: 2.0557e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4104e-04\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0106 - metrics_pearsonr: 2.0549e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4114e-04\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0106 - metrics_pearsonr: 2.0541e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4126e-04\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0107 - metrics_pearsonr: 2.0534e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4143e-04\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0107 - metrics_pearsonr: 2.0527e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4162e-04\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0107 - metrics_pearsonr: 2.0521e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4181e-04\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0107 - metrics_pearsonr: 2.0514e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4197e-04\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0107 - metrics_pearsonr: 2.0505e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4208e-04\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0107 - metrics_pearsonr: 2.0495e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4215e-04\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0106 - metrics_pearsonr: 2.0483e-04 - val_loss: 0.0196 - val_metrics_pearsonr: 5.4220e-04\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0106 - metrics_pearsonr: 2.0473e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4226e-04\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0107 - metrics_pearsonr: 2.0464e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.4242e-04\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0107 - metrics_pearsonr: 2.0457e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.4264e-04\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0108 - metrics_pearsonr: 2.0452e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.4290e-04\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0108 - metrics_pearsonr: 2.0449e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.4323e-04\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0109 - metrics_pearsonr: 2.0447e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.4349e-04\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0108 - metrics_pearsonr: 2.0444e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.4362e-04\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0108 - metrics_pearsonr: 2.0441e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.4360e-04\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0108 - metrics_pearsonr: 2.0438e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.4352e-04\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0108 - metrics_pearsonr: 2.0439e-04 - val_loss: 0.0197 - val_metrics_pearsonr: 5.4355e-04\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0109 - metrics_pearsonr: 2.0447e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4389e-04\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0112 - metrics_pearsonr: 2.0467e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.4468e-04\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0115 - metrics_pearsonr: 2.0500e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.4596e-04\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0118 - metrics_pearsonr: 2.0540e-04 - val_loss: 0.0217 - val_metrics_pearsonr: 5.4754e-04\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0121 - metrics_pearsonr: 2.0583e-04 - val_loss: 0.0222 - val_metrics_pearsonr: 5.4903e-04\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0122 - metrics_pearsonr: 2.0618e-04 - val_loss: 0.0223 - val_metrics_pearsonr: 5.4999e-04\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0121 - metrics_pearsonr: 2.0640e-04 - val_loss: 0.0219 - val_metrics_pearsonr: 5.5019e-04\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0118 - metrics_pearsonr: 2.0648e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.4971e-04\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0116 - metrics_pearsonr: 2.0653e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.4887e-04\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0116 - metrics_pearsonr: 2.0670e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.4834e-04\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0122 - metrics_pearsonr: 2.0714e-04 - val_loss: 0.0208 - val_metrics_pearsonr: 5.4928e-04\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0133 - metrics_pearsonr: 2.0799e-04 - val_loss: 0.0234 - val_metrics_pearsonr: 5.5252e-04\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0148 - metrics_pearsonr: 2.0926e-04 - val_loss: 0.0271 - val_metrics_pearsonr: 5.5838e-04\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0164 - metrics_pearsonr: 2.1080e-04 - val_loss: 0.0311 - val_metrics_pearsonr: 5.6500e-04\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0174 - metrics_pearsonr: 2.1288e-04 - val_loss: 0.0333 - val_metrics_pearsonr: 5.7042e-04\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0176 - metrics_pearsonr: 2.1549e-04 - val_loss: 0.0317 - val_metrics_pearsonr: 5.7118e-04\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0167 - metrics_pearsonr: 2.1737e-04 - val_loss: 0.0262 - val_metrics_pearsonr: 5.6636e-04\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0156 - metrics_pearsonr: 2.1733e-04 - val_loss: 0.0208 - val_metrics_pearsonr: 5.6104e-04\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0160 - metrics_pearsonr: 2.1778e-04 - val_loss: 0.0221 - val_metrics_pearsonr: 5.6370e-04\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0192 - metrics_pearsonr: 2.2171e-04 - val_loss: 0.0318 - val_metrics_pearsonr: 5.7825e-04\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0235 - metrics_pearsonr: 2.2571e-04 - val_loss: 0.0430 - val_metrics_pearsonr: 5.9493e-04\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0257 - metrics_pearsonr: 2.2737e-04 - val_loss: 0.0437 - val_metrics_pearsonr: 6.0049e-04\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0241 - metrics_pearsonr: 2.2942e-04 - val_loss: 0.0305 - val_metrics_pearsonr: 5.8954e-04\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0204 - metrics_pearsonr: 2.2890e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.7450e-04\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0190 - metrics_pearsonr: 2.2642e-04 - val_loss: 0.0290 - val_metrics_pearsonr: 5.7835e-04\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0212 - metrics_pearsonr: 2.2527e-04 - val_loss: 0.0390 - val_metrics_pearsonr: 5.9157e-04\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0215 - metrics_pearsonr: 2.2650e-04 - val_loss: 0.0321 - val_metrics_pearsonr: 5.9884e-04\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0188 - metrics_pearsonr: 2.3221e-04 - val_loss: 0.0209 - val_metrics_pearsonr: 5.7198e-04\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0160 - metrics_pearsonr: 2.2591e-04 - val_loss: 0.0239 - val_metrics_pearsonr: 5.6273e-04\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0161 - metrics_pearsonr: 2.2063e-04 - val_loss: 0.0279 - val_metrics_pearsonr: 5.7109e-04\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0156 - metrics_pearsonr: 2.1951e-04 - val_loss: 0.0230 - val_metrics_pearsonr: 5.8061e-04\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0139 - metrics_pearsonr: 2.2200e-04 - val_loss: 0.0206 - val_metrics_pearsonr: 5.7218e-04\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0129 - metrics_pearsonr: 2.1648e-04 - val_loss: 0.0230 - val_metrics_pearsonr: 5.6171e-04\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0128 - metrics_pearsonr: 2.1192e-04 - val_loss: 0.0224 - val_metrics_pearsonr: 5.6058e-04\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0121 - metrics_pearsonr: 2.0954e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.5496e-04\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0117 - metrics_pearsonr: 2.0902e-04 - val_loss: 0.0208 - val_metrics_pearsonr: 5.6276e-04\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0117 - metrics_pearsonr: 2.0956e-04 - val_loss: 0.0212 - val_metrics_pearsonr: 5.5425e-04\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0115 - metrics_pearsonr: 2.0702e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.5613e-04\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0112 - metrics_pearsonr: 2.0690e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5558e-04\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0110 - metrics_pearsonr: 2.0655e-04 - val_loss: 0.0206 - val_metrics_pearsonr: 5.5393e-04\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0110 - metrics_pearsonr: 2.0533e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.5551e-04\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0109 - metrics_pearsonr: 2.0452e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5160e-04\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0108 - metrics_pearsonr: 2.0326e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5000e-04\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0108 - metrics_pearsonr: 2.0244e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.5076e-04\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0108 - metrics_pearsonr: 2.0218e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5236e-04\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0107 - metrics_pearsonr: 2.0216e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5122e-04\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0106 - metrics_pearsonr: 2.0165e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.4993e-04\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0106 - metrics_pearsonr: 2.0109e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.4975e-04\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0106 - metrics_pearsonr: 2.0082e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4993e-04\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0105 - metrics_pearsonr: 2.0078e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.4981e-04\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0105 - metrics_pearsonr: 2.0060e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4941e-04\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0105 - metrics_pearsonr: 2.0034e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4991e-04\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0105 - metrics_pearsonr: 2.0023e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.5071e-04\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0105 - metrics_pearsonr: 2.0019e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5051e-04\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0105 - metrics_pearsonr: 2.0001e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5025e-04\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0105 - metrics_pearsonr: 1.9977e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5007e-04\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0104 - metrics_pearsonr: 1.9955e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.4981e-04\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0104 - metrics_pearsonr: 1.9939e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.4989e-04\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0104 - metrics_pearsonr: 1.9928e-04 - val_loss: 0.0198 - val_metrics_pearsonr: 5.5020e-04\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0104 - metrics_pearsonr: 1.9918e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5039e-04\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0104 - metrics_pearsonr: 1.9909e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5059e-04\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0104 - metrics_pearsonr: 1.9900e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5066e-04\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0104 - metrics_pearsonr: 1.9890e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5062e-04\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0104 - metrics_pearsonr: 1.9878e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5057e-04\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0104 - metrics_pearsonr: 1.9864e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5056e-04\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0104 - metrics_pearsonr: 1.9852e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5061e-04\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0104 - metrics_pearsonr: 1.9841e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5072e-04\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0104 - metrics_pearsonr: 1.9831e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5085e-04\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0104 - metrics_pearsonr: 1.9823e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5100e-04\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0104 - metrics_pearsonr: 1.9815e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5109e-04\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0104 - metrics_pearsonr: 1.9805e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5113e-04\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0104 - metrics_pearsonr: 1.9795e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5115e-04\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0104 - metrics_pearsonr: 1.9785e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5117e-04\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0104 - metrics_pearsonr: 1.9774e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5120e-04\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0104 - metrics_pearsonr: 1.9764e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5125e-04\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0104 - metrics_pearsonr: 1.9754e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5129e-04\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0104 - metrics_pearsonr: 1.9745e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5137e-04\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0104 - metrics_pearsonr: 1.9737e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5146e-04\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0104 - metrics_pearsonr: 1.9728e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5158e-04\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0103 - metrics_pearsonr: 1.9719e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5168e-04\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0103 - metrics_pearsonr: 1.9710e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5176e-04\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0103 - metrics_pearsonr: 1.9701e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5182e-04\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0103 - metrics_pearsonr: 1.9691e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5186e-04\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0103 - metrics_pearsonr: 1.9681e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5190e-04\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0103 - metrics_pearsonr: 1.9672e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5195e-04\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0103 - metrics_pearsonr: 1.9663e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5201e-04\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0103 - metrics_pearsonr: 1.9654e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5206e-04\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0103 - metrics_pearsonr: 1.9645e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5214e-04\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0103 - metrics_pearsonr: 1.9636e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5224e-04\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0103 - metrics_pearsonr: 1.9627e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5234e-04\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0103 - metrics_pearsonr: 1.9619e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5245e-04\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0103 - metrics_pearsonr: 1.9610e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5254e-04\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0103 - metrics_pearsonr: 1.9602e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5262e-04\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0103 - metrics_pearsonr: 1.9593e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5268e-04\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0103 - metrics_pearsonr: 1.9583e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5273e-04\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0103 - metrics_pearsonr: 1.9574e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5279e-04\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0103 - metrics_pearsonr: 1.9565e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5285e-04\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0103 - metrics_pearsonr: 1.9556e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5289e-04\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0103 - metrics_pearsonr: 1.9546e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5295e-04\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0103 - metrics_pearsonr: 1.9538e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5303e-04\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0103 - metrics_pearsonr: 1.9529e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5312e-04\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0103 - metrics_pearsonr: 1.9521e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5323e-04\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0103 - metrics_pearsonr: 1.9512e-04 - val_loss: 0.0199 - val_metrics_pearsonr: 5.5335e-04\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0103 - metrics_pearsonr: 1.9504e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5347e-04\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0103 - metrics_pearsonr: 1.9496e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5358e-04\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0103 - metrics_pearsonr: 1.9488e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5368e-04\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0103 - metrics_pearsonr: 1.9479e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5376e-04\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0103 - metrics_pearsonr: 1.9470e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5381e-04\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0103 - metrics_pearsonr: 1.9461e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5386e-04\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0103 - metrics_pearsonr: 1.9451e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5390e-04\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0103 - metrics_pearsonr: 1.9442e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5396e-04\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0103 - metrics_pearsonr: 1.9433e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5401e-04\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0103 - metrics_pearsonr: 1.9424e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5407e-04\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0103 - metrics_pearsonr: 1.9416e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5414e-04\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0103 - metrics_pearsonr: 1.9407e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5423e-04\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0102 - metrics_pearsonr: 1.9399e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5434e-04\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0102 - metrics_pearsonr: 1.9391e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5449e-04\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0103 - metrics_pearsonr: 1.9384e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5468e-04\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0103 - metrics_pearsonr: 1.9378e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5489e-04\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0103 - metrics_pearsonr: 1.9371e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5509e-04\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0103 - metrics_pearsonr: 1.9365e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5525e-04\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0103 - metrics_pearsonr: 1.9358e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5537e-04\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0103 - metrics_pearsonr: 1.9350e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5540e-04\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0102 - metrics_pearsonr: 1.9341e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5538e-04\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0102 - metrics_pearsonr: 1.9332e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5537e-04\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0103 - metrics_pearsonr: 1.9323e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.5537e-04\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0103 - metrics_pearsonr: 1.9316e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.5544e-04\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0103 - metrics_pearsonr: 1.9310e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.5556e-04\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0104 - metrics_pearsonr: 1.9304e-04 - val_loss: 0.0204 - val_metrics_pearsonr: 5.5572e-04\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0104 - metrics_pearsonr: 1.9300e-04 - val_loss: 0.0204 - val_metrics_pearsonr: 5.5586e-04\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0103 - metrics_pearsonr: 1.9295e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.5595e-04\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0103 - metrics_pearsonr: 1.9290e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.5600e-04\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0103 - metrics_pearsonr: 1.9285e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.5608e-04\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0103 - metrics_pearsonr: 1.9283e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.5632e-04\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0104 - metrics_pearsonr: 1.9286e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.5681e-04\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0106 - metrics_pearsonr: 1.9297e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.5760e-04\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0108 - metrics_pearsonr: 1.9314e-04 - val_loss: 0.0209 - val_metrics_pearsonr: 5.5862e-04\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0109 - metrics_pearsonr: 1.9336e-04 - val_loss: 0.0212 - val_metrics_pearsonr: 5.5976e-04\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0110 - metrics_pearsonr: 1.9357e-04 - val_loss: 0.0214 - val_metrics_pearsonr: 5.6078e-04\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0110 - metrics_pearsonr: 1.9376e-04 - val_loss: 0.0213 - val_metrics_pearsonr: 5.6149e-04\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0109 - metrics_pearsonr: 1.9387e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.6156e-04\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0108 - metrics_pearsonr: 1.9394e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.6112e-04\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0107 - metrics_pearsonr: 1.9397e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.6028e-04\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0109 - metrics_pearsonr: 1.9412e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.5983e-04\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0113 - metrics_pearsonr: 1.9442e-04 - val_loss: 0.0212 - val_metrics_pearsonr: 5.6026e-04\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0120 - metrics_pearsonr: 1.9492e-04 - val_loss: 0.0229 - val_metrics_pearsonr: 5.6213e-04\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0129 - metrics_pearsonr: 1.9569e-04 - val_loss: 0.0251 - val_metrics_pearsonr: 5.6548e-04\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0138 - metrics_pearsonr: 1.9677e-04 - val_loss: 0.0272 - val_metrics_pearsonr: 5.6956e-04\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0143 - metrics_pearsonr: 1.9812e-04 - val_loss: 0.0283 - val_metrics_pearsonr: 5.7324e-04\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0144 - metrics_pearsonr: 1.9974e-04 - val_loss: 0.0275 - val_metrics_pearsonr: 5.7490e-04\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0139 - metrics_pearsonr: 2.0106e-04 - val_loss: 0.0247 - val_metrics_pearsonr: 5.7342e-04\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0133 - metrics_pearsonr: 2.0123e-04 - val_loss: 0.0215 - val_metrics_pearsonr: 5.7026e-04\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0133 - metrics_pearsonr: 2.0123e-04 - val_loss: 0.0207 - val_metrics_pearsonr: 5.6927e-04\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0149 - metrics_pearsonr: 2.0322e-04 - val_loss: 0.0244 - val_metrics_pearsonr: 5.7475e-04\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0181 - metrics_pearsonr: 2.0736e-04 - val_loss: 0.0323 - val_metrics_pearsonr: 5.8684e-04\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0215 - metrics_pearsonr: 2.1047e-04 - val_loss: 0.0404 - val_metrics_pearsonr: 6.0063e-04\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0232 - metrics_pearsonr: 2.1233e-04 - val_loss: 0.0416 - val_metrics_pearsonr: 6.0857e-04\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0222 - metrics_pearsonr: 2.1479e-04 - val_loss: 0.0324 - val_metrics_pearsonr: 6.0446e-04\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0194 - metrics_pearsonr: 2.1638e-04 - val_loss: 0.0218 - val_metrics_pearsonr: 5.9055e-04\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0182 - metrics_pearsonr: 2.1557e-04 - val_loss: 0.0248 - val_metrics_pearsonr: 5.8765e-04\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0208 - metrics_pearsonr: 2.1499e-04 - val_loss: 0.0389 - val_metrics_pearsonr: 6.0205e-04\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0235 - metrics_pearsonr: 2.1521e-04 - val_loss: 0.0428 - val_metrics_pearsonr: 6.2070e-04\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0226 - metrics_pearsonr: 2.2224e-04 - val_loss: 0.0297 - val_metrics_pearsonr: 6.1099e-04\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0190 - metrics_pearsonr: 2.2545e-04 - val_loss: 0.0206 - val_metrics_pearsonr: 5.7818e-04\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0169 - metrics_pearsonr: 2.1560e-04 - val_loss: 0.0287 - val_metrics_pearsonr: 5.8900e-04\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0179 - metrics_pearsonr: 2.1622e-04 - val_loss: 0.0304 - val_metrics_pearsonr: 6.0093e-04\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0167 - metrics_pearsonr: 2.2042e-04 - val_loss: 0.0240 - val_metrics_pearsonr: 6.2909e-04\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0145 - metrics_pearsonr: 2.2694e-04 - val_loss: 0.0210 - val_metrics_pearsonr: 5.8448e-04\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0133 - metrics_pearsonr: 2.1477e-04 - val_loss: 0.0246 - val_metrics_pearsonr: 5.9131e-04\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0133 - metrics_pearsonr: 2.1047e-04 - val_loss: 0.0232 - val_metrics_pearsonr: 5.8121e-04\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0122 - metrics_pearsonr: 2.0487e-04 - val_loss: 0.0207 - val_metrics_pearsonr: 5.7510e-04\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0117 - metrics_pearsonr: 2.0474e-04 - val_loss: 0.0214 - val_metrics_pearsonr: 5.9065e-04\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0116 - metrics_pearsonr: 2.0585e-04 - val_loss: 0.0217 - val_metrics_pearsonr: 5.6789e-04\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0113 - metrics_pearsonr: 2.0121e-04 - val_loss: 0.0208 - val_metrics_pearsonr: 5.8463e-04\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0109 - metrics_pearsonr: 2.0276e-04 - val_loss: 0.0205 - val_metrics_pearsonr: 5.6911e-04\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0108 - metrics_pearsonr: 1.9959e-04 - val_loss: 0.0211 - val_metrics_pearsonr: 5.7507e-04\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0108 - metrics_pearsonr: 1.9826e-04 - val_loss: 0.0208 - val_metrics_pearsonr: 5.6500e-04\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0106 - metrics_pearsonr: 1.9508e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.6273e-04\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0105 - metrics_pearsonr: 1.9344e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.6031e-04\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0105 - metrics_pearsonr: 1.9239e-04 - val_loss: 0.0204 - val_metrics_pearsonr: 5.6422e-04\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0104 - metrics_pearsonr: 1.9238e-04 - val_loss: 0.0202 - val_metrics_pearsonr: 5.6224e-04\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0103 - metrics_pearsonr: 1.9167e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.6052e-04\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0103 - metrics_pearsonr: 1.9104e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.6023e-04\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0103 - metrics_pearsonr: 1.9074e-04 - val_loss: 0.0203 - val_metrics_pearsonr: 5.6189e-04\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0102 - metrics_pearsonr: 1.9074e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.6035e-04\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0102 - metrics_pearsonr: 1.9027e-04 - val_loss: 0.0200 - val_metrics_pearsonr: 5.5903e-04\n",
      "Epoch 1002/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0102 - metrics_pearsonr: 1.8986e-04 - val_loss: 0.0201 - val_metrics_pearsonr: 5.5971e-04\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024D4F3EDF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "相关系数 0.986350083445571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_1\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_2\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_3\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_4\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215_5\\assets\n"
     ]
    }
   ],
   "source": [
    "model,predicty,testy,r,p,weights=Auto_Transformer(vy,vx,6,[['transformer'],['fc',7]],test_size=0.2,valid_size=0.1,k_fold=5,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=1,key_dim=1,ifdropout='no',trans_dropout_rate=0.0,trans_units=256,trans_activation='tanh',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='Adam',metrics='Pearsonr',if_early_stopping=1000,learning_rate=0.0001,epochs=5000,batch_size=5000,ifrandom_split='yes',ifweight='no',ifmute='no',ifsave='yes',savepath='E:/huawei/huawei_gnss_wind_w_30min_press_k5_onestation_1215',device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3f567a-a1dd-44d8-ae75-32e5c3444498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11403965\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(np.abs(testy-predicty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b3ea65-a427-49f2-8c0a-8c13eb49f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3519, 7) (3519, 7)\n"
     ]
    }
   ],
   "source": [
    "print(testy.shape,predicty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c8da8d-a175-4d49-a95b-fe7772942950",
   "metadata": {},
   "outputs": [],
   "source": [
    "times=np.arange(3519)\n",
    "testy_w=testy\n",
    "predicty_w=predicty\n",
    "levels=[1000,925,850,700,600,500,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96deff50-b780-48c5-b826-5a0b87e142ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times',  'levels')\n",
    "\n",
    "\n",
    "testy_w_da = xr.DataArray(\n",
    "    data=testy_w,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='testy_w' \n",
    ")\n",
    "\n",
    "\n",
    "predicty_w_da = xr.DataArray(\n",
    "    data=predicty_w,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_w'\n",
    ")\n",
    "\n",
    "testy_w_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_w_onestation_1215.nc')\n",
    "predicty_w_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_w_onestation_1215.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da782789-c599-4b53-b10c-c6c3133369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "testy_w_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_w_onestation_1215.nc')\n",
    "predicty_w_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_w_onestation_1215.nc')\n",
    "testy_w=np.array(testy_w_file['testy_w'])\n",
    "predicty_w=np.array(predicty_w_file['predicty_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f862ec-d92c-46f0-8cd2-402f35c377aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CDF匹配\n",
    "def Auto_cdf_matching(vx,vy):\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    if np.array(vx).ndim==1:\n",
    "        vx_cdf = (np.arange(len(vx)) +  1) / (len(vx))\n",
    "        vy_cdf = (np.arange(len(vy)) +  1) / (len(vy))\n",
    "        \n",
    "        spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx))\n",
    "        vx_interp = spl(vy_cdf)\n",
    "        \n",
    "        def func(x, a, b, c, d):\n",
    "            return a*x + b*x**2 + c*x**3 + d\n",
    "        \n",
    "        popt = curve_fit(func, vx_interp, np.sort(vy))[0]\n",
    "        \n",
    "        matched_vx = func(vx, *popt)\n",
    "    elif np.array(vx).ndim==2:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            vx_cdf = (np.arange(len(vx[:,i])) +  1) / (len(vx[:,i]))\n",
    "            vy_cdf = (np.arange(len(vy[:,i])) +  1) / (len(vy[:,i]))\n",
    "            \n",
    "            spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i]))\n",
    "            vx_interp = spl(vy_cdf)\n",
    "            \n",
    "            def func(x, a, b, c, d):\n",
    "                return a*x + b*x**2 + c*x**3 + d\n",
    "            \n",
    "            popt = curve_fit(func, vx_interp, np.sort(vy[:,i]))[0]\n",
    "            \n",
    "            matched_vx[:,i] = func(vx[:,i], *popt)\n",
    "    elif np.array(vx).ndim==3:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                vx_cdf = (np.arange(len(vx[:,i,j])) +  1) / (len(vx[:,i,j]))\n",
    "                vy_cdf = (np.arange(len(vy[:,i,j])) +  1) / (len(vy[:,i,j]))\n",
    "                \n",
    "                spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j]))\n",
    "                vx_interp = spl(vy_cdf)\n",
    "                \n",
    "                def func(x, a, b, c, d):\n",
    "                    return a*x + b*x**2 + c*x**3 + d\n",
    "                \n",
    "                popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j]))[0]\n",
    "                \n",
    "                matched_vx[:,i,j] = func(vx[:,i,j], *popt)\n",
    "    elif np.array(vx).ndim==4:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2],vx.shape[3]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                for k in range(vx.shape[3]):\n",
    "                    vx_cdf = (np.arange(len(vx[:,i,j,k])) +  1) / (len(vx[:,i,j,k]))\n",
    "                    vy_cdf = (np.arange(len(vy[:,i,j,k])) +  1) / (len(vy[:,i,j,k]))\n",
    "                    \n",
    "                    spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j,k]))\n",
    "                    vx_interp = spl(vy_cdf)\n",
    "                    \n",
    "                    def func(x, a, b, c, d):\n",
    "                        return a*x + b*x**2 + c*x**3 + d\n",
    "                    \n",
    "                    popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j,k]))[0]\n",
    "                    \n",
    "                    matched_vx[:,i,j,k] = func(vx[:,i,j,k], *popt)\n",
    "\n",
    "    return matched_vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd141a83-bd3f-4bf4-aa3a-53fc576e7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import Auto_paint_self\n",
    "np.random.seed(25)\n",
    "trainy,testy,trainx,testx = train_test_split(np.array(vy),vx,test_size=0.2,random_state=25)\n",
    "predicty_w=Auto_cdf_matching(np.array(predicty_w),trainy[np.random.randint(0,trainy.shape[0], predicty_w.shape[0]),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a2b5b3-4679-4e1b-89c3-5a0b3d9e71d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 388.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from metpy.calc import wind_direction,wind_speed\n",
    "from metpy.units import units\n",
    "u_rmse=np.zeros((predicty_w.shape[1]))\n",
    "u_mae=np.zeros((predicty_w.shape[1]))\n",
    "u_pearson=np.zeros((predicty_w.shape[1]))\n",
    "u_mape=np.zeros((predicty_w.shape[1]))\n",
    "for i in tqdm(range(predicty_w.shape[1])):\n",
    "    u_rmse[i]=mean_squared_error(testy_w[:,i],predicty_w[:,i])\n",
    "    u_pearson[i],_=pearsonr(testy_w[:,i],predicty_w[:,i])\n",
    "    u_mae[i]=mean_absolute_error(testy_w[:,i],predicty_w[:,i])\n",
    "    u_mape[i]=mean_absolute_percentage_error(testy_w[:,i],predicty_w[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5312b1cf-880f-49cd-9c25-a78afc4f5bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16142966 0.15057529 0.14657648 0.15814691 0.06042247 0.07819435\n",
      " 0.07684993]\n",
      "0.11888501500277142\n"
     ]
    }
   ],
   "source": [
    "print(u_mae)\n",
    "print(np.nanmean(u_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2511a33f-1e5a-4bed-bade-a1a97d95a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07627189 0.06005264 0.05755768 0.06795721 0.00807889 0.01218768\n",
      " 0.01152946]\n",
      "0.041947920673508464\n"
     ]
    }
   ],
   "source": [
    "print(u_rmse)\n",
    "print(np.nanmean(u_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec04903-de35-4c66-92f3-c76447a7e1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03249102 0.02753443 0.02615779 0.02899702 0.03231177 0.0188191\n",
      " 0.03055365]\n",
      "0.028123537205345096\n"
     ]
    }
   ],
   "source": [
    "u_p=np.sqrt(u_rmse)/(np.nanmax(testy_w,axis=0)-np.nanmin(testy_w,axis=0))\n",
    "#v_p=np.sqrt(v_rmse)/(np.nanmax(testy_w,axis=0)-np.nanmin(testy_w,axis=0))\n",
    "#wind_p=np.sqrt(wind_rmse)/(np.nanmax(np.sqrt(testy_w**2+testy_w**2),axis=0)-np.nanmin(np.sqrt(testy_w**2+testy_w**2),axis=0))\n",
    "print(u_p)\n",
    "print(np.nanmean(u_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1efbcb-42c8-49c3-ac71-f9e20cf8d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times',  'levels')\n",
    "\n",
    "predicty_w_da_cdf = xr.DataArray(\n",
    "    data=predicty_w,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_w'\n",
    ")\n",
    "\n",
    "predicty_w_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_w_cdf_onestation_1215.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae365d1-6d3f-4e24-9758-8706a11bc665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
