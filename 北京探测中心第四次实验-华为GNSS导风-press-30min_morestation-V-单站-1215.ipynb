{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9e7b6e-77fa-4b65-a533-d0f8835c97fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载原始数据文件...\n",
      "文件加载完毕。\n",
      "正在对原始数据进行预处理...\n",
      "预处理完成。\n",
      "\n",
      "--- 开始筛选站点 (新逻辑) ---\n",
      "目标风场站点: 58557\n",
      "使用预设的目标站点经纬度: Lon=120.0717, Lat=29.3619\n",
      "在GNSS数据文件中找到 1215 个可用站点。\n",
      "在CSV和GNSS数据文件中共有 1215 个共同站点。\n",
      "找到的最近 1215 个GNSS站点: ['H992830', 'H998276', 'H11705423', 'H11705435', 'H792737', 'H892451', 'H992254', 'H11705447', 'H11705440', 'H892504', 'H998585', 'H997648', 'H992221', 'H998596', 'H11705442', 'H11705404', 'H798684', 'H997915', 'H997714', 'H11705408', 'H892866', 'H992792', 'H992154', 'H991217', 'H998172', 'H997618', 'H992023', 'H756621', 'H999268', 'H990477', 'H999166', 'H756021', 'H996453', 'H990638', 'H998429', 'H990413', 'H999194', 'H991454', 'H999941', 'H999072', 'H990004', 'H799390', 'H990379', 'H999070', 'H990896', 'H796752', 'H756990', 'H990312', 'H999634', 'H990100', 'H999409', 'H999227', 'H890501', 'H999651', 'H796767', 'H990819', 'H992352', 'H993271', 'H994528', 'H796788', 'H993233', 'H990014', 'H799263', 'H799424', 'H994427', 'H999342', 'H891649', 'H997770', 'H999401', 'H899701', 'H854592', 'H756069', 'H756507', 'H990435', 'H956637', 'H956050', 'H999174', 'H993527', 'H956776', 'H999425', 'H994430', 'H799188', 'H754810', 'H758362', 'H754825', 'H990287', 'H754964', 'H994827', 'H754070', 'H990589', 'H956437', 'H11705362', 'H999137', 'H754047', 'H756643', 'H994535', 'H899502', 'H799069', 'H999036', 'H899953', 'H899447', 'H994080', 'H999195', 'H999208', 'H997384', 'H756089', 'H999192', 'H790349', 'H990300', 'H999220', 'H996009', 'H990270', 'H756613', 'H990220', 'H999926', 'H11705360', 'H799361', 'H990658', 'H890734', 'H999753', 'H752190', 'H990362', 'H999080', 'H790044', 'H990791', 'H890125', 'H11705511', 'H890930', 'H991672', 'H990356', 'H990975', 'H891646', 'H990933', 'H990805', 'H990390', 'H999508', 'H999127', 'H990029', 'H799256', 'H994615', 'H990208', 'H990790', 'H991684', 'H11705376', 'H999099', 'H990665', 'H11705375', 'H995070', 'H990785', 'H990635', 'H754576', 'H994622', 'H890721', 'H999660', 'H752327', 'H990247', 'H990936', 'H995674', 'H899154', 'H756366', 'H890990', 'H999153', 'H999664', 'H990190', 'H999237', 'H11705381', 'H11705382', 'H999672', 'H11705371', 'H752344', 'H899851', 'H996184', 'H754323', 'H11705373', 'H990225', 'H996542', 'H990520', 'H756680', 'H11705384', 'H996903', 'H752178', 'H990544', 'H890545', 'H754077', 'H890236', 'H990148', 'H996176', 'H754458', 'H899660', 'H990098', 'H752439', 'H996150', 'H991654', 'H996402', 'H756649', 'H996284', 'H713716', 'H752478', 'H990211', 'H996016', 'H754497', 'H990815', 'H996587', 'H752365', 'H756451', 'H899223', 'H799497', 'H996177', 'H913879', 'H990318', 'H996085', 'H996408', 'H999197', 'H752355', 'H996276', 'H899700', 'H996162', 'H790122', 'H713099', 'H999289', 'H752598', 'H996172', 'H752993', 'H752561', 'H752080', 'H712795', 'H990656', 'H952235', 'H752312', 'H999033', 'H752172', 'H854560', 'H990385', 'H996058', 'H999251', 'H815529', 'H752612', 'H996458', 'H991682', 'H812229', 'H999001', 'H999337', 'H999670', 'H812364', 'H717664', 'H918333', 'H917541', 'H712500', 'H996073', 'H990826', 'H952754', 'H996406', 'H790852', 'H815368', 'H916985', 'H899680', 'H799026', 'H999079', 'H917558', 'H713454', 'H990363', 'H712465', 'H999784', 'H717503', 'H752972', 'H852847', 'H812830', 'H890309', 'H990326', 'H752784', 'H996078', 'H996202', 'H910437', 'H852873', 'H818012', 'H713420', 'H752051', 'H995552', 'H996091', 'H952696', 'H752654', 'H815373', 'H813115', 'H996419', 'H816290', 'H790844', 'H894896', 'H990814', 'H713333', 'H752371', 'H752363', 'H990842', 'H990450', 'H912930', 'H813277', 'H752360', 'H752331', 'H812960', 'H911031', 'H812339', 'H912330', 'H817058', 'H917272', 'H913901', 'H814890', 'H713104', 'H712231', 'H811399', 'H911080', 'H752329', 'H912596', 'H752321', 'H914283', 'H910993', 'H914268', 'H812472', 'H719197', 'H711205', 'H711417', 'H712372', 'H815654', 'H815683', 'H717490', 'H911092', 'H917915', 'H913045', 'H717441', 'H516440', 'H711437', 'H811053', 'H714575', 'H414954', 'H913997', 'H913183', 'H811100', 'H416412', 'H779871', 'H711370', 'H714024', 'H717064', 'H912003', 'H779869', 'H712277', 'H819770', 'H714675', 'H912015', 'H418645', 'H711288', 'H475383', 'H714836', 'H711897', 'H711196', 'H776415', 'H812051', 'H944935', 'H515808', 'H717342', 'H913143', 'H719139', 'H944929', 'H717753', 'H715046', 'H813668', 'H944916', 'H944885', 'H710894', 'H944927', 'H944200', 'H444117', 'H944389', 'H873456', 'H944436', 'H776146', 'H776173', 'H544723', 'H944686', 'H944411', 'H944811', 'H944312', 'H11681931', 'H771248', 'H944329', 'H544715', 'H770190', 'H444168', 'H771268', 'H874165', 'H771828', 'H877273', 'H944190', 'H876753', 'H940874', 'H771123', 'H944285', 'H944148', 'H11682037', 'H944812', 'H947727', 'H940937', 'H940208', 'H949348', 'H940153', 'H776679', 'H940152', 'H941086', 'H776680', 'H949201', 'H941719', 'H947393', 'H777359', 'H779860', 'H949076', 'H779864', 'H873410', 'H775525', 'H949002', 'H871938', 'H943744', 'H940288', 'H440142', 'H773894', 'H943717', 'H945116', 'H943840', 'H945643', 'H945596', 'H945338', 'H948168', 'H949087', 'H475613', 'H948161', 'H945701', 'H949152', 'H945789', 'H943783', 'H949198', 'H943739', 'H949035', 'H445201', 'H949600', 'H949051', 'H771839', 'H949037', 'H943424', 'H11682008', 'H945631', 'H876616', 'H943849', 'H948239', 'H941838', 'H11682007', 'H779345', 'H445169', 'H945933', 'H771727', 'H875870', 'H948586', 'H947392', 'H777361', 'H773975', 'H11678387', 'H773959', 'H477543', 'H475201', 'H771227', 'H872486', 'H11682022', 'H971814', 'H943096', 'H778483', 'H877659', 'H11682000', 'H945117', 'H874967', 'H877863', 'H941425', 'H771463', 'H873916', 'H778478', 'H11682031', 'H670431', 'H945249', 'H776798', 'H978076', 'H778780', 'H945253', 'H943701', 'H943032', 'H779531', 'H872324', 'H945081', 'H11682020', 'H945785', 'H945548', 'H470820', 'H945732', 'H977455', 'H941421', 'H940758', 'H973268', 'H778510', 'H777878', 'H943712', 'H875021', 'H945768', 'H776029', 'H945056', 'H948159', 'H872490', 'H477835', 'H974225', 'H947494', 'H945779', 'H947423', 'H478496', 'H945195', 'H777754', 'H943012', 'H949137', 'H771956', 'H941723', 'H943753', 'H778636', 'H973065', 'H943897', 'H11681811', 'H945094', 'H949139', 'H473477', 'H472113', 'H943473', 'H448399', 'H545716', 'H943863', 'H774016', 'H479294', 'H479646', 'H946337', 'H876191', 'H775628', 'H947346', 'H770953', 'H548894', 'H778402', 'H879557', 'H946945', 'H875715', 'H11547837', 'H943738', 'H479685', 'H946187', 'H770271', 'H947324', 'H872968', 'H941871', 'H973363', 'H873821', 'H877203', 'H479731', 'H472671', 'H973194', 'H977670', 'H11558032', 'H776239', 'H879771', 'H972521', 'H772569', 'H772718', 'H946334', 'H779838', 'H879448', 'H872768', 'H872341', 'H774944', 'H872745', 'H872036', 'H946872', 'H946637', 'H774788', 'H448389', 'H877140', 'H771291', 'H774339', 'H872734', 'H877091', 'H772131', 'H877093', 'H777022', 'H973582', 'H946835', 'H476441', 'H476827', 'H878110', 'H876948', 'H946786', 'H771599', 'H773789', 'H774384', 'H875467', 'H774416', 'H771366', 'H773543', 'H479151', 'H973407', 'H874881', 'H477930', 'H974157', 'H774752', 'H779692', 'H875000', 'H976520', 'H470188', 'H906303', 'H906292', 'H11548254', 'H706213', 'H906161', 'H706249', 'H708810', 'H706665', 'H970399', 'H706842', 'H706136', 'H706294', 'H976578', 'H706417', 'H906103', 'H906378', 'H706207', 'H706540', 'H706390', 'H706393', 'H706566', 'H706415', 'H706713', 'H706866', 'H706231', 'H906301', 'H906758', 'H706432', 'H906229', 'H906747', 'H706197', 'H11681888', 'H706228', 'H706352', 'H706183', 'H709301', 'H11681892', 'H709611', 'H706285', 'H906671', 'H709481', 'H706481', 'H775193', 'H709181', 'H709177', 'H776883', 'H709421', 'H709166', 'H706122', 'H709483', 'H706321', 'H709241', 'H709512', 'H877856', 'H706289', 'H709168', 'H709211', 'H709518', 'H906166', 'H709484', 'H706482', 'H906240', 'H709204', 'H706194', 'H706433', 'H709296', 'H706278', 'H709234', 'H706348', 'H706120', 'H709171', 'H909437', 'H806108', 'H706522', 'H706726', 'H906130', 'H906140', 'H709829', 'H708804', 'H906158', 'H709316', 'H706476', 'H706443', 'H709435', 'H706642', 'H709184', 'H708014', 'H709480', 'H706590', 'H706587', 'H909212', 'H709125', 'H706201', 'H709456', 'H706379', 'H706740', 'H909443', 'H706318', 'H709190', 'H706212', 'H709881', 'H906808', 'H709295', 'H708800', 'H908806', 'H706405', 'H709341', 'H709120', 'H706250', 'H706851', 'H706794', 'H708817', 'H706573', 'H906172', 'H706102', 'H906633', 'H706406', 'H709658', 'H706480', 'H706351', 'H906844', 'H709391', 'H709160', 'H706143', 'H709342', 'H706409', 'H706465', 'H709195', 'H709108', 'H709571', 'H706419', 'H706891', 'H709281', 'H906519', 'H706402', 'H706392', 'H706690', 'H706486', 'H706448', 'H706164', 'H706890', 'H909349', 'H706752', 'H706883', 'H906261', 'H706020', 'H706612', 'H706182', 'H709197', 'H709385', 'H706702', 'H706291', 'H706428', 'H706467', 'H709249', 'H706551', 'H906441', 'H706261', 'H706295', 'H906319', 'H906468', 'H706337', 'H706271', 'H806515', 'H706537', 'H706632', 'H706911', 'H706741', 'H706812', 'H706581', 'H706594', 'H706639', 'H706634', 'H706450', 'H706329', 'H906327', 'H706268', 'H706899', 'H706189', 'H708700', 'H706407', 'H706886', 'H706418', 'H909206', 'H706472', 'H906169', 'H907500', 'H706288', 'H706498', 'H906247', 'H706061', 'H909180', 'H706361', 'H706644', 'H706550', 'H706416', 'H906181', 'H706731', 'H707060', 'H706846', 'H706704', 'H909464', 'H907553', 'H706580', 'H706728', 'H706129', 'H706827', 'H706223', 'H906280', 'H709238', 'H706403', 'H709361', 'H706395', 'H906435', 'H709320', 'H909323', 'H706918', 'H806050', 'H709415', 'H706344', 'H706499', 'H706715', 'H909265', 'H806030', 'H709321', 'H709304', 'H706748', 'H708823', 'H706394', 'H776824', 'H909247', 'H709157', 'H706269', 'H706816', 'H708733', 'H706743', 'H706469', 'H706188', 'H706755', 'H706325', 'H706265', 'H706651', 'H706758', 'H706286', 'H709416', 'H706105', 'H708042', 'H706092', 'H706681', 'H706111', 'H706679', 'H706154', 'H706479', 'H706484', 'H706487', 'H706101', 'H706998', 'H706938', 'H706263', 'H706473', 'H706977', 'H906373', 'H706323', 'H706248', 'H708842', 'H708711', 'H907551', 'H706374', 'H709273', 'H906827', 'H709657', 'H906177', 'H709221', 'H906422', 'H907162', 'H706927', 'H706760', 'H706253', 'H709521', 'H906297', 'H709538', 'H706421', 'H707219', 'H707408', 'H709276', 'H706674', 'H708808', 'H706152', 'H707373', 'H706820', 'H706350', 'H706501', 'H707378', 'H706369', 'H906389', 'H706186', 'H707282', 'H709949', 'H706708', 'H709497', 'H707380', 'H706246', 'H706338', 'H706709', 'H707377', 'H907270', 'H706762', 'H809240', 'H709673', 'H707382', 'H708011', 'H706493', 'H706399', 'H909488', 'H709546', 'H706751', 'H709145', 'H709486', 'H709446', 'H706830', 'H907376', 'H909259', 'H709193', 'H709014', 'H709243', 'H709001', 'H706828', 'H709372', 'H706749', 'H709173', 'H706192', 'H707484', 'H706722', 'H707220', 'H709309', 'H706397', 'H707381', 'H706696', 'H709185', 'H709351', 'H709151', 'H707325', 'H709136', 'H706306', 'H709401', 'H709042', 'H709418', 'H706398', 'H707274', 'H709143', 'H907429', 'H709882', 'H709154', 'H709989', 'H906459', 'H709340', 'H707956', 'H909136', 'H709051', 'H909675', 'H709399', 'H807573', 'H709860', 'H809818', 'H707375', 'H708866', 'H909083', 'H709096', 'H709559', 'H907496', 'H707206', 'H709280', 'H707496', 'H709116', 'H709012', 'H907316', 'H707409', 'H707312', 'H709387', 'H709915', 'H709285', 'H707350', 'H709445', 'H709608', 'H707279', 'H709692', 'H909293', 'H709388', 'H709147', 'H707349', 'H709182', 'H709878', 'H709382', 'H707286', 'H707275', 'H707320', 'H709196', 'H709471', 'H709408', 'H709409', 'H709144', 'H709472', 'H709643', 'H707452', 'H709492', 'H709359', 'H707430', 'H709346', 'H709709', 'H709470', 'H907024', 'H709912', 'H707348', 'H707280', 'H707323', 'H707433', 'H709530', 'H909671', 'H707236', 'H707267', 'H909139', 'H709381', 'H709811', 'H709395', 'H707346', 'H707177', 'H709655', 'H907171', 'H707234', 'H709815', 'H709070', 'H909961', 'H707402', 'H707264', 'H707339', 'H707244', 'H907453', 'H709010', 'H709419', 'H707337', 'H707213', 'H909261', 'H707247', 'H709561', 'H909216', 'H709501', 'H707398', 'H909993', 'H907522', 'H707237', 'H707243', 'H707207', 'H709299', 'H707494', 'H709367', 'H707265', 'H709347', 'H707142', 'H707973', 'H707933', 'H709333', 'H709498', 'H709572', 'H909291', 'H709693', 'H707424', 'H707257', 'H909138', 'H709378', 'H707511', 'H709511', 'H709887', 'H709493', 'H707260', 'H707170', 'H709105', 'H709163', 'H707399', 'H709308', 'H907261', 'H709260', 'H709659', 'H709269', 'H709618', 'H707544', 'H709095', 'H709663', 'H709312', 'H709685', 'H909314', 'H709389', 'H907524', 'H709283', 'H709584', 'H809522', 'H709365', 'H709462', 'H909318', 'H709477', 'H707545', 'H709358', 'H709984', 'H709278', 'H908208', 'H708306', 'H709941', 'H909167', 'H909149', 'H909218', 'H909119', 'H908142', 'H707548', 'H709111', 'H907383', 'H708300', 'H909324', 'H708124', 'H707396', 'H708210', 'H707391', 'H708197', 'H907166', 'H909159', 'H709816', 'H770091', 'H708105', 'H707127', 'H707299', 'H707310', 'H707357', 'H707354', 'H907599', 'H707451', 'H707168', 'H707209', 'H707138', 'H707326', 'H807013', 'H707358', 'H907364', 'H707372', 'H707210', 'H707434', 'H707335', 'H807130', 'H707370', 'H707174', 'H907211', 'H707196', 'H707369', 'H707158', 'H907169', 'H707441', 'H707610', 'H707136', 'H907122', 'H807572', 'H707116', 'H707609', 'H707214', 'H907190', 'H708176', 'H809879', 'H908120', 'H708263', 'H908260', 'H708236', 'H708529', 'H908136', 'H708193', 'H908496', 'H908502', 'H708248', 'H708189', 'H808249', 'H708217', 'H708305', 'H908230', 'H908161', 'H708227', 'H908237', 'H908240', 'H708264', 'H908239', 'H908158', 'H708159', 'H708195', 'H808519', 'H808516', 'H908132', 'H708301', 'H908148', 'H908155', 'H908111', 'H908164', 'H908498', 'H708130', 'H908201', 'H708154', 'H708202', 'H708206', 'H708258', 'H908138']\n",
      "站点筛选完成。\n",
      "\n",
      "--- 正在根据筛选结果过滤数据集 ---\n",
      "数据集过滤完成。\n",
      "  - 过滤后GNSS数据站点数: 1215\n",
      "  - 过滤后风场数据站点数: 1\n",
      "\n",
      "--- 开始调用数据准备函数 ---\n",
      "Pass 1: 正在扫描有效的连续序列 (稳健模式)...\n",
      "GNSS 时间 dtype: datetime64[ns], Wind 时间 dtype: datetime64[ns]\n",
      "Pass 1 完成. 共找到 17594 个有效样本。耗时: 20.88 秒。\n",
      "正在预分配内存...\n",
      "Pass 2: 正在填充数据...\n",
      "Pass 2 完成. 数据填充完毕。耗时: 12.74 秒。\n",
      "正在创建最终的 xarray.DataArray...\n",
      "所有处理完成！总耗时: 33.63 秒。\n",
      "\n",
      "--- 处理后结果 ---\n",
      "输入变量 vx:\n",
      "  - 形状: (17594, 6, 1215)\n",
      "  - 维度: ('sample', 'timesteps', 'station')\n",
      "  - 站点: ['H992830' 'H998276' 'H11705423' ... 'H708206' 'H708258' 'H908138']\n",
      "  - 内存占用: 513.04 MB\n",
      "\n",
      "目标变量 vy:\n",
      "  - 形状: (17594, 7)\n",
      "  - 维度: ('sample', 'station_press_flat')\n",
      "  - 站点: [58557]\n",
      "  - 内存占用: 0.49 MB\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    使用Haversine公式计算两个经纬度点之间的距离（单位：公里）。\n",
    "    \"\"\"\n",
    "    # 将十进制度数转化为弧度\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine公式\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371 # 地球平均半径，单位为公里\n",
    "    return c * r\n",
    "\n",
    "def prepare_transformer_inputs_mem_efficient_robust(gnss_ds: xr.Dataset, wind_ds: xr.Dataset):\n",
    "    \"\"\"\n",
    "    更稳健的版本，处理时间戳 dtype 不匹配的问题。\n",
    "    (此函数无需任何修改)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gnss_ztd = gnss_ds['ztd']\n",
    "    wind_u = wind_ds['V']\n",
    "    \n",
    "    sequence_length = 6\n",
    "    time_step = pd.to_timedelta('5min')\n",
    "    expected_duration = time_step * (sequence_length - 1)\n",
    "\n",
    "    num_gnss_times = len(gnss_ztd.time)\n",
    "    \n",
    "    # --- Pass 1: 扫描并找到所有有效样本的起始索引 ---\n",
    "    print(\"Pass 1: 正在扫描有效的连续序列 (稳健模式)...\")\n",
    "    \n",
    "    gnss_dtype = gnss_ztd.time.dtype\n",
    "    wind_dtype = wind_u.Datetime.dtype\n",
    "    print(f\"GNSS 时间 dtype: {gnss_dtype}, Wind 时间 dtype: {wind_dtype}\")\n",
    "    wind_dtype_unit = np.datetime_data(wind_dtype)[0]\n",
    "\n",
    "    valid_start_indices = []\n",
    "    wind_times_set = set(wind_u.Datetime.values)\n",
    "\n",
    "    for i in range(num_gnss_times - sequence_length + 1):\n",
    "        window_times = gnss_ztd.time[i : i + sequence_length]\n",
    "        \n",
    "        actual_duration = window_times[-1].values - window_times[0].values\n",
    "        if np.abs(actual_duration - expected_duration) < pd.to_timedelta('1s'):\n",
    "            \n",
    "            target_wind_time_raw = window_times[-1].values + 6*time_step\n",
    "            target_wind_time_converted = np.datetime64(target_wind_time_raw, wind_dtype_unit)\n",
    "\n",
    "            if target_wind_time_converted in wind_times_set:\n",
    "                valid_start_indices.append(i)\n",
    "    \n",
    "    num_samples = len(valid_start_indices)\n",
    "    print(f\"Pass 1 完成. 共找到 {num_samples} 个有效样本。耗时: {time.time() - start_time:.2f} 秒。\")\n",
    "\n",
    "    if num_samples == 0:\n",
    "        print(\"在稳健模式下仍然未找到任何有效序列。请检查数据本身，例如风场数据是否覆盖了GNSS数据的时间范围。\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 内存分配 (Pass 2) ---\n",
    "    print(\"正在预分配内存...\")\n",
    "    num_stations_gnss = len(gnss_ztd.station)\n",
    "    num_stations_wind = len(wind_u.station)\n",
    "    num_press_levels = len(wind_u.PRESS)\n",
    "    \n",
    "    vx_data = np.empty((num_samples, sequence_length, num_stations_gnss), dtype=np.float32)\n",
    "    vy_data = np.empty((num_samples, num_stations_wind * num_press_levels), dtype=np.float32)\n",
    "\n",
    "    print(\"Pass 2: 正在填充数据...\")\n",
    "    fill_start_time = time.time()\n",
    "    gnss_ztd_values = gnss_ztd.values\n",
    "    \n",
    "    for k, start_idx in enumerate(valid_start_indices):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        vx_data[k, :, :] = gnss_ztd_values[start_idx:end_idx, :]\n",
    "        \n",
    "        last_gnss_time = gnss_ztd.time[end_idx - 1]\n",
    "        target_wind_time = last_gnss_time.values + 6*time_step\n",
    "        \n",
    "        target_wind_time_converted = np.datetime64(target_wind_time, wind_dtype_unit)\n",
    "        vy_slice_values = wind_u.sel(Datetime=target_wind_time_converted).values\n",
    "        vy_data[k, :] = vy_slice_values.flatten()\n",
    "        \n",
    "    print(f\"Pass 2 完成. 数据填充完毕。耗时: {time.time() - fill_start_time:.2f} 秒。\")\n",
    "\n",
    "    print(\"正在创建最终的 xarray.DataArray...\")\n",
    "    sample_coords = gnss_ztd.time.values[valid_start_indices]\n",
    "    vx = xr.DataArray(\n",
    "        vx_data,\n",
    "        dims=('sample', 'timesteps', 'station'),\n",
    "        coords={'sample': sample_coords, 'timesteps': np.arange(sequence_length), 'station': gnss_ztd.station.values}\n",
    "    )\n",
    "\n",
    "    vy_flat_coords = wind_u.stack(station_press_flat=('station', 'PRESS')).coords['station_press_flat']\n",
    "    vy = xr.DataArray(\n",
    "        vy_data,\n",
    "        dims=('sample', 'station_press_flat'),\n",
    "        coords={'sample': sample_coords, 'station_press_flat': vy_flat_coords}\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"所有处理完成！总耗时: {total_time:.2f} 秒。\")\n",
    "    return vx, vy\n",
    "\n",
    "# --- 主程序 ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. 定义文件路径和目标站点信息\n",
    "    gnss_nc_path = r'E:/gnss_ztd_combined_robust_morestation.nc'\n",
    "    wind_nc_path = r'E:/merged_stations_6min_common_period_float32_no_nan_press.nc'\n",
    "    gnss_info_path = r'E:\\huawei_gnss_morestation\\zj_allid.csv'\n",
    "    \n",
    "    target_wind_station_id = 58557 \n",
    "    target_wind_station_lon = 120.0717\n",
    "    target_wind_station_lat = 29.3619\n",
    "    \n",
    "    num_nearest_stations = 1215 \n",
    "\n",
    "    # 2. 加载原始数据文件\n",
    "    print(\"正在加载原始数据文件...\")\n",
    "    gnss_file = xr.open_dataset(gnss_nc_path)\n",
    "    wind_file = xr.open_dataset(wind_nc_path)\n",
    "    gnss_info_df = pd.read_csv(gnss_info_path)\n",
    "    print(\"文件加载完毕。\")\n",
    "\n",
    "    # 3. 对原始数据进行预处理（插值、填充等）\n",
    "    print(\"正在对原始数据进行预处理...\")\n",
    "    wind_new_time = pd.date_range(wind_file.Datetime.values[0], wind_file.Datetime.values[-1], freq='5min')\n",
    "    wind_file = wind_file.interp(Datetime=wind_new_time)\n",
    "    gnss_file = gnss_file.interpolate_na(dim='time')\n",
    "    gnss_file = gnss_file.ffill(dim='time').bfill(dim='time')\n",
    "    print(\"预处理完成。\")\n",
    "\n",
    "    # 4. MODIFIED LOGIC: 寻找实际存在于数据中的最近10个GNSS站点\n",
    "    print(\"\\n--- 开始筛选站点 (新逻辑) ---\")\n",
    "    print(f\"目标风场站点: {target_wind_station_id}\")\n",
    "    print(f\"使用预设的目标站点经纬度: Lon={target_wind_station_lon}, Lat={target_wind_station_lat}\")\n",
    "\n",
    "    # 步骤 4.1: 获取gnss数据文件中实际存在的所有站点ID\n",
    "    available_gnss_in_nc = gnss_file.station.values\n",
    "    print(f\"在GNSS数据文件中找到 {len(available_gnss_in_nc)} 个可用站点。\")\n",
    "\n",
    "    # 步骤 4.2: 从CSV站点信息中，只保留那些实际存在于gnss数据文件中的站点\n",
    "    gnss_info_df['id'] = gnss_info_df['id'].astype(str)\n",
    "    # 使用.copy()避免SettingWithCopyWarning\n",
    "    valid_stations_info_df = gnss_info_df[gnss_info_df['id'].isin(available_gnss_in_nc)].copy()\n",
    "    if valid_stations_info_df.empty:\n",
    "        raise ValueError(\"CSV站点信息文件和GNSS数据文件之间没有共同的站点。\")\n",
    "    print(f\"在CSV和GNSS数据文件中共有 {len(valid_stations_info_df)} 个共同站点。\")\n",
    "\n",
    "\n",
    "    # 步骤 4.3: 在这个有效站点子集上计算到目标的距离\n",
    "    valid_stations_info_df['distance_km'] = valid_stations_info_df.apply(\n",
    "        lambda row: haversine(target_wind_station_lon, target_wind_station_lat, row['lon'], row['lat']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 步骤 4.4: 按距离排序并选出最近的N个\n",
    "    # 检查可用站点是否少于期望数量\n",
    "    if len(valid_stations_info_df) < num_nearest_stations:\n",
    "        print(f\"警告: 可用站点总数 ({len(valid_stations_info_df)}) 小于期望的数量 ({num_nearest_stations})。将使用所有可用的站点。\")\n",
    "        num_to_select = len(valid_stations_info_df)\n",
    "    else:\n",
    "        num_to_select = num_nearest_stations\n",
    "\n",
    "    nearest_stations_df = valid_stations_info_df.sort_values(by='distance_km').head(num_to_select)\n",
    "    final_gnss_selection = nearest_stations_df['id'].tolist()\n",
    "    \n",
    "    print(f\"找到的最近 {len(final_gnss_selection)} 个GNSS站点: {final_gnss_selection}\")\n",
    "    print(\"站点筛选完成。\")\n",
    "\n",
    "\n",
    "    # 5. 根据筛选出的站点ID来过滤xarray数据集\n",
    "    print(\"\\n--- 正在根据筛选结果过滤数据集 ---\")\n",
    "    \n",
    "    # 确保目标站点存在于wind_file中\n",
    "    if target_wind_station_id not in wind_file.station.values:\n",
    "        raise ValueError(f\"目标站点 {target_wind_station_id} 在风场数据中未找到!\")\n",
    "\n",
    "    gnss_file_filtered = gnss_file.sel(station=final_gnss_selection)\n",
    "    wind_file_filtered = wind_file.sel(station=[target_wind_station_id])\n",
    "\n",
    "    print(\"数据集过滤完成。\")\n",
    "    print(f\"  - 过滤后GNSS数据站点数: {len(gnss_file_filtered.station)}\")\n",
    "    print(f\"  - 过滤后风场数据站点数: {len(wind_file_filtered.station)}\")\n",
    "\n",
    "    # 6. 调用核心处理函数\n",
    "    print(\"\\n--- 开始调用数据准备函数 ---\")\n",
    "    vx, vy = prepare_transformer_inputs_mem_efficient_robust(gnss_file_filtered, wind_file_filtered)\n",
    "\n",
    "    # 7. 打印最终结果\n",
    "    if vx is not None and vy is not None:\n",
    "        print(\"\\n--- 处理后结果 ---\")\n",
    "        print(\"输入变量 vx:\")\n",
    "        print(f\"  - 形状: {vx.shape}\")\n",
    "        print(f\"  - 维度: {vx.dims}\")\n",
    "        print(f\"  - 站点: {vx.station.values}\")\n",
    "        print(f\"  - 内存占用: {vx.nbytes / 1e6:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n目标变量 vy:\")\n",
    "        print(f\"  - 形状: {vy.shape}\")\n",
    "        print(f\"  - 维度: {vy.dims}\")\n",
    "        vy_station = vy.station_press_flat.to_index().get_level_values('station').unique().to_list()\n",
    "        print(f\"  - 站点: {vy_station}\")\n",
    "        print(f\"  - 内存占用: {vy.nbytes / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28420690-6159-40b4-97b6-977a409e4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer网络\n",
    "def Auto_Transformer(vy,vx,timestep,model_list,test_size=0.2,valid_size=0.1,k_fold=None,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=2,key_dim=2,ifdropout='no',trans_dropout_rate=0.0,trans_units=64,trans_activation='sigmoid',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='SGD',metrics='default',if_early_stopping=None,learning_rate=0.01,epochs=2000,batch_size=20,ifrandom_split='yes',ifweight='yes',ifmute='no',ifsave='no',savepath=None,device='cpu'):\n",
    "    import tensorflow as tf\n",
    "    if device=='gpu':\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                # 设置只使用 GPU 0\n",
    "                tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "                # 设置 GPU 0 的内存动态增长\n",
    "                tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    from keras.models import Sequential,Model\n",
    "    from keras.layers.core import Activation,Dropout,Dense\n",
    "    from keras.layers import Input,BatchNormalization,LayerNormalization,Embedding,Add,MultiHeadAttention,Flatten\n",
    "    from keras.initializers import TruncatedNormal,RandomNormal,RandomUniform\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import KFold\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.optimizers import SGD,Adam\n",
    "    import keras\n",
    "    from scipy.stats import pearsonr\n",
    "    import os\n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "    from keras.models import load_model\n",
    "    import sklearn\n",
    "    import copy\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from tensorflow.keras import backend as K\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    if embedding_num==None:\n",
    "        embedding_num=timestep+1\n",
    "    if task_mode=='regression':\n",
    "        if loss_function=='default' or loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanAbsoluteError':\n",
    "            loss=tf.keras.losses.MeanAbsoluteError()\n",
    "        elif loss_function=='MeanAbsolutePercentageError':\n",
    "            loss=tf.keras.losses.MeanAbsolutePercentageError()\n",
    "        elif loss_function=='MeanSquaredLogarithmicError':\n",
    "            loss=tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "        elif loss_function=='CosineSimilarity':\n",
    "            loss=tf.keras.losses.CosineSimilarity()\n",
    "        elif loss_function=='Huber':\n",
    "            loss=tf.keras.losses.Huber()\n",
    "        elif loss_function=='LogCosh':\n",
    "            loss=tf.keras.losses.LogCosh()\n",
    "        elif loss_function=='Pearsonr':\n",
    "            def loss_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            loss=loss_pearsonr\n",
    "        if metrics=='default' or metrics=='MeanSquaredError':\n",
    "            metric=tf.keras.metrics.MeanSquaredError()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='MeanAbsolutePercentageError':\n",
    "            metric=tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "        elif metrics=='MeanSquaredLogarithmicError':\n",
    "            metric=tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        elif metrics=='CosineSimilarity':\n",
    "            metric=tf.keras.metrics.CosineSimilarity()\n",
    "        elif metrics=='LogCoshError':\n",
    "            metric=tf.keras.metrics.LogCoshError()\n",
    "        elif metrics=='Pearsonr':\n",
    "            def metrics_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            metric=metrics_pearsonr\n",
    "    elif task_mode=='binary_classify':\n",
    "        if loss_function=='default' or loss_function=='BinaryCrossentropy':\n",
    "            loss=tf.keras.losses.BinaryCrossentropy()\n",
    "        elif loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        elif loss_function=='f1':\n",
    "            def loss_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return 1 - f1\n",
    "            loss=loss_f1\n",
    "        if metrics=='default' or metrics=='BinaryAccuracy':\n",
    "            metric=tf.keras.metrics.BinaryAccuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='BinaryCrossentropy':\n",
    "            metric=tf.keras.metrics.BinaryCrossentropy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "        elif metrics=='AUC':\n",
    "            metric=tf.keras.metrics.AUC()\n",
    "        elif metrics=='Precision':\n",
    "            metric=tf.keras.metrics.Precision()\n",
    "        elif metrics=='Recall':\n",
    "            metric=tf.keras.metrics.Recall()\n",
    "        elif metrics=='TruePositives':\n",
    "            metric=tf.keras.metrics.TruePositives()\n",
    "        elif metrics=='TrueNegatives':\n",
    "            metric=tf.keras.metrics.TrueNegatives()\n",
    "        elif metrics=='FalsePositives':\n",
    "            metric=tf.keras.metrics.FalsePositives()\n",
    "        elif metrics=='FalseNegatives':\n",
    "            metric=tf.keras.metrics.FalseNegatives()\n",
    "        elif metrics=='PrecisionAtRecall':\n",
    "            metric=tf.keras.metrics.PrecisionAtRecall()\n",
    "        elif metrics=='SensitivityAtSpecificity':\n",
    "            metric=tf.keras.metrics.SensitivityAtSpecificity()\n",
    "        elif metrics=='SpecificityAtSensitivity':\n",
    "            metric=tf.keras.metrics.SpecificityAtSensitivity()\n",
    "        elif metrics=='f1':\n",
    "            def metric_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return f1\n",
    "            metric=metric_f1\n",
    "    elif task_mode=='multi_classify':\n",
    "        if loss_function=='default' or loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        if metrics=='default' or metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "    weights=0\n",
    "    model=0\n",
    "    if vy.ndim==1:\n",
    "        vy=vy.reshape(vy.shape[0],1)\n",
    "    if ifrandom_split=='yes':\n",
    "        trainy,testy,trainx,testx = train_test_split(vy,vx,test_size=test_size,random_state=25)\n",
    "    else:\n",
    "        index=int((1-test_size)*vy.shape[0])\n",
    "        trainy=vy[:index]\n",
    "        testy=vy[index:]\n",
    "        trainx=vx[:index,:,:]\n",
    "        testx=vx[index:,:,:]\n",
    "    train_position=np.zeros((trainx.shape[0],trainx.shape[1]))\n",
    "    test_position=np.zeros((testx.shape[0],testx.shape[1]))\n",
    "    for i in range(trainx.shape[0]):\n",
    "        train_position[i,:]=np.arange(0,timestep,1)\n",
    "    for i in range(testx.shape[0]):\n",
    "        test_position[i,:]=np.arange(0,timestep,1)\n",
    "    if task_mode!='regression':\n",
    "        def create_sample_weights_for_batch_multitask(y_batch_multitask, list_of_task_weights_dicts):\n",
    "            batch_size, num_tasks = y_batch_multitask.shape\n",
    "            \n",
    "            if len(list_of_task_weights_dicts) != num_tasks:\n",
    "                raise ValueError(f\"Number of tasks in y_batch_multitask ({num_tasks}) \"\n",
    "                                 f\"must match length of list_of_task_weights_dicts ({len(list_of_task_weights_dicts)}).\")\n",
    "        \n",
    "            sample_weight_batch = np.ones_like(y_batch_multitask, dtype=np.float32)\n",
    "        \n",
    "            for i in range(num_tasks):\n",
    "                task_labels_current_channel = y_batch_multitask[:, i] \n",
    "                weights_dict_for_task_i = list_of_task_weights_dicts[i]\n",
    "                \n",
    "                weight_for_0 = weights_dict_for_task_i.get(0, 1.0)\n",
    "                weight_for_1 = weights_dict_for_task_i.get(1, 1.0)\n",
    "                \n",
    "                current_task_weights = sample_weight_batch[:, i] \n",
    "                current_task_weights[task_labels_current_channel == 0] = weight_for_0\n",
    "                current_task_weights[task_labels_current_channel == 1] = weight_for_1\n",
    "                sample_weight_batch[:, i] = current_task_weights\n",
    "                \n",
    "            return sample_weight_batch\n",
    "        def compute_unified_class_weights(y, task_mode=task_mode):\n",
    "            if task_mode == 'binary_classify':\n",
    "                if y.ndim == 2 and y.shape[-1] > 1:\n",
    "                    num_tasks = y.shape[-1]\n",
    "                    list_of_task_weights_dicts = []\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    for i in range(num_tasks):\n",
    "                        y_task_i_flat = y[:, i].ravel()\n",
    "                        if len(y_task_i_flat) == 0:\n",
    "                            weights_dict_task_i = {0: 1.0, 1: 1.0} \n",
    "                        else:\n",
    "                            valid_labels_mask = np.isin(y_task_i_flat, possible_binary_classes)\n",
    "                            if not np.all(valid_labels_mask) and np.any(valid_labels_mask): \n",
    "                                y_task_i_flat_filtered = y_task_i_flat[valid_labels_mask]\n",
    "                                if len(y_task_i_flat_filtered) == 0 : y_task_i_flat_filtered = np.array([0]) \n",
    "                            elif not np.any(valid_labels_mask): \n",
    "                                 y_task_i_flat_filtered = np.array([0]) \n",
    "                            else:\n",
    "                                y_task_i_flat_filtered = y_task_i_flat\n",
    "                            class_weights_arr = compute_class_weight(\n",
    "                                class_weight='balanced',\n",
    "                                classes=possible_binary_classes, \n",
    "                                y=y_task_i_flat_filtered\n",
    "                            )\n",
    "                            weights_dict_task_i = dict(zip(possible_binary_classes, class_weights_arr))\n",
    "                        list_of_task_weights_dicts.append(weights_dict_task_i)\n",
    "                    return list_of_task_weights_dicts \n",
    "        \n",
    "                else: \n",
    "                    y_flat = y.ravel()\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    valid_labels_mask = np.isin(y_flat, possible_binary_classes)\n",
    "                    if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                        y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                        if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0])\n",
    "                    elif not np.any(valid_labels_mask):\n",
    "                         y_flat_filtered = np.array([0])\n",
    "                    else:\n",
    "                        y_flat_filtered = y_flat\n",
    "        \n",
    "                    class_weights_arr = compute_class_weight(\n",
    "                        class_weight='balanced',\n",
    "                        classes=possible_binary_classes,\n",
    "                        y=y_flat_filtered\n",
    "                    )\n",
    "                    return dict(zip(possible_binary_classes, class_weights_arr)) \n",
    "        \n",
    "            elif task_mode == 'multi_classify':\n",
    "                y_flat = y.ravel()\n",
    "                possible_multiclass_classes = np.arange(int(np.max(y)+1))\n",
    "                valid_labels_mask = np.isin(y_flat, possible_multiclass_classes)\n",
    "                if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                    if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0]) \n",
    "                elif not np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = np.array([0]) \n",
    "                else:\n",
    "                    y_flat_filtered = y_flat\n",
    "                class_weights_arr = compute_class_weight(\n",
    "                    class_weight='balanced',\n",
    "                    classes=possible_multiclass_classes,\n",
    "                    y=y_flat_filtered\n",
    "                )\n",
    "                return dict(zip(possible_multiclass_classes, class_weights_arr)) \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported task_mode: {task_mode}\")\n",
    "        def create_unified_sample_weights_for_batch(y_batch, unified_class_weights):\n",
    "            if isinstance(unified_class_weights, list):\n",
    "                if not (y_batch.ndim == 2 and y_batch.shape[-1] == len(unified_class_weights)):\n",
    "                     raise ValueError(f\"Shape mismatch for multi-task binary weights. \"\n",
    "                                      f\"y_batch shape: {y_batch.shape}, num_weight_dicts: {len(unified_class_weights)}\")\n",
    "                return create_sample_weights_for_batch_multitask(y_batch, unified_class_weights)\n",
    "            elif isinstance(unified_class_weights, dict):\n",
    "                y_int_labels_for_weights = y_batch\n",
    "                if y_batch.ndim == 2 and y_batch.shape[-1] == 1: \n",
    "                    y_int_labels_for_weights = np.squeeze(y_batch, axis=-1)\n",
    "                sample_weight_for_batch = np.ones_like(y_int_labels_for_weights, dtype=np.float32)\n",
    "                for class_label, weight in unified_class_weights.items():\n",
    "                    sample_weight_for_batch[y_int_labels_for_weights == class_label] = weight\n",
    "                \n",
    "                return sample_weight_for_batch\n",
    "            else:\n",
    "                raise TypeError(f\"unified_class_weights has unexpected type: {type(unified_class_weights)}. Expected dict or list.\")\n",
    "        def train_data_generator(x,position, y, batch_size, task_mode=task_mode):\n",
    "            num_samples = x.shape[0]\n",
    "            global_unified_weights = compute_unified_class_weights(y, task_mode)\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    if len(batch_indices) == 0:\n",
    "                        continue\n",
    "        \n",
    "                    x_batch = x[batch_indices]\n",
    "                    position_batch = position[batch_indices]\n",
    "                    y_batch = y[batch_indices] \n",
    "                    sample_weight_batch = create_unified_sample_weights_for_batch(\n",
    "                        y_batch, \n",
    "                        global_unified_weights\n",
    "                    )\n",
    "                    yield {\"input_1\": x_batch, \"input_2\": position_batch}, y_batch, sample_weight_batch\n",
    "    else:\n",
    "        def train_data_generator(x, position, y, batch_size):\n",
    "            num_samples = x.shape[0]\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    x_batch = x[batch_indices]  \n",
    "                    position_batch = position[batch_indices]   \n",
    "                    y_batch = y[batch_indices]      \n",
    "                    \n",
    "                    yield ({\"input_1\": x_batch, \"input_2\": position_batch}, y_batch)\n",
    "    def test_data_generator(x, position, batch_size):\n",
    "        num_samples = x.shape[0]\n",
    "        while True:\n",
    "            indices = np.arange(num_samples)\n",
    "            \n",
    "            for start in range(0, num_samples, batch_size):\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                x_batch = x[batch_indices]  # 第一个输入特征\n",
    "                position_batch = position[batch_indices]\n",
    "                \n",
    "                yield ({\"input_1\": x_batch, \"input_2\": position_batch})\n",
    "    if if_best_mode=='no':\n",
    "        inputshape1=(None,timestep,trainx.shape[2])\n",
    "        inputshape2=(None,timestep)\n",
    "        inputs1=Input(shape=(timestep,trainx.shape[2]))\n",
    "        inputs2=Input(shape=(timestep))\n",
    "        for i in range(len(model_list)):\n",
    "            if model_list[i][0] == 'transformer':\n",
    "                position_embedding=Embedding(embedding_num,trainx.shape[2],input_length=timestep,input_shape=inputshape2)(inputs2)\n",
    "                add=Add(input_shape=inputshape1)([inputs1,position_embedding])\n",
    "                for j in range(encoder_deep):\n",
    "                    if j ==0:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(add,add,add)')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([add,en_multihead'+str(j+1)+'])')\n",
    "                    else:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(en_layernormalization'+str(j)+',en_layernormalization'+str(j)+',en_layernormalization'+str(j)+')')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([en_layernormalization'+str(j)+',en_multihead'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                    if ifdropout=='yes':\n",
    "                        exec('en_dropout'+str(j+1)+'=Dropout(trans_dropout_rate)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_dropout'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    else:\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    exec('en_add'+str(j+1)+'=Add()([en_fc'+str(j+1)+',en_layernormalization'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                exec('en_fla=Flatten()(en_layernormalization'+str(j+1)+')')\n",
    "            elif model_list[i][0] == 'batchnormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'layernormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'activation':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'flatten':\n",
    "                if model_list[i-1][0]=='transformer':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(en_fla)')\n",
    "                elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(norm'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='activation':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(act'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='dropout':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(drop'+str(i)+')')\n",
    "            elif model_list[i][0] =='fc':\n",
    "                if if_weight_initialize=='no':\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            outputs=eval('Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            outputs=eval('Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            outputs=eval('Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            outputs=eval('Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'dropout':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "        if optimizer == 'SGD':\n",
    "            opt = SGD(lr = learning_rate)\n",
    "        elif optimizer == 'Adam':\n",
    "            opt = Adam(lr = learning_rate)\n",
    "        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "    elif if_best_mode=='yes' or if_best_mode=='load':\n",
    "        if k_fold!=None:\n",
    "            models=[]\n",
    "            for i in range(k_fold):\n",
    "                models.append(load_model(modelpath+'_'+str(i+1)))\n",
    "        else:\n",
    "            model=load_model(modelpath)\n",
    "    if if_print_model=='yes':\n",
    "        if k_fold!=None:\n",
    "            if if_best_mode=='yes' or if_best_mode=='load':\n",
    "                print(models[0].summary())\n",
    "            else:\n",
    "                print(model.summary())\n",
    "        else:\n",
    "            print(model.summary())\n",
    "    if epochs!=0:\n",
    "        if valid_size!=None or k_fold !=None:\n",
    "            if k_fold!=None:\n",
    "                if if_best_mode=='no' :\n",
    "                    models = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "                        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models.append(model)\n",
    "                else:\n",
    "                    models_new = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models_new.append(models[fold_no])\n",
    "                    models=models_new\n",
    "            else:\n",
    "                if ifrandom_split=='yes':\n",
    "                    trainy,validy,trainx,validx,train_position,valid_position = train_test_split(trainy,trainx,train_position,test_size=valid_size/(1-test_size),random_state=25)\n",
    "                else:\n",
    "                    index=int((1-valid_size/(1-test_size))*trainy.shape[0])\n",
    "                    validy=trainy[index:]\n",
    "                    trainy=trainy[:index]\n",
    "                    validx=trainx[index:]\n",
    "                    trainx=trainx[:index]\n",
    "                    valid_position=train_position[index:]\n",
    "                    train_position=train_position[:index]\n",
    "                if if_early_stopping!=None:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                else:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "        else:\n",
    "            if if_early_stopping!=None:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "            else:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "    if k_fold!=None:\n",
    "        predicty = [model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0))) for model in models]\n",
    "        predicty=np.nanmean(predicty,axis=0)\n",
    "    else:\n",
    "        predicty = model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)))\n",
    "    predicty = np.nan_to_num(predicty,nan=0)\n",
    "    if task_mode=='regression':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        p=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i],p[i] = pearsonr(predicty[:,i],testy[:,i])\n",
    "            r=np.nan_to_num(r,nan=0)\n",
    "    elif task_mode=='binary_classify':\n",
    "        accuracy=np.zeros((testy.shape[1]))\n",
    "        recall=np.zeros((testy.shape[1]))\n",
    "        precision=np.zeros((testy.shape[1]))\n",
    "        f1=np.zeros((testy.shape[1]))\n",
    "        for i in range(predicty.shape[1]):\n",
    "            predicty[:,i]=[int(round(predicty[j,i],0)) for j in range(predicty.shape[0])]\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            if metrics=='Recall':\n",
    "                r[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            elif metrics=='Precision':\n",
    "                r[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            else:\n",
    "                r[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            recall[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            precision[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            accuracy[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            f1[i]=f1_score(testy[:,i], predicty[:,i])\n",
    "        p=0\n",
    "    elif task_mode=='multi_classify':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i]=accuracy_score(testy[:,i], np.argmax(predicty,axis=1))\n",
    "        p=0\n",
    "    if ifmute == 'no':\n",
    "        if task_mode=='regression':\n",
    "            print('相关系数',np.nanmean(r))\n",
    "        elif task_mode=='binary_classify':\n",
    "            print('召回率+精确率',np.nanmean(f1),'准确率',np.nanmean(accuracy),'召回率',np.nanmean(recall),'精确率',np.nanmean(precision))\n",
    "        elif task_mode=='multi_classify':\n",
    "            print('准确率',np.nanmean(r))\n",
    "    if ifweight=='yes':\n",
    "        weights=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        weight_more=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                testx_new=copy.deepcopy(testx)\n",
    "                weight=[]\n",
    "                for k in range(10):\n",
    "                    per=np.random.permutation(testx.shape[0])\n",
    "                    testx_shuffle=testx[per,:,j]\n",
    "                    testx_new[:,:,j]=testx_shuffle\n",
    "                    if k_fold!=None:\n",
    "                        predicty_new = [model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0))) for model in models]\n",
    "                        predicty_new=np.nanmean(predicty_new,axis=0)\n",
    "                    else:\n",
    "                        predicty_new = model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0)))\n",
    "                    if task_mode=='regression':\n",
    "                        weight.append(sklearn.metrics.mean_squared_error(testy[:,i],predicty_new[:,i])-sklearn.metrics.mean_squared_error(testy[:,i],predicty[:,i]))\n",
    "                    elif task_mode=='multi_classify':\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,:])-sklearn.metrics.log_loss(testy[:,i],predicty[:,:]))\n",
    "                    else:\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,i])-sklearn.metrics.log_loss(testy[:,i],predicty[:,i]))\n",
    "                weight_more[i,j]=np.nanmean(weight)\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                weights[i,j]=(weight_more[i,j]/np.nansum(weight_more[i,:]))*100\n",
    "                print('预报因子',j+1,'对预报值',i+1,'的贡献：',np.array(weights[i,j]),'％')\n",
    "            print('\\n')\n",
    "    if ifsave=='yes':\n",
    "        if k_fold!=None:\n",
    "            for i, model in enumerate(models):\n",
    "                model.save(savepath+'_'+str(i+1))\n",
    "        else:\n",
    "            model.save(savepath)\n",
    "    if k_fold!=None:\n",
    "        return models,predicty,testy,r,p,weights\n",
    "    else:\n",
    "        return model,predicty,testy,r,p,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5694aac2-581f-4745-8d73-80163b988f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 424/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0550 - metrics_pearsonr: 3.8483e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.2605e-05\n",
      "Epoch 425/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0550 - metrics_pearsonr: 3.8516e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 7.2547e-05\n",
      "Epoch 426/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0551 - metrics_pearsonr: 3.8528e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.2644e-05\n",
      "Epoch 427/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0554 - metrics_pearsonr: 3.8600e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.2787e-05\n",
      "Epoch 428/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0558 - metrics_pearsonr: 3.8654e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.2993e-05\n",
      "Epoch 429/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0561 - metrics_pearsonr: 3.8714e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.3142e-05\n",
      "Epoch 430/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0562 - metrics_pearsonr: 3.8717e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.3140e-05\n",
      "Epoch 431/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0560 - metrics_pearsonr: 3.8675e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.3022e-05\n",
      "Epoch 432/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0556 - metrics_pearsonr: 3.8581e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.2827e-05\n",
      "Epoch 433/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0553 - metrics_pearsonr: 3.8486e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 7.2678e-05\n",
      "Epoch 434/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0551 - metrics_pearsonr: 3.8400e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.2662e-05\n",
      "Epoch 435/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0553 - metrics_pearsonr: 3.8356e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.2728e-05\n",
      "Epoch 436/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0558 - metrics_pearsonr: 3.8324e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.2951e-05\n",
      "Epoch 437/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0564 - metrics_pearsonr: 3.8325e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.3125e-05\n",
      "Epoch 438/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0569 - metrics_pearsonr: 3.8320e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.3395e-05\n",
      "Epoch 439/5000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0572 - metrics_pearsonr: 3.8337e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.3460e-05\n",
      "Epoch 440/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0571 - metrics_pearsonr: 3.8329e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 7.3547e-05\n",
      "Epoch 441/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0568 - metrics_pearsonr: 3.8351e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.3394e-05\n",
      "Epoch 442/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0564 - metrics_pearsonr: 3.8351e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.3290e-05\n",
      "Epoch 443/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0562 - metrics_pearsonr: 3.8402e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.3164e-05\n",
      "Epoch 444/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0564 - metrics_pearsonr: 3.8448e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 7.3239e-05\n",
      "Epoch 445/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0571 - metrics_pearsonr: 3.8565e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.3574e-05\n",
      "Epoch 446/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0580 - metrics_pearsonr: 3.8679e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.3968e-05\n",
      "Epoch 447/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0587 - metrics_pearsonr: 3.8771e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 7.4275e-05\n",
      "Epoch 448/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0587 - metrics_pearsonr: 3.8764e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 7.4113e-05\n",
      "Epoch 449/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0580 - metrics_pearsonr: 3.8625e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.3711e-05\n",
      "Epoch 450/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0571 - metrics_pearsonr: 3.8461e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.3395e-05\n",
      "Epoch 451/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0567 - metrics_pearsonr: 3.8334e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 7.3427e-05\n",
      "Epoch 452/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0572 - metrics_pearsonr: 3.8297e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 7.3821e-05\n",
      "Epoch 453/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0583 - metrics_pearsonr: 3.8301e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 7.4120e-05\n",
      "Epoch 454/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0594 - metrics_pearsonr: 3.8305e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 7.4353e-05\n",
      "Epoch 455/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0599 - metrics_pearsonr: 3.8363e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.4243e-05\n",
      "Epoch 456/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0595 - metrics_pearsonr: 3.8428e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 7.4053e-05\n",
      "Epoch 457/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0585 - metrics_pearsonr: 3.8493e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.3766e-05\n",
      "Epoch 458/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0576 - metrics_pearsonr: 3.8462e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.3736e-05\n",
      "Epoch 459/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0576 - metrics_pearsonr: 3.8428e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.4039e-05\n",
      "Epoch 460/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0583 - metrics_pearsonr: 3.8386e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 7.4453e-05\n",
      "Epoch 461/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0591 - metrics_pearsonr: 3.8370e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 7.4684e-05\n",
      "Epoch 462/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0591 - metrics_pearsonr: 3.8323e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 7.4465e-05\n",
      "Epoch 463/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0580 - metrics_pearsonr: 3.8213e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.4091e-05\n",
      "Epoch 464/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0569 - metrics_pearsonr: 3.8117e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 7.3927e-05\n",
      "Epoch 465/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0566 - metrics_pearsonr: 3.8057e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.4051e-05\n",
      "Epoch 466/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0571 - metrics_pearsonr: 3.8011e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 7.4296e-05\n",
      "Epoch 467/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0579 - metrics_pearsonr: 3.8000e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 7.4273e-05\n",
      "Epoch 468/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0581 - metrics_pearsonr: 3.8016e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 7.4114e-05\n",
      "Epoch 469/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0575 - metrics_pearsonr: 3.8095e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.3788e-05\n",
      "Epoch 470/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0566 - metrics_pearsonr: 3.8124e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.3697e-05\n",
      "Epoch 471/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0561 - metrics_pearsonr: 3.8131e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.3907e-05\n",
      "Epoch 472/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0562 - metrics_pearsonr: 3.8118e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.4228e-05\n",
      "Epoch 473/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0565 - metrics_pearsonr: 3.8084e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.4408e-05\n",
      "Epoch 474/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0565 - metrics_pearsonr: 3.8012e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.4269e-05\n",
      "Epoch 475/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0561 - metrics_pearsonr: 3.7883e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.4146e-05\n",
      "Epoch 476/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0558 - metrics_pearsonr: 3.7775e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.4323e-05\n",
      "Epoch 477/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0559 - metrics_pearsonr: 3.7708e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 7.4720e-05\n",
      "Epoch 478/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0561 - metrics_pearsonr: 3.7660e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.5098e-05\n",
      "Epoch 479/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0561 - metrics_pearsonr: 3.7630e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.4986e-05\n",
      "Epoch 480/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0558 - metrics_pearsonr: 3.7611e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.4618e-05\n",
      "Epoch 481/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0552 - metrics_pearsonr: 3.7649e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.4055e-05\n",
      "Epoch 482/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0549 - metrics_pearsonr: 3.7695e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.3828e-05\n",
      "Epoch 483/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0551 - metrics_pearsonr: 3.7798e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.3924e-05\n",
      "Epoch 484/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0557 - metrics_pearsonr: 3.7858e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.4128e-05\n",
      "Epoch 485/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0563 - metrics_pearsonr: 3.7901e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.4208e-05\n",
      "Epoch 486/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0563 - metrics_pearsonr: 3.7840e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 7.4015e-05\n",
      "Epoch 487/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0560 - metrics_pearsonr: 3.7697e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.3791e-05\n",
      "Epoch 488/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0555 - metrics_pearsonr: 3.7533e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.3843e-05\n",
      "Epoch 489/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0552 - metrics_pearsonr: 3.7416e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.4156e-05\n",
      "Epoch 490/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0552 - metrics_pearsonr: 3.7364e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.4587e-05\n",
      "Epoch 491/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0555 - metrics_pearsonr: 3.7356e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.4788e-05\n",
      "Epoch 492/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0561 - metrics_pearsonr: 3.7344e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.4904e-05\n",
      "Epoch 493/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0569 - metrics_pearsonr: 3.7362e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 7.4933e-05\n",
      "Epoch 494/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0578 - metrics_pearsonr: 3.7436e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 7.5131e-05\n",
      "Epoch 495/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0587 - metrics_pearsonr: 3.7516e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 7.5422e-05\n",
      "Epoch 496/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0590 - metrics_pearsonr: 3.7610e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 7.5528e-05\n",
      "Epoch 497/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0586 - metrics_pearsonr: 3.7638e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 7.5396e-05\n",
      "Epoch 498/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0576 - metrics_pearsonr: 3.7598e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.4999e-05\n",
      "Epoch 499/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0568 - metrics_pearsonr: 3.7532e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.4591e-05\n",
      "Epoch 500/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0569 - metrics_pearsonr: 3.7492e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 7.4350e-05\n",
      "Epoch 501/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0581 - metrics_pearsonr: 3.7508e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.4273e-05\n",
      "Epoch 502/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0599 - metrics_pearsonr: 3.7540e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 7.4409e-05\n",
      "Epoch 503/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0617 - metrics_pearsonr: 3.7646e-05 - val_loss: 0.0866 - val_metrics_pearsonr: 7.4611e-05\n",
      "Epoch 504/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0623 - metrics_pearsonr: 3.7673e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 7.4674e-05\n",
      "Epoch 505/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0615 - metrics_pearsonr: 3.7642e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.4602e-05\n",
      "Epoch 506/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0601 - metrics_pearsonr: 3.7517e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.4760e-05\n",
      "Epoch 507/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0591 - metrics_pearsonr: 3.7422e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.5222e-05\n",
      "Epoch 508/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0597 - metrics_pearsonr: 3.7374e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.6065e-05\n",
      "Epoch 509/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0618 - metrics_pearsonr: 3.7413e-05 - val_loss: 0.0855 - val_metrics_pearsonr: 7.6694e-05\n",
      "Epoch 510/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0643 - metrics_pearsonr: 3.7507e-05 - val_loss: 0.0928 - val_metrics_pearsonr: 7.7047e-05\n",
      "Epoch 511/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0658 - metrics_pearsonr: 3.7641e-05 - val_loss: 0.0949 - val_metrics_pearsonr: 7.6884e-05\n",
      "Epoch 512/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0655 - metrics_pearsonr: 3.7817e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 7.6361e-05\n",
      "Epoch 513/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0639 - metrics_pearsonr: 3.7916e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 7.5649e-05\n",
      "Epoch 514/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0624 - metrics_pearsonr: 3.7946e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.5254e-05\n",
      "Epoch 515/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0623 - metrics_pearsonr: 3.8022e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 7.5276e-05\n",
      "Epoch 516/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0633 - metrics_pearsonr: 3.7994e-05 - val_loss: 0.0857 - val_metrics_pearsonr: 7.5394e-05\n",
      "Epoch 517/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0640 - metrics_pearsonr: 3.7966e-05 - val_loss: 0.0864 - val_metrics_pearsonr: 7.5389e-05\n",
      "Epoch 518/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0631 - metrics_pearsonr: 3.7789e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 7.5335e-05\n",
      "Epoch 519/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0613 - metrics_pearsonr: 3.7528e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 7.5533e-05\n",
      "Epoch 520/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0601 - metrics_pearsonr: 3.7325e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 7.6267e-05\n",
      "Epoch 521/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0600 - metrics_pearsonr: 3.7262e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 7.6777e-05\n",
      "Epoch 522/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0602 - metrics_pearsonr: 3.7249e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 7.6450e-05\n",
      "Epoch 523/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0600 - metrics_pearsonr: 3.7290e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 7.5791e-05\n",
      "Epoch 524/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0592 - metrics_pearsonr: 3.7360e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 7.5195e-05\n",
      "Epoch 525/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0583 - metrics_pearsonr: 3.7443e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.5076e-05\n",
      "Epoch 526/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0576 - metrics_pearsonr: 3.7512e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.5154e-05\n",
      "Epoch 527/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0569 - metrics_pearsonr: 3.7405e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.5058e-05\n",
      "Epoch 528/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0562 - metrics_pearsonr: 3.7219e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.4985e-05\n",
      "Epoch 529/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0557 - metrics_pearsonr: 3.6959e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.5193e-05\n",
      "Epoch 530/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0552 - metrics_pearsonr: 3.6736e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.5389e-05\n",
      "Epoch 531/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0547 - metrics_pearsonr: 3.6601e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.5606e-05\n",
      "Epoch 532/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0543 - metrics_pearsonr: 3.6573e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.5533e-05\n",
      "Epoch 533/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0542 - metrics_pearsonr: 3.6582e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.5230e-05\n",
      "Epoch 534/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0542 - metrics_pearsonr: 3.6579e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.5001e-05\n",
      "Epoch 535/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0541 - metrics_pearsonr: 3.6603e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.4834e-05\n",
      "Epoch 536/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0538 - metrics_pearsonr: 3.6643e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.4707e-05\n",
      "Epoch 537/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0534 - metrics_pearsonr: 3.6650e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.4771e-05\n",
      "Epoch 538/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0532 - metrics_pearsonr: 3.6614e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.4913e-05\n",
      "Epoch 539/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0532 - metrics_pearsonr: 3.6582e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 7.4957e-05\n",
      "Epoch 540/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0531 - metrics_pearsonr: 3.6530e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5096e-05\n",
      "Epoch 541/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0529 - metrics_pearsonr: 3.6456e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.5062e-05\n",
      "Epoch 542/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0527 - metrics_pearsonr: 3.6357e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5043e-05\n",
      "Epoch 543/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0526 - metrics_pearsonr: 3.6313e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.5015e-05\n",
      "Epoch 544/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0527 - metrics_pearsonr: 3.6292e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.5016e-05\n",
      "Epoch 545/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0527 - metrics_pearsonr: 3.6246e-05 - val_loss: 0.0744 - val_metrics_pearsonr: 7.5127e-05\n",
      "Epoch 546/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0526 - metrics_pearsonr: 3.6215e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.5167e-05\n",
      "Epoch 547/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0525 - metrics_pearsonr: 3.6196e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.5003e-05\n",
      "Epoch 548/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0523 - metrics_pearsonr: 3.6190e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 7.4955e-05\n",
      "Epoch 549/5000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0523 - metrics_pearsonr: 3.6182e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 7.4970e-05\n",
      "Epoch 550/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0523 - metrics_pearsonr: 3.6198e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.4967e-05\n",
      "Epoch 551/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0524 - metrics_pearsonr: 3.6211e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.5073e-05\n",
      "Epoch 552/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0524 - metrics_pearsonr: 3.6221e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5104e-05\n",
      "Epoch 553/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0523 - metrics_pearsonr: 3.6225e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5122e-05\n",
      "Epoch 554/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0523 - metrics_pearsonr: 3.6211e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5212e-05\n",
      "Epoch 555/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0523 - metrics_pearsonr: 3.6186e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.5224e-05\n",
      "Epoch 556/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0524 - metrics_pearsonr: 3.6152e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5209e-05\n",
      "Epoch 557/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0524 - metrics_pearsonr: 3.6107e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.5284e-05\n",
      "Epoch 558/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0523 - metrics_pearsonr: 3.6044e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.5303e-05\n",
      "Epoch 559/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0522 - metrics_pearsonr: 3.5997e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5285e-05\n",
      "Epoch 560/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0521 - metrics_pearsonr: 3.5982e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.5236e-05\n",
      "Epoch 561/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0520 - metrics_pearsonr: 3.5944e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5247e-05\n",
      "Epoch 562/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0519 - metrics_pearsonr: 3.5913e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5268e-05\n",
      "Epoch 563/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0519 - metrics_pearsonr: 3.5884e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5200e-05\n",
      "Epoch 564/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0520 - metrics_pearsonr: 3.5898e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5165e-05\n",
      "Epoch 565/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0520 - metrics_pearsonr: 3.5893e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.5199e-05\n",
      "Epoch 566/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0520 - metrics_pearsonr: 3.5890e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5251e-05\n",
      "Epoch 567/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0520 - metrics_pearsonr: 3.5890e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.5296e-05\n",
      "Epoch 568/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0520 - metrics_pearsonr: 3.5883e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.5353e-05\n",
      "Epoch 569/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0521 - metrics_pearsonr: 3.5875e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.5413e-05\n",
      "Epoch 570/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0522 - metrics_pearsonr: 3.5866e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.5520e-05\n",
      "Epoch 571/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0522 - metrics_pearsonr: 3.5849e-05 - val_loss: 0.0744 - val_metrics_pearsonr: 7.5583e-05\n",
      "Epoch 572/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0523 - metrics_pearsonr: 3.5832e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 7.5628e-05\n",
      "Epoch 573/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0523 - metrics_pearsonr: 3.5818e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 7.5645e-05\n",
      "Epoch 574/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0522 - metrics_pearsonr: 3.5806e-05 - val_loss: 0.0744 - val_metrics_pearsonr: 7.5645e-05\n",
      "Epoch 575/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0521 - metrics_pearsonr: 3.5800e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.5596e-05\n",
      "Epoch 576/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0520 - metrics_pearsonr: 3.5790e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.5574e-05\n",
      "Epoch 577/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0520 - metrics_pearsonr: 3.5794e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.5502e-05\n",
      "Epoch 578/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0520 - metrics_pearsonr: 3.5788e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.5502e-05\n",
      "Epoch 579/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0520 - metrics_pearsonr: 3.5798e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.5471e-05\n",
      "Epoch 580/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0521 - metrics_pearsonr: 3.5772e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5498e-05\n",
      "Epoch 581/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0522 - metrics_pearsonr: 3.5758e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.5468e-05\n",
      "Epoch 582/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0522 - metrics_pearsonr: 3.5714e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.5537e-05\n",
      "Epoch 583/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0521 - metrics_pearsonr: 3.5677e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5535e-05\n",
      "Epoch 584/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0521 - metrics_pearsonr: 3.5619e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5674e-05\n",
      "Epoch 585/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0521 - metrics_pearsonr: 3.5582e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.5773e-05\n",
      "Epoch 586/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0522 - metrics_pearsonr: 3.5541e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 7.6024e-05\n",
      "Epoch 587/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0524 - metrics_pearsonr: 3.5523e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.6190e-05\n",
      "Epoch 588/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0526 - metrics_pearsonr: 3.5510e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.6424e-05\n",
      "Epoch 589/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0528 - metrics_pearsonr: 3.5523e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 7.6461e-05\n",
      "Epoch 590/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0529 - metrics_pearsonr: 3.5554e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 7.6498e-05\n",
      "Epoch 591/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0528 - metrics_pearsonr: 3.5616e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.6314e-05\n",
      "Epoch 592/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0528 - metrics_pearsonr: 3.5708e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.6180e-05\n",
      "Epoch 593/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0528 - metrics_pearsonr: 3.5849e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 7.5989e-05\n",
      "Epoch 594/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0529 - metrics_pearsonr: 3.6000e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.6040e-05\n",
      "Epoch 595/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0533 - metrics_pearsonr: 3.6199e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 7.6279e-05\n",
      "Epoch 596/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0539 - metrics_pearsonr: 3.6376e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 7.6817e-05\n",
      "Epoch 597/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0545 - metrics_pearsonr: 3.6538e-05 - val_loss: 0.0774 - val_metrics_pearsonr: 7.7310e-05\n",
      "Epoch 598/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0549 - metrics_pearsonr: 3.6609e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.7574e-05\n",
      "Epoch 599/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0548 - metrics_pearsonr: 3.6551e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.7182e-05\n",
      "Epoch 600/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0543 - metrics_pearsonr: 3.6353e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 7.6554e-05\n",
      "Epoch 601/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0537 - metrics_pearsonr: 3.6079e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.6084e-05\n",
      "Epoch 602/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0534 - metrics_pearsonr: 3.5871e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.6480e-05\n",
      "Epoch 603/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0537 - metrics_pearsonr: 3.5815e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.7501e-05\n",
      "Epoch 604/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0546 - metrics_pearsonr: 3.5871e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 7.8625e-05\n",
      "Epoch 605/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0558 - metrics_pearsonr: 3.5946e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 7.9008e-05\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0567 - metrics_pearsonr: 3.5947e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 7.8596e-05\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0574 - metrics_pearsonr: 3.5928e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 7.7886e-05\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0577 - metrics_pearsonr: 3.6004e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 7.7518e-05\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0575 - metrics_pearsonr: 3.6205e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.7621e-05\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0568 - metrics_pearsonr: 3.6405e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.7843e-05\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0560 - metrics_pearsonr: 3.6460e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.7738e-05\n",
      "Epoch 612/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0557 - metrics_pearsonr: 3.6345e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.7320e-05\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0564 - metrics_pearsonr: 3.6096e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.6985e-05\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0575 - metrics_pearsonr: 3.5811e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 7.7045e-05\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0583 - metrics_pearsonr: 3.5617e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 7.7392e-05\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0583 - metrics_pearsonr: 3.5577e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 7.7612e-05\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0578 - metrics_pearsonr: 3.5643e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 7.7509e-05\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0573 - metrics_pearsonr: 3.5700e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 7.7226e-05\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0572 - metrics_pearsonr: 3.5691e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.7166e-05\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0577 - metrics_pearsonr: 3.5674e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 7.7415e-05\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0585 - metrics_pearsonr: 3.5683e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 7.7746e-05\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0591 - metrics_pearsonr: 3.5649e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 7.8055e-05\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0593 - metrics_pearsonr: 3.5543e-05 - val_loss: 0.0869 - val_metrics_pearsonr: 7.8444e-05\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0592 - metrics_pearsonr: 3.5449e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 7.8744e-05\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0586 - metrics_pearsonr: 3.5466e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 7.8497e-05\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0575 - metrics_pearsonr: 3.5588e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.7655e-05\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0565 - metrics_pearsonr: 3.5716e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.7054e-05\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0566 - metrics_pearsonr: 3.5815e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.7315e-05\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0575 - metrics_pearsonr: 3.5956e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 7.7715e-05\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0577 - metrics_pearsonr: 3.6040e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.7264e-05\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0563 - metrics_pearsonr: 3.5862e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.6767e-05\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0546 - metrics_pearsonr: 3.5556e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.7723e-05\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0543 - metrics_pearsonr: 3.5387e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.9480e-05\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0549 - metrics_pearsonr: 3.5344e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 7.9967e-05\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0552 - metrics_pearsonr: 3.5280e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 7.8900e-05\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0548 - metrics_pearsonr: 3.5194e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 7.7626e-05\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0542 - metrics_pearsonr: 3.5198e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.7043e-05\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0536 - metrics_pearsonr: 3.5228e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.6864e-05\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0532 - metrics_pearsonr: 3.5184e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.6827e-05\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0532 - metrics_pearsonr: 3.5071e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.7020e-05\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0533 - metrics_pearsonr: 3.4876e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 7.7292e-05\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0534 - metrics_pearsonr: 3.4826e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 7.7389e-05\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0531 - metrics_pearsonr: 3.4769e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 7.7364e-05\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0529 - metrics_pearsonr: 3.4754e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 7.7354e-05\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0530 - metrics_pearsonr: 3.4702e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 7.7489e-05\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0532 - metrics_pearsonr: 3.4660e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 7.7582e-05\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0531 - metrics_pearsonr: 3.4581e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.7621e-05\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0525 - metrics_pearsonr: 3.4488e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.7569e-05\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0519 - metrics_pearsonr: 3.4418e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.7454e-05\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0516 - metrics_pearsonr: 3.4436e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 7.7103e-05\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0518 - metrics_pearsonr: 3.4440e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.6819e-05\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0524 - metrics_pearsonr: 3.4545e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.6651e-05\n",
      "Epoch 653/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0532 - metrics_pearsonr: 3.4540e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.6742e-05\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0539 - metrics_pearsonr: 3.4612e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.6866e-05\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0546 - metrics_pearsonr: 3.4644e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 7.7136e-05\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0549 - metrics_pearsonr: 3.4664e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 7.7374e-05\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0549 - metrics_pearsonr: 3.4603e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 7.7909e-05\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0546 - metrics_pearsonr: 3.4615e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 7.8536e-05\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0541 - metrics_pearsonr: 3.4642e-05 - val_loss: 0.0802 - val_metrics_pearsonr: 7.9166e-05\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0536 - metrics_pearsonr: 3.4722e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.9301e-05\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0534 - metrics_pearsonr: 3.4829e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.8841e-05\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0538 - metrics_pearsonr: 3.4990e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.7998e-05\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0550 - metrics_pearsonr: 3.5124e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.7872e-05\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0572 - metrics_pearsonr: 3.5355e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 7.8642e-05\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0598 - metrics_pearsonr: 3.5600e-05 - val_loss: 0.0901 - val_metrics_pearsonr: 7.9958e-05\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0621 - metrics_pearsonr: 3.5893e-05 - val_loss: 0.0956 - val_metrics_pearsonr: 8.0960e-05\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0629 - metrics_pearsonr: 3.5869e-05 - val_loss: 0.0963 - val_metrics_pearsonr: 8.0582e-05\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0619 - metrics_pearsonr: 3.5600e-05 - val_loss: 0.0920 - val_metrics_pearsonr: 7.9718e-05\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0599 - metrics_pearsonr: 3.5320e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 7.9803e-05\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0586 - metrics_pearsonr: 3.5291e-05 - val_loss: 0.0814 - val_metrics_pearsonr: 8.0680e-05\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0585 - metrics_pearsonr: 3.5424e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 8.0508e-05\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0596 - metrics_pearsonr: 3.5442e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 7.8992e-05\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0618 - metrics_pearsonr: 3.5427e-05 - val_loss: 0.0892 - val_metrics_pearsonr: 7.8350e-05\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0650 - metrics_pearsonr: 3.5773e-05 - val_loss: 0.0980 - val_metrics_pearsonr: 7.9578e-05\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0672 - metrics_pearsonr: 3.6199e-05 - val_loss: 0.1003 - val_metrics_pearsonr: 8.0337e-05\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0661 - metrics_pearsonr: 3.6176e-05 - val_loss: 0.0918 - val_metrics_pearsonr: 7.9068e-05\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0625 - metrics_pearsonr: 3.5600e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 7.8731e-05\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0607 - metrics_pearsonr: 3.5517e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 8.1191e-05\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0618 - metrics_pearsonr: 3.5680e-05 - val_loss: 0.0877 - val_metrics_pearsonr: 8.2186e-05\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0638 - metrics_pearsonr: 3.5822e-05 - val_loss: 0.0965 - val_metrics_pearsonr: 8.0893e-05\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0651 - metrics_pearsonr: 3.5976e-05 - val_loss: 0.0972 - val_metrics_pearsonr: 8.0308e-05\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0642 - metrics_pearsonr: 3.6359e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 8.1479e-05\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0614 - metrics_pearsonr: 3.6625e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.0569e-05\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0590 - metrics_pearsonr: 3.6223e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.8353e-05\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0584 - metrics_pearsonr: 3.5471e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 7.9145e-05\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0584 - metrics_pearsonr: 3.5049e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 8.0587e-05\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0576 - metrics_pearsonr: 3.5016e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.9376e-05\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0558 - metrics_pearsonr: 3.4838e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 7.8087e-05\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0544 - metrics_pearsonr: 3.4597e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.8532e-05\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0544 - metrics_pearsonr: 3.4516e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 7.9098e-05\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0545 - metrics_pearsonr: 3.4341e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 7.9084e-05\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0537 - metrics_pearsonr: 3.4124e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 7.9026e-05\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0526 - metrics_pearsonr: 3.4094e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.8436e-05\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0521 - metrics_pearsonr: 3.4103e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.7581e-05\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0521 - metrics_pearsonr: 3.4097e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.7395e-05\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0521 - metrics_pearsonr: 3.4124e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.7629e-05\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0518 - metrics_pearsonr: 3.4060e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 7.7804e-05\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0511 - metrics_pearsonr: 3.3861e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.8002e-05\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0506 - metrics_pearsonr: 3.3679e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.8325e-05\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0505 - metrics_pearsonr: 3.3612e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.8328e-05\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0506 - metrics_pearsonr: 3.3603e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 7.8015e-05\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0506 - metrics_pearsonr: 3.3618e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.7751e-05\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0503 - metrics_pearsonr: 3.3629e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.7623e-05\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0500 - metrics_pearsonr: 3.3614e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.7573e-05\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0500 - metrics_pearsonr: 3.3567e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.7590e-05\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0500 - metrics_pearsonr: 3.3516e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.7684e-05\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0500 - metrics_pearsonr: 3.3486e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.7787e-05\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0499 - metrics_pearsonr: 3.3476e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.7830e-05\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0498 - metrics_pearsonr: 3.3455e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.7871e-05\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0497 - metrics_pearsonr: 3.3438e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.7904e-05\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0497 - metrics_pearsonr: 3.3415e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.7939e-05\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0497 - metrics_pearsonr: 3.3408e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.7904e-05\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0496 - metrics_pearsonr: 3.3398e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.7841e-05\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0495 - metrics_pearsonr: 3.3416e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.7743e-05\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0495 - metrics_pearsonr: 3.3376e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.7711e-05\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0494 - metrics_pearsonr: 3.3381e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.7667e-05\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0494 - metrics_pearsonr: 3.3328e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.7752e-05\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0494 - metrics_pearsonr: 3.3316e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.7790e-05\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0494 - metrics_pearsonr: 3.3274e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.7901e-05\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0494 - metrics_pearsonr: 3.3266e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.7942e-05\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0494 - metrics_pearsonr: 3.3247e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.8023e-05\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0495 - metrics_pearsonr: 3.3248e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.8030e-05\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0495 - metrics_pearsonr: 3.3236e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.8058e-05\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0495 - metrics_pearsonr: 3.3247e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.8020e-05\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0494 - metrics_pearsonr: 3.3236e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.8005e-05\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0494 - metrics_pearsonr: 3.3253e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.7948e-05\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0493 - metrics_pearsonr: 3.3225e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.7940e-05\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0493 - metrics_pearsonr: 3.3228e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.7899e-05\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0493 - metrics_pearsonr: 3.3185e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.7919e-05\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0492 - metrics_pearsonr: 3.3162e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.7922e-05\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0492 - metrics_pearsonr: 3.3113e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.8004e-05\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0492 - metrics_pearsonr: 3.3083e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.8055e-05\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0492 - metrics_pearsonr: 3.3048e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.8170e-05\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0491 - metrics_pearsonr: 3.3032e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.8219e-05\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0492 - metrics_pearsonr: 3.3017e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.8306e-05\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0492 - metrics_pearsonr: 3.3026e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.8305e-05\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0493 - metrics_pearsonr: 3.3025e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.8349e-05\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0494 - metrics_pearsonr: 3.3051e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 7.8298e-05\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0494 - metrics_pearsonr: 3.3043e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.8316e-05\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0495 - metrics_pearsonr: 3.3073e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.8272e-05\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0494 - metrics_pearsonr: 3.3052e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.8289e-05\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0494 - metrics_pearsonr: 3.3061e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.8231e-05\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0493 - metrics_pearsonr: 3.3027e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.8227e-05\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0493 - metrics_pearsonr: 3.3016e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.8182e-05\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0492 - metrics_pearsonr: 3.2968e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.8210e-05\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0491 - metrics_pearsonr: 3.2937e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.8203e-05\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0491 - metrics_pearsonr: 3.2890e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.8286e-05\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0491 - metrics_pearsonr: 3.2858e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.8330e-05\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0491 - metrics_pearsonr: 3.2819e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.8478e-05\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0492 - metrics_pearsonr: 3.2805e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.8533e-05\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0492 - metrics_pearsonr: 3.2782e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.8664e-05\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0492 - metrics_pearsonr: 3.2793e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.8657e-05\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0492 - metrics_pearsonr: 3.2786e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.8711e-05\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0492 - metrics_pearsonr: 3.2814e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.8629e-05\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0492 - metrics_pearsonr: 3.2816e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.8644e-05\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0493 - metrics_pearsonr: 3.2860e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.8555e-05\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0494 - metrics_pearsonr: 3.2874e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 7.8601e-05\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0497 - metrics_pearsonr: 3.2924e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.8585e-05\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0500 - metrics_pearsonr: 3.2937e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.8669e-05\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0503 - metrics_pearsonr: 3.2971e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 7.8681e-05\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0504 - metrics_pearsonr: 3.2962e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 7.8749e-05\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0505 - metrics_pearsonr: 3.2960e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 7.8716e-05\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0504 - metrics_pearsonr: 3.2911e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.8766e-05\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0503 - metrics_pearsonr: 3.2876e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.8747e-05\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0501 - metrics_pearsonr: 3.2809e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.8877e-05\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0499 - metrics_pearsonr: 3.2773e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.8938e-05\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0498 - metrics_pearsonr: 3.2719e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.9143e-05\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0499 - metrics_pearsonr: 3.2706e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.9192e-05\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0501 - metrics_pearsonr: 3.2676e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 7.9340e-05\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0503 - metrics_pearsonr: 3.2693e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.9266e-05\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0507 - metrics_pearsonr: 3.2690e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.9297e-05\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0510 - metrics_pearsonr: 3.2739e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.9123e-05\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0514 - metrics_pearsonr: 3.2769e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.9109e-05\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0517 - metrics_pearsonr: 3.2851e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.8979e-05\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0521 - metrics_pearsonr: 3.2911e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 7.9056e-05\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0524 - metrics_pearsonr: 3.3000e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 7.9077e-05\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0527 - metrics_pearsonr: 3.3052e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 7.9229e-05\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0527 - metrics_pearsonr: 3.3098e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 7.9256e-05\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0526 - metrics_pearsonr: 3.3095e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 7.9305e-05\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0525 - metrics_pearsonr: 3.3080e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.9225e-05\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0527 - metrics_pearsonr: 3.3048e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.9292e-05\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0535 - metrics_pearsonr: 3.3055e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.9437e-05\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0551 - metrics_pearsonr: 3.3079e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 7.9938e-05\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0574 - metrics_pearsonr: 3.3148e-05 - val_loss: 0.0889 - val_metrics_pearsonr: 8.0595e-05\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0598 - metrics_pearsonr: 3.3188e-05 - val_loss: 0.0958 - val_metrics_pearsonr: 8.1485e-05\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0614 - metrics_pearsonr: 3.3233e-05 - val_loss: 0.1005 - val_metrics_pearsonr: 8.2129e-05\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0617 - metrics_pearsonr: 3.3261e-05 - val_loss: 0.0998 - val_metrics_pearsonr: 8.2467e-05\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0605 - metrics_pearsonr: 3.3340e-05 - val_loss: 0.0927 - val_metrics_pearsonr: 8.1982e-05\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0586 - metrics_pearsonr: 3.3432e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.1079e-05\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0575 - metrics_pearsonr: 3.3561e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 8.0002e-05\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0585 - metrics_pearsonr: 3.3579e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 7.9921e-05\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0618 - metrics_pearsonr: 3.3791e-05 - val_loss: 0.0945 - val_metrics_pearsonr: 8.0774e-05\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0650 - metrics_pearsonr: 3.4013e-05 - val_loss: 0.1012 - val_metrics_pearsonr: 8.1355e-05\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0649 - metrics_pearsonr: 3.3972e-05 - val_loss: 0.0945 - val_metrics_pearsonr: 8.0563e-05\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0617 - metrics_pearsonr: 3.3692e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.0255e-05\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0593 - metrics_pearsonr: 3.3623e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.1952e-05\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0597 - metrics_pearsonr: 3.3786e-05 - val_loss: 0.0905 - val_metrics_pearsonr: 8.4014e-05\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0609 - metrics_pearsonr: 3.3874e-05 - val_loss: 0.0967 - val_metrics_pearsonr: 8.3560e-05\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0603 - metrics_pearsonr: 3.3955e-05 - val_loss: 0.0900 - val_metrics_pearsonr: 8.1526e-05\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0580 - metrics_pearsonr: 3.4231e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 8.0689e-05\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0559 - metrics_pearsonr: 3.4432e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.1769e-05\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0558 - metrics_pearsonr: 3.4445e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 8.2183e-05\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0559 - metrics_pearsonr: 3.4088e-05 - val_loss: 0.0850 - val_metrics_pearsonr: 8.1108e-05\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0548 - metrics_pearsonr: 3.3392e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 8.1518e-05\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0537 - metrics_pearsonr: 3.3104e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 8.2966e-05\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0533 - metrics_pearsonr: 3.3149e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 8.2553e-05\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0528 - metrics_pearsonr: 3.3094e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 8.0667e-05\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0521 - metrics_pearsonr: 3.3033e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 8.0094e-05\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0518 - metrics_pearsonr: 3.3153e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 8.0514e-05\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0521 - metrics_pearsonr: 3.3239e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.0136e-05\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0525 - metrics_pearsonr: 3.3049e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 7.9536e-05\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0527 - metrics_pearsonr: 3.2731e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.0340e-05\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0526 - metrics_pearsonr: 3.2623e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.1350e-05\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0523 - metrics_pearsonr: 3.2659e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.1265e-05\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0518 - metrics_pearsonr: 3.2683e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 8.0141e-05\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0514 - metrics_pearsonr: 3.2641e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 7.9594e-05\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0514 - metrics_pearsonr: 3.2642e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.9914e-05\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0522 - metrics_pearsonr: 3.2645e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.0528e-05\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0535 - metrics_pearsonr: 3.2577e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 8.1038e-05\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0547 - metrics_pearsonr: 3.2479e-05 - val_loss: 0.0888 - val_metrics_pearsonr: 8.1371e-05\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0550 - metrics_pearsonr: 3.2405e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 8.1413e-05\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0542 - metrics_pearsonr: 3.2427e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 8.1006e-05\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0531 - metrics_pearsonr: 3.2471e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.0312e-05\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0523 - metrics_pearsonr: 3.2490e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.9784e-05\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0527 - metrics_pearsonr: 3.2522e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 7.9642e-05\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0541 - metrics_pearsonr: 3.2501e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 7.9851e-05\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0556 - metrics_pearsonr: 3.2504e-05 - val_loss: 0.0882 - val_metrics_pearsonr: 8.0052e-05\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0560 - metrics_pearsonr: 3.2424e-05 - val_loss: 0.0878 - val_metrics_pearsonr: 8.0319e-05\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0549 - metrics_pearsonr: 3.2359e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.0397e-05\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0534 - metrics_pearsonr: 3.2303e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 8.0644e-05\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0528 - metrics_pearsonr: 3.2309e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 8.0753e-05\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0536 - metrics_pearsonr: 3.2303e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.0980e-05\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0553 - metrics_pearsonr: 3.2354e-05 - val_loss: 0.0892 - val_metrics_pearsonr: 8.1334e-05\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0564 - metrics_pearsonr: 3.2479e-05 - val_loss: 0.0911 - val_metrics_pearsonr: 8.1518e-05\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0559 - metrics_pearsonr: 3.2544e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 8.1199e-05\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0542 - metrics_pearsonr: 3.2510e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.0534e-05\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0528 - metrics_pearsonr: 3.2393e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0074e-05\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0529 - metrics_pearsonr: 3.2306e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.0022e-05\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0539 - metrics_pearsonr: 3.2271e-05 - val_loss: 0.0851 - val_metrics_pearsonr: 8.0161e-05\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0543 - metrics_pearsonr: 3.2231e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.0239e-05\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0534 - metrics_pearsonr: 3.2213e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 8.0147e-05\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0519 - metrics_pearsonr: 3.2108e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 8.0281e-05\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0512 - metrics_pearsonr: 3.2022e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 8.0600e-05\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0517 - metrics_pearsonr: 3.1947e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.1088e-05\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0525 - metrics_pearsonr: 3.1941e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.1244e-05\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0525 - metrics_pearsonr: 3.1981e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 8.0964e-05\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0515 - metrics_pearsonr: 3.1985e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 8.0401e-05\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0505 - metrics_pearsonr: 3.1969e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.9950e-05\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0502 - metrics_pearsonr: 3.1946e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 7.9766e-05\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0506 - metrics_pearsonr: 3.1908e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 7.9846e-05\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0509 - metrics_pearsonr: 3.1926e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 7.9917e-05\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0504 - metrics_pearsonr: 3.1852e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 8.0034e-05\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0496 - metrics_pearsonr: 3.1799e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0065e-05\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0492 - metrics_pearsonr: 3.1718e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0349e-05\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0494 - metrics_pearsonr: 3.1669e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 8.0600e-05\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0498 - metrics_pearsonr: 3.1639e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.0717e-05\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0498 - metrics_pearsonr: 3.1620e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.0586e-05\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0493 - metrics_pearsonr: 3.1609e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 8.0316e-05\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0487 - metrics_pearsonr: 3.1581e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 8.0029e-05\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0486 - metrics_pearsonr: 3.1570e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.9890e-05\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0487 - metrics_pearsonr: 3.1569e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.9856e-05\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0489 - metrics_pearsonr: 3.1573e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.9908e-05\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0488 - metrics_pearsonr: 3.1584e-05 - val_loss: 0.0774 - val_metrics_pearsonr: 7.9984e-05\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0485 - metrics_pearsonr: 3.1560e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0083e-05\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0483 - metrics_pearsonr: 3.1543e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0216e-05\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0484 - metrics_pearsonr: 3.1504e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 8.0411e-05\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0486 - metrics_pearsonr: 3.1497e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 8.0509e-05\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0487 - metrics_pearsonr: 3.1478e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.0536e-05\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0486 - metrics_pearsonr: 3.1482e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 8.0379e-05\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0483 - metrics_pearsonr: 3.1461e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0243e-05\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0480 - metrics_pearsonr: 3.1469e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 8.0039e-05\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0480 - metrics_pearsonr: 3.1424e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0021e-05\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0481 - metrics_pearsonr: 3.1431e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.9942e-05\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0482 - metrics_pearsonr: 3.1390e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 8.0052e-05\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0481 - metrics_pearsonr: 3.1381e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 8.0049e-05\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0480 - metrics_pearsonr: 3.1338e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0209e-05\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0478 - metrics_pearsonr: 3.1314e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 8.0291e-05\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0479 - metrics_pearsonr: 3.1285e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 8.0498e-05\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0481 - metrics_pearsonr: 3.1271e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 8.0596e-05\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0483 - metrics_pearsonr: 3.1275e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 8.0702e-05\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0483 - metrics_pearsonr: 3.1289e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 8.0628e-05\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0482 - metrics_pearsonr: 3.1312e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 8.0553e-05\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0480 - metrics_pearsonr: 3.1350e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0360e-05\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0479 - metrics_pearsonr: 3.1350e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0280e-05\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0480 - metrics_pearsonr: 3.1393e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 8.0165e-05\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0481 - metrics_pearsonr: 3.1365e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 8.0227e-05\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0483 - metrics_pearsonr: 3.1382e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 8.0172e-05\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0482 - metrics_pearsonr: 3.1340e-05 - val_loss: 0.0774 - val_metrics_pearsonr: 8.0277e-05\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0480 - metrics_pearsonr: 3.1308e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 8.0257e-05\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0478 - metrics_pearsonr: 3.1238e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0419e-05\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0478 - metrics_pearsonr: 3.1184e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 8.0534e-05\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0479 - metrics_pearsonr: 3.1134e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 8.0809e-05\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0482 - metrics_pearsonr: 3.1105e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.0955e-05\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0484 - metrics_pearsonr: 3.1095e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.1136e-05\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0484 - metrics_pearsonr: 3.1103e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 8.1059e-05\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0482 - metrics_pearsonr: 3.1122e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 8.0996e-05\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0480 - metrics_pearsonr: 3.1164e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 8.0734e-05\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0479 - metrics_pearsonr: 3.1171e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 8.0598e-05\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0480 - metrics_pearsonr: 3.1231e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0397e-05\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0483 - metrics_pearsonr: 3.1219e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 8.0435e-05\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0487 - metrics_pearsonr: 3.1268e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 8.0362e-05\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0489 - metrics_pearsonr: 3.1259e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.0502e-05\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0488 - metrics_pearsonr: 3.1259e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 8.0467e-05\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0485 - metrics_pearsonr: 3.1205e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 8.0597e-05\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0484 - metrics_pearsonr: 3.1154e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0663e-05\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0485 - metrics_pearsonr: 3.1107e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 8.0943e-05\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0490 - metrics_pearsonr: 3.1079e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.1154e-05\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0497 - metrics_pearsonr: 3.1079e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.1469e-05\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0502 - metrics_pearsonr: 3.1096e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.1527e-05\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0502 - metrics_pearsonr: 3.1134e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.1572e-05\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0498 - metrics_pearsonr: 3.1177e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.1323e-05\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0493 - metrics_pearsonr: 3.1190e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 8.1119e-05\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0490 - metrics_pearsonr: 3.1239e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0805e-05\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0492 - metrics_pearsonr: 3.1206e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 8.0742e-05\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0499 - metrics_pearsonr: 3.1265e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 8.0647e-05\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0509 - metrics_pearsonr: 3.1264e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.0835e-05\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0514 - metrics_pearsonr: 3.1292e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.0765e-05\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0513 - metrics_pearsonr: 3.1234e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.0839e-05\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0506 - metrics_pearsonr: 3.1162e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.0836e-05\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0499 - metrics_pearsonr: 3.1074e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 8.1330e-05\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0500 - metrics_pearsonr: 3.1050e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 8.1970e-05\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0510 - metrics_pearsonr: 3.1067e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.2950e-05\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0524 - metrics_pearsonr: 3.1122e-05 - val_loss: 0.0873 - val_metrics_pearsonr: 8.3522e-05\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0535 - metrics_pearsonr: 3.1199e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 8.3776e-05\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0537 - metrics_pearsonr: 3.1321e-05 - val_loss: 0.0889 - val_metrics_pearsonr: 8.3271e-05\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0531 - metrics_pearsonr: 3.1504e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 8.2489e-05\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0521 - metrics_pearsonr: 3.1703e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.1667e-05\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0518 - metrics_pearsonr: 3.1878e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 8.1615e-05\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0529 - metrics_pearsonr: 3.2127e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.2198e-05\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0547 - metrics_pearsonr: 3.2211e-05 - val_loss: 0.0882 - val_metrics_pearsonr: 8.2893e-05\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0558 - metrics_pearsonr: 3.2272e-05 - val_loss: 0.0899 - val_metrics_pearsonr: 8.2465e-05\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0551 - metrics_pearsonr: 3.2010e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 8.1854e-05\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0534 - metrics_pearsonr: 3.1694e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.1846e-05\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0523 - metrics_pearsonr: 3.1461e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 8.3256e-05\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0526 - metrics_pearsonr: 3.1487e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 8.4578e-05\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0537 - metrics_pearsonr: 3.1615e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 8.4132e-05\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0543 - metrics_pearsonr: 3.1781e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 8.2765e-05\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0541 - metrics_pearsonr: 3.2117e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.2562e-05\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0535 - metrics_pearsonr: 3.2560e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.3987e-05\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0528 - metrics_pearsonr: 3.2939e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.5054e-05\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0526 - metrics_pearsonr: 3.3065e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.3686e-05\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0522 - metrics_pearsonr: 3.2695e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 8.1659e-05\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0514 - metrics_pearsonr: 3.1994e-05 - val_loss: 0.0814 - val_metrics_pearsonr: 8.2697e-05\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0509 - metrics_pearsonr: 3.1782e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.5464e-05\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0506 - metrics_pearsonr: 3.1867e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.5953e-05\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0504 - metrics_pearsonr: 3.1804e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.3519e-05\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0500 - metrics_pearsonr: 3.1468e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.1678e-05\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0501 - metrics_pearsonr: 3.1290e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.1845e-05\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0503 - metrics_pearsonr: 3.1342e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 8.2307e-05\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0499 - metrics_pearsonr: 3.1236e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 8.1927e-05\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0493 - metrics_pearsonr: 3.0926e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.2040e-05\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0490 - metrics_pearsonr: 3.0692e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 8.2580e-05\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0492 - metrics_pearsonr: 3.0682e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 8.2421e-05\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0495 - metrics_pearsonr: 3.0801e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 8.1765e-05\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0498 - metrics_pearsonr: 3.0957e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.1578e-05\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0501 - metrics_pearsonr: 3.1116e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.1873e-05\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0501 - metrics_pearsonr: 3.1205e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.1923e-05\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0497 - metrics_pearsonr: 3.1147e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.1629e-05\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0490 - metrics_pearsonr: 3.0936e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 8.1634e-05\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0483 - metrics_pearsonr: 3.0739e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 8.1887e-05\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0481 - metrics_pearsonr: 3.0608e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 8.1981e-05\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0483 - metrics_pearsonr: 3.0542e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.1847e-05\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0488 - metrics_pearsonr: 3.0523e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 8.1793e-05\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0493 - metrics_pearsonr: 3.0542e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 8.1758e-05\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0497 - metrics_pearsonr: 3.0567e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 8.1723e-05\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0497 - metrics_pearsonr: 3.0550e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 8.1682e-05\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0495 - metrics_pearsonr: 3.0521e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 8.1973e-05\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0493 - metrics_pearsonr: 3.0532e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.2235e-05\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0490 - metrics_pearsonr: 3.0544e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 8.2343e-05\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0488 - metrics_pearsonr: 3.0604e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 8.2043e-05\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0488 - metrics_pearsonr: 3.0619e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 8.1829e-05\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0493 - metrics_pearsonr: 3.0667e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 8.1830e-05\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0504 - metrics_pearsonr: 3.0715e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 8.2241e-05\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0517 - metrics_pearsonr: 3.0782e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 8.2644e-05\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0527 - metrics_pearsonr: 3.0813e-05 - val_loss: 0.0891 - val_metrics_pearsonr: 8.2855e-05\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0528 - metrics_pearsonr: 3.0789e-05 - val_loss: 0.0886 - val_metrics_pearsonr: 8.2702e-05\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0521 - metrics_pearsonr: 3.0715e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.2391e-05\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0510 - metrics_pearsonr: 3.0661e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.1962e-05\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0503 - metrics_pearsonr: 3.0597e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 8.1663e-05\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0505 - metrics_pearsonr: 3.0601e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.1435e-05\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0516 - metrics_pearsonr: 3.0573e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.1553e-05\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0530 - metrics_pearsonr: 3.0576e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 8.1734e-05\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0538 - metrics_pearsonr: 3.0544e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 8.2077e-05\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0535 - metrics_pearsonr: 3.0486e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 8.2245e-05\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0522 - metrics_pearsonr: 3.0432e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.2646e-05\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0512 - metrics_pearsonr: 3.0457e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.2987e-05\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0513 - metrics_pearsonr: 3.0520e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 8.3233e-05\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0527 - metrics_pearsonr: 3.0588e-05 - val_loss: 0.0866 - val_metrics_pearsonr: 8.3142e-05\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0543 - metrics_pearsonr: 3.0662e-05 - val_loss: 0.0920 - val_metrics_pearsonr: 8.3092e-05\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0550 - metrics_pearsonr: 3.0772e-05 - val_loss: 0.0921 - val_metrics_pearsonr: 8.2969e-05\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0541 - metrics_pearsonr: 3.0863e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 8.2614e-05\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0523 - metrics_pearsonr: 3.0825e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 8.2103e-05\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0511 - metrics_pearsonr: 3.0637e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 8.1867e-05\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0513 - metrics_pearsonr: 3.0468e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.1963e-05\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0520 - metrics_pearsonr: 3.0292e-05 - val_loss: 0.0854 - val_metrics_pearsonr: 8.2265e-05\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0519 - metrics_pearsonr: 3.0244e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 8.2210e-05\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0509 - metrics_pearsonr: 3.0235e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.2158e-05\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0500 - metrics_pearsonr: 3.0272e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 8.2060e-05\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0500 - metrics_pearsonr: 3.0319e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 8.2301e-05\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0510 - metrics_pearsonr: 3.0391e-05 - val_loss: 0.0857 - val_metrics_pearsonr: 8.2697e-05\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0516 - metrics_pearsonr: 3.0456e-05 - val_loss: 0.0870 - val_metrics_pearsonr: 8.2906e-05\n",
      "Epoch 1/5000\n",
      "3/3 [==============================] - 2s 344ms/step - loss: 0.0756 - metrics_pearsonr: 5.9836e-05 - val_loss: 0.0549 - val_metrics_pearsonr: 4.4284e-05\n",
      "Epoch 2/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0733 - metrics_pearsonr: 5.9136e-05 - val_loss: 0.0550 - val_metrics_pearsonr: 4.5372e-05\n",
      "Epoch 3/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0726 - metrics_pearsonr: 5.8916e-05 - val_loss: 0.0557 - val_metrics_pearsonr: 4.6114e-05\n",
      "Epoch 4/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0722 - metrics_pearsonr: 5.7968e-05 - val_loss: 0.0575 - val_metrics_pearsonr: 4.6924e-05\n",
      "Epoch 5/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0725 - metrics_pearsonr: 5.7485e-05 - val_loss: 0.0603 - val_metrics_pearsonr: 4.7852e-05\n",
      "Epoch 6/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0730 - metrics_pearsonr: 5.7177e-05 - val_loss: 0.0626 - val_metrics_pearsonr: 4.9796e-05\n",
      "Epoch 7/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0729 - metrics_pearsonr: 5.6891e-05 - val_loss: 0.0628 - val_metrics_pearsonr: 5.0100e-05\n",
      "Epoch 8/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0722 - metrics_pearsonr: 5.6166e-05 - val_loss: 0.0618 - val_metrics_pearsonr: 5.0615e-05\n",
      "Epoch 9/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0714 - metrics_pearsonr: 5.5666e-05 - val_loss: 0.0607 - val_metrics_pearsonr: 5.1075e-05\n",
      "Epoch 10/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0712 - metrics_pearsonr: 5.5535e-05 - val_loss: 0.0600 - val_metrics_pearsonr: 5.1740e-05\n",
      "Epoch 11/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0716 - metrics_pearsonr: 5.5501e-05 - val_loss: 0.0599 - val_metrics_pearsonr: 5.2716e-05\n",
      "Epoch 12/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0728 - metrics_pearsonr: 5.5497e-05 - val_loss: 0.0614 - val_metrics_pearsonr: 5.3329e-05\n",
      "Epoch 13/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0747 - metrics_pearsonr: 5.5262e-05 - val_loss: 0.0654 - val_metrics_pearsonr: 5.4114e-05\n",
      "Epoch 14/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0773 - metrics_pearsonr: 5.5158e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 5.4848e-05\n",
      "Epoch 15/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0802 - metrics_pearsonr: 5.5009e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 5.5418e-05\n",
      "Epoch 16/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0822 - metrics_pearsonr: 5.4903e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 5.6035e-05\n",
      "Epoch 17/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0826 - metrics_pearsonr: 5.4908e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 5.6533e-05\n",
      "Epoch 18/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0811 - metrics_pearsonr: 5.5029e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 5.6672e-05\n",
      "Epoch 19/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0784 - metrics_pearsonr: 5.4945e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 5.6410e-05\n",
      "Epoch 20/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0767 - metrics_pearsonr: 5.4643e-05 - val_loss: 0.0631 - val_metrics_pearsonr: 5.6576e-05\n",
      "Epoch 21/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0781 - metrics_pearsonr: 5.4371e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 5.7490e-05\n",
      "Epoch 22/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0821 - metrics_pearsonr: 5.4240e-05 - val_loss: 0.0864 - val_metrics_pearsonr: 5.8701e-05\n",
      "Epoch 23/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0853 - metrics_pearsonr: 5.4068e-05 - val_loss: 0.0940 - val_metrics_pearsonr: 5.9334e-05\n",
      "Epoch 24/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0842 - metrics_pearsonr: 5.3759e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 5.8912e-05\n",
      "Epoch 25/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0796 - metrics_pearsonr: 5.3435e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 5.8012e-05\n",
      "Epoch 26/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0758 - metrics_pearsonr: 5.3211e-05 - val_loss: 0.0624 - val_metrics_pearsonr: 5.7718e-05\n",
      "Epoch 27/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0761 - metrics_pearsonr: 5.3124e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 5.8827e-05\n",
      "Epoch 28/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0796 - metrics_pearsonr: 5.3275e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 6.0062e-05\n",
      "Epoch 29/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0809 - metrics_pearsonr: 5.3227e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 5.9539e-05\n",
      "Epoch 30/5000\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0775 - metrics_pearsonr: 5.2637e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 5.8577e-05\n",
      "Epoch 31/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0736 - metrics_pearsonr: 5.2145e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 5.8557e-05\n",
      "Epoch 32/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0727 - metrics_pearsonr: 5.2051e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 5.9262e-05\n",
      "Epoch 33/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0737 - metrics_pearsonr: 5.2210e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 6.0132e-05\n",
      "Epoch 34/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0735 - metrics_pearsonr: 5.2280e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 6.0085e-05\n",
      "Epoch 35/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0715 - metrics_pearsonr: 5.1896e-05 - val_loss: 0.0665 - val_metrics_pearsonr: 5.9620e-05\n",
      "Epoch 36/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0703 - metrics_pearsonr: 5.1411e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 5.9830e-05\n",
      "Epoch 37/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0704 - metrics_pearsonr: 5.1270e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 6.0397e-05\n",
      "Epoch 38/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0701 - metrics_pearsonr: 5.1377e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 6.0701e-05\n",
      "Epoch 39/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0687 - metrics_pearsonr: 5.1304e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.0410e-05\n",
      "Epoch 40/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0673 - metrics_pearsonr: 5.0891e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 5.9944e-05\n",
      "Epoch 41/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0668 - metrics_pearsonr: 5.0401e-05 - val_loss: 0.0664 - val_metrics_pearsonr: 5.9834e-05\n",
      "Epoch 42/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0668 - metrics_pearsonr: 5.0123e-05 - val_loss: 0.0673 - val_metrics_pearsonr: 5.9882e-05\n",
      "Epoch 43/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0667 - metrics_pearsonr: 5.0053e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 5.9950e-05\n",
      "Epoch 44/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0665 - metrics_pearsonr: 5.0036e-05 - val_loss: 0.0667 - val_metrics_pearsonr: 6.0193e-05\n",
      "Epoch 45/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0663 - metrics_pearsonr: 4.9990e-05 - val_loss: 0.0660 - val_metrics_pearsonr: 6.0439e-05\n",
      "Epoch 46/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0659 - metrics_pearsonr: 4.9885e-05 - val_loss: 0.0647 - val_metrics_pearsonr: 6.0594e-05\n",
      "Epoch 47/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0656 - metrics_pearsonr: 4.9766e-05 - val_loss: 0.0640 - val_metrics_pearsonr: 6.0800e-05\n",
      "Epoch 48/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0658 - metrics_pearsonr: 4.9735e-05 - val_loss: 0.0652 - val_metrics_pearsonr: 6.1171e-05\n",
      "Epoch 49/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0663 - metrics_pearsonr: 4.9775e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 6.1632e-05\n",
      "Epoch 50/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0669 - metrics_pearsonr: 4.9763e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 6.1864e-05\n",
      "Epoch 51/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0667 - metrics_pearsonr: 4.9615e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.1814e-05\n",
      "Epoch 52/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0660 - metrics_pearsonr: 4.9401e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 6.1672e-05\n",
      "Epoch 53/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0652 - metrics_pearsonr: 4.9217e-05 - val_loss: 0.0653 - val_metrics_pearsonr: 6.1563e-05\n",
      "Epoch 54/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0646 - metrics_pearsonr: 4.9091e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.1595e-05\n",
      "Epoch 55/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0647 - metrics_pearsonr: 4.9008e-05 - val_loss: 0.0653 - val_metrics_pearsonr: 6.1685e-05\n",
      "Epoch 56/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0651 - metrics_pearsonr: 4.8910e-05 - val_loss: 0.0672 - val_metrics_pearsonr: 6.1776e-05\n",
      "Epoch 57/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0657 - metrics_pearsonr: 4.8787e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 6.1862e-05\n",
      "Epoch 58/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0660 - metrics_pearsonr: 4.8681e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 6.1970e-05\n",
      "Epoch 59/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0659 - metrics_pearsonr: 4.8649e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.2080e-05\n",
      "Epoch 60/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0654 - metrics_pearsonr: 4.8678e-05 - val_loss: 0.0667 - val_metrics_pearsonr: 6.2226e-05\n",
      "Epoch 61/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0650 - metrics_pearsonr: 4.8713e-05 - val_loss: 0.0652 - val_metrics_pearsonr: 6.2461e-05\n",
      "Epoch 62/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0650 - metrics_pearsonr: 4.8735e-05 - val_loss: 0.0656 - val_metrics_pearsonr: 6.2821e-05\n",
      "Epoch 63/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0656 - metrics_pearsonr: 4.8739e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 6.3225e-05\n",
      "Epoch 64/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0664 - metrics_pearsonr: 4.8722e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 6.3584e-05\n",
      "Epoch 65/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0670 - metrics_pearsonr: 4.8672e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.3753e-05\n",
      "Epoch 66/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0667 - metrics_pearsonr: 4.8565e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 6.3696e-05\n",
      "Epoch 67/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0658 - metrics_pearsonr: 4.8400e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 6.3484e-05\n",
      "Epoch 68/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0648 - metrics_pearsonr: 4.8215e-05 - val_loss: 0.0659 - val_metrics_pearsonr: 6.3278e-05\n",
      "Epoch 69/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0643 - metrics_pearsonr: 4.8063e-05 - val_loss: 0.0659 - val_metrics_pearsonr: 6.3213e-05\n",
      "Epoch 70/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0648 - metrics_pearsonr: 4.7960e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 6.3303e-05\n",
      "Epoch 71/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0656 - metrics_pearsonr: 4.7891e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 6.3456e-05\n",
      "Epoch 72/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0663 - metrics_pearsonr: 4.7838e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.3582e-05\n",
      "Epoch 73/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0663 - metrics_pearsonr: 4.7795e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 6.3645e-05\n",
      "Epoch 74/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0657 - metrics_pearsonr: 4.7775e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 6.3708e-05\n",
      "Epoch 75/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0649 - metrics_pearsonr: 4.7795e-05 - val_loss: 0.0663 - val_metrics_pearsonr: 6.3878e-05\n",
      "Epoch 76/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0648 - metrics_pearsonr: 4.7846e-05 - val_loss: 0.0665 - val_metrics_pearsonr: 6.4282e-05\n",
      "Epoch 77/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0655 - metrics_pearsonr: 4.7904e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 6.4785e-05\n",
      "Epoch 78/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0666 - metrics_pearsonr: 4.7936e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.5216e-05\n",
      "Epoch 79/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0672 - metrics_pearsonr: 4.7872e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 6.5290e-05\n",
      "Epoch 80/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0668 - metrics_pearsonr: 4.7745e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.5138e-05\n",
      "Epoch 81/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0656 - metrics_pearsonr: 4.7551e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.4804e-05\n",
      "Epoch 82/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0644 - metrics_pearsonr: 4.7408e-05 - val_loss: 0.0666 - val_metrics_pearsonr: 6.4642e-05\n",
      "Epoch 83/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0642 - metrics_pearsonr: 4.7283e-05 - val_loss: 0.0675 - val_metrics_pearsonr: 6.4603e-05\n",
      "Epoch 84/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0649 - metrics_pearsonr: 4.7224e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 6.4748e-05\n",
      "Epoch 85/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0658 - metrics_pearsonr: 4.7147e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.4836e-05\n",
      "Epoch 86/5000\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0662 - metrics_pearsonr: 4.7096e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.4910e-05\n",
      "Epoch 87/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0657 - metrics_pearsonr: 4.7070e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 6.4913e-05\n",
      "Epoch 88/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0648 - metrics_pearsonr: 4.7101e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 6.5067e-05\n",
      "Epoch 89/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0643 - metrics_pearsonr: 4.7129e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 6.5387e-05\n",
      "Epoch 90/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0647 - metrics_pearsonr: 4.7205e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 6.5935e-05\n",
      "Epoch 91/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0657 - metrics_pearsonr: 4.7185e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.6289e-05\n",
      "Epoch 92/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0662 - metrics_pearsonr: 4.7138e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 6.6402e-05\n",
      "Epoch 93/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0657 - metrics_pearsonr: 4.6960e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.6146e-05\n",
      "Epoch 94/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0645 - metrics_pearsonr: 4.6786e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 6.5870e-05\n",
      "Epoch 95/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0635 - metrics_pearsonr: 4.6627e-05 - val_loss: 0.0672 - val_metrics_pearsonr: 6.5695e-05\n",
      "Epoch 96/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0634 - metrics_pearsonr: 4.6535e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 6.5733e-05\n",
      "Epoch 97/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0641 - metrics_pearsonr: 4.6472e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 6.5834e-05\n",
      "Epoch 98/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0648 - metrics_pearsonr: 4.6413e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 6.5918e-05\n",
      "Epoch 99/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0648 - metrics_pearsonr: 4.6352e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.5920e-05\n",
      "Epoch 100/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0642 - metrics_pearsonr: 4.6326e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 6.5995e-05\n",
      "Epoch 101/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0635 - metrics_pearsonr: 4.6338e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 6.6183e-05\n",
      "Epoch 102/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0633 - metrics_pearsonr: 4.6390e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 6.6619e-05\n",
      "Epoch 103/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0639 - metrics_pearsonr: 4.6416e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 6.6983e-05\n",
      "Epoch 104/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0645 - metrics_pearsonr: 4.6412e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.7208e-05\n",
      "Epoch 105/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0644 - metrics_pearsonr: 4.6283e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.7036e-05\n",
      "Epoch 106/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0637 - metrics_pearsonr: 4.6163e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 6.6874e-05\n",
      "Epoch 107/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0627 - metrics_pearsonr: 4.6000e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 6.6631e-05\n",
      "Epoch 108/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0623 - metrics_pearsonr: 4.5909e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 6.6640e-05\n",
      "Epoch 109/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0626 - metrics_pearsonr: 4.5880e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 6.6735e-05\n",
      "Epoch 110/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0632 - metrics_pearsonr: 4.5843e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.6795e-05\n",
      "Epoch 111/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0636 - metrics_pearsonr: 4.5778e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.6867e-05\n",
      "Epoch 112/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0633 - metrics_pearsonr: 4.5827e-05 - val_loss: 0.0708 - val_metrics_pearsonr: 6.7031e-05\n",
      "Epoch 113/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0628 - metrics_pearsonr: 4.5825e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.7140e-05\n",
      "Epoch 114/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0625 - metrics_pearsonr: 4.5848e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 6.7476e-05\n",
      "Epoch 115/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0627 - metrics_pearsonr: 4.5864e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 6.7727e-05\n",
      "Epoch 116/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0632 - metrics_pearsonr: 4.5854e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 6.7909e-05\n",
      "Epoch 117/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0633 - metrics_pearsonr: 4.5715e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.7862e-05\n",
      "Epoch 118/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0630 - metrics_pearsonr: 4.5637e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 6.7955e-05\n",
      "Epoch 119/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0623 - metrics_pearsonr: 4.5562e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 6.7773e-05\n",
      "Epoch 120/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0617 - metrics_pearsonr: 4.5471e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 6.7725e-05\n",
      "Epoch 121/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0617 - metrics_pearsonr: 4.5384e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 6.7722e-05\n",
      "Epoch 122/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0621 - metrics_pearsonr: 4.5337e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 6.7734e-05\n",
      "Epoch 123/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0625 - metrics_pearsonr: 4.5243e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.7712e-05\n",
      "Epoch 124/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0627 - metrics_pearsonr: 4.5172e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.7739e-05\n",
      "Epoch 125/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0624 - metrics_pearsonr: 4.5137e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 6.7808e-05\n",
      "Epoch 126/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0620 - metrics_pearsonr: 4.5158e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 6.7994e-05\n",
      "Epoch 127/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0619 - metrics_pearsonr: 4.5190e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 6.8286e-05\n",
      "Epoch 128/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0621 - metrics_pearsonr: 4.5206e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 6.8602e-05\n",
      "Epoch 129/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0625 - metrics_pearsonr: 4.5150e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.8732e-05\n",
      "Epoch 130/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0626 - metrics_pearsonr: 4.5066e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.8752e-05\n",
      "Epoch 131/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0623 - metrics_pearsonr: 4.4946e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 6.8584e-05\n",
      "Epoch 132/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0616 - metrics_pearsonr: 4.4833e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 6.8470e-05\n",
      "Epoch 133/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0610 - metrics_pearsonr: 4.4733e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 6.8379e-05\n",
      "Epoch 134/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0609 - metrics_pearsonr: 4.4685e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 6.8408e-05\n",
      "Epoch 135/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0613 - metrics_pearsonr: 4.4634e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 6.8451e-05\n",
      "Epoch 136/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0619 - metrics_pearsonr: 4.4613e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.8538e-05\n",
      "Epoch 137/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0622 - metrics_pearsonr: 4.4594e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.8611e-05\n",
      "Epoch 138/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0622 - metrics_pearsonr: 4.4610e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 6.8759e-05\n",
      "Epoch 139/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0619 - metrics_pearsonr: 4.4638e-05 - val_loss: 0.0706 - val_metrics_pearsonr: 6.8900e-05\n",
      "Epoch 140/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0618 - metrics_pearsonr: 4.4701e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 6.9225e-05\n",
      "Epoch 141/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0619 - metrics_pearsonr: 4.4728e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 6.9495e-05\n",
      "Epoch 142/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0624 - metrics_pearsonr: 4.4765e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.9807e-05\n",
      "Epoch 143/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0627 - metrics_pearsonr: 4.4686e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 6.9793e-05\n",
      "Epoch 144/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0625 - metrics_pearsonr: 4.4597e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 6.9726e-05\n",
      "Epoch 145/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0619 - metrics_pearsonr: 4.4433e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.9474e-05\n",
      "Epoch 146/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0611 - metrics_pearsonr: 4.4309e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 6.9332e-05\n",
      "Epoch 147/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0607 - metrics_pearsonr: 4.4189e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 6.9245e-05\n",
      "Epoch 148/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0608 - metrics_pearsonr: 4.4130e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 6.9299e-05\n",
      "Epoch 149/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0613 - metrics_pearsonr: 4.4076e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.9374e-05\n",
      "Epoch 150/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0618 - metrics_pearsonr: 4.4064e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.9459e-05\n",
      "Epoch 151/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0621 - metrics_pearsonr: 4.4054e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 6.9496e-05\n",
      "Epoch 152/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0620 - metrics_pearsonr: 4.4096e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.9634e-05\n",
      "Epoch 153/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0618 - metrics_pearsonr: 4.4161e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 6.9832e-05\n",
      "Epoch 154/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0618 - metrics_pearsonr: 4.4278e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 7.0284e-05\n",
      "Epoch 155/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0623 - metrics_pearsonr: 4.4356e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.0687e-05\n",
      "Epoch 156/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0631 - metrics_pearsonr: 4.4441e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.1084e-05\n",
      "Epoch 157/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0634 - metrics_pearsonr: 4.4378e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.1034e-05\n",
      "Epoch 158/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0630 - metrics_pearsonr: 4.4282e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.0854e-05\n",
      "Epoch 159/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0620 - metrics_pearsonr: 4.4086e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 7.0437e-05\n",
      "Epoch 160/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0610 - metrics_pearsonr: 4.3925e-05 - val_loss: 0.0706 - val_metrics_pearsonr: 7.0204e-05\n",
      "Epoch 161/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0605 - metrics_pearsonr: 4.3778e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.0117e-05\n",
      "Epoch 162/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0608 - metrics_pearsonr: 4.3700e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 7.0216e-05\n",
      "Epoch 163/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0615 - metrics_pearsonr: 4.3638e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 7.0342e-05\n",
      "Epoch 164/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0619 - metrics_pearsonr: 4.3610e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.0409e-05\n",
      "Epoch 165/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0619 - metrics_pearsonr: 4.3583e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.0405e-05\n",
      "Epoch 166/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0615 - metrics_pearsonr: 4.3624e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.0482e-05\n",
      "Epoch 167/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0613 - metrics_pearsonr: 4.3693e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 7.0697e-05\n",
      "Epoch 168/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0616 - metrics_pearsonr: 4.3841e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 7.1249e-05\n",
      "Epoch 169/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0624 - metrics_pearsonr: 4.3945e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.1742e-05\n",
      "Epoch 170/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0632 - metrics_pearsonr: 4.4056e-05 - val_loss: 0.0774 - val_metrics_pearsonr: 7.2139e-05\n",
      "Epoch 171/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0633 - metrics_pearsonr: 4.3983e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.1925e-05\n",
      "Epoch 172/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0625 - metrics_pearsonr: 4.3852e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 7.1595e-05\n",
      "Epoch 173/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0612 - metrics_pearsonr: 4.3630e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.1106e-05\n",
      "Epoch 174/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0604 - metrics_pearsonr: 4.3463e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 7.0948e-05\n",
      "Epoch 175/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0603 - metrics_pearsonr: 4.3331e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 7.0956e-05\n",
      "Epoch 176/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0607 - metrics_pearsonr: 4.3259e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.1086e-05\n",
      "Epoch 177/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0612 - metrics_pearsonr: 4.3189e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.1124e-05\n",
      "Epoch 178/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0611 - metrics_pearsonr: 4.3139e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.1107e-05\n",
      "Epoch 179/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0607 - metrics_pearsonr: 4.3100e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 7.1140e-05\n",
      "Epoch 180/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0604 - metrics_pearsonr: 4.3140e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.1406e-05\n",
      "Epoch 181/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0608 - metrics_pearsonr: 4.3202e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 7.1783e-05\n",
      "Epoch 182/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0615 - metrics_pearsonr: 4.3322e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.2284e-05\n",
      "Epoch 183/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0620 - metrics_pearsonr: 4.3333e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 7.2367e-05\n",
      "Epoch 184/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0618 - metrics_pearsonr: 4.3299e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 7.2252e-05\n",
      "Epoch 185/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0609 - metrics_pearsonr: 4.3114e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.1808e-05\n",
      "Epoch 186/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0599 - metrics_pearsonr: 4.2968e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 7.1596e-05\n",
      "Epoch 187/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0594 - metrics_pearsonr: 4.2816e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 7.1479e-05\n",
      "Epoch 188/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0595 - metrics_pearsonr: 4.2750e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 7.1593e-05\n",
      "Epoch 189/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0600 - metrics_pearsonr: 4.2717e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 7.1696e-05\n",
      "Epoch 190/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0603 - metrics_pearsonr: 4.2716e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.1735e-05\n",
      "Epoch 191/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0604 - metrics_pearsonr: 4.2699e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.1751e-05\n",
      "Epoch 192/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0603 - metrics_pearsonr: 4.2743e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 7.1945e-05\n",
      "Epoch 193/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0605 - metrics_pearsonr: 4.2817e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.2270e-05\n",
      "Epoch 194/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0610 - metrics_pearsonr: 4.2960e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.2837e-05\n",
      "Epoch 195/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0613 - metrics_pearsonr: 4.3049e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.3090e-05\n",
      "Epoch 196/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0613 - metrics_pearsonr: 4.3070e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.3162e-05\n",
      "Epoch 197/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0607 - metrics_pearsonr: 4.2930e-05 - val_loss: 0.0744 - val_metrics_pearsonr: 7.2747e-05\n",
      "Epoch 198/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0598 - metrics_pearsonr: 4.2757e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 7.2438e-05\n",
      "Epoch 199/5000\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 0.0592 - metrics_pearsonr: 4.2561e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 7.2163e-05\n",
      "Epoch 200/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0591 - metrics_pearsonr: 4.2452e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 7.2206e-05\n",
      "Epoch 201/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0594 - metrics_pearsonr: 4.2366e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.2314e-05\n",
      "Epoch 202/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0599 - metrics_pearsonr: 4.2339e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 7.2482e-05\n",
      "Epoch 203/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0603 - metrics_pearsonr: 4.2288e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.2576e-05\n",
      "Epoch 204/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0604 - metrics_pearsonr: 4.2286e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.2696e-05\n",
      "Epoch 205/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0605 - metrics_pearsonr: 4.2259e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.2796e-05\n",
      "Epoch 206/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0606 - metrics_pearsonr: 4.2322e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.3040e-05\n",
      "Epoch 207/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0607 - metrics_pearsonr: 4.2337e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.3174e-05\n",
      "Epoch 208/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0607 - metrics_pearsonr: 4.2409e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.3370e-05\n",
      "Epoch 209/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0603 - metrics_pearsonr: 4.2373e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.3254e-05\n",
      "Epoch 210/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0599 - metrics_pearsonr: 4.2344e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.3195e-05\n",
      "Epoch 211/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0597 - metrics_pearsonr: 4.2246e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.2998e-05\n",
      "Epoch 212/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0602 - metrics_pearsonr: 4.2215e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.3055e-05\n",
      "Epoch 213/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0614 - metrics_pearsonr: 4.2208e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.3161e-05\n",
      "Epoch 214/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0630 - metrics_pearsonr: 4.2275e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.3440e-05\n",
      "Epoch 215/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0646 - metrics_pearsonr: 4.2342e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 7.3641e-05\n",
      "Epoch 216/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0657 - metrics_pearsonr: 4.2421e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 7.3882e-05\n",
      "Epoch 217/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0661 - metrics_pearsonr: 4.2480e-05 - val_loss: 0.0850 - val_metrics_pearsonr: 7.4010e-05\n",
      "Epoch 218/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0657 - metrics_pearsonr: 4.2539e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 7.4242e-05\n",
      "Epoch 219/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0649 - metrics_pearsonr: 4.2592e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 7.4320e-05\n",
      "Epoch 220/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0641 - metrics_pearsonr: 4.2643e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.4460e-05\n",
      "Epoch 221/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0637 - metrics_pearsonr: 4.2642e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.4391e-05\n",
      "Epoch 222/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0644 - metrics_pearsonr: 4.2653e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.4515e-05\n",
      "Epoch 223/5000\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0662 - metrics_pearsonr: 4.2601e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 7.4722e-05\n",
      "Epoch 224/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0687 - metrics_pearsonr: 4.2621e-05 - val_loss: 0.0888 - val_metrics_pearsonr: 7.5205e-05\n",
      "Epoch 225/5000\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0709 - metrics_pearsonr: 4.2576e-05 - val_loss: 0.0946 - val_metrics_pearsonr: 7.5656e-05\n",
      "Epoch 226/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0717 - metrics_pearsonr: 4.2606e-05 - val_loss: 0.0952 - val_metrics_pearsonr: 7.5720e-05\n",
      "Epoch 227/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0706 - metrics_pearsonr: 4.2619e-05 - val_loss: 0.0889 - val_metrics_pearsonr: 7.5441e-05\n",
      "Epoch 228/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0686 - metrics_pearsonr: 4.2807e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 7.4961e-05\n",
      "Epoch 229/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0674 - metrics_pearsonr: 4.2911e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 7.5167e-05\n",
      "Epoch 230/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0683 - metrics_pearsonr: 4.3131e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 7.6398e-05\n",
      "Epoch 231/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0711 - metrics_pearsonr: 4.3389e-05 - val_loss: 0.0934 - val_metrics_pearsonr: 7.7456e-05\n",
      "Epoch 232/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0727 - metrics_pearsonr: 4.3545e-05 - val_loss: 0.0943 - val_metrics_pearsonr: 7.7175e-05\n",
      "Epoch 233/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0712 - metrics_pearsonr: 4.3235e-05 - val_loss: 0.0854 - val_metrics_pearsonr: 7.5539e-05\n",
      "Epoch 234/5000\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0685 - metrics_pearsonr: 4.2716e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 7.4692e-05\n",
      "Epoch 235/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0678 - metrics_pearsonr: 4.2448e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 7.5002e-05\n",
      "Epoch 236/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0692 - metrics_pearsonr: 4.2430e-05 - val_loss: 0.0910 - val_metrics_pearsonr: 7.5840e-05\n",
      "Epoch 237/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0702 - metrics_pearsonr: 4.2504e-05 - val_loss: 0.0924 - val_metrics_pearsonr: 7.6145e-05\n",
      "Epoch 238/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0685 - metrics_pearsonr: 4.2508e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 7.5528e-05\n",
      "Epoch 239/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0654 - metrics_pearsonr: 4.2332e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.4990e-05\n",
      "Epoch 240/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0636 - metrics_pearsonr: 4.2184e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.5137e-05\n",
      "Epoch 241/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0642 - metrics_pearsonr: 4.2184e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 7.5823e-05\n",
      "Epoch 242/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0650 - metrics_pearsonr: 4.2226e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 7.6026e-05\n",
      "Epoch 243/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0644 - metrics_pearsonr: 4.2037e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 7.5425e-05\n",
      "Epoch 244/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0628 - metrics_pearsonr: 4.1632e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.4818e-05\n",
      "Epoch 245/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0615 - metrics_pearsonr: 4.1331e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 7.4666e-05\n",
      "Epoch 246/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0608 - metrics_pearsonr: 4.1269e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.4652e-05\n",
      "Epoch 247/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0606 - metrics_pearsonr: 4.1392e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.4861e-05\n",
      "Epoch 248/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0606 - metrics_pearsonr: 4.1505e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.5148e-05\n",
      "Epoch 249/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0608 - metrics_pearsonr: 4.1495e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.5122e-05\n",
      "Epoch 250/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0610 - metrics_pearsonr: 4.1300e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 7.4779e-05\n",
      "Epoch 251/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0607 - metrics_pearsonr: 4.1083e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.4606e-05\n",
      "Epoch 252/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0601 - metrics_pearsonr: 4.0984e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.4584e-05\n",
      "Epoch 253/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0594 - metrics_pearsonr: 4.0990e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.4758e-05\n",
      "Epoch 254/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0591 - metrics_pearsonr: 4.1032e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.5047e-05\n",
      "Epoch 255/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0595 - metrics_pearsonr: 4.1096e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.5432e-05\n",
      "Epoch 256/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0604 - metrics_pearsonr: 4.1098e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 7.5667e-05\n",
      "Epoch 257/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0612 - metrics_pearsonr: 4.1112e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 7.5794e-05\n",
      "Epoch 258/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0612 - metrics_pearsonr: 4.1016e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 7.5595e-05\n",
      "Epoch 259/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0604 - metrics_pearsonr: 4.0932e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.5344e-05\n",
      "Epoch 260/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0592 - metrics_pearsonr: 4.0774e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.5034e-05\n",
      "Epoch 261/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0586 - metrics_pearsonr: 4.0677e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.4850e-05\n",
      "Epoch 262/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0590 - metrics_pearsonr: 4.0606e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.4855e-05\n",
      "Epoch 263/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0600 - metrics_pearsonr: 4.0633e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.5079e-05\n",
      "Epoch 264/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0611 - metrics_pearsonr: 4.0677e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 7.5293e-05\n",
      "Epoch 265/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0615 - metrics_pearsonr: 4.0726e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 7.5466e-05\n",
      "Epoch 266/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0608 - metrics_pearsonr: 4.0740e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 7.5462e-05\n",
      "Epoch 267/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0597 - metrics_pearsonr: 4.0716e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 7.5575e-05\n",
      "Epoch 268/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0591 - metrics_pearsonr: 4.0675e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.5731e-05\n",
      "Epoch 269/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0596 - metrics_pearsonr: 4.0666e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 7.6076e-05\n",
      "Epoch 270/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0607 - metrics_pearsonr: 4.0649e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 7.6328e-05\n",
      "Epoch 271/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0615 - metrics_pearsonr: 4.0650e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 7.6381e-05\n",
      "Epoch 272/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0612 - metrics_pearsonr: 4.0550e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 7.6093e-05\n",
      "Epoch 273/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0601 - metrics_pearsonr: 4.0470e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 7.5772e-05\n",
      "Epoch 274/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0590 - metrics_pearsonr: 4.0377e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.5550e-05\n",
      "Epoch 275/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0589 - metrics_pearsonr: 4.0384e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.5609e-05\n",
      "Epoch 276/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0598 - metrics_pearsonr: 4.0406e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 7.5789e-05\n",
      "Epoch 277/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0610 - metrics_pearsonr: 4.0444e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 7.5999e-05\n",
      "Epoch 278/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0614 - metrics_pearsonr: 4.0417e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 7.5976e-05\n",
      "Epoch 279/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0607 - metrics_pearsonr: 4.0358e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.5958e-05\n",
      "Epoch 280/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0596 - metrics_pearsonr: 4.0320e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.5960e-05\n",
      "Epoch 281/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0589 - metrics_pearsonr: 4.0340e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.6281e-05\n",
      "Epoch 282/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0594 - metrics_pearsonr: 4.0379e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.6705e-05\n",
      "Epoch 283/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0606 - metrics_pearsonr: 4.0442e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 7.7078e-05\n",
      "Epoch 284/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0612 - metrics_pearsonr: 4.0381e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 7.6944e-05\n",
      "Epoch 285/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0607 - metrics_pearsonr: 4.0286e-05 - val_loss: 0.0795 - val_metrics_pearsonr: 7.6574e-05\n",
      "Epoch 286/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0593 - metrics_pearsonr: 4.0116e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.6128e-05\n",
      "Epoch 287/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0584 - metrics_pearsonr: 4.0062e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.5996e-05\n",
      "Epoch 288/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0585 - metrics_pearsonr: 4.0048e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.6108e-05\n",
      "Epoch 289/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0595 - metrics_pearsonr: 4.0106e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 7.6389e-05\n",
      "Epoch 290/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0603 - metrics_pearsonr: 4.0113e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 7.6453e-05\n",
      "Epoch 291/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0602 - metrics_pearsonr: 4.0053e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 7.6432e-05\n",
      "Epoch 292/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0592 - metrics_pearsonr: 3.9984e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.6387e-05\n",
      "Epoch 293/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0584 - metrics_pearsonr: 3.9968e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.6618e-05\n",
      "Epoch 294/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0584 - metrics_pearsonr: 4.0004e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.6965e-05\n",
      "Epoch 295/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0592 - metrics_pearsonr: 4.0078e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 7.7399e-05\n",
      "Epoch 296/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0599 - metrics_pearsonr: 4.0065e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 7.7396e-05\n",
      "Epoch 297/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0596 - metrics_pearsonr: 3.9995e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 7.7083e-05\n",
      "Epoch 298/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0586 - metrics_pearsonr: 3.9810e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 7.6602e-05\n",
      "Epoch 299/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0576 - metrics_pearsonr: 3.9726e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.6412e-05\n",
      "Epoch 300/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0575 - metrics_pearsonr: 3.9691e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.6451e-05\n",
      "Epoch 301/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0582 - metrics_pearsonr: 3.9754e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.6753e-05\n",
      "Epoch 302/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0590 - metrics_pearsonr: 3.9789e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 7.6902e-05\n",
      "Epoch 303/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0590 - metrics_pearsonr: 3.9762e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 7.6931e-05\n",
      "Epoch 304/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0583 - metrics_pearsonr: 3.9681e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 7.6844e-05\n",
      "Epoch 305/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0576 - metrics_pearsonr: 3.9629e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 7.7001e-05\n",
      "Epoch 306/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0574 - metrics_pearsonr: 3.9631e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.7229e-05\n",
      "Epoch 307/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0580 - metrics_pearsonr: 3.9695e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 7.7618e-05\n",
      "Epoch 308/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0586 - metrics_pearsonr: 3.9702e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 7.7699e-05\n",
      "Epoch 309/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0586 - metrics_pearsonr: 3.9678e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.7542e-05\n",
      "Epoch 310/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0578 - metrics_pearsonr: 3.9524e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 7.7123e-05\n",
      "Epoch 311/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0570 - metrics_pearsonr: 3.9430e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 7.6907e-05\n",
      "Epoch 312/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0567 - metrics_pearsonr: 3.9361e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.6852e-05\n",
      "Epoch 313/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0572 - metrics_pearsonr: 3.9401e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.7087e-05\n",
      "Epoch 314/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0579 - metrics_pearsonr: 3.9441e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 7.7282e-05\n",
      "Epoch 315/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0581 - metrics_pearsonr: 3.9453e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 7.7418e-05\n",
      "Epoch 316/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0578 - metrics_pearsonr: 3.9403e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.7346e-05\n",
      "Epoch 317/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0571 - metrics_pearsonr: 3.9339e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.7430e-05\n",
      "Epoch 318/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0568 - metrics_pearsonr: 3.9308e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.7551e-05\n",
      "Epoch 319/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0571 - metrics_pearsonr: 3.9343e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 7.7875e-05\n",
      "Epoch 320/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0576 - metrics_pearsonr: 3.9358e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.8029e-05\n",
      "Epoch 321/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0579 - metrics_pearsonr: 3.9377e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 7.8056e-05\n",
      "Epoch 322/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0576 - metrics_pearsonr: 3.9274e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.7754e-05\n",
      "Epoch 323/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0569 - metrics_pearsonr: 3.9193e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.7515e-05\n",
      "Epoch 324/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0564 - metrics_pearsonr: 3.9087e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.7322e-05\n",
      "Epoch 325/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0564 - metrics_pearsonr: 3.9087e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 7.7434e-05\n",
      "Epoch 326/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0570 - metrics_pearsonr: 3.9104e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.7595e-05\n",
      "Epoch 327/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0575 - metrics_pearsonr: 3.9146e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.7845e-05\n",
      "Epoch 328/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0577 - metrics_pearsonr: 3.9144e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 7.7866e-05\n",
      "Epoch 329/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0573 - metrics_pearsonr: 3.9100e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.7919e-05\n",
      "Epoch 330/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0567 - metrics_pearsonr: 3.9048e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.7921e-05\n",
      "Epoch 331/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0565 - metrics_pearsonr: 3.9047e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.8154e-05\n",
      "Epoch 332/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0569 - metrics_pearsonr: 3.9054e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.8346e-05\n",
      "Epoch 333/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0575 - metrics_pearsonr: 3.9099e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 7.8582e-05\n",
      "Epoch 334/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0578 - metrics_pearsonr: 3.9057e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 7.8493e-05\n",
      "Epoch 335/5000\n",
      "3/3 [==============================] - 0s 181ms/step - loss: 0.0575 - metrics_pearsonr: 3.9016e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 7.8321e-05\n",
      "Epoch 336/5000\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0568 - metrics_pearsonr: 3.8886e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.7980e-05\n",
      "Epoch 337/5000\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0562 - metrics_pearsonr: 3.8834e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.7874e-05\n",
      "Epoch 338/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0562 - metrics_pearsonr: 3.8788e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 7.7862e-05\n",
      "Epoch 339/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0568 - metrics_pearsonr: 3.8829e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 7.8111e-05\n",
      "Epoch 340/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0575 - metrics_pearsonr: 3.8862e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 7.8277e-05\n",
      "Epoch 341/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0578 - metrics_pearsonr: 3.8877e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 7.8445e-05\n",
      "Epoch 342/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0576 - metrics_pearsonr: 3.8850e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 7.8409e-05\n",
      "Epoch 343/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0570 - metrics_pearsonr: 3.8814e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 7.8490e-05\n",
      "Epoch 344/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0566 - metrics_pearsonr: 3.8791e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.8575e-05\n",
      "Epoch 345/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0568 - metrics_pearsonr: 3.8825e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 7.8897e-05\n",
      "Epoch 346/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0574 - metrics_pearsonr: 3.8839e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 7.9098e-05\n",
      "Epoch 347/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0581 - metrics_pearsonr: 3.8874e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 7.9256e-05\n",
      "Epoch 348/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0582 - metrics_pearsonr: 3.8790e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 7.9014e-05\n",
      "Epoch 349/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0575 - metrics_pearsonr: 3.8711e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.8756e-05\n",
      "Epoch 350/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0567 - metrics_pearsonr: 3.8579e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.8403e-05\n",
      "Epoch 351/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0562 - metrics_pearsonr: 3.8547e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.8359e-05\n",
      "Epoch 352/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0565 - metrics_pearsonr: 3.8527e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.8415e-05\n",
      "Epoch 353/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0574 - metrics_pearsonr: 3.8578e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 7.8714e-05\n",
      "Epoch 354/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0583 - metrics_pearsonr: 3.8632e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 7.8911e-05\n",
      "Epoch 355/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0585 - metrics_pearsonr: 3.8640e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 7.9037e-05\n",
      "Epoch 356/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0580 - metrics_pearsonr: 3.8603e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.8977e-05\n",
      "Epoch 357/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0573 - metrics_pearsonr: 3.8585e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 7.9086e-05\n",
      "Epoch 358/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0570 - metrics_pearsonr: 3.8587e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.9249e-05\n",
      "Epoch 359/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0575 - metrics_pearsonr: 3.8647e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.9688e-05\n",
      "Epoch 360/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0585 - metrics_pearsonr: 3.8680e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 7.9940e-05\n",
      "Epoch 361/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0592 - metrics_pearsonr: 3.8715e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.0054e-05\n",
      "Epoch 362/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0590 - metrics_pearsonr: 3.8590e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 7.9654e-05\n",
      "Epoch 363/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0580 - metrics_pearsonr: 3.8468e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.9237e-05\n",
      "Epoch 364/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0569 - metrics_pearsonr: 3.8311e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.8847e-05\n",
      "Epoch 365/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0565 - metrics_pearsonr: 3.8285e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 7.8829e-05\n",
      "Epoch 366/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0572 - metrics_pearsonr: 3.8276e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 7.8955e-05\n",
      "Epoch 367/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0584 - metrics_pearsonr: 3.8345e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 7.9329e-05\n",
      "Epoch 368/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0593 - metrics_pearsonr: 3.8426e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 7.9564e-05\n",
      "Epoch 369/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0592 - metrics_pearsonr: 3.8418e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.9615e-05\n",
      "Epoch 370/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0583 - metrics_pearsonr: 3.8368e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.9519e-05\n",
      "Epoch 371/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0575 - metrics_pearsonr: 3.8374e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 7.9728e-05\n",
      "Epoch 372/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0576 - metrics_pearsonr: 3.8403e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 8.0031e-05\n",
      "Epoch 373/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0586 - metrics_pearsonr: 3.8484e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.0575e-05\n",
      "Epoch 374/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0598 - metrics_pearsonr: 3.8553e-05 - val_loss: 0.0854 - val_metrics_pearsonr: 8.0838e-05\n",
      "Epoch 375/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0601 - metrics_pearsonr: 3.8564e-05 - val_loss: 0.0851 - val_metrics_pearsonr: 8.0627e-05\n",
      "Epoch 376/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0591 - metrics_pearsonr: 3.8389e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 8.0015e-05\n",
      "Epoch 377/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0576 - metrics_pearsonr: 3.8277e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.9625e-05\n",
      "Epoch 378/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0567 - metrics_pearsonr: 3.8139e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.9321e-05\n",
      "Epoch 379/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0572 - metrics_pearsonr: 3.8125e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.9498e-05\n",
      "Epoch 380/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0585 - metrics_pearsonr: 3.8194e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 7.9769e-05\n",
      "Epoch 381/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0595 - metrics_pearsonr: 3.8269e-05 - val_loss: 0.0851 - val_metrics_pearsonr: 8.0057e-05\n",
      "Epoch 382/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0594 - metrics_pearsonr: 3.8240e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.0077e-05\n",
      "Epoch 383/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0582 - metrics_pearsonr: 3.8147e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.0015e-05\n",
      "Epoch 384/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0573 - metrics_pearsonr: 3.8094e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 8.0077e-05\n",
      "Epoch 385/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0575 - metrics_pearsonr: 3.8103e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 8.0504e-05\n",
      "Epoch 386/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0585 - metrics_pearsonr: 3.8145e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 8.0903e-05\n",
      "Epoch 387/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0594 - metrics_pearsonr: 3.8220e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 8.1124e-05\n",
      "Epoch 388/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0592 - metrics_pearsonr: 3.8179e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.0779e-05\n",
      "Epoch 389/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0579 - metrics_pearsonr: 3.8057e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 8.0191e-05\n",
      "Epoch 390/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0565 - metrics_pearsonr: 3.7835e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.9699e-05\n",
      "Epoch 391/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0562 - metrics_pearsonr: 3.7747e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.9628e-05\n",
      "Epoch 392/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0570 - metrics_pearsonr: 3.7740e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 7.9835e-05\n",
      "Epoch 393/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0580 - metrics_pearsonr: 3.7808e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 8.0177e-05\n",
      "Epoch 394/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0582 - metrics_pearsonr: 3.7870e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.0378e-05\n",
      "Epoch 395/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0576 - metrics_pearsonr: 3.7895e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.0555e-05\n",
      "Epoch 396/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0568 - metrics_pearsonr: 3.7903e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 8.0678e-05\n",
      "Epoch 397/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0567 - metrics_pearsonr: 3.7905e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 8.1052e-05\n",
      "Epoch 398/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0573 - metrics_pearsonr: 3.7908e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.1330e-05\n",
      "Epoch 399/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0580 - metrics_pearsonr: 3.7932e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 8.1479e-05\n",
      "Epoch 400/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0578 - metrics_pearsonr: 3.7842e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 8.1074e-05\n",
      "Epoch 401/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0568 - metrics_pearsonr: 3.7727e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.0598e-05\n",
      "Epoch 402/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0557 - metrics_pearsonr: 3.7546e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 8.0123e-05\n",
      "Epoch 403/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0554 - metrics_pearsonr: 3.7476e-05 - val_loss: 0.0774 - val_metrics_pearsonr: 8.0084e-05\n",
      "Epoch 404/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0559 - metrics_pearsonr: 3.7438e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.0156e-05\n",
      "Epoch 405/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0566 - metrics_pearsonr: 3.7469e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 8.0422e-05\n",
      "Epoch 406/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0567 - metrics_pearsonr: 3.7485e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.0549e-05\n",
      "Epoch 407/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0562 - metrics_pearsonr: 3.7485e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.0705e-05\n",
      "Epoch 408/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0557 - metrics_pearsonr: 3.7478e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 8.0833e-05\n",
      "Epoch 409/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0556 - metrics_pearsonr: 3.7502e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 8.1180e-05\n",
      "Epoch 410/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0561 - metrics_pearsonr: 3.7519e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.1401e-05\n",
      "Epoch 411/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0566 - metrics_pearsonr: 3.7552e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.1569e-05\n",
      "Epoch 412/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0565 - metrics_pearsonr: 3.7485e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.1281e-05\n",
      "Epoch 413/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0558 - metrics_pearsonr: 3.7403e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 8.0954e-05\n",
      "Epoch 414/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0550 - metrics_pearsonr: 3.7250e-05 - val_loss: 0.0769 - val_metrics_pearsonr: 8.0536e-05\n",
      "Epoch 415/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0547 - metrics_pearsonr: 3.7189e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 8.0467e-05\n",
      "Epoch 416/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0550 - metrics_pearsonr: 3.7151e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.0483e-05\n",
      "Epoch 417/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0556 - metrics_pearsonr: 3.7192e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 8.0733e-05\n",
      "Epoch 418/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0560 - metrics_pearsonr: 3.7246e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 8.0894e-05\n",
      "Epoch 419/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0558 - metrics_pearsonr: 3.7298e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 8.1141e-05\n",
      "Epoch 420/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0556 - metrics_pearsonr: 3.7347e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 8.1323e-05\n",
      "Epoch 421/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0555 - metrics_pearsonr: 3.7409e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 8.1719e-05\n",
      "Epoch 422/5000\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0559 - metrics_pearsonr: 3.7458e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.2016e-05\n",
      "Epoch 423/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0565 - metrics_pearsonr: 3.7515e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 8.2339e-05\n",
      "Epoch 424/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0566 - metrics_pearsonr: 3.7476e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 8.2186e-05\n",
      "Epoch 425/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0561 - metrics_pearsonr: 3.7396e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.1932e-05\n",
      "Epoch 426/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0553 - metrics_pearsonr: 3.7215e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 8.1411e-05\n",
      "Epoch 427/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0546 - metrics_pearsonr: 3.7090e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 8.1196e-05\n",
      "Epoch 428/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0546 - metrics_pearsonr: 3.6978e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 8.1024e-05\n",
      "Epoch 429/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0549 - metrics_pearsonr: 3.6948e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 8.1163e-05\n",
      "Epoch 430/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0552 - metrics_pearsonr: 3.6926e-05 - val_loss: 0.0802 - val_metrics_pearsonr: 8.1238e-05\n",
      "Epoch 431/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0552 - metrics_pearsonr: 3.6924e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 8.1397e-05\n",
      "Epoch 432/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0550 - metrics_pearsonr: 3.6911e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 8.1441e-05\n",
      "Epoch 433/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0548 - metrics_pearsonr: 3.6915e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 8.1650e-05\n",
      "Epoch 434/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0551 - metrics_pearsonr: 3.6911e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.1817e-05\n",
      "Epoch 435/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0557 - metrics_pearsonr: 3.6947e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.2133e-05\n",
      "Epoch 436/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0564 - metrics_pearsonr: 3.6938e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.2194e-05\n",
      "Epoch 437/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0567 - metrics_pearsonr: 3.6946e-05 - val_loss: 0.0830 - val_metrics_pearsonr: 8.2208e-05\n",
      "Epoch 438/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0564 - metrics_pearsonr: 3.6855e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.1891e-05\n",
      "Epoch 439/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0558 - metrics_pearsonr: 3.6811e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 8.1699e-05\n",
      "Epoch 440/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0554 - metrics_pearsonr: 3.6717e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 8.1438e-05\n",
      "Epoch 441/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0553 - metrics_pearsonr: 3.6713e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 8.1458e-05\n",
      "Epoch 442/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0557 - metrics_pearsonr: 3.6691e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 8.1431e-05\n",
      "Epoch 443/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0561 - metrics_pearsonr: 3.6751e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 8.1596e-05\n",
      "Epoch 444/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0562 - metrics_pearsonr: 3.6829e-05 - val_loss: 0.0814 - val_metrics_pearsonr: 8.1633e-05\n",
      "Epoch 445/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0561 - metrics_pearsonr: 3.6951e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 8.1861e-05\n",
      "Epoch 446/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0561 - metrics_pearsonr: 3.7106e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 8.2099e-05\n",
      "Epoch 447/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0567 - metrics_pearsonr: 3.7318e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.2734e-05\n",
      "Epoch 448/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0579 - metrics_pearsonr: 3.7525e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.3351e-05\n",
      "Epoch 449/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0595 - metrics_pearsonr: 3.7732e-05 - val_loss: 0.0857 - val_metrics_pearsonr: 8.4106e-05\n",
      "Epoch 450/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0609 - metrics_pearsonr: 3.7801e-05 - val_loss: 0.0879 - val_metrics_pearsonr: 8.4253e-05\n",
      "Epoch 451/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0618 - metrics_pearsonr: 3.7776e-05 - val_loss: 0.0887 - val_metrics_pearsonr: 8.4211e-05\n",
      "Epoch 452/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0622 - metrics_pearsonr: 3.7607e-05 - val_loss: 0.0890 - val_metrics_pearsonr: 8.3715e-05\n",
      "Epoch 453/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0627 - metrics_pearsonr: 3.7455e-05 - val_loss: 0.0905 - val_metrics_pearsonr: 8.3506e-05\n",
      "Epoch 454/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0633 - metrics_pearsonr: 3.7333e-05 - val_loss: 0.0931 - val_metrics_pearsonr: 8.3333e-05\n",
      "Epoch 455/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0637 - metrics_pearsonr: 3.7292e-05 - val_loss: 0.0949 - val_metrics_pearsonr: 8.3376e-05\n",
      "Epoch 456/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0632 - metrics_pearsonr: 3.7272e-05 - val_loss: 0.0926 - val_metrics_pearsonr: 8.3250e-05\n",
      "Epoch 457/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0618 - metrics_pearsonr: 3.7255e-05 - val_loss: 0.0865 - val_metrics_pearsonr: 8.3049e-05\n",
      "Epoch 458/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0605 - metrics_pearsonr: 3.7247e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.2974e-05\n",
      "Epoch 459/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0608 - metrics_pearsonr: 3.7304e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.3396e-05\n",
      "Epoch 460/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0635 - metrics_pearsonr: 3.7428e-05 - val_loss: 0.0894 - val_metrics_pearsonr: 8.4290e-05\n",
      "Epoch 461/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0675 - metrics_pearsonr: 3.7614e-05 - val_loss: 0.1009 - val_metrics_pearsonr: 8.5322e-05\n",
      "Epoch 462/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0703 - metrics_pearsonr: 3.7702e-05 - val_loss: 0.1064 - val_metrics_pearsonr: 8.5603e-05\n",
      "Epoch 463/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0698 - metrics_pearsonr: 3.7673e-05 - val_loss: 0.1014 - val_metrics_pearsonr: 8.5153e-05\n",
      "Epoch 464/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0666 - metrics_pearsonr: 3.7543e-05 - val_loss: 0.0906 - val_metrics_pearsonr: 8.4350e-05\n",
      "Epoch 465/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0635 - metrics_pearsonr: 3.7627e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 8.3661e-05\n",
      "Epoch 466/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0625 - metrics_pearsonr: 3.7749e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 8.3092e-05\n",
      "Epoch 467/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0636 - metrics_pearsonr: 3.8109e-05 - val_loss: 0.0901 - val_metrics_pearsonr: 8.4027e-05\n",
      "Epoch 468/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0657 - metrics_pearsonr: 3.8732e-05 - val_loss: 0.0959 - val_metrics_pearsonr: 8.6513e-05\n",
      "Epoch 469/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0665 - metrics_pearsonr: 3.9236e-05 - val_loss: 0.0963 - val_metrics_pearsonr: 8.8325e-05\n",
      "Epoch 470/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0647 - metrics_pearsonr: 3.9033e-05 - val_loss: 0.0896 - val_metrics_pearsonr: 8.6718e-05\n",
      "Epoch 471/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0612 - metrics_pearsonr: 3.8131e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 8.4130e-05\n",
      "Epoch 472/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0590 - metrics_pearsonr: 3.7253e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.3327e-05\n",
      "Epoch 473/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0586 - metrics_pearsonr: 3.6892e-05 - val_loss: 0.0855 - val_metrics_pearsonr: 8.3578e-05\n",
      "Epoch 474/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0584 - metrics_pearsonr: 3.6735e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 8.3302e-05\n",
      "Epoch 475/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0573 - metrics_pearsonr: 3.6780e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.2931e-05\n",
      "Epoch 476/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0561 - metrics_pearsonr: 3.6773e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 8.3301e-05\n",
      "Epoch 477/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0557 - metrics_pearsonr: 3.6762e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.4013e-05\n",
      "Epoch 478/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0558 - metrics_pearsonr: 3.6662e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.3947e-05\n",
      "Epoch 479/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0553 - metrics_pearsonr: 3.6460e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 8.3442e-05\n",
      "Epoch 480/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0546 - metrics_pearsonr: 3.6250e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 8.3003e-05\n",
      "Epoch 481/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0544 - metrics_pearsonr: 3.6126e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.3021e-05\n",
      "Epoch 482/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0544 - metrics_pearsonr: 3.6061e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.2977e-05\n",
      "Epoch 483/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0541 - metrics_pearsonr: 3.6093e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 8.2936e-05\n",
      "Epoch 484/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0537 - metrics_pearsonr: 3.6090e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.2950e-05\n",
      "Epoch 485/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0534 - metrics_pearsonr: 3.6094e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 8.3228e-05\n",
      "Epoch 486/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0534 - metrics_pearsonr: 3.6060e-05 - val_loss: 0.0795 - val_metrics_pearsonr: 8.3346e-05\n",
      "Epoch 487/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0533 - metrics_pearsonr: 3.6002e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.3377e-05\n",
      "Epoch 488/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0532 - metrics_pearsonr: 3.5896e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 8.3171e-05\n",
      "Epoch 489/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0530 - metrics_pearsonr: 3.5797e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.3079e-05\n",
      "Epoch 490/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0530 - metrics_pearsonr: 3.5702e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 8.2975e-05\n",
      "Epoch 491/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0530 - metrics_pearsonr: 3.5697e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 8.3057e-05\n",
      "Epoch 492/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0530 - metrics_pearsonr: 3.5707e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 8.3089e-05\n",
      "Epoch 493/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0530 - metrics_pearsonr: 3.5780e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 8.3276e-05\n",
      "Epoch 494/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0529 - metrics_pearsonr: 3.5790e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.3292e-05\n",
      "Epoch 495/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0528 - metrics_pearsonr: 3.5796e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 8.3346e-05\n",
      "Epoch 496/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0529 - metrics_pearsonr: 3.5711e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 8.3144e-05\n",
      "Epoch 497/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0531 - metrics_pearsonr: 3.5657e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 8.3164e-05\n",
      "Epoch 498/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0533 - metrics_pearsonr: 3.5599e-05 - val_loss: 0.0805 - val_metrics_pearsonr: 8.3083e-05\n",
      "Epoch 499/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0534 - metrics_pearsonr: 3.5608e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.3259e-05\n",
      "Epoch 500/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0534 - metrics_pearsonr: 3.5626e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.3341e-05\n",
      "Epoch 501/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0533 - metrics_pearsonr: 3.5663e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 8.3555e-05\n",
      "Epoch 502/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0531 - metrics_pearsonr: 3.5661e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 8.3611e-05\n",
      "Epoch 503/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0530 - metrics_pearsonr: 3.5659e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 8.3717e-05\n",
      "Epoch 504/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0530 - metrics_pearsonr: 3.5598e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 8.3659e-05\n",
      "Epoch 505/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0532 - metrics_pearsonr: 3.5581e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 8.3739e-05\n",
      "Epoch 506/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0535 - metrics_pearsonr: 3.5523e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.3684e-05\n",
      "Epoch 507/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0538 - metrics_pearsonr: 3.5524e-05 - val_loss: 0.0814 - val_metrics_pearsonr: 8.3776e-05\n",
      "Epoch 508/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0539 - metrics_pearsonr: 3.5480e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 8.3702e-05\n",
      "Epoch 509/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0537 - metrics_pearsonr: 3.5478e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 8.3733e-05\n",
      "Epoch 510/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0534 - metrics_pearsonr: 3.5434e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 8.3593e-05\n",
      "Epoch 511/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0531 - metrics_pearsonr: 3.5430e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 8.3608e-05\n",
      "Epoch 512/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0531 - metrics_pearsonr: 3.5408e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 8.3526e-05\n",
      "Epoch 513/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0534 - metrics_pearsonr: 3.5437e-05 - val_loss: 0.0796 - val_metrics_pearsonr: 8.3683e-05\n",
      "Epoch 514/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0542 - metrics_pearsonr: 3.5464e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 8.3740e-05\n",
      "Epoch 515/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0551 - metrics_pearsonr: 3.5526e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.4040e-05\n",
      "Epoch 516/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0560 - metrics_pearsonr: 3.5561e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 8.4124e-05\n",
      "Epoch 517/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0564 - metrics_pearsonr: 3.5607e-05 - val_loss: 0.0868 - val_metrics_pearsonr: 8.4357e-05\n",
      "Epoch 518/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0562 - metrics_pearsonr: 3.5604e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 8.4277e-05\n",
      "Epoch 519/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0555 - metrics_pearsonr: 3.5615e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.4334e-05\n",
      "Epoch 520/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0547 - metrics_pearsonr: 3.5581e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.4209e-05\n",
      "Epoch 521/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0543 - metrics_pearsonr: 3.5593e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.4355e-05\n",
      "Epoch 522/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0547 - metrics_pearsonr: 3.5564e-05 - val_loss: 0.0802 - val_metrics_pearsonr: 8.4493e-05\n",
      "Epoch 523/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0559 - metrics_pearsonr: 3.5595e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 8.4850e-05\n",
      "Epoch 524/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0574 - metrics_pearsonr: 3.5565e-05 - val_loss: 0.0875 - val_metrics_pearsonr: 8.5032e-05\n",
      "Epoch 525/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0585 - metrics_pearsonr: 3.5554e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 8.5102e-05\n",
      "Epoch 526/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0586 - metrics_pearsonr: 3.5456e-05 - val_loss: 0.0895 - val_metrics_pearsonr: 8.4861e-05\n",
      "Epoch 527/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0576 - metrics_pearsonr: 3.5405e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 8.4553e-05\n",
      "Epoch 528/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0562 - metrics_pearsonr: 3.5333e-05 - val_loss: 0.0814 - val_metrics_pearsonr: 8.4173e-05\n",
      "Epoch 529/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0555 - metrics_pearsonr: 3.5401e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 8.4140e-05\n",
      "Epoch 530/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0561 - metrics_pearsonr: 3.5472e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 8.4259e-05\n",
      "Epoch 531/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0580 - metrics_pearsonr: 3.5615e-05 - val_loss: 0.0876 - val_metrics_pearsonr: 8.4915e-05\n",
      "Epoch 532/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0602 - metrics_pearsonr: 3.5759e-05 - val_loss: 0.0937 - val_metrics_pearsonr: 8.5305e-05\n",
      "Epoch 533/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0614 - metrics_pearsonr: 3.5775e-05 - val_loss: 0.0958 - val_metrics_pearsonr: 8.5413e-05\n",
      "Epoch 534/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0608 - metrics_pearsonr: 3.5676e-05 - val_loss: 0.0917 - val_metrics_pearsonr: 8.4952e-05\n",
      "Epoch 535/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0588 - metrics_pearsonr: 3.5566e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 8.4672e-05\n",
      "Epoch 536/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0572 - metrics_pearsonr: 3.5477e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.4608e-05\n",
      "Epoch 537/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0572 - metrics_pearsonr: 3.5496e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.5081e-05\n",
      "Epoch 538/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0589 - metrics_pearsonr: 3.5586e-05 - val_loss: 0.0884 - val_metrics_pearsonr: 8.5809e-05\n",
      "Epoch 539/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0608 - metrics_pearsonr: 3.5730e-05 - val_loss: 0.0932 - val_metrics_pearsonr: 8.6280e-05\n",
      "Epoch 540/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0613 - metrics_pearsonr: 3.5676e-05 - val_loss: 0.0926 - val_metrics_pearsonr: 8.6058e-05\n",
      "Epoch 541/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0602 - metrics_pearsonr: 3.5615e-05 - val_loss: 0.0879 - val_metrics_pearsonr: 8.5550e-05\n",
      "Epoch 542/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0583 - metrics_pearsonr: 3.5439e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.4937e-05\n",
      "Epoch 543/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0574 - metrics_pearsonr: 3.5454e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.4901e-05\n",
      "Epoch 544/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0577 - metrics_pearsonr: 3.5570e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 8.5116e-05\n",
      "Epoch 545/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0585 - metrics_pearsonr: 3.5675e-05 - val_loss: 0.0891 - val_metrics_pearsonr: 8.5426e-05\n",
      "Epoch 546/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0588 - metrics_pearsonr: 3.5595e-05 - val_loss: 0.0894 - val_metrics_pearsonr: 8.5426e-05\n",
      "Epoch 547/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0582 - metrics_pearsonr: 3.5440e-05 - val_loss: 0.0870 - val_metrics_pearsonr: 8.5253e-05\n",
      "Epoch 548/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0570 - metrics_pearsonr: 3.5261e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 8.4948e-05\n",
      "Epoch 549/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0561 - metrics_pearsonr: 3.5125e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.5047e-05\n",
      "Epoch 550/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0560 - metrics_pearsonr: 3.5124e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.5207e-05\n",
      "Epoch 551/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0564 - metrics_pearsonr: 3.5209e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.5604e-05\n",
      "Epoch 552/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0569 - metrics_pearsonr: 3.5294e-05 - val_loss: 0.0868 - val_metrics_pearsonr: 8.5914e-05\n",
      "Epoch 553/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0569 - metrics_pearsonr: 3.5405e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 8.6076e-05\n",
      "Epoch 554/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0560 - metrics_pearsonr: 3.5382e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.5783e-05\n",
      "Epoch 555/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0550 - metrics_pearsonr: 3.5323e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.5509e-05\n",
      "Epoch 556/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0546 - metrics_pearsonr: 3.5163e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 8.5199e-05\n",
      "Epoch 557/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0548 - metrics_pearsonr: 3.5065e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 8.5296e-05\n",
      "Epoch 558/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0549 - metrics_pearsonr: 3.4982e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 8.5185e-05\n",
      "Epoch 559/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0545 - metrics_pearsonr: 3.4880e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.5018e-05\n",
      "Epoch 560/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0537 - metrics_pearsonr: 3.4776e-05 - val_loss: 0.0802 - val_metrics_pearsonr: 8.4854e-05\n",
      "Epoch 561/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0533 - metrics_pearsonr: 3.4720e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.4997e-05\n",
      "Epoch 562/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0536 - metrics_pearsonr: 3.4722e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.5240e-05\n",
      "Epoch 563/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0541 - metrics_pearsonr: 3.4811e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 8.5517e-05\n",
      "Epoch 564/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0542 - metrics_pearsonr: 3.4878e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.5582e-05\n",
      "Epoch 565/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0537 - metrics_pearsonr: 3.4962e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.5690e-05\n",
      "Epoch 566/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0531 - metrics_pearsonr: 3.4911e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 8.5555e-05\n",
      "Epoch 567/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0528 - metrics_pearsonr: 3.4860e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.5600e-05\n",
      "Epoch 568/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0531 - metrics_pearsonr: 3.4741e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.5389e-05\n",
      "Epoch 569/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0533 - metrics_pearsonr: 3.4652e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 8.5349e-05\n",
      "Epoch 570/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0532 - metrics_pearsonr: 3.4578e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 8.5138e-05\n",
      "Epoch 571/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0528 - metrics_pearsonr: 3.4528e-05 - val_loss: 0.0805 - val_metrics_pearsonr: 8.5109e-05\n",
      "Epoch 572/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0523 - metrics_pearsonr: 3.4507e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 8.5150e-05\n",
      "Epoch 573/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0523 - metrics_pearsonr: 3.4537e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.5423e-05\n",
      "Epoch 574/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0527 - metrics_pearsonr: 3.4543e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 8.5620e-05\n",
      "Epoch 575/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0530 - metrics_pearsonr: 3.4570e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 8.5796e-05\n",
      "Epoch 576/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0529 - metrics_pearsonr: 3.4506e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.5602e-05\n",
      "Epoch 577/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0524 - metrics_pearsonr: 3.4465e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.5436e-05\n",
      "Epoch 578/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0519 - metrics_pearsonr: 3.4367e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 8.5154e-05\n",
      "Epoch 579/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0518 - metrics_pearsonr: 3.4374e-05 - val_loss: 0.0799 - val_metrics_pearsonr: 8.5242e-05\n",
      "Epoch 580/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0521 - metrics_pearsonr: 3.4387e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.5329e-05\n",
      "Epoch 581/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0526 - metrics_pearsonr: 3.4467e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.5698e-05\n",
      "Epoch 582/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0528 - metrics_pearsonr: 3.4529e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.5846e-05\n",
      "Epoch 583/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0527 - metrics_pearsonr: 3.4558e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.6017e-05\n",
      "Epoch 584/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0524 - metrics_pearsonr: 3.4523e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.5949e-05\n",
      "Epoch 585/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0522 - metrics_pearsonr: 3.4483e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.5998e-05\n",
      "Epoch 586/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0521 - metrics_pearsonr: 3.4396e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 8.5926e-05\n",
      "Epoch 587/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0522 - metrics_pearsonr: 3.4358e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.5982e-05\n",
      "Epoch 588/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0522 - metrics_pearsonr: 3.4266e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 8.5804e-05\n",
      "Epoch 589/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0521 - metrics_pearsonr: 3.4231e-05 - val_loss: 0.0815 - val_metrics_pearsonr: 8.5719e-05\n",
      "Epoch 590/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0517 - metrics_pearsonr: 3.4136e-05 - val_loss: 0.0805 - val_metrics_pearsonr: 8.5443e-05\n",
      "Epoch 591/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0515 - metrics_pearsonr: 3.4129e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 8.5413e-05\n",
      "Epoch 592/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0516 - metrics_pearsonr: 3.4100e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 8.5326e-05\n",
      "Epoch 593/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0519 - metrics_pearsonr: 3.4152e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 8.5563e-05\n",
      "Epoch 594/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0523 - metrics_pearsonr: 3.4201e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.5698e-05\n",
      "Epoch 595/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0525 - metrics_pearsonr: 3.4270e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 8.6012e-05\n",
      "Epoch 596/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0525 - metrics_pearsonr: 3.4310e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.6089e-05\n",
      "Epoch 597/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0523 - metrics_pearsonr: 3.4333e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 8.6287e-05\n",
      "Epoch 598/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0521 - metrics_pearsonr: 3.4303e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 8.6292e-05\n",
      "Epoch 599/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0523 - metrics_pearsonr: 3.4301e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 8.6488e-05\n",
      "Epoch 600/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0527 - metrics_pearsonr: 3.4242e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.6474e-05\n",
      "Epoch 601/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0530 - metrics_pearsonr: 3.4233e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 8.6563e-05\n",
      "Epoch 602/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0530 - metrics_pearsonr: 3.4143e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.6348e-05\n",
      "Epoch 603/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0527 - metrics_pearsonr: 3.4110e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.6242e-05\n",
      "Epoch 604/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0521 - metrics_pearsonr: 3.4014e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 8.5908e-05\n",
      "Epoch 605/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0517 - metrics_pearsonr: 3.3992e-05 - val_loss: 0.0802 - val_metrics_pearsonr: 8.5887e-05\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0518 - metrics_pearsonr: 3.3966e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 8.5796e-05\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0524 - metrics_pearsonr: 3.3999e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.6040e-05\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0531 - metrics_pearsonr: 3.4023e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 8.6122e-05\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0537 - metrics_pearsonr: 3.4050e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 8.6314e-05\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0538 - metrics_pearsonr: 3.4040e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.6233e-05\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0535 - metrics_pearsonr: 3.4025e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 8.6285e-05\n",
      "Epoch 612/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0530 - metrics_pearsonr: 3.3991e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.6197e-05\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 0s 190ms/step - loss: 0.0529 - metrics_pearsonr: 3.4005e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.6385e-05\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0531 - metrics_pearsonr: 3.3994e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.6500e-05\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0538 - metrics_pearsonr: 3.4059e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 8.6799e-05\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0544 - metrics_pearsonr: 3.4071e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 8.6861e-05\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0548 - metrics_pearsonr: 3.4156e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 8.6974e-05\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0547 - metrics_pearsonr: 3.4153e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 8.6828e-05\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0546 - metrics_pearsonr: 3.4250e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 8.6961e-05\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0548 - metrics_pearsonr: 3.4299e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 8.7031e-05\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0555 - metrics_pearsonr: 3.4409e-05 - val_loss: 0.0868 - val_metrics_pearsonr: 8.7633e-05\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0565 - metrics_pearsonr: 3.4598e-05 - val_loss: 0.0896 - val_metrics_pearsonr: 8.8098e-05\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0571 - metrics_pearsonr: 3.4656e-05 - val_loss: 0.0908 - val_metrics_pearsonr: 8.8170e-05\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0568 - metrics_pearsonr: 3.4559e-05 - val_loss: 0.0890 - val_metrics_pearsonr: 8.7798e-05\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0559 - metrics_pearsonr: 3.4419e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 8.7187e-05\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0550 - metrics_pearsonr: 3.4244e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.6682e-05\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0550 - metrics_pearsonr: 3.4160e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.6857e-05\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0562 - metrics_pearsonr: 3.4149e-05 - val_loss: 0.0881 - val_metrics_pearsonr: 8.7199e-05\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0578 - metrics_pearsonr: 3.4213e-05 - val_loss: 0.0932 - val_metrics_pearsonr: 8.7791e-05\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0586 - metrics_pearsonr: 3.4211e-05 - val_loss: 0.0944 - val_metrics_pearsonr: 8.7884e-05\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0579 - metrics_pearsonr: 3.4259e-05 - val_loss: 0.0903 - val_metrics_pearsonr: 8.7616e-05\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0562 - metrics_pearsonr: 3.4255e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 8.7066e-05\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0549 - metrics_pearsonr: 3.4304e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 8.7008e-05\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0552 - metrics_pearsonr: 3.4366e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 8.7575e-05\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0571 - metrics_pearsonr: 3.4572e-05 - val_loss: 0.0911 - val_metrics_pearsonr: 8.8742e-05\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0589 - metrics_pearsonr: 3.4768e-05 - val_loss: 0.0948 - val_metrics_pearsonr: 8.9295e-05\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0588 - metrics_pearsonr: 3.4762e-05 - val_loss: 0.0914 - val_metrics_pearsonr: 8.8857e-05\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0568 - metrics_pearsonr: 3.4468e-05 - val_loss: 0.0846 - val_metrics_pearsonr: 8.7654e-05\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0549 - metrics_pearsonr: 3.4138e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.7143e-05\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0545 - metrics_pearsonr: 3.3936e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 8.7206e-05\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0553 - metrics_pearsonr: 3.3914e-05 - val_loss: 0.0888 - val_metrics_pearsonr: 8.7624e-05\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0556 - metrics_pearsonr: 3.3929e-05 - val_loss: 0.0886 - val_metrics_pearsonr: 8.7689e-05\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0549 - metrics_pearsonr: 3.3959e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 8.7512e-05\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0537 - metrics_pearsonr: 3.3859e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 8.7145e-05\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0533 - metrics_pearsonr: 3.3768e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.7215e-05\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0538 - metrics_pearsonr: 3.3673e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 8.7224e-05\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0543 - metrics_pearsonr: 3.3641e-05 - val_loss: 0.0876 - val_metrics_pearsonr: 8.7320e-05\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0539 - metrics_pearsonr: 3.3601e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 8.6985e-05\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0529 - metrics_pearsonr: 3.3546e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.6877e-05\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0522 - metrics_pearsonr: 3.3498e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 8.6898e-05\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0524 - metrics_pearsonr: 3.3533e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.7256e-05\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0532 - metrics_pearsonr: 3.3593e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 8.7566e-05\n",
      "Epoch 653/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0538 - metrics_pearsonr: 3.3727e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 8.7916e-05\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0540 - metrics_pearsonr: 3.3778e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 8.8059e-05\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0541 - metrics_pearsonr: 3.3860e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 8.8453e-05\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0539 - metrics_pearsonr: 3.3841e-05 - val_loss: 0.0864 - val_metrics_pearsonr: 8.8466e-05\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0536 - metrics_pearsonr: 3.3816e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 8.8543e-05\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0530 - metrics_pearsonr: 3.3707e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 8.7958e-05\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0523 - metrics_pearsonr: 3.3544e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.7482e-05\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0519 - metrics_pearsonr: 3.3368e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 8.7022e-05\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0523 - metrics_pearsonr: 3.3276e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.7017e-05\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0532 - metrics_pearsonr: 3.3231e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 8.7095e-05\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0540 - metrics_pearsonr: 3.3262e-05 - val_loss: 0.0882 - val_metrics_pearsonr: 8.7295e-05\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0544 - metrics_pearsonr: 3.3300e-05 - val_loss: 0.0882 - val_metrics_pearsonr: 8.7297e-05\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0540 - metrics_pearsonr: 3.3381e-05 - val_loss: 0.0865 - val_metrics_pearsonr: 8.7378e-05\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0535 - metrics_pearsonr: 3.3460e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 8.7471e-05\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0530 - metrics_pearsonr: 3.3573e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.7910e-05\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0532 - metrics_pearsonr: 3.3669e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.8357e-05\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0541 - metrics_pearsonr: 3.3783e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 8.8989e-05\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0554 - metrics_pearsonr: 3.3786e-05 - val_loss: 0.0887 - val_metrics_pearsonr: 8.9185e-05\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0566 - metrics_pearsonr: 3.3763e-05 - val_loss: 0.0918 - val_metrics_pearsonr: 8.9255e-05\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0569 - metrics_pearsonr: 3.3595e-05 - val_loss: 0.0925 - val_metrics_pearsonr: 8.8798e-05\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0563 - metrics_pearsonr: 3.3447e-05 - val_loss: 0.0903 - val_metrics_pearsonr: 8.8349e-05\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0549 - metrics_pearsonr: 3.3259e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 8.7727e-05\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0536 - metrics_pearsonr: 3.3204e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 8.7414e-05\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0534 - metrics_pearsonr: 3.3180e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.7204e-05\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0546 - metrics_pearsonr: 3.3251e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 8.7550e-05\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0568 - metrics_pearsonr: 3.3348e-05 - val_loss: 0.0922 - val_metrics_pearsonr: 8.7973e-05\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0587 - metrics_pearsonr: 3.3435e-05 - val_loss: 0.0968 - val_metrics_pearsonr: 8.8381e-05\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0592 - metrics_pearsonr: 3.3466e-05 - val_loss: 0.0956 - val_metrics_pearsonr: 8.8263e-05\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0579 - metrics_pearsonr: 3.3434e-05 - val_loss: 0.0896 - val_metrics_pearsonr: 8.8097e-05\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0561 - metrics_pearsonr: 3.3410e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.7929e-05\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0555 - metrics_pearsonr: 3.3477e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.8403e-05\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0568 - metrics_pearsonr: 3.3577e-05 - val_loss: 0.0897 - val_metrics_pearsonr: 8.9126e-05\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0591 - metrics_pearsonr: 3.3770e-05 - val_loss: 0.0966 - val_metrics_pearsonr: 9.0098e-05\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0602 - metrics_pearsonr: 3.3827e-05 - val_loss: 0.0976 - val_metrics_pearsonr: 9.0134e-05\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0591 - metrics_pearsonr: 3.3750e-05 - val_loss: 0.0913 - val_metrics_pearsonr: 8.9362e-05\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0565 - metrics_pearsonr: 3.3443e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 8.8188e-05\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0549 - metrics_pearsonr: 3.3252e-05 - val_loss: 0.0830 - val_metrics_pearsonr: 8.7750e-05\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0555 - metrics_pearsonr: 3.3169e-05 - val_loss: 0.0883 - val_metrics_pearsonr: 8.7829e-05\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0572 - metrics_pearsonr: 3.3215e-05 - val_loss: 0.0938 - val_metrics_pearsonr: 8.8332e-05\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0580 - metrics_pearsonr: 3.3308e-05 - val_loss: 0.0929 - val_metrics_pearsonr: 8.8515e-05\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0567 - metrics_pearsonr: 3.3318e-05 - val_loss: 0.0871 - val_metrics_pearsonr: 8.8396e-05\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0550 - metrics_pearsonr: 3.3214e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.8299e-05\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0543 - metrics_pearsonr: 3.3163e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 8.8669e-05\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0551 - metrics_pearsonr: 3.3170e-05 - val_loss: 0.0899 - val_metrics_pearsonr: 8.9006e-05\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0557 - metrics_pearsonr: 3.3238e-05 - val_loss: 0.0906 - val_metrics_pearsonr: 8.9179e-05\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0549 - metrics_pearsonr: 3.3250e-05 - val_loss: 0.0864 - val_metrics_pearsonr: 8.8852e-05\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0534 - metrics_pearsonr: 3.3233e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.8645e-05\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0525 - metrics_pearsonr: 3.3133e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.8652e-05\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0528 - metrics_pearsonr: 3.3102e-05 - val_loss: 0.0866 - val_metrics_pearsonr: 8.8798e-05\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0534 - metrics_pearsonr: 3.3037e-05 - val_loss: 0.0874 - val_metrics_pearsonr: 8.8450e-05\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0529 - metrics_pearsonr: 3.2891e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 8.8024e-05\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0519 - metrics_pearsonr: 3.2734e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.7773e-05\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0513 - metrics_pearsonr: 3.2689e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.8020e-05\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0515 - metrics_pearsonr: 3.2736e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 8.8303e-05\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0520 - metrics_pearsonr: 3.2880e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 8.8740e-05\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0520 - metrics_pearsonr: 3.2967e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 8.8888e-05\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0514 - metrics_pearsonr: 3.3029e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.9055e-05\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0508 - metrics_pearsonr: 3.2941e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.8919e-05\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0506 - metrics_pearsonr: 3.2842e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.8864e-05\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0507 - metrics_pearsonr: 3.2700e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 8.8496e-05\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0507 - metrics_pearsonr: 3.2577e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 8.8285e-05\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0503 - metrics_pearsonr: 3.2480e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.7990e-05\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0500 - metrics_pearsonr: 3.2434e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 8.8029e-05\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0499 - metrics_pearsonr: 3.2415e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 8.8106e-05\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0500 - metrics_pearsonr: 3.2470e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8344e-05\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0501 - metrics_pearsonr: 3.2499e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.8443e-05\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0502 - metrics_pearsonr: 3.2563e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.8628e-05\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0500 - metrics_pearsonr: 3.2550e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.8614e-05\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0499 - metrics_pearsonr: 3.2559e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8752e-05\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0498 - metrics_pearsonr: 3.2507e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8653e-05\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0498 - metrics_pearsonr: 3.2476e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.8731e-05\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0498 - metrics_pearsonr: 3.2420e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.8536e-05\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0498 - metrics_pearsonr: 3.2381e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8544e-05\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0496 - metrics_pearsonr: 3.2323e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.8385e-05\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0495 - metrics_pearsonr: 3.2308e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 8.8463e-05\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0494 - metrics_pearsonr: 3.2285e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 8.8422e-05\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0495 - metrics_pearsonr: 3.2312e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 8.8588e-05\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0495 - metrics_pearsonr: 3.2301e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.8621e-05\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0496 - metrics_pearsonr: 3.2332e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.8796e-05\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0495 - metrics_pearsonr: 3.2305e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8749e-05\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0495 - metrics_pearsonr: 3.2305e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8809e-05\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0494 - metrics_pearsonr: 3.2248e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 8.8643e-05\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0494 - metrics_pearsonr: 3.2235e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 8.8673e-05\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0494 - metrics_pearsonr: 3.2186e-05 - val_loss: 0.0822 - val_metrics_pearsonr: 8.8523e-05\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0495 - metrics_pearsonr: 3.2192e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.8652e-05\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0496 - metrics_pearsonr: 3.2190e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.8613e-05\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0496 - metrics_pearsonr: 3.2231e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.8824e-05\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0496 - metrics_pearsonr: 3.2250e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8852e-05\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0496 - metrics_pearsonr: 3.2296e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.9094e-05\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0496 - metrics_pearsonr: 3.2293e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.9153e-05\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0496 - metrics_pearsonr: 3.2307e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.9365e-05\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0496 - metrics_pearsonr: 3.2261e-05 - val_loss: 0.0830 - val_metrics_pearsonr: 8.9321e-05\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0496 - metrics_pearsonr: 3.2230e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.9362e-05\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0495 - metrics_pearsonr: 3.2139e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.9111e-05\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0493 - metrics_pearsonr: 3.2083e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 8.9009e-05\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0491 - metrics_pearsonr: 3.1988e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.8707e-05\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0491 - metrics_pearsonr: 3.1955e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.8677e-05\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0492 - metrics_pearsonr: 3.1919e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 8.8512e-05\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0493 - metrics_pearsonr: 3.1948e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 8.8653e-05\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0496 - metrics_pearsonr: 3.1978e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 8.8628e-05\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0498 - metrics_pearsonr: 3.2059e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 8.8888e-05\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0499 - metrics_pearsonr: 3.2129e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.8977e-05\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0500 - metrics_pearsonr: 3.2233e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 8.9374e-05\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0501 - metrics_pearsonr: 3.2306e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 8.9581e-05\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0502 - metrics_pearsonr: 3.2383e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 9.0058e-05\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0504 - metrics_pearsonr: 3.2397e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 9.0247e-05\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0504 - metrics_pearsonr: 3.2394e-05 - val_loss: 0.0850 - val_metrics_pearsonr: 9.0513e-05\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0504 - metrics_pearsonr: 3.2308e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 9.0317e-05\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0502 - metrics_pearsonr: 3.2203e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 9.0138e-05\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0499 - metrics_pearsonr: 3.2035e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 8.9606e-05\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0496 - metrics_pearsonr: 3.1910e-05 - val_loss: 0.0829 - val_metrics_pearsonr: 8.9329e-05\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0494 - metrics_pearsonr: 3.1786e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.8931e-05\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0495 - metrics_pearsonr: 3.1750e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 8.8890e-05\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0497 - metrics_pearsonr: 3.1706e-05 - val_loss: 0.0830 - val_metrics_pearsonr: 8.8722e-05\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0499 - metrics_pearsonr: 3.1736e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.8827e-05\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0501 - metrics_pearsonr: 3.1756e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 8.8737e-05\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0502 - metrics_pearsonr: 3.1830e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 8.8925e-05\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0502 - metrics_pearsonr: 3.1921e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.8964e-05\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0504 - metrics_pearsonr: 3.2049e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 8.9405e-05\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0508 - metrics_pearsonr: 3.2197e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 8.9797e-05\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0515 - metrics_pearsonr: 3.2350e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 9.0594e-05\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0524 - metrics_pearsonr: 3.2476e-05 - val_loss: 0.0881 - val_metrics_pearsonr: 9.1131e-05\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0530 - metrics_pearsonr: 3.2533e-05 - val_loss: 0.0901 - val_metrics_pearsonr: 9.1639e-05\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0531 - metrics_pearsonr: 3.2452e-05 - val_loss: 0.0901 - val_metrics_pearsonr: 9.1339e-05\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0525 - metrics_pearsonr: 3.2289e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 9.0891e-05\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0514 - metrics_pearsonr: 3.2021e-05 - val_loss: 0.0855 - val_metrics_pearsonr: 8.9998e-05\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0505 - metrics_pearsonr: 3.1850e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 8.9586e-05\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0502 - metrics_pearsonr: 3.1710e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 8.9209e-05\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0506 - metrics_pearsonr: 3.1709e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.9269e-05\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0513 - metrics_pearsonr: 3.1697e-05 - val_loss: 0.0851 - val_metrics_pearsonr: 8.9226e-05\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0520 - metrics_pearsonr: 3.1767e-05 - val_loss: 0.0869 - val_metrics_pearsonr: 8.9431e-05\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0524 - metrics_pearsonr: 3.1832e-05 - val_loss: 0.0874 - val_metrics_pearsonr: 8.9621e-05\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0524 - metrics_pearsonr: 3.1953e-05 - val_loss: 0.0870 - val_metrics_pearsonr: 8.9976e-05\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0522 - metrics_pearsonr: 3.2076e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 9.0343e-05\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0520 - metrics_pearsonr: 3.2212e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 9.0879e-05\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0522 - metrics_pearsonr: 3.2318e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 9.1293e-05\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0527 - metrics_pearsonr: 3.2393e-05 - val_loss: 0.0876 - val_metrics_pearsonr: 9.1640e-05\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0532 - metrics_pearsonr: 3.2365e-05 - val_loss: 0.0891 - val_metrics_pearsonr: 9.1622e-05\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0536 - metrics_pearsonr: 3.2316e-05 - val_loss: 0.0903 - val_metrics_pearsonr: 9.1504e-05\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0535 - metrics_pearsonr: 3.2144e-05 - val_loss: 0.0900 - val_metrics_pearsonr: 9.0917e-05\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0529 - metrics_pearsonr: 3.2054e-05 - val_loss: 0.0881 - val_metrics_pearsonr: 9.0537e-05\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0519 - metrics_pearsonr: 3.1887e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 8.9893e-05\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0511 - metrics_pearsonr: 3.1850e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 8.9647e-05\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0508 - metrics_pearsonr: 3.1765e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 8.9455e-05\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0513 - metrics_pearsonr: 3.1751e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 8.9811e-05\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0522 - metrics_pearsonr: 3.1773e-05 - val_loss: 0.0887 - val_metrics_pearsonr: 9.0270e-05\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0526 - metrics_pearsonr: 3.1838e-05 - val_loss: 0.0892 - val_metrics_pearsonr: 9.0631e-05\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0524 - metrics_pearsonr: 3.1857e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 9.0579e-05\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0516 - metrics_pearsonr: 3.1830e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 9.0418e-05\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0512 - metrics_pearsonr: 3.1755e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 9.0287e-05\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0515 - metrics_pearsonr: 3.1769e-05 - val_loss: 0.0868 - val_metrics_pearsonr: 9.0617e-05\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0519 - metrics_pearsonr: 3.1770e-05 - val_loss: 0.0881 - val_metrics_pearsonr: 9.0600e-05\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0519 - metrics_pearsonr: 3.1872e-05 - val_loss: 0.0869 - val_metrics_pearsonr: 9.0637e-05\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0514 - metrics_pearsonr: 3.1916e-05 - val_loss: 0.0846 - val_metrics_pearsonr: 9.0432e-05\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0511 - metrics_pearsonr: 3.1965e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 9.0777e-05\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0515 - metrics_pearsonr: 3.1986e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 9.1229e-05\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0523 - metrics_pearsonr: 3.2013e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 9.1747e-05\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0529 - metrics_pearsonr: 3.1981e-05 - val_loss: 0.0894 - val_metrics_pearsonr: 9.1491e-05\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0528 - metrics_pearsonr: 3.1827e-05 - val_loss: 0.0886 - val_metrics_pearsonr: 9.0987e-05\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0522 - metrics_pearsonr: 3.1620e-05 - val_loss: 0.0872 - val_metrics_pearsonr: 9.0350e-05\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0515 - metrics_pearsonr: 3.1509e-05 - val_loss: 0.0864 - val_metrics_pearsonr: 9.0269e-05\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0511 - metrics_pearsonr: 3.1486e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 9.0214e-05\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0510 - metrics_pearsonr: 3.1598e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 9.0476e-05\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0510 - metrics_pearsonr: 3.1720e-05 - val_loss: 0.0850 - val_metrics_pearsonr: 9.0737e-05\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0513 - metrics_pearsonr: 3.1819e-05 - val_loss: 0.0855 - val_metrics_pearsonr: 9.1304e-05\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0519 - metrics_pearsonr: 3.1852e-05 - val_loss: 0.0869 - val_metrics_pearsonr: 9.1539e-05\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0527 - metrics_pearsonr: 3.1852e-05 - val_loss: 0.0890 - val_metrics_pearsonr: 9.1466e-05\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0537 - metrics_pearsonr: 3.1789e-05 - val_loss: 0.0908 - val_metrics_pearsonr: 9.0921e-05\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0543 - metrics_pearsonr: 3.1759e-05 - val_loss: 0.0923 - val_metrics_pearsonr: 9.0792e-05\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0543 - metrics_pearsonr: 3.1709e-05 - val_loss: 0.0926 - val_metrics_pearsonr: 9.0940e-05\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0538 - metrics_pearsonr: 3.1798e-05 - val_loss: 0.0912 - val_metrics_pearsonr: 9.1160e-05\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0528 - metrics_pearsonr: 3.1860e-05 - val_loss: 0.0880 - val_metrics_pearsonr: 9.0661e-05\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0520 - metrics_pearsonr: 3.2053e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 9.0195e-05\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0520 - metrics_pearsonr: 3.2303e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.0646e-05\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0532 - metrics_pearsonr: 3.2678e-05 - val_loss: 0.0868 - val_metrics_pearsonr: 9.2807e-05\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0554 - metrics_pearsonr: 3.3008e-05 - val_loss: 0.0930 - val_metrics_pearsonr: 9.4964e-05\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0576 - metrics_pearsonr: 3.3140e-05 - val_loss: 0.0983 - val_metrics_pearsonr: 9.5297e-05\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0585 - metrics_pearsonr: 3.2812e-05 - val_loss: 0.0987 - val_metrics_pearsonr: 9.3274e-05\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0574 - metrics_pearsonr: 3.2244e-05 - val_loss: 0.0947 - val_metrics_pearsonr: 9.1493e-05\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0555 - metrics_pearsonr: 3.1803e-05 - val_loss: 0.0889 - val_metrics_pearsonr: 9.0658e-05\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0540 - metrics_pearsonr: 3.1783e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 9.0490e-05\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0538 - metrics_pearsonr: 3.1855e-05 - val_loss: 0.0854 - val_metrics_pearsonr: 9.0406e-05\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0550 - metrics_pearsonr: 3.1943e-05 - val_loss: 0.0911 - val_metrics_pearsonr: 9.1475e-05\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0570 - metrics_pearsonr: 3.2131e-05 - val_loss: 0.0981 - val_metrics_pearsonr: 9.3082e-05\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0583 - metrics_pearsonr: 3.2310e-05 - val_loss: 0.0995 - val_metrics_pearsonr: 9.3312e-05\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0573 - metrics_pearsonr: 3.2113e-05 - val_loss: 0.0939 - val_metrics_pearsonr: 9.2050e-05\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0547 - metrics_pearsonr: 3.1732e-05 - val_loss: 0.0870 - val_metrics_pearsonr: 9.1092e-05\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0529 - metrics_pearsonr: 3.1515e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 9.0782e-05\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0530 - metrics_pearsonr: 3.1580e-05 - val_loss: 0.0870 - val_metrics_pearsonr: 9.0993e-05\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0545 - metrics_pearsonr: 3.1731e-05 - val_loss: 0.0916 - val_metrics_pearsonr: 9.1761e-05\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0559 - metrics_pearsonr: 3.1953e-05 - val_loss: 0.0942 - val_metrics_pearsonr: 9.2782e-05\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0561 - metrics_pearsonr: 3.1990e-05 - val_loss: 0.0924 - val_metrics_pearsonr: 9.2468e-05\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0551 - metrics_pearsonr: 3.1731e-05 - val_loss: 0.0897 - val_metrics_pearsonr: 9.1198e-05\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0545 - metrics_pearsonr: 3.1408e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 9.0451e-05\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0547 - metrics_pearsonr: 3.1275e-05 - val_loss: 0.0934 - val_metrics_pearsonr: 9.0617e-05\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0549 - metrics_pearsonr: 3.1313e-05 - val_loss: 0.0943 - val_metrics_pearsonr: 9.0734e-05\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0543 - metrics_pearsonr: 3.1437e-05 - val_loss: 0.0911 - val_metrics_pearsonr: 9.0861e-05\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0530 - metrics_pearsonr: 3.1542e-05 - val_loss: 0.0862 - val_metrics_pearsonr: 9.1266e-05\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0522 - metrics_pearsonr: 3.1627e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 9.1921e-05\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0525 - metrics_pearsonr: 3.1583e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 9.2096e-05\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0540 - metrics_pearsonr: 3.1490e-05 - val_loss: 0.0896 - val_metrics_pearsonr: 9.1944e-05\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0557 - metrics_pearsonr: 3.1344e-05 - val_loss: 0.0923 - val_metrics_pearsonr: 9.1576e-05\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0569 - metrics_pearsonr: 3.1260e-05 - val_loss: 0.0950 - val_metrics_pearsonr: 9.1613e-05\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0577 - metrics_pearsonr: 3.1222e-05 - val_loss: 0.0981 - val_metrics_pearsonr: 9.1848e-05\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0581 - metrics_pearsonr: 3.1289e-05 - val_loss: 0.1001 - val_metrics_pearsonr: 9.2216e-05\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0575 - metrics_pearsonr: 3.1333e-05 - val_loss: 0.0979 - val_metrics_pearsonr: 9.2215e-05\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0559 - metrics_pearsonr: 3.1392e-05 - val_loss: 0.0912 - val_metrics_pearsonr: 9.1830e-05\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0540 - metrics_pearsonr: 3.1321e-05 - val_loss: 0.0846 - val_metrics_pearsonr: 9.1107e-05\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0537 - metrics_pearsonr: 3.1282e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 9.0951e-05\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0559 - metrics_pearsonr: 3.1276e-05 - val_loss: 0.0911 - val_metrics_pearsonr: 9.1163e-05\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0599 - metrics_pearsonr: 3.1374e-05 - val_loss: 0.1026 - val_metrics_pearsonr: 9.1890e-05\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0635 - metrics_pearsonr: 3.1521e-05 - val_loss: 0.1108 - val_metrics_pearsonr: 9.2215e-05\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0644 - metrics_pearsonr: 3.1554e-05 - val_loss: 0.1093 - val_metrics_pearsonr: 9.2021e-05\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0621 - metrics_pearsonr: 3.1518e-05 - val_loss: 0.0980 - val_metrics_pearsonr: 9.1420e-05\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0587 - metrics_pearsonr: 3.1534e-05 - val_loss: 0.0865 - val_metrics_pearsonr: 9.1162e-05\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0574 - metrics_pearsonr: 3.1602e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 9.1613e-05\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0596 - metrics_pearsonr: 3.1751e-05 - val_loss: 0.0980 - val_metrics_pearsonr: 9.3091e-05\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0634 - metrics_pearsonr: 3.1921e-05 - val_loss: 0.1102 - val_metrics_pearsonr: 9.4551e-05\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0647 - metrics_pearsonr: 3.2012e-05 - val_loss: 0.1072 - val_metrics_pearsonr: 9.4106e-05\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0611 - metrics_pearsonr: 3.1634e-05 - val_loss: 0.0920 - val_metrics_pearsonr: 9.2135e-05\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0566 - metrics_pearsonr: 3.1277e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.0830e-05\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0554 - metrics_pearsonr: 3.1133e-05 - val_loss: 0.0899 - val_metrics_pearsonr: 9.0799e-05\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0573 - metrics_pearsonr: 3.1255e-05 - val_loss: 0.0997 - val_metrics_pearsonr: 9.1661e-05\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0584 - metrics_pearsonr: 3.1447e-05 - val_loss: 0.0984 - val_metrics_pearsonr: 9.2390e-05\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0563 - metrics_pearsonr: 3.1476e-05 - val_loss: 0.0884 - val_metrics_pearsonr: 9.2277e-05\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0532 - metrics_pearsonr: 3.1232e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1698e-05\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0523 - metrics_pearsonr: 3.0940e-05 - val_loss: 0.0886 - val_metrics_pearsonr: 9.1726e-05\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0529 - metrics_pearsonr: 3.0813e-05 - val_loss: 0.0919 - val_metrics_pearsonr: 9.1805e-05\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0525 - metrics_pearsonr: 3.0804e-05 - val_loss: 0.0881 - val_metrics_pearsonr: 9.1543e-05\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0508 - metrics_pearsonr: 3.0749e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 9.1257e-05\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0497 - metrics_pearsonr: 3.0709e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 9.1320e-05\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0498 - metrics_pearsonr: 3.0683e-05 - val_loss: 0.0874 - val_metrics_pearsonr: 9.1454e-05\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0500 - metrics_pearsonr: 3.0661e-05 - val_loss: 0.0871 - val_metrics_pearsonr: 9.1297e-05\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0495 - metrics_pearsonr: 3.0562e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 9.0972e-05\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0487 - metrics_pearsonr: 3.0472e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 9.0964e-05\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0484 - metrics_pearsonr: 3.0450e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 9.1195e-05\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0485 - metrics_pearsonr: 3.0483e-05 - val_loss: 0.0851 - val_metrics_pearsonr: 9.1570e-05\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0485 - metrics_pearsonr: 3.0515e-05 - val_loss: 0.0847 - val_metrics_pearsonr: 9.1712e-05\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0481 - metrics_pearsonr: 3.0486e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1558e-05\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0477 - metrics_pearsonr: 3.0388e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1233e-05\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0476 - metrics_pearsonr: 3.0306e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1008e-05\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0476 - metrics_pearsonr: 3.0258e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 9.0883e-05\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0476 - metrics_pearsonr: 3.0274e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.0992e-05\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0475 - metrics_pearsonr: 3.0309e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 9.1123e-05\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0475 - metrics_pearsonr: 3.0360e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1404e-05\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0475 - metrics_pearsonr: 3.0370e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 9.1541e-05\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0475 - metrics_pearsonr: 3.0366e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 9.1618e-05\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0474 - metrics_pearsonr: 3.0301e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 9.1439e-05\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0472 - metrics_pearsonr: 3.0258e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1317e-05\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0471 - metrics_pearsonr: 3.0190e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 9.1124e-05\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0471 - metrics_pearsonr: 3.0193e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1140e-05\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0471 - metrics_pearsonr: 3.0172e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1100e-05\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0471 - metrics_pearsonr: 3.0210e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1277e-05\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0472 - metrics_pearsonr: 3.0216e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1332e-05\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0472 - metrics_pearsonr: 3.0243e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1535e-05\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0472 - metrics_pearsonr: 3.0225e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1557e-05\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0472 - metrics_pearsonr: 3.0224e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1658e-05\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0471 - metrics_pearsonr: 3.0178e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1538e-05\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0471 - metrics_pearsonr: 3.0163e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1527e-05\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0470 - metrics_pearsonr: 3.0102e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1362e-05\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0469 - metrics_pearsonr: 3.0104e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1384e-05\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0469 - metrics_pearsonr: 3.0072e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 9.1292e-05\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0469 - metrics_pearsonr: 3.0093e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1420e-05\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0470 - metrics_pearsonr: 3.0085e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1409e-05\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0470 - metrics_pearsonr: 3.0109e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1585e-05\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0470 - metrics_pearsonr: 3.0100e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1578e-05\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0470 - metrics_pearsonr: 3.0114e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1725e-05\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0470 - metrics_pearsonr: 3.0088e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1677e-05\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0470 - metrics_pearsonr: 3.0092e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 9.1772e-05\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0470 - metrics_pearsonr: 3.0053e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1675e-05\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0469 - metrics_pearsonr: 3.0053e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1731e-05\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0469 - metrics_pearsonr: 3.0009e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1594e-05\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0468 - metrics_pearsonr: 3.0012e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1658e-05\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0468 - metrics_pearsonr: 2.9972e-05 - val_loss: 0.0834 - val_metrics_pearsonr: 9.1533e-05\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0468 - metrics_pearsonr: 2.9975e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1629e-05\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0468 - metrics_pearsonr: 2.9956e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1549e-05\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0468 - metrics_pearsonr: 2.9971e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1697e-05\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0469 - metrics_pearsonr: 2.9963e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1671e-05\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0469 - metrics_pearsonr: 2.9988e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1848e-05\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0469 - metrics_pearsonr: 2.9980e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1842e-05\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0469 - metrics_pearsonr: 3.0000e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.2014e-05\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0469 - metrics_pearsonr: 2.9976e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1957e-05\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0469 - metrics_pearsonr: 2.9983e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 9.2073e-05\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0469 - metrics_pearsonr: 2.9940e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1933e-05\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0468 - metrics_pearsonr: 2.9927e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1990e-05\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0467 - metrics_pearsonr: 2.9875e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1810e-05\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0467 - metrics_pearsonr: 2.9865e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1866e-05\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0467 - metrics_pearsonr: 2.9826e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 9.1713e-05\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0467 - metrics_pearsonr: 2.9829e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1818e-05\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0467 - metrics_pearsonr: 2.9812e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1723e-05\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0467 - metrics_pearsonr: 2.9832e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1884e-05\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0468 - metrics_pearsonr: 2.9830e-05 - val_loss: 0.0837 - val_metrics_pearsonr: 9.1847e-05\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0468 - metrics_pearsonr: 2.9858e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.2050e-05\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0468 - metrics_pearsonr: 2.9861e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.2044e-05\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0469 - metrics_pearsonr: 2.9887e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 9.2261e-05\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0469 - metrics_pearsonr: 2.9879e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 9.2237e-05\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0469 - metrics_pearsonr: 2.9892e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 9.2424e-05\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0469 - metrics_pearsonr: 2.9862e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 9.2329e-05\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0469 - metrics_pearsonr: 2.9856e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 9.2439e-05\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0469 - metrics_pearsonr: 2.9803e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 9.2253e-05\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0468 - metrics_pearsonr: 2.9780e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 9.2297e-05\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0467 - metrics_pearsonr: 2.9724e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.2076e-05\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0466 - metrics_pearsonr: 2.9703e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.2123e-05\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0465 - metrics_pearsonr: 2.9661e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 9.1927e-05\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0466 - metrics_pearsonr: 2.9655e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.2016e-05\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0466 - metrics_pearsonr: 2.9636e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 9.1884e-05\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0467 - metrics_pearsonr: 2.9649e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 9.2033e-05\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0468 - metrics_pearsonr: 2.9652e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 9.1962e-05\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0468 - metrics_pearsonr: 2.9682e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 9.2162e-05\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0469 - metrics_pearsonr: 2.9699e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 9.2153e-05\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0469 - metrics_pearsonr: 2.9739e-05 - val_loss: 0.0843 - val_metrics_pearsonr: 9.2403e-05\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0470 - metrics_pearsonr: 2.9766e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 9.2444e-05\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0471 - metrics_pearsonr: 2.9808e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 9.2738e-05\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0472 - metrics_pearsonr: 2.9826e-05 - val_loss: 0.0846 - val_metrics_pearsonr: 9.2798e-05\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0474 - metrics_pearsonr: 2.9857e-05 - val_loss: 0.0852 - val_metrics_pearsonr: 9.3080e-05\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0476 - metrics_pearsonr: 2.9843e-05 - val_loss: 0.0855 - val_metrics_pearsonr: 9.3054e-05\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0477 - metrics_pearsonr: 2.9840e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 9.3219e-05\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0477 - metrics_pearsonr: 2.9780e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 9.3023e-05\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0476 - metrics_pearsonr: 2.9735e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 9.3028e-05\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0474 - metrics_pearsonr: 2.9647e-05 - val_loss: 0.0854 - val_metrics_pearsonr: 9.2700e-05\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0471 - metrics_pearsonr: 2.9593e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 9.2642e-05\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0469 - metrics_pearsonr: 2.9515e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 9.2316e-05\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0468 - metrics_pearsonr: 2.9486e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 9.2315e-05\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0469 - metrics_pearsonr: 2.9445e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 9.2095e-05\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0472 - metrics_pearsonr: 2.9448e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 9.2192e-05\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0478 - metrics_pearsonr: 2.9442e-05 - val_loss: 0.0856 - val_metrics_pearsonr: 9.2081e-05\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0483 - metrics_pearsonr: 2.9471e-05 - val_loss: 0.0870 - val_metrics_pearsonr: 9.2243e-05\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0488 - metrics_pearsonr: 2.9493e-05 - val_loss: 0.0879 - val_metrics_pearsonr: 9.2185e-05\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0491 - metrics_pearsonr: 2.9536e-05 - val_loss: 0.0887 - val_metrics_pearsonr: 9.2364e-05\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0493 - metrics_pearsonr: 2.9587e-05 - val_loss: 0.0886 - val_metrics_pearsonr: 9.2327e-05\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0492 - metrics_pearsonr: 2.9660e-05 - val_loss: 0.0881 - val_metrics_pearsonr: 9.2542e-05\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0491 - metrics_pearsonr: 2.9760e-05 - val_loss: 0.0869 - val_metrics_pearsonr: 9.2610e-05\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0491 - metrics_pearsonr: 2.9892e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 9.3032e-05\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0495 - metrics_pearsonr: 3.0058e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 9.3458e-05\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0505 - metrics_pearsonr: 3.0256e-05 - val_loss: 0.0876 - val_metrics_pearsonr: 9.4318e-05\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0520 - metrics_pearsonr: 3.0441e-05 - val_loss: 0.0906 - val_metrics_pearsonr: 9.5143e-05\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0539 - metrics_pearsonr: 3.0623e-05 - val_loss: 0.0950 - val_metrics_pearsonr: 9.6081e-05\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0557 - metrics_pearsonr: 3.0666e-05 - val_loss: 0.0990 - val_metrics_pearsonr: 9.6355e-05\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0568 - metrics_pearsonr: 3.0631e-05 - val_loss: 0.1013 - val_metrics_pearsonr: 9.6133e-05\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0565 - metrics_pearsonr: 3.0383e-05 - val_loss: 0.1000 - val_metrics_pearsonr: 9.5026e-05\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0552 - metrics_pearsonr: 3.0141e-05 - val_loss: 0.0959 - val_metrics_pearsonr: 9.4055e-05\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0536 - metrics_pearsonr: 2.9940e-05 - val_loss: 0.0905 - val_metrics_pearsonr: 9.3268e-05\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0528 - metrics_pearsonr: 2.9980e-05 - val_loss: 0.0873 - val_metrics_pearsonr: 9.3242e-05\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0535 - metrics_pearsonr: 3.0060e-05 - val_loss: 0.0883 - val_metrics_pearsonr: 9.3281e-05\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0557 - metrics_pearsonr: 3.0197e-05 - val_loss: 0.0945 - val_metrics_pearsonr: 9.3707e-05\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0587 - metrics_pearsonr: 3.0303e-05 - val_loss: 0.1028 - val_metrics_pearsonr: 9.4166e-05\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0612 - metrics_pearsonr: 3.0494e-05 - val_loss: 0.1080 - val_metrics_pearsonr: 9.4732e-05\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0620 - metrics_pearsonr: 3.0750e-05 - val_loss: 0.1050 - val_metrics_pearsonr: 9.4761e-05\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0606 - metrics_pearsonr: 3.0922e-05 - val_loss: 0.0971 - val_metrics_pearsonr: 9.4572e-05\n",
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B3D878CF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "相关系数 0.9968714280160048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_1\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_2\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_3\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_4\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215_5\\assets\n"
     ]
    }
   ],
   "source": [
    "model,predicty,testy,r,p,weights=Auto_Transformer(vy,vx,6,[['transformer'],['fc',7]],test_size=0.2,valid_size=0.1,k_fold=5,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=1,key_dim=1,ifdropout='no',trans_dropout_rate=0.0,trans_units=256,trans_activation='tanh',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='Adam',metrics='Pearsonr',if_early_stopping=1000,learning_rate=0.0001,epochs=5000,batch_size=5000,ifrandom_split='yes',ifweight='no',ifmute='no',ifsave='yes',savepath='E:/huawei/huawei_gnss_wind_v_30min_press_k5_onestation_1215',device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3f567a-a1dd-44d8-ae75-32e5c3444498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21712951\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(np.abs(testy-predicty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b3ea65-a427-49f2-8c0a-8c13eb49f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3519, 7) (3519, 7)\n"
     ]
    }
   ],
   "source": [
    "print(testy.shape,predicty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c8da8d-a175-4d49-a95b-fe7772942950",
   "metadata": {},
   "outputs": [],
   "source": [
    "times=np.arange(3519)\n",
    "testy_v=testy\n",
    "predicty_v=predicty\n",
    "levels=[1000,925,850,700,600,500,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96deff50-b780-48c5-b826-5a0b87e142ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times',  'levels')\n",
    "\n",
    "\n",
    "testy_v_da = xr.DataArray(\n",
    "    data=testy_v,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='testy_v' \n",
    ")\n",
    "\n",
    "\n",
    "predicty_v_da = xr.DataArray(\n",
    "    data=predicty_v,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_v'\n",
    ")\n",
    "\n",
    "testy_v_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_v_onestation_1215.nc')\n",
    "predicty_v_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_v_onestation_1215.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da782789-c599-4b53-b10c-c6c3133369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "testy_v_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_v_onestation_1215.nc')\n",
    "predicty_v_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_v_onestation_1215.nc')\n",
    "testy_v=np.array(testy_v_file['testy_v'])\n",
    "predicty_v=np.array(predicty_v_file['predicty_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f862ec-d92c-46f0-8cd2-402f35c377aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CDF匹配\n",
    "def Auto_cdf_matching(vx,vy):\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    if np.array(vx).ndim==1:\n",
    "        vx_cdf = (np.arange(len(vx)) +  1) / (len(vx))\n",
    "        vy_cdf = (np.arange(len(vy)) +  1) / (len(vy))\n",
    "        \n",
    "        spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx))\n",
    "        vx_interp = spl(vy_cdf)\n",
    "        \n",
    "        def func(x, a, b, c, d):\n",
    "            return a*x + b*x**2 + c*x**3 + d\n",
    "        \n",
    "        popt = curve_fit(func, vx_interp, np.sort(vy))[0]\n",
    "        \n",
    "        matched_vx = func(vx, *popt)\n",
    "    elif np.array(vx).ndim==2:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            vx_cdf = (np.arange(len(vx[:,i])) +  1) / (len(vx[:,i]))\n",
    "            vy_cdf = (np.arange(len(vy[:,i])) +  1) / (len(vy[:,i]))\n",
    "            \n",
    "            spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i]))\n",
    "            vx_interp = spl(vy_cdf)\n",
    "            \n",
    "            def func(x, a, b, c, d):\n",
    "                return a*x + b*x**2 + c*x**3 + d\n",
    "            \n",
    "            popt = curve_fit(func, vx_interp, np.sort(vy[:,i]))[0]\n",
    "            \n",
    "            matched_vx[:,i] = func(vx[:,i], *popt)\n",
    "    elif np.array(vx).ndim==3:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                vx_cdf = (np.arange(len(vx[:,i,j])) +  1) / (len(vx[:,i,j]))\n",
    "                vy_cdf = (np.arange(len(vy[:,i,j])) +  1) / (len(vy[:,i,j]))\n",
    "                \n",
    "                spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j]))\n",
    "                vx_interp = spl(vy_cdf)\n",
    "                \n",
    "                def func(x, a, b, c, d):\n",
    "                    return a*x + b*x**2 + c*x**3 + d\n",
    "                \n",
    "                popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j]))[0]\n",
    "                \n",
    "                matched_vx[:,i,j] = func(vx[:,i,j], *popt)\n",
    "    elif np.array(vx).ndim==4:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2],vx.shape[3]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                for k in range(vx.shape[3]):\n",
    "                    vx_cdf = (np.arange(len(vx[:,i,j,k])) +  1) / (len(vx[:,i,j,k]))\n",
    "                    vy_cdf = (np.arange(len(vy[:,i,j,k])) +  1) / (len(vy[:,i,j,k]))\n",
    "                    \n",
    "                    spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j,k]))\n",
    "                    vx_interp = spl(vy_cdf)\n",
    "                    \n",
    "                    def func(x, a, b, c, d):\n",
    "                        return a*x + b*x**2 + c*x**3 + d\n",
    "                    \n",
    "                    popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j,k]))[0]\n",
    "                    \n",
    "                    matched_vx[:,i,j,k] = func(vx[:,i,j,k], *popt)\n",
    "\n",
    "    return matched_vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd141a83-bd3f-4bf4-aa3a-53fc576e7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import Auto_paint_self\n",
    "np.random.seed(25)\n",
    "trainy,testy,trainx,testx = train_test_split(np.array(vy),vx,test_size=0.2,random_state=25)\n",
    "predicty_v=Auto_cdf_matching(np.array(predicty_v),trainy[np.random.randint(0,trainy.shape[0], predicty_v.shape[0]),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a2b5b3-4679-4e1b-89c3-5a0b3d9e71d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 318.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from metpy.calc import wind_direction,wind_speed\n",
    "from metpy.units import units\n",
    "u_rmse=np.zeros((predicty_v.shape[1]))\n",
    "u_mae=np.zeros((predicty_v.shape[1]))\n",
    "u_pearson=np.zeros((predicty_v.shape[1]))\n",
    "u_mape=np.zeros((predicty_v.shape[1]))\n",
    "for i in tqdm(range(predicty_v.shape[1])):\n",
    "    u_rmse[i]=mean_squared_error(testy_v[:,i],predicty_v[:,i])\n",
    "    u_pearson[i],_=pearsonr(testy_v[:,i],predicty_v[:,i])\n",
    "    u_mae[i]=mean_absolute_error(testy_v[:,i],predicty_v[:,i])\n",
    "    u_mape[i]=mean_absolute_percentage_error(testy_v[:,i],predicty_v[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5312b1cf-880f-49cd-9c25-a78afc4f5bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21459385 0.21827204 0.22497987 0.23514085 0.2635974  0.28374911\n",
      " 0.2951167 ]\n",
      "0.24792140278711794\n"
     ]
    }
   ],
   "source": [
    "print(u_mae)\n",
    "print(np.nanmean(u_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2511a33f-1e5a-4bed-bade-a1a97d95a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08449925 0.09494642 0.10219844 0.14660765 0.21861135 0.18717803\n",
      " 0.26042227]\n",
      "0.1563519156362905\n"
     ]
    }
   ],
   "source": [
    "print(u_rmse)\n",
    "print(np.nanmean(u_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec04903-de35-4c66-92f3-c76447a7e1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01333456 0.01023931 0.00876127 0.01269221 0.02333505 0.01109519\n",
      " 0.00934225]\n",
      "0.012685691618543953\n"
     ]
    }
   ],
   "source": [
    "u_p=np.sqrt(u_rmse)/(np.nanmax(testy_v,axis=0)-np.nanmin(testy_v,axis=0))\n",
    "#v_p=np.sqrt(v_rmse)/(np.nanmax(testy_v,axis=0)-np.nanmin(testy_v,axis=0))\n",
    "#wind_p=np.sqrt(wind_rmse)/(np.nanmax(np.sqrt(testy_v**2+testy_v**2),axis=0)-np.nanmin(np.sqrt(testy_v**2+testy_v**2),axis=0))\n",
    "print(u_p)\n",
    "print(np.nanmean(u_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1efbcb-42c8-49c3-ac71-f9e20cf8d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times',  'levels')\n",
    "\n",
    "predicty_v_da_cdf = xr.DataArray(\n",
    "    data=predicty_v,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_v'\n",
    ")\n",
    "\n",
    "predicty_v_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_v_cdf_onestation_1215.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41648ee2-f4f2-47c3-97e1-5a812152f002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
