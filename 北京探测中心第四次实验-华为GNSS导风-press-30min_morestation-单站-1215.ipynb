{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd95e3a4-ec22-4572-904c-cfc063048129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载原始数据文件...\n",
      "文件加载完毕。\n",
      "正在对原始数据进行预处理...\n",
      "预处理完成。\n",
      "\n",
      "--- 开始筛选站点 (新逻辑) ---\n",
      "目标风场站点: 58557\n",
      "使用预设的目标站点经纬度: Lon=120.0717, Lat=29.3619\n",
      "在GNSS数据文件中找到 1215 个可用站点。\n",
      "在CSV和GNSS数据文件中共有 1215 个共同站点。\n",
      "找到的最近 1215 个GNSS站点: ['H992830', 'H998276', 'H11705423', 'H11705435', 'H792737', 'H892451', 'H992254', 'H11705447', 'H11705440', 'H892504', 'H998585', 'H997648', 'H992221', 'H998596', 'H11705442', 'H11705404', 'H798684', 'H997915', 'H997714', 'H11705408', 'H892866', 'H992792', 'H992154', 'H991217', 'H998172', 'H997618', 'H992023', 'H756621', 'H999268', 'H990477', 'H999166', 'H756021', 'H996453', 'H990638', 'H998429', 'H990413', 'H999194', 'H991454', 'H999941', 'H999072', 'H990004', 'H799390', 'H990379', 'H999070', 'H990896', 'H796752', 'H756990', 'H990312', 'H999634', 'H990100', 'H999409', 'H999227', 'H890501', 'H999651', 'H796767', 'H990819', 'H992352', 'H993271', 'H994528', 'H796788', 'H993233', 'H990014', 'H799263', 'H799424', 'H994427', 'H999342', 'H891649', 'H997770', 'H999401', 'H899701', 'H854592', 'H756069', 'H756507', 'H990435', 'H956637', 'H956050', 'H999174', 'H993527', 'H956776', 'H999425', 'H994430', 'H799188', 'H754810', 'H758362', 'H754825', 'H990287', 'H754964', 'H994827', 'H754070', 'H990589', 'H956437', 'H11705362', 'H999137', 'H754047', 'H756643', 'H994535', 'H899502', 'H799069', 'H999036', 'H899953', 'H899447', 'H994080', 'H999195', 'H999208', 'H997384', 'H756089', 'H999192', 'H790349', 'H990300', 'H999220', 'H996009', 'H990270', 'H756613', 'H990220', 'H999926', 'H11705360', 'H799361', 'H990658', 'H890734', 'H999753', 'H752190', 'H990362', 'H999080', 'H790044', 'H990791', 'H890125', 'H11705511', 'H890930', 'H991672', 'H990356', 'H990975', 'H891646', 'H990933', 'H990805', 'H990390', 'H999508', 'H999127', 'H990029', 'H799256', 'H994615', 'H990208', 'H990790', 'H991684', 'H11705376', 'H999099', 'H990665', 'H11705375', 'H995070', 'H990785', 'H990635', 'H754576', 'H994622', 'H890721', 'H999660', 'H752327', 'H990247', 'H990936', 'H995674', 'H899154', 'H756366', 'H890990', 'H999153', 'H999664', 'H990190', 'H999237', 'H11705381', 'H11705382', 'H999672', 'H11705371', 'H752344', 'H899851', 'H996184', 'H754323', 'H11705373', 'H990225', 'H996542', 'H990520', 'H756680', 'H11705384', 'H996903', 'H752178', 'H990544', 'H890545', 'H754077', 'H890236', 'H990148', 'H996176', 'H754458', 'H899660', 'H990098', 'H752439', 'H996150', 'H991654', 'H996402', 'H756649', 'H996284', 'H713716', 'H752478', 'H990211', 'H996016', 'H754497', 'H990815', 'H996587', 'H752365', 'H756451', 'H899223', 'H799497', 'H996177', 'H913879', 'H990318', 'H996085', 'H996408', 'H999197', 'H752355', 'H996276', 'H899700', 'H996162', 'H790122', 'H713099', 'H999289', 'H752598', 'H996172', 'H752993', 'H752561', 'H752080', 'H712795', 'H990656', 'H952235', 'H752312', 'H999033', 'H752172', 'H854560', 'H990385', 'H996058', 'H999251', 'H815529', 'H752612', 'H996458', 'H991682', 'H812229', 'H999001', 'H999337', 'H999670', 'H812364', 'H717664', 'H918333', 'H917541', 'H712500', 'H996073', 'H990826', 'H952754', 'H996406', 'H790852', 'H815368', 'H916985', 'H899680', 'H799026', 'H999079', 'H917558', 'H713454', 'H990363', 'H712465', 'H999784', 'H717503', 'H752972', 'H852847', 'H812830', 'H890309', 'H990326', 'H752784', 'H996078', 'H996202', 'H910437', 'H852873', 'H818012', 'H713420', 'H752051', 'H995552', 'H996091', 'H952696', 'H752654', 'H815373', 'H813115', 'H996419', 'H816290', 'H790844', 'H894896', 'H990814', 'H713333', 'H752371', 'H752363', 'H990842', 'H990450', 'H912930', 'H813277', 'H752360', 'H752331', 'H812960', 'H911031', 'H812339', 'H912330', 'H817058', 'H917272', 'H913901', 'H814890', 'H713104', 'H712231', 'H811399', 'H911080', 'H752329', 'H912596', 'H752321', 'H914283', 'H910993', 'H914268', 'H812472', 'H719197', 'H711205', 'H711417', 'H712372', 'H815654', 'H815683', 'H717490', 'H911092', 'H917915', 'H913045', 'H717441', 'H516440', 'H711437', 'H811053', 'H714575', 'H414954', 'H913997', 'H913183', 'H811100', 'H416412', 'H779871', 'H711370', 'H714024', 'H717064', 'H912003', 'H779869', 'H712277', 'H819770', 'H714675', 'H912015', 'H418645', 'H711288', 'H475383', 'H714836', 'H711897', 'H711196', 'H776415', 'H812051', 'H944935', 'H515808', 'H717342', 'H913143', 'H719139', 'H944929', 'H717753', 'H715046', 'H813668', 'H944916', 'H944885', 'H710894', 'H944927', 'H944200', 'H444117', 'H944389', 'H873456', 'H944436', 'H776146', 'H776173', 'H544723', 'H944686', 'H944411', 'H944811', 'H944312', 'H11681931', 'H771248', 'H944329', 'H544715', 'H770190', 'H444168', 'H771268', 'H874165', 'H771828', 'H877273', 'H944190', 'H876753', 'H940874', 'H771123', 'H944285', 'H944148', 'H11682037', 'H944812', 'H947727', 'H940937', 'H940208', 'H949348', 'H940153', 'H776679', 'H940152', 'H941086', 'H776680', 'H949201', 'H941719', 'H947393', 'H777359', 'H779860', 'H949076', 'H779864', 'H873410', 'H775525', 'H949002', 'H871938', 'H943744', 'H940288', 'H440142', 'H773894', 'H943717', 'H945116', 'H943840', 'H945643', 'H945596', 'H945338', 'H948168', 'H949087', 'H475613', 'H948161', 'H945701', 'H949152', 'H945789', 'H943783', 'H949198', 'H943739', 'H949035', 'H445201', 'H949600', 'H949051', 'H771839', 'H949037', 'H943424', 'H11682008', 'H945631', 'H876616', 'H943849', 'H948239', 'H941838', 'H11682007', 'H779345', 'H445169', 'H945933', 'H771727', 'H875870', 'H948586', 'H947392', 'H777361', 'H773975', 'H11678387', 'H773959', 'H477543', 'H475201', 'H771227', 'H872486', 'H11682022', 'H971814', 'H943096', 'H778483', 'H877659', 'H11682000', 'H945117', 'H874967', 'H877863', 'H941425', 'H771463', 'H873916', 'H778478', 'H11682031', 'H670431', 'H945249', 'H776798', 'H978076', 'H778780', 'H945253', 'H943701', 'H943032', 'H779531', 'H872324', 'H945081', 'H11682020', 'H945785', 'H945548', 'H470820', 'H945732', 'H977455', 'H941421', 'H940758', 'H973268', 'H778510', 'H777878', 'H943712', 'H875021', 'H945768', 'H776029', 'H945056', 'H948159', 'H872490', 'H477835', 'H974225', 'H947494', 'H945779', 'H947423', 'H478496', 'H945195', 'H777754', 'H943012', 'H949137', 'H771956', 'H941723', 'H943753', 'H778636', 'H973065', 'H943897', 'H11681811', 'H945094', 'H949139', 'H473477', 'H472113', 'H943473', 'H448399', 'H545716', 'H943863', 'H774016', 'H479294', 'H479646', 'H946337', 'H876191', 'H775628', 'H947346', 'H770953', 'H548894', 'H778402', 'H879557', 'H946945', 'H875715', 'H11547837', 'H943738', 'H479685', 'H946187', 'H770271', 'H947324', 'H872968', 'H941871', 'H973363', 'H873821', 'H877203', 'H479731', 'H472671', 'H973194', 'H977670', 'H11558032', 'H776239', 'H879771', 'H972521', 'H772569', 'H772718', 'H946334', 'H779838', 'H879448', 'H872768', 'H872341', 'H774944', 'H872745', 'H872036', 'H946872', 'H946637', 'H774788', 'H448389', 'H877140', 'H771291', 'H774339', 'H872734', 'H877091', 'H772131', 'H877093', 'H777022', 'H973582', 'H946835', 'H476441', 'H476827', 'H878110', 'H876948', 'H946786', 'H771599', 'H773789', 'H774384', 'H875467', 'H774416', 'H771366', 'H773543', 'H479151', 'H973407', 'H874881', 'H477930', 'H974157', 'H774752', 'H779692', 'H875000', 'H976520', 'H470188', 'H906303', 'H906292', 'H11548254', 'H706213', 'H906161', 'H706249', 'H708810', 'H706665', 'H970399', 'H706842', 'H706136', 'H706294', 'H976578', 'H706417', 'H906103', 'H906378', 'H706207', 'H706540', 'H706390', 'H706393', 'H706566', 'H706415', 'H706713', 'H706866', 'H706231', 'H906301', 'H906758', 'H706432', 'H906229', 'H906747', 'H706197', 'H11681888', 'H706228', 'H706352', 'H706183', 'H709301', 'H11681892', 'H709611', 'H706285', 'H906671', 'H709481', 'H706481', 'H775193', 'H709181', 'H709177', 'H776883', 'H709421', 'H709166', 'H706122', 'H709483', 'H706321', 'H709241', 'H709512', 'H877856', 'H706289', 'H709168', 'H709211', 'H709518', 'H906166', 'H709484', 'H706482', 'H906240', 'H709204', 'H706194', 'H706433', 'H709296', 'H706278', 'H709234', 'H706348', 'H706120', 'H709171', 'H909437', 'H806108', 'H706522', 'H706726', 'H906130', 'H906140', 'H709829', 'H708804', 'H906158', 'H709316', 'H706476', 'H706443', 'H709435', 'H706642', 'H709184', 'H708014', 'H709480', 'H706590', 'H706587', 'H909212', 'H709125', 'H706201', 'H709456', 'H706379', 'H706740', 'H909443', 'H706318', 'H709190', 'H706212', 'H709881', 'H906808', 'H709295', 'H708800', 'H908806', 'H706405', 'H709341', 'H709120', 'H706250', 'H706851', 'H706794', 'H708817', 'H706573', 'H906172', 'H706102', 'H906633', 'H706406', 'H709658', 'H706480', 'H706351', 'H906844', 'H709391', 'H709160', 'H706143', 'H709342', 'H706409', 'H706465', 'H709195', 'H709108', 'H709571', 'H706419', 'H706891', 'H709281', 'H906519', 'H706402', 'H706392', 'H706690', 'H706486', 'H706448', 'H706164', 'H706890', 'H909349', 'H706752', 'H706883', 'H906261', 'H706020', 'H706612', 'H706182', 'H709197', 'H709385', 'H706702', 'H706291', 'H706428', 'H706467', 'H709249', 'H706551', 'H906441', 'H706261', 'H706295', 'H906319', 'H906468', 'H706337', 'H706271', 'H806515', 'H706537', 'H706632', 'H706911', 'H706741', 'H706812', 'H706581', 'H706594', 'H706639', 'H706634', 'H706450', 'H706329', 'H906327', 'H706268', 'H706899', 'H706189', 'H708700', 'H706407', 'H706886', 'H706418', 'H909206', 'H706472', 'H906169', 'H907500', 'H706288', 'H706498', 'H906247', 'H706061', 'H909180', 'H706361', 'H706644', 'H706550', 'H706416', 'H906181', 'H706731', 'H707060', 'H706846', 'H706704', 'H909464', 'H907553', 'H706580', 'H706728', 'H706129', 'H706827', 'H706223', 'H906280', 'H709238', 'H706403', 'H709361', 'H706395', 'H906435', 'H709320', 'H909323', 'H706918', 'H806050', 'H709415', 'H706344', 'H706499', 'H706715', 'H909265', 'H806030', 'H709321', 'H709304', 'H706748', 'H708823', 'H706394', 'H776824', 'H909247', 'H709157', 'H706269', 'H706816', 'H708733', 'H706743', 'H706469', 'H706188', 'H706755', 'H706325', 'H706265', 'H706651', 'H706758', 'H706286', 'H709416', 'H706105', 'H708042', 'H706092', 'H706681', 'H706111', 'H706679', 'H706154', 'H706479', 'H706484', 'H706487', 'H706101', 'H706998', 'H706938', 'H706263', 'H706473', 'H706977', 'H906373', 'H706323', 'H706248', 'H708842', 'H708711', 'H907551', 'H706374', 'H709273', 'H906827', 'H709657', 'H906177', 'H709221', 'H906422', 'H907162', 'H706927', 'H706760', 'H706253', 'H709521', 'H906297', 'H709538', 'H706421', 'H707219', 'H707408', 'H709276', 'H706674', 'H708808', 'H706152', 'H707373', 'H706820', 'H706350', 'H706501', 'H707378', 'H706369', 'H906389', 'H706186', 'H707282', 'H709949', 'H706708', 'H709497', 'H707380', 'H706246', 'H706338', 'H706709', 'H707377', 'H907270', 'H706762', 'H809240', 'H709673', 'H707382', 'H708011', 'H706493', 'H706399', 'H909488', 'H709546', 'H706751', 'H709145', 'H709486', 'H709446', 'H706830', 'H907376', 'H909259', 'H709193', 'H709014', 'H709243', 'H709001', 'H706828', 'H709372', 'H706749', 'H709173', 'H706192', 'H707484', 'H706722', 'H707220', 'H709309', 'H706397', 'H707381', 'H706696', 'H709185', 'H709351', 'H709151', 'H707325', 'H709136', 'H706306', 'H709401', 'H709042', 'H709418', 'H706398', 'H707274', 'H709143', 'H907429', 'H709882', 'H709154', 'H709989', 'H906459', 'H709340', 'H707956', 'H909136', 'H709051', 'H909675', 'H709399', 'H807573', 'H709860', 'H809818', 'H707375', 'H708866', 'H909083', 'H709096', 'H709559', 'H907496', 'H707206', 'H709280', 'H707496', 'H709116', 'H709012', 'H907316', 'H707409', 'H707312', 'H709387', 'H709915', 'H709285', 'H707350', 'H709445', 'H709608', 'H707279', 'H709692', 'H909293', 'H709388', 'H709147', 'H707349', 'H709182', 'H709878', 'H709382', 'H707286', 'H707275', 'H707320', 'H709196', 'H709471', 'H709408', 'H709409', 'H709144', 'H709472', 'H709643', 'H707452', 'H709492', 'H709359', 'H707430', 'H709346', 'H709709', 'H709470', 'H907024', 'H709912', 'H707348', 'H707280', 'H707323', 'H707433', 'H709530', 'H909671', 'H707236', 'H707267', 'H909139', 'H709381', 'H709811', 'H709395', 'H707346', 'H707177', 'H709655', 'H907171', 'H707234', 'H709815', 'H709070', 'H909961', 'H707402', 'H707264', 'H707339', 'H707244', 'H907453', 'H709010', 'H709419', 'H707337', 'H707213', 'H909261', 'H707247', 'H709561', 'H909216', 'H709501', 'H707398', 'H909993', 'H907522', 'H707237', 'H707243', 'H707207', 'H709299', 'H707494', 'H709367', 'H707265', 'H709347', 'H707142', 'H707973', 'H707933', 'H709333', 'H709498', 'H709572', 'H909291', 'H709693', 'H707424', 'H707257', 'H909138', 'H709378', 'H707511', 'H709511', 'H709887', 'H709493', 'H707260', 'H707170', 'H709105', 'H709163', 'H707399', 'H709308', 'H907261', 'H709260', 'H709659', 'H709269', 'H709618', 'H707544', 'H709095', 'H709663', 'H709312', 'H709685', 'H909314', 'H709389', 'H907524', 'H709283', 'H709584', 'H809522', 'H709365', 'H709462', 'H909318', 'H709477', 'H707545', 'H709358', 'H709984', 'H709278', 'H908208', 'H708306', 'H709941', 'H909167', 'H909149', 'H909218', 'H909119', 'H908142', 'H707548', 'H709111', 'H907383', 'H708300', 'H909324', 'H708124', 'H707396', 'H708210', 'H707391', 'H708197', 'H907166', 'H909159', 'H709816', 'H770091', 'H708105', 'H707127', 'H707299', 'H707310', 'H707357', 'H707354', 'H907599', 'H707451', 'H707168', 'H707209', 'H707138', 'H707326', 'H807013', 'H707358', 'H907364', 'H707372', 'H707210', 'H707434', 'H707335', 'H807130', 'H707370', 'H707174', 'H907211', 'H707196', 'H707369', 'H707158', 'H907169', 'H707441', 'H707610', 'H707136', 'H907122', 'H807572', 'H707116', 'H707609', 'H707214', 'H907190', 'H708176', 'H809879', 'H908120', 'H708263', 'H908260', 'H708236', 'H708529', 'H908136', 'H708193', 'H908496', 'H908502', 'H708248', 'H708189', 'H808249', 'H708217', 'H708305', 'H908230', 'H908161', 'H708227', 'H908237', 'H908240', 'H708264', 'H908239', 'H908158', 'H708159', 'H708195', 'H808519', 'H808516', 'H908132', 'H708301', 'H908148', 'H908155', 'H908111', 'H908164', 'H908498', 'H708130', 'H908201', 'H708154', 'H708202', 'H708206', 'H708258', 'H908138']\n",
      "站点筛选完成。\n",
      "\n",
      "--- 正在根据筛选结果过滤数据集 ---\n",
      "数据集过滤完成。\n",
      "  - 过滤后GNSS数据站点数: 1215\n",
      "  - 过滤后风场数据站点数: 1\n",
      "\n",
      "--- 开始调用数据准备函数 ---\n",
      "Pass 1: 正在扫描有效的连续序列 (稳健模式)...\n",
      "GNSS 时间 dtype: datetime64[ns], Wind 时间 dtype: datetime64[ns]\n",
      "Pass 1 完成. 共找到 17594 个有效样本。耗时: 21.00 秒。\n",
      "正在预分配内存...\n",
      "Pass 2: 正在填充数据...\n",
      "Pass 2 完成. 数据填充完毕。耗时: 12.81 秒。\n",
      "正在创建最终的 xarray.DataArray...\n",
      "所有处理完成！总耗时: 33.82 秒。\n",
      "\n",
      "--- 处理后结果 ---\n",
      "输入变量 vx:\n",
      "  - 形状: (17594, 6, 1215)\n",
      "  - 维度: ('sample', 'timesteps', 'station')\n",
      "  - 站点: ['H992830' 'H998276' 'H11705423' ... 'H708206' 'H708258' 'H908138']\n",
      "  - 内存占用: 513.04 MB\n",
      "\n",
      "目标变量 vy:\n",
      "  - 形状: (17594, 7)\n",
      "  - 维度: ('sample', 'station_press_flat')\n",
      "  - 站点: [58557]\n",
      "  - 内存占用: 0.49 MB\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    使用Haversine公式计算两个经纬度点之间的距离（单位：公里）。\n",
    "    \"\"\"\n",
    "    # 将十进制度数转化为弧度\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine公式\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371 # 地球平均半径，单位为公里\n",
    "    return c * r\n",
    "\n",
    "def prepare_transformer_inputs_mem_efficient_robust(gnss_ds: xr.Dataset, wind_ds: xr.Dataset):\n",
    "    \"\"\"\n",
    "    更稳健的版本，处理时间戳 dtype 不匹配的问题。\n",
    "    (此函数无需任何修改)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gnss_ztd = gnss_ds['ztd']\n",
    "    wind_u = wind_ds['U']\n",
    "    \n",
    "    sequence_length = 6\n",
    "    time_step = pd.to_timedelta('5min')\n",
    "    expected_duration = time_step * (sequence_length - 1)\n",
    "\n",
    "    num_gnss_times = len(gnss_ztd.time)\n",
    "    \n",
    "    # --- Pass 1: 扫描并找到所有有效样本的起始索引 ---\n",
    "    print(\"Pass 1: 正在扫描有效的连续序列 (稳健模式)...\")\n",
    "    \n",
    "    gnss_dtype = gnss_ztd.time.dtype\n",
    "    wind_dtype = wind_u.Datetime.dtype\n",
    "    print(f\"GNSS 时间 dtype: {gnss_dtype}, Wind 时间 dtype: {wind_dtype}\")\n",
    "    wind_dtype_unit = np.datetime_data(wind_dtype)[0]\n",
    "\n",
    "    valid_start_indices = []\n",
    "    wind_times_set = set(wind_u.Datetime.values)\n",
    "\n",
    "    for i in range(num_gnss_times - sequence_length + 1):\n",
    "        window_times = gnss_ztd.time[i : i + sequence_length]\n",
    "        \n",
    "        actual_duration = window_times[-1].values - window_times[0].values\n",
    "        if np.abs(actual_duration - expected_duration) < pd.to_timedelta('1s'):\n",
    "            \n",
    "            target_wind_time_raw = window_times[-1].values + 6*time_step\n",
    "            target_wind_time_converted = np.datetime64(target_wind_time_raw, wind_dtype_unit)\n",
    "\n",
    "            if target_wind_time_converted in wind_times_set:\n",
    "                valid_start_indices.append(i)\n",
    "    \n",
    "    num_samples = len(valid_start_indices)\n",
    "    print(f\"Pass 1 完成. 共找到 {num_samples} 个有效样本。耗时: {time.time() - start_time:.2f} 秒。\")\n",
    "\n",
    "    if num_samples == 0:\n",
    "        print(\"在稳健模式下仍然未找到任何有效序列。请检查数据本身，例如风场数据是否覆盖了GNSS数据的时间范围。\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 内存分配 (Pass 2) ---\n",
    "    print(\"正在预分配内存...\")\n",
    "    num_stations_gnss = len(gnss_ztd.station)\n",
    "    num_stations_wind = len(wind_u.station)\n",
    "    num_press_levels = len(wind_u.PRESS)\n",
    "    \n",
    "    vx_data = np.empty((num_samples, sequence_length, num_stations_gnss), dtype=np.float32)\n",
    "    vy_data = np.empty((num_samples, num_stations_wind * num_press_levels), dtype=np.float32)\n",
    "\n",
    "    print(\"Pass 2: 正在填充数据...\")\n",
    "    fill_start_time = time.time()\n",
    "    gnss_ztd_values = gnss_ztd.values\n",
    "    \n",
    "    for k, start_idx in enumerate(valid_start_indices):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        vx_data[k, :, :] = gnss_ztd_values[start_idx:end_idx, :]\n",
    "        \n",
    "        last_gnss_time = gnss_ztd.time[end_idx - 1]\n",
    "        target_wind_time = last_gnss_time.values + 6*time_step\n",
    "        \n",
    "        target_wind_time_converted = np.datetime64(target_wind_time, wind_dtype_unit)\n",
    "        vy_slice_values = wind_u.sel(Datetime=target_wind_time_converted).values\n",
    "        vy_data[k, :] = vy_slice_values.flatten()\n",
    "        \n",
    "    print(f\"Pass 2 完成. 数据填充完毕。耗时: {time.time() - fill_start_time:.2f} 秒。\")\n",
    "\n",
    "    print(\"正在创建最终的 xarray.DataArray...\")\n",
    "    sample_coords = gnss_ztd.time.values[valid_start_indices]\n",
    "    vx = xr.DataArray(\n",
    "        vx_data,\n",
    "        dims=('sample', 'timesteps', 'station'),\n",
    "        coords={'sample': sample_coords, 'timesteps': np.arange(sequence_length), 'station': gnss_ztd.station.values}\n",
    "    )\n",
    "\n",
    "    vy_flat_coords = wind_u.stack(station_press_flat=('station', 'PRESS')).coords['station_press_flat']\n",
    "    vy = xr.DataArray(\n",
    "        vy_data,\n",
    "        dims=('sample', 'station_press_flat'),\n",
    "        coords={'sample': sample_coords, 'station_press_flat': vy_flat_coords}\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"所有处理完成！总耗时: {total_time:.2f} 秒。\")\n",
    "    return vx, vy\n",
    "\n",
    "# --- 主程序 ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. 定义文件路径和目标站点信息\n",
    "    gnss_nc_path = r'E:/gnss_ztd_combined_robust_morestation.nc'\n",
    "    wind_nc_path = r'E:/merged_stations_6min_common_period_float32_no_nan_press.nc'\n",
    "    gnss_info_path = r'E:\\huawei_gnss_morestation\\zj_allid.csv'\n",
    "    \n",
    "    target_wind_station_id = 58557 \n",
    "    target_wind_station_lon = 120.0717\n",
    "    target_wind_station_lat = 29.3619\n",
    "    \n",
    "    num_nearest_stations = 1215 \n",
    "\n",
    "    # 2. 加载原始数据文件\n",
    "    print(\"正在加载原始数据文件...\")\n",
    "    gnss_file = xr.open_dataset(gnss_nc_path)\n",
    "    wind_file = xr.open_dataset(wind_nc_path)\n",
    "    gnss_info_df = pd.read_csv(gnss_info_path)\n",
    "    print(\"文件加载完毕。\")\n",
    "\n",
    "    # 3. 对原始数据进行预处理（插值、填充等）\n",
    "    print(\"正在对原始数据进行预处理...\")\n",
    "    wind_new_time = pd.date_range(wind_file.Datetime.values[0], wind_file.Datetime.values[-1], freq='5min')\n",
    "    wind_file = wind_file.interp(Datetime=wind_new_time)\n",
    "    gnss_file = gnss_file.interpolate_na(dim='time')\n",
    "    gnss_file = gnss_file.ffill(dim='time').bfill(dim='time')\n",
    "    print(\"预处理完成。\")\n",
    "\n",
    "    # 4. MODIFIED LOGIC: 寻找实际存在于数据中的最近10个GNSS站点\n",
    "    print(\"\\n--- 开始筛选站点 (新逻辑) ---\")\n",
    "    print(f\"目标风场站点: {target_wind_station_id}\")\n",
    "    print(f\"使用预设的目标站点经纬度: Lon={target_wind_station_lon}, Lat={target_wind_station_lat}\")\n",
    "\n",
    "    # 步骤 4.1: 获取gnss数据文件中实际存在的所有站点ID\n",
    "    available_gnss_in_nc = gnss_file.station.values\n",
    "    print(f\"在GNSS数据文件中找到 {len(available_gnss_in_nc)} 个可用站点。\")\n",
    "\n",
    "    # 步骤 4.2: 从CSV站点信息中，只保留那些实际存在于gnss数据文件中的站点\n",
    "    gnss_info_df['id'] = gnss_info_df['id'].astype(str)\n",
    "    # 使用.copy()避免SettingWithCopyWarning\n",
    "    valid_stations_info_df = gnss_info_df[gnss_info_df['id'].isin(available_gnss_in_nc)].copy()\n",
    "    if valid_stations_info_df.empty:\n",
    "        raise ValueError(\"CSV站点信息文件和GNSS数据文件之间没有共同的站点。\")\n",
    "    print(f\"在CSV和GNSS数据文件中共有 {len(valid_stations_info_df)} 个共同站点。\")\n",
    "\n",
    "\n",
    "    # 步骤 4.3: 在这个有效站点子集上计算到目标的距离\n",
    "    valid_stations_info_df['distance_km'] = valid_stations_info_df.apply(\n",
    "        lambda row: haversine(target_wind_station_lon, target_wind_station_lat, row['lon'], row['lat']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 步骤 4.4: 按距离排序并选出最近的N个\n",
    "    # 检查可用站点是否少于期望数量\n",
    "    if len(valid_stations_info_df) < num_nearest_stations:\n",
    "        print(f\"警告: 可用站点总数 ({len(valid_stations_info_df)}) 小于期望的数量 ({num_nearest_stations})。将使用所有可用的站点。\")\n",
    "        num_to_select = len(valid_stations_info_df)\n",
    "    else:\n",
    "        num_to_select = num_nearest_stations\n",
    "\n",
    "    nearest_stations_df = valid_stations_info_df.sort_values(by='distance_km').head(num_to_select)\n",
    "    final_gnss_selection = nearest_stations_df['id'].tolist()\n",
    "    \n",
    "    print(f\"找到的最近 {len(final_gnss_selection)} 个GNSS站点: {final_gnss_selection}\")\n",
    "    print(\"站点筛选完成。\")\n",
    "\n",
    "\n",
    "    # 5. 根据筛选出的站点ID来过滤xarray数据集\n",
    "    print(\"\\n--- 正在根据筛选结果过滤数据集 ---\")\n",
    "    \n",
    "    # 确保目标站点存在于wind_file中\n",
    "    if target_wind_station_id not in wind_file.station.values:\n",
    "        raise ValueError(f\"目标站点 {target_wind_station_id} 在风场数据中未找到!\")\n",
    "\n",
    "    gnss_file_filtered = gnss_file.sel(station=final_gnss_selection)\n",
    "    wind_file_filtered = wind_file.sel(station=[target_wind_station_id])\n",
    "\n",
    "    print(\"数据集过滤完成。\")\n",
    "    print(f\"  - 过滤后GNSS数据站点数: {len(gnss_file_filtered.station)}\")\n",
    "    print(f\"  - 过滤后风场数据站点数: {len(wind_file_filtered.station)}\")\n",
    "\n",
    "    # 6. 调用核心处理函数\n",
    "    print(\"\\n--- 开始调用数据准备函数 ---\")\n",
    "    vx, vy = prepare_transformer_inputs_mem_efficient_robust(gnss_file_filtered, wind_file_filtered)\n",
    "\n",
    "    # 7. 打印最终结果\n",
    "    if vx is not None and vy is not None:\n",
    "        print(\"\\n--- 处理后结果 ---\")\n",
    "        print(\"输入变量 vx:\")\n",
    "        print(f\"  - 形状: {vx.shape}\")\n",
    "        print(f\"  - 维度: {vx.dims}\")\n",
    "        print(f\"  - 站点: {vx.station.values}\")\n",
    "        print(f\"  - 内存占用: {vx.nbytes / 1e6:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n目标变量 vy:\")\n",
    "        print(f\"  - 形状: {vy.shape}\")\n",
    "        print(f\"  - 维度: {vy.dims}\")\n",
    "        vy_station = vy.station_press_flat.to_index().get_level_values('station').unique().to_list()\n",
    "        print(f\"  - 站点: {vy_station}\")\n",
    "        print(f\"  - 内存占用: {vy.nbytes / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28420690-6159-40b4-97b6-977a409e4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer网络\n",
    "def Auto_Transformer(vy,vx,timestep,model_list,test_size=0.2,valid_size=0.1,k_fold=None,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=2,key_dim=2,ifdropout='no',trans_dropout_rate=0.0,trans_units=64,trans_activation='sigmoid',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='SGD',metrics='default',if_early_stopping=None,learning_rate=0.01,epochs=2000,batch_size=20,ifrandom_split='yes',ifweight='yes',ifmute='no',ifsave='no',savepath=None,device='cpu'):\n",
    "    import tensorflow as tf\n",
    "    if device=='gpu':\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                # 设置只使用 GPU 0\n",
    "                tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "                # 设置 GPU 0 的内存动态增长\n",
    "                tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    from keras.models import Sequential,Model\n",
    "    from keras.layers.core import Activation,Dropout,Dense\n",
    "    from keras.layers import Input,BatchNormalization,LayerNormalization,Embedding,Add,MultiHeadAttention,Flatten\n",
    "    from keras.initializers import TruncatedNormal,RandomNormal,RandomUniform\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import KFold\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.optimizers import SGD,Adam\n",
    "    import keras\n",
    "    from scipy.stats import pearsonr\n",
    "    import os\n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "    from keras.models import load_model\n",
    "    import sklearn\n",
    "    import copy\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from tensorflow.keras import backend as K\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    if embedding_num==None:\n",
    "        embedding_num=timestep+1\n",
    "    if task_mode=='regression':\n",
    "        if loss_function=='default' or loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanAbsoluteError':\n",
    "            loss=tf.keras.losses.MeanAbsoluteError()\n",
    "        elif loss_function=='MeanAbsolutePercentageError':\n",
    "            loss=tf.keras.losses.MeanAbsolutePercentageError()\n",
    "        elif loss_function=='MeanSquaredLogarithmicError':\n",
    "            loss=tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "        elif loss_function=='CosineSimilarity':\n",
    "            loss=tf.keras.losses.CosineSimilarity()\n",
    "        elif loss_function=='Huber':\n",
    "            loss=tf.keras.losses.Huber()\n",
    "        elif loss_function=='LogCosh':\n",
    "            loss=tf.keras.losses.LogCosh()\n",
    "        elif loss_function=='Pearsonr':\n",
    "            def loss_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            loss=loss_pearsonr\n",
    "        if metrics=='default' or metrics=='MeanSquaredError':\n",
    "            metric=tf.keras.metrics.MeanSquaredError()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='MeanAbsolutePercentageError':\n",
    "            metric=tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "        elif metrics=='MeanSquaredLogarithmicError':\n",
    "            metric=tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        elif metrics=='CosineSimilarity':\n",
    "            metric=tf.keras.metrics.CosineSimilarity()\n",
    "        elif metrics=='LogCoshError':\n",
    "            metric=tf.keras.metrics.LogCoshError()\n",
    "        elif metrics=='Pearsonr':\n",
    "            def metrics_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            metric=metrics_pearsonr\n",
    "    elif task_mode=='binary_classify':\n",
    "        if loss_function=='default' or loss_function=='BinaryCrossentropy':\n",
    "            loss=tf.keras.losses.BinaryCrossentropy()\n",
    "        elif loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        elif loss_function=='f1':\n",
    "            def loss_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return 1 - f1\n",
    "            loss=loss_f1\n",
    "        if metrics=='default' or metrics=='BinaryAccuracy':\n",
    "            metric=tf.keras.metrics.BinaryAccuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='BinaryCrossentropy':\n",
    "            metric=tf.keras.metrics.BinaryCrossentropy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "        elif metrics=='AUC':\n",
    "            metric=tf.keras.metrics.AUC()\n",
    "        elif metrics=='Precision':\n",
    "            metric=tf.keras.metrics.Precision()\n",
    "        elif metrics=='Recall':\n",
    "            metric=tf.keras.metrics.Recall()\n",
    "        elif metrics=='TruePositives':\n",
    "            metric=tf.keras.metrics.TruePositives()\n",
    "        elif metrics=='TrueNegatives':\n",
    "            metric=tf.keras.metrics.TrueNegatives()\n",
    "        elif metrics=='FalsePositives':\n",
    "            metric=tf.keras.metrics.FalsePositives()\n",
    "        elif metrics=='FalseNegatives':\n",
    "            metric=tf.keras.metrics.FalseNegatives()\n",
    "        elif metrics=='PrecisionAtRecall':\n",
    "            metric=tf.keras.metrics.PrecisionAtRecall()\n",
    "        elif metrics=='SensitivityAtSpecificity':\n",
    "            metric=tf.keras.metrics.SensitivityAtSpecificity()\n",
    "        elif metrics=='SpecificityAtSensitivity':\n",
    "            metric=tf.keras.metrics.SpecificityAtSensitivity()\n",
    "        elif metrics=='f1':\n",
    "            def metric_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return f1\n",
    "            metric=metric_f1\n",
    "    elif task_mode=='multi_classify':\n",
    "        if loss_function=='default' or loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        if metrics=='default' or metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "    weights=0\n",
    "    model=0\n",
    "    if vy.ndim==1:\n",
    "        vy=vy.reshape(vy.shape[0],1)\n",
    "    if ifrandom_split=='yes':\n",
    "        trainy,testy,trainx,testx = train_test_split(vy,vx,test_size=test_size,random_state=25)\n",
    "    else:\n",
    "        index=int((1-test_size)*vy.shape[0])\n",
    "        trainy=vy[:index]\n",
    "        testy=vy[index:]\n",
    "        trainx=vx[:index,:,:]\n",
    "        testx=vx[index:,:,:]\n",
    "    train_position=np.zeros((trainx.shape[0],trainx.shape[1]))\n",
    "    test_position=np.zeros((testx.shape[0],testx.shape[1]))\n",
    "    for i in range(trainx.shape[0]):\n",
    "        train_position[i,:]=np.arange(0,timestep,1)\n",
    "    for i in range(testx.shape[0]):\n",
    "        test_position[i,:]=np.arange(0,timestep,1)\n",
    "    if task_mode!='regression':\n",
    "        def create_sample_weights_for_batch_multitask(y_batch_multitask, list_of_task_weights_dicts):\n",
    "            batch_size, num_tasks = y_batch_multitask.shape\n",
    "            \n",
    "            if len(list_of_task_weights_dicts) != num_tasks:\n",
    "                raise ValueError(f\"Number of tasks in y_batch_multitask ({num_tasks}) \"\n",
    "                                 f\"must match length of list_of_task_weights_dicts ({len(list_of_task_weights_dicts)}).\")\n",
    "        \n",
    "            sample_weight_batch = np.ones_like(y_batch_multitask, dtype=np.float32)\n",
    "        \n",
    "            for i in range(num_tasks):\n",
    "                task_labels_current_channel = y_batch_multitask[:, i] \n",
    "                weights_dict_for_task_i = list_of_task_weights_dicts[i]\n",
    "                \n",
    "                weight_for_0 = weights_dict_for_task_i.get(0, 1.0)\n",
    "                weight_for_1 = weights_dict_for_task_i.get(1, 1.0)\n",
    "                \n",
    "                current_task_weights = sample_weight_batch[:, i] \n",
    "                current_task_weights[task_labels_current_channel == 0] = weight_for_0\n",
    "                current_task_weights[task_labels_current_channel == 1] = weight_for_1\n",
    "                sample_weight_batch[:, i] = current_task_weights\n",
    "                \n",
    "            return sample_weight_batch\n",
    "        def compute_unified_class_weights(y, task_mode=task_mode):\n",
    "            if task_mode == 'binary_classify':\n",
    "                if y.ndim == 2 and y.shape[-1] > 1:\n",
    "                    num_tasks = y.shape[-1]\n",
    "                    list_of_task_weights_dicts = []\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    for i in range(num_tasks):\n",
    "                        y_task_i_flat = y[:, i].ravel()\n",
    "                        if len(y_task_i_flat) == 0:\n",
    "                            weights_dict_task_i = {0: 1.0, 1: 1.0} \n",
    "                        else:\n",
    "                            valid_labels_mask = np.isin(y_task_i_flat, possible_binary_classes)\n",
    "                            if not np.all(valid_labels_mask) and np.any(valid_labels_mask): \n",
    "                                y_task_i_flat_filtered = y_task_i_flat[valid_labels_mask]\n",
    "                                if len(y_task_i_flat_filtered) == 0 : y_task_i_flat_filtered = np.array([0]) \n",
    "                            elif not np.any(valid_labels_mask): \n",
    "                                 y_task_i_flat_filtered = np.array([0]) \n",
    "                            else:\n",
    "                                y_task_i_flat_filtered = y_task_i_flat\n",
    "                            class_weights_arr = compute_class_weight(\n",
    "                                class_weight='balanced',\n",
    "                                classes=possible_binary_classes, \n",
    "                                y=y_task_i_flat_filtered\n",
    "                            )\n",
    "                            weights_dict_task_i = dict(zip(possible_binary_classes, class_weights_arr))\n",
    "                        list_of_task_weights_dicts.append(weights_dict_task_i)\n",
    "                    return list_of_task_weights_dicts \n",
    "        \n",
    "                else: \n",
    "                    y_flat = y.ravel()\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    valid_labels_mask = np.isin(y_flat, possible_binary_classes)\n",
    "                    if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                        y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                        if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0])\n",
    "                    elif not np.any(valid_labels_mask):\n",
    "                         y_flat_filtered = np.array([0])\n",
    "                    else:\n",
    "                        y_flat_filtered = y_flat\n",
    "        \n",
    "                    class_weights_arr = compute_class_weight(\n",
    "                        class_weight='balanced',\n",
    "                        classes=possible_binary_classes,\n",
    "                        y=y_flat_filtered\n",
    "                    )\n",
    "                    return dict(zip(possible_binary_classes, class_weights_arr)) \n",
    "        \n",
    "            elif task_mode == 'multi_classify':\n",
    "                y_flat = y.ravel()\n",
    "                possible_multiclass_classes = np.arange(int(np.max(y)+1))\n",
    "                valid_labels_mask = np.isin(y_flat, possible_multiclass_classes)\n",
    "                if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                    if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0]) \n",
    "                elif not np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = np.array([0]) \n",
    "                else:\n",
    "                    y_flat_filtered = y_flat\n",
    "                class_weights_arr = compute_class_weight(\n",
    "                    class_weight='balanced',\n",
    "                    classes=possible_multiclass_classes,\n",
    "                    y=y_flat_filtered\n",
    "                )\n",
    "                return dict(zip(possible_multiclass_classes, class_weights_arr)) \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported task_mode: {task_mode}\")\n",
    "        def create_unified_sample_weights_for_batch(y_batch, unified_class_weights):\n",
    "            if isinstance(unified_class_weights, list):\n",
    "                if not (y_batch.ndim == 2 and y_batch.shape[-1] == len(unified_class_weights)):\n",
    "                     raise ValueError(f\"Shape mismatch for multi-task binary weights. \"\n",
    "                                      f\"y_batch shape: {y_batch.shape}, num_weight_dicts: {len(unified_class_weights)}\")\n",
    "                return create_sample_weights_for_batch_multitask(y_batch, unified_class_weights)\n",
    "            elif isinstance(unified_class_weights, dict):\n",
    "                y_int_labels_for_weights = y_batch\n",
    "                if y_batch.ndim == 2 and y_batch.shape[-1] == 1: \n",
    "                    y_int_labels_for_weights = np.squeeze(y_batch, axis=-1)\n",
    "                sample_weight_for_batch = np.ones_like(y_int_labels_for_weights, dtype=np.float32)\n",
    "                for class_label, weight in unified_class_weights.items():\n",
    "                    sample_weight_for_batch[y_int_labels_for_weights == class_label] = weight\n",
    "                \n",
    "                return sample_weight_for_batch\n",
    "            else:\n",
    "                raise TypeError(f\"unified_class_weights has unexpected type: {type(unified_class_weights)}. Expected dict or list.\")\n",
    "        def train_data_generator(x,position, y, batch_size, task_mode=task_mode):\n",
    "            num_samples = x.shape[0]\n",
    "            global_unified_weights = compute_unified_class_weights(y, task_mode)\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    if len(batch_indices) == 0:\n",
    "                        continue\n",
    "        \n",
    "                    x_batch = x[batch_indices]\n",
    "                    position_batch = position[batch_indices]\n",
    "                    y_batch = y[batch_indices] \n",
    "                    sample_weight_batch = create_unified_sample_weights_for_batch(\n",
    "                        y_batch, \n",
    "                        global_unified_weights\n",
    "                    )\n",
    "                    yield {\"input_1\": x_batch, \"input_2\": position_batch}, y_batch, sample_weight_batch\n",
    "    else:\n",
    "        def train_data_generator(x, position, y, batch_size):\n",
    "            num_samples = x.shape[0]\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    x_batch = x[batch_indices]  \n",
    "                    position_batch = position[batch_indices]   \n",
    "                    y_batch = y[batch_indices]      \n",
    "                    \n",
    "                    yield ({\"input_1\": x_batch, \"input_2\": position_batch}, y_batch)\n",
    "    def test_data_generator(x, position, batch_size):\n",
    "        num_samples = x.shape[0]\n",
    "        while True:\n",
    "            indices = np.arange(num_samples)\n",
    "            \n",
    "            for start in range(0, num_samples, batch_size):\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                x_batch = x[batch_indices]  # 第一个输入特征\n",
    "                position_batch = position[batch_indices]\n",
    "                \n",
    "                yield ({\"input_1\": x_batch, \"input_2\": position_batch})\n",
    "    if if_best_mode=='no':\n",
    "        inputshape1=(None,timestep,trainx.shape[2])\n",
    "        inputshape2=(None,timestep)\n",
    "        inputs1=Input(shape=(timestep,trainx.shape[2]))\n",
    "        inputs2=Input(shape=(timestep))\n",
    "        for i in range(len(model_list)):\n",
    "            if model_list[i][0] == 'transformer':\n",
    "                position_embedding=Embedding(embedding_num,trainx.shape[2],input_length=timestep,input_shape=inputshape2)(inputs2)\n",
    "                add=Add(input_shape=inputshape1)([inputs1,position_embedding])\n",
    "                for j in range(encoder_deep):\n",
    "                    if j ==0:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(add,add,add)')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([add,en_multihead'+str(j+1)+'])')\n",
    "                    else:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(en_layernormalization'+str(j)+',en_layernormalization'+str(j)+',en_layernormalization'+str(j)+')')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([en_layernormalization'+str(j)+',en_multihead'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                    if ifdropout=='yes':\n",
    "                        exec('en_dropout'+str(j+1)+'=Dropout(trans_dropout_rate)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_dropout'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    else:\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    exec('en_add'+str(j+1)+'=Add()([en_fc'+str(j+1)+',en_layernormalization'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                exec('en_fla=Flatten()(en_layernormalization'+str(j+1)+')')\n",
    "            elif model_list[i][0] == 'batchnormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'layernormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'activation':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'flatten':\n",
    "                if model_list[i-1][0]=='transformer':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(en_fla)')\n",
    "                elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(norm'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='activation':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(act'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='dropout':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(drop'+str(i)+')')\n",
    "            elif model_list[i][0] =='fc':\n",
    "                if if_weight_initialize=='no':\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            outputs=eval('Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            outputs=eval('Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            outputs=eval('Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            outputs=eval('Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'dropout':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "        if optimizer == 'SGD':\n",
    "            opt = SGD(lr = learning_rate)\n",
    "        elif optimizer == 'Adam':\n",
    "            opt = Adam(lr = learning_rate)\n",
    "        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "    elif if_best_mode=='yes' or if_best_mode=='load':\n",
    "        if k_fold!=None:\n",
    "            models=[]\n",
    "            for i in range(k_fold):\n",
    "                models.append(load_model(modelpath+'_'+str(i+1)))\n",
    "        else:\n",
    "            model=load_model(modelpath)\n",
    "    if if_print_model=='yes':\n",
    "        if k_fold!=None:\n",
    "            if if_best_mode=='yes' or if_best_mode=='load':\n",
    "                print(models[0].summary())\n",
    "            else:\n",
    "                print(model.summary())\n",
    "        else:\n",
    "            print(model.summary())\n",
    "    if epochs!=0:\n",
    "        if valid_size!=None or k_fold !=None:\n",
    "            if k_fold!=None:\n",
    "                if if_best_mode=='no' :\n",
    "                    models = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "                        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models.append(model)\n",
    "                else:\n",
    "                    models_new = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models_new.append(models[fold_no])\n",
    "                    models=models_new\n",
    "            else:\n",
    "                if ifrandom_split=='yes':\n",
    "                    trainy,validy,trainx,validx,train_position,valid_position = train_test_split(trainy,trainx,train_position,test_size=valid_size/(1-test_size),random_state=25)\n",
    "                else:\n",
    "                    index=int((1-valid_size/(1-test_size))*trainy.shape[0])\n",
    "                    validy=trainy[index:]\n",
    "                    trainy=trainy[:index]\n",
    "                    validx=trainx[index:]\n",
    "                    trainx=trainx[:index]\n",
    "                    valid_position=train_position[index:]\n",
    "                    train_position=train_position[:index]\n",
    "                if if_early_stopping!=None:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                else:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "        else:\n",
    "            if if_early_stopping!=None:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "            else:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "    if k_fold!=None:\n",
    "        predicty = [model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0))) for model in models]\n",
    "        predicty=np.nanmean(predicty,axis=0)\n",
    "    else:\n",
    "        predicty = model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)))\n",
    "    predicty = np.nan_to_num(predicty,nan=0)\n",
    "    if task_mode=='regression':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        p=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i],p[i] = pearsonr(predicty[:,i],testy[:,i])\n",
    "            r=np.nan_to_num(r,nan=0)\n",
    "    elif task_mode=='binary_classify':\n",
    "        accuracy=np.zeros((testy.shape[1]))\n",
    "        recall=np.zeros((testy.shape[1]))\n",
    "        precision=np.zeros((testy.shape[1]))\n",
    "        f1=np.zeros((testy.shape[1]))\n",
    "        for i in range(predicty.shape[1]):\n",
    "            predicty[:,i]=[int(round(predicty[j,i],0)) for j in range(predicty.shape[0])]\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            if metrics=='Recall':\n",
    "                r[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            elif metrics=='Precision':\n",
    "                r[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            else:\n",
    "                r[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            recall[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            precision[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            accuracy[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            f1[i]=f1_score(testy[:,i], predicty[:,i])\n",
    "        p=0\n",
    "    elif task_mode=='multi_classify':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i]=accuracy_score(testy[:,i], np.argmax(predicty,axis=1))\n",
    "        p=0\n",
    "    if ifmute == 'no':\n",
    "        if task_mode=='regression':\n",
    "            print('相关系数',np.nanmean(r))\n",
    "        elif task_mode=='binary_classify':\n",
    "            print('召回率+精确率',np.nanmean(f1),'准确率',np.nanmean(accuracy),'召回率',np.nanmean(recall),'精确率',np.nanmean(precision))\n",
    "        elif task_mode=='multi_classify':\n",
    "            print('准确率',np.nanmean(r))\n",
    "    if ifweight=='yes':\n",
    "        weights=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        weight_more=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                testx_new=copy.deepcopy(testx)\n",
    "                weight=[]\n",
    "                for k in range(10):\n",
    "                    per=np.random.permutation(testx.shape[0])\n",
    "                    testx_shuffle=testx[per,:,j]\n",
    "                    testx_new[:,:,j]=testx_shuffle\n",
    "                    if k_fold!=None:\n",
    "                        predicty_new = [model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0))) for model in models]\n",
    "                        predicty_new=np.nanmean(predicty_new,axis=0)\n",
    "                    else:\n",
    "                        predicty_new = model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0)))\n",
    "                    if task_mode=='regression':\n",
    "                        weight.append(sklearn.metrics.mean_squared_error(testy[:,i],predicty_new[:,i])-sklearn.metrics.mean_squared_error(testy[:,i],predicty[:,i]))\n",
    "                    elif task_mode=='multi_classify':\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,:])-sklearn.metrics.log_loss(testy[:,i],predicty[:,:]))\n",
    "                    else:\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,i])-sklearn.metrics.log_loss(testy[:,i],predicty[:,i]))\n",
    "                weight_more[i,j]=np.nanmean(weight)\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                weights[i,j]=(weight_more[i,j]/np.nansum(weight_more[i,:]))*100\n",
    "                print('预报因子',j+1,'对预报值',i+1,'的贡献：',np.array(weights[i,j]),'％')\n",
    "            print('\\n')\n",
    "    if ifsave=='yes':\n",
    "        if k_fold!=None:\n",
    "            for i, model in enumerate(models):\n",
    "                model.save(savepath+'_'+str(i+1))\n",
    "        else:\n",
    "            model.save(savepath)\n",
    "    if k_fold!=None:\n",
    "        return models,predicty,testy,r,p,weights\n",
    "    else:\n",
    "        return model,predicty,testy,r,p,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5694aac2-581f-4745-8d73-80163b988f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0726 - metrics_pearsonr: 3.7440e-05 - val_loss: 0.1049 - val_metrics_pearsonr: 6.4358e-05\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0785 - metrics_pearsonr: 3.7746e-05 - val_loss: 0.1186 - val_metrics_pearsonr: 6.4987e-05\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0815 - metrics_pearsonr: 3.7972e-05 - val_loss: 0.1228 - val_metrics_pearsonr: 6.4882e-05\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0806 - metrics_pearsonr: 3.8074e-05 - val_loss: 0.1146 - val_metrics_pearsonr: 6.4186e-05\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0771 - metrics_pearsonr: 3.8182e-05 - val_loss: 0.1009 - val_metrics_pearsonr: 6.4120e-05\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0744 - metrics_pearsonr: 3.8605e-05 - val_loss: 0.0932 - val_metrics_pearsonr: 6.6069e-05\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0748 - metrics_pearsonr: 3.9454e-05 - val_loss: 0.0965 - val_metrics_pearsonr: 7.0175e-05\n",
      "Epoch 612/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0772 - metrics_pearsonr: 4.0467e-05 - val_loss: 0.1039 - val_metrics_pearsonr: 7.3774e-05\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0785 - metrics_pearsonr: 4.1175e-05 - val_loss: 0.1019 - val_metrics_pearsonr: 7.0304e-05\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0778 - metrics_pearsonr: 4.0552e-05 - val_loss: 0.0974 - val_metrics_pearsonr: 6.3135e-05\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0811 - metrics_pearsonr: 3.9922e-05 - val_loss: 0.1165 - val_metrics_pearsonr: 6.6796e-05\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0885 - metrics_pearsonr: 4.1596e-05 - val_loss: 0.1344 - val_metrics_pearsonr: 7.3094e-05\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0875 - metrics_pearsonr: 4.2928e-05 - val_loss: 0.1052 - val_metrics_pearsonr: 6.4153e-05\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0747 - metrics_pearsonr: 3.9410e-05 - val_loss: 0.0865 - val_metrics_pearsonr: 6.6138e-05\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0693 - metrics_pearsonr: 3.8592e-05 - val_loss: 0.0821 - val_metrics_pearsonr: 6.7337e-05\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0694 - metrics_pearsonr: 3.8234e-05 - val_loss: 0.0861 - val_metrics_pearsonr: 6.2924e-05\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0719 - metrics_pearsonr: 3.7435e-05 - val_loss: 0.1054 - val_metrics_pearsonr: 6.4370e-05\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0746 - metrics_pearsonr: 3.7737e-05 - val_loss: 0.1057 - val_metrics_pearsonr: 6.3130e-05\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0722 - metrics_pearsonr: 3.7190e-05 - val_loss: 0.1011 - val_metrics_pearsonr: 6.7027e-05\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0691 - metrics_pearsonr: 3.7777e-05 - val_loss: 0.0825 - val_metrics_pearsonr: 6.3853e-05\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0643 - metrics_pearsonr: 3.7029e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 6.2607e-05\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0630 - metrics_pearsonr: 3.6810e-05 - val_loss: 0.0820 - val_metrics_pearsonr: 6.2441e-05\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0647 - metrics_pearsonr: 3.6571e-05 - val_loss: 0.0945 - val_metrics_pearsonr: 6.3404e-05\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0652 - metrics_pearsonr: 3.6459e-05 - val_loss: 0.0945 - val_metrics_pearsonr: 6.3342e-05\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0632 - metrics_pearsonr: 3.6293e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 6.2702e-05\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0594 - metrics_pearsonr: 3.6196e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.2336e-05\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0570 - metrics_pearsonr: 3.6060e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 6.2436e-05\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0576 - metrics_pearsonr: 3.5908e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 6.2931e-05\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0584 - metrics_pearsonr: 3.5823e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 6.2319e-05\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0573 - metrics_pearsonr: 3.5702e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 6.2013e-05\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0552 - metrics_pearsonr: 3.5687e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.1991e-05\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0540 - metrics_pearsonr: 3.5646e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.2268e-05\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0541 - metrics_pearsonr: 3.5612e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 6.2119e-05\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0544 - metrics_pearsonr: 3.5506e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 6.2026e-05\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0538 - metrics_pearsonr: 3.5470e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 6.1944e-05\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0525 - metrics_pearsonr: 3.5419e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2024e-05\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0516 - metrics_pearsonr: 3.5347e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2028e-05\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0516 - metrics_pearsonr: 3.5274e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 6.1862e-05\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0519 - metrics_pearsonr: 3.5220e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 6.1824e-05\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0518 - metrics_pearsonr: 3.5212e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 6.1849e-05\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0514 - metrics_pearsonr: 3.5205e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.1868e-05\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0509 - metrics_pearsonr: 3.5197e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.1803e-05\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0507 - metrics_pearsonr: 3.5158e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.1745e-05\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0508 - metrics_pearsonr: 3.5138e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.1764e-05\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0508 - metrics_pearsonr: 3.5120e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.1792e-05\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0505 - metrics_pearsonr: 3.5100e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.1833e-05\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0501 - metrics_pearsonr: 3.5072e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 6.1851e-05\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0499 - metrics_pearsonr: 3.5019e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 6.1819e-05\n",
      "Epoch 653/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0500 - metrics_pearsonr: 3.4987e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.1803e-05\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0501 - metrics_pearsonr: 3.4975e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.1854e-05\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0502 - metrics_pearsonr: 3.4961e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.1884e-05\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0500 - metrics_pearsonr: 3.4946e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 6.1811e-05\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0498 - metrics_pearsonr: 3.4932e-05 - val_loss: 0.0713 - val_metrics_pearsonr: 6.1752e-05\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0497 - metrics_pearsonr: 3.4919e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.1754e-05\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0498 - metrics_pearsonr: 3.4911e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 6.1799e-05\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0498 - metrics_pearsonr: 3.4901e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.1838e-05\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0498 - metrics_pearsonr: 3.4879e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.1847e-05\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0497 - metrics_pearsonr: 3.4857e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 6.1841e-05\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0495 - metrics_pearsonr: 3.4832e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.1844e-05\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0494 - metrics_pearsonr: 3.4807e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 6.1874e-05\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0494 - metrics_pearsonr: 3.4780e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 6.1887e-05\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0495 - metrics_pearsonr: 3.4761e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.1876e-05\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0496 - metrics_pearsonr: 3.4743e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.1860e-05\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0496 - metrics_pearsonr: 3.4733e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.1858e-05\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0495 - metrics_pearsonr: 3.4723e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 6.1861e-05\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0494 - metrics_pearsonr: 3.4713e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.1872e-05\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0494 - metrics_pearsonr: 3.4703e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 6.1877e-05\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0495 - metrics_pearsonr: 3.4693e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 6.1870e-05\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0495 - metrics_pearsonr: 3.4680e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.1876e-05\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0495 - metrics_pearsonr: 3.4666e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.1893e-05\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0495 - metrics_pearsonr: 3.4647e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.1903e-05\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0493 - metrics_pearsonr: 3.4624e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 6.1910e-05\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0492 - metrics_pearsonr: 3.4599e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.1906e-05\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0492 - metrics_pearsonr: 3.4574e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 6.1905e-05\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0493 - metrics_pearsonr: 3.4553e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.1921e-05\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0494 - metrics_pearsonr: 3.4538e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.1940e-05\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0495 - metrics_pearsonr: 3.4523e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.1954e-05\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0496 - metrics_pearsonr: 3.4513e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.1961e-05\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0495 - metrics_pearsonr: 3.4503e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.1956e-05\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0494 - metrics_pearsonr: 3.4492e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 6.1948e-05\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0493 - metrics_pearsonr: 3.4486e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.1949e-05\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0494 - metrics_pearsonr: 3.4477e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 6.1952e-05\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0495 - metrics_pearsonr: 3.4469e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.1958e-05\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0497 - metrics_pearsonr: 3.4459e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.1965e-05\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0498 - metrics_pearsonr: 3.4448e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.1973e-05\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0498 - metrics_pearsonr: 3.4433e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.1980e-05\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0496 - metrics_pearsonr: 3.4413e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.1981e-05\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0494 - metrics_pearsonr: 3.4388e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 6.1979e-05\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0492 - metrics_pearsonr: 3.4361e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 6.1977e-05\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0493 - metrics_pearsonr: 3.4336e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 6.1988e-05\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0496 - metrics_pearsonr: 3.4315e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.2014e-05\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0500 - metrics_pearsonr: 3.4300e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 6.2059e-05\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0504 - metrics_pearsonr: 3.4289e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 6.2103e-05\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0506 - metrics_pearsonr: 3.4279e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 6.2136e-05\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0506 - metrics_pearsonr: 3.4276e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 6.2154e-05\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0504 - metrics_pearsonr: 3.4271e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 6.2154e-05\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0501 - metrics_pearsonr: 3.4270e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2138e-05\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0500 - metrics_pearsonr: 3.4268e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 6.2120e-05\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0502 - metrics_pearsonr: 3.4270e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2110e-05\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0509 - metrics_pearsonr: 3.4275e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 6.2115e-05\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0518 - metrics_pearsonr: 3.4282e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 6.2145e-05\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0527 - metrics_pearsonr: 3.4291e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 6.2186e-05\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0532 - metrics_pearsonr: 3.4294e-05 - val_loss: 0.0795 - val_metrics_pearsonr: 6.2229e-05\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0532 - metrics_pearsonr: 3.4288e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 6.2250e-05\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0526 - metrics_pearsonr: 3.4268e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 6.2245e-05\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0518 - metrics_pearsonr: 3.4237e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 6.2218e-05\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0512 - metrics_pearsonr: 3.4201e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2190e-05\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0513 - metrics_pearsonr: 3.4170e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2191e-05\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0525 - metrics_pearsonr: 3.4150e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 6.2242e-05\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0546 - metrics_pearsonr: 3.4144e-05 - val_loss: 0.0806 - val_metrics_pearsonr: 6.2366e-05\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0569 - metrics_pearsonr: 3.4152e-05 - val_loss: 0.0868 - val_metrics_pearsonr: 6.2536e-05\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0589 - metrics_pearsonr: 3.4171e-05 - val_loss: 0.0914 - val_metrics_pearsonr: 6.2726e-05\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0597 - metrics_pearsonr: 3.4199e-05 - val_loss: 0.0922 - val_metrics_pearsonr: 6.2873e-05\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0592 - metrics_pearsonr: 3.4234e-05 - val_loss: 0.0884 - val_metrics_pearsonr: 6.2927e-05\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0578 - metrics_pearsonr: 3.4270e-05 - val_loss: 0.0814 - val_metrics_pearsonr: 6.2875e-05\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0564 - metrics_pearsonr: 3.4304e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 6.2758e-05\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0563 - metrics_pearsonr: 3.4327e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.2654e-05\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0585 - metrics_pearsonr: 3.4361e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 6.2653e-05\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0629 - metrics_pearsonr: 3.4441e-05 - val_loss: 0.0917 - val_metrics_pearsonr: 6.2809e-05\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0683 - metrics_pearsonr: 3.4534e-05 - val_loss: 0.1059 - val_metrics_pearsonr: 6.3062e-05\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0721 - metrics_pearsonr: 3.4627e-05 - val_loss: 0.1132 - val_metrics_pearsonr: 6.3264e-05\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0722 - metrics_pearsonr: 3.4675e-05 - val_loss: 0.1076 - val_metrics_pearsonr: 6.3281e-05\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0686 - metrics_pearsonr: 3.4627e-05 - val_loss: 0.0914 - val_metrics_pearsonr: 6.3128e-05\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0642 - metrics_pearsonr: 3.4538e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 6.2943e-05\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0629 - metrics_pearsonr: 3.4465e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 6.2898e-05\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0666 - metrics_pearsonr: 3.4422e-05 - val_loss: 0.0943 - val_metrics_pearsonr: 6.3048e-05\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0734 - metrics_pearsonr: 3.4406e-05 - val_loss: 0.1165 - val_metrics_pearsonr: 6.3335e-05\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0780 - metrics_pearsonr: 3.4425e-05 - val_loss: 0.1224 - val_metrics_pearsonr: 6.3570e-05\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0766 - metrics_pearsonr: 3.4467e-05 - val_loss: 0.1048 - val_metrics_pearsonr: 6.3651e-05\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0710 - metrics_pearsonr: 3.4535e-05 - val_loss: 0.0813 - val_metrics_pearsonr: 6.3634e-05\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0667 - metrics_pearsonr: 3.4597e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 6.3469e-05\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0674 - metrics_pearsonr: 3.4576e-05 - val_loss: 0.0945 - val_metrics_pearsonr: 6.3397e-05\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0712 - metrics_pearsonr: 3.4592e-05 - val_loss: 0.1100 - val_metrics_pearsonr: 6.3540e-05\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0721 - metrics_pearsonr: 3.4705e-05 - val_loss: 0.1020 - val_metrics_pearsonr: 6.3454e-05\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0673 - metrics_pearsonr: 3.4658e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 6.3210e-05\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0614 - metrics_pearsonr: 3.4442e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 6.3239e-05\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0601 - metrics_pearsonr: 3.4258e-05 - val_loss: 0.0871 - val_metrics_pearsonr: 6.3529e-05\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0619 - metrics_pearsonr: 3.4155e-05 - val_loss: 0.0950 - val_metrics_pearsonr: 6.3466e-05\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0614 - metrics_pearsonr: 3.4125e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 6.3083e-05\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0579 - metrics_pearsonr: 3.4076e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 6.2734e-05\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0552 - metrics_pearsonr: 3.4032e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 6.2770e-05\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0552 - metrics_pearsonr: 3.3979e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 6.3019e-05\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0553 - metrics_pearsonr: 3.3956e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 6.3111e-05\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0537 - metrics_pearsonr: 3.3942e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 6.2986e-05\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0518 - metrics_pearsonr: 3.3880e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2859e-05\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0510 - metrics_pearsonr: 3.3805e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 6.2875e-05\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0512 - metrics_pearsonr: 3.3726e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 6.2824e-05\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0510 - metrics_pearsonr: 3.3655e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 6.2726e-05\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0501 - metrics_pearsonr: 3.3602e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.2577e-05\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0496 - metrics_pearsonr: 3.3598e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.2572e-05\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0495 - metrics_pearsonr: 3.3571e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 6.2551e-05\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0495 - metrics_pearsonr: 3.3538e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 6.2538e-05\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0491 - metrics_pearsonr: 3.3492e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.2548e-05\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0487 - metrics_pearsonr: 3.3462e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2598e-05\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0486 - metrics_pearsonr: 3.3430e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.2628e-05\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0486 - metrics_pearsonr: 3.3403e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.2652e-05\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0486 - metrics_pearsonr: 3.3383e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.2652e-05\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0485 - metrics_pearsonr: 3.3366e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2623e-05\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0483 - metrics_pearsonr: 3.3348e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2569e-05\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0482 - metrics_pearsonr: 3.3334e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2525e-05\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0482 - metrics_pearsonr: 3.3324e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2522e-05\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0482 - metrics_pearsonr: 3.3312e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2538e-05\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0481 - metrics_pearsonr: 3.3298e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2564e-05\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0480 - metrics_pearsonr: 3.3281e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2588e-05\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0479 - metrics_pearsonr: 3.3258e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2609e-05\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0479 - metrics_pearsonr: 3.3233e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2599e-05\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0479 - metrics_pearsonr: 3.3211e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2583e-05\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0479 - metrics_pearsonr: 3.3190e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2554e-05\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0478 - metrics_pearsonr: 3.3174e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2552e-05\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0478 - metrics_pearsonr: 3.3158e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2565e-05\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0478 - metrics_pearsonr: 3.3147e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2588e-05\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0478 - metrics_pearsonr: 3.3135e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2599e-05\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0478 - metrics_pearsonr: 3.3127e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2618e-05\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0477 - metrics_pearsonr: 3.3117e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2617e-05\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0477 - metrics_pearsonr: 3.3102e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2624e-05\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0477 - metrics_pearsonr: 3.3087e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2614e-05\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0477 - metrics_pearsonr: 3.3072e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2611e-05\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0477 - metrics_pearsonr: 3.3055e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2594e-05\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0476 - metrics_pearsonr: 3.3039e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2596e-05\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0476 - metrics_pearsonr: 3.3024e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2593e-05\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0476 - metrics_pearsonr: 3.3007e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2605e-05\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0476 - metrics_pearsonr: 3.2990e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2606e-05\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0476 - metrics_pearsonr: 3.2973e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2616e-05\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0476 - metrics_pearsonr: 3.2957e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2617e-05\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0476 - metrics_pearsonr: 3.2940e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2621e-05\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0475 - metrics_pearsonr: 3.2923e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2616e-05\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0475 - metrics_pearsonr: 3.2907e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2619e-05\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0475 - metrics_pearsonr: 3.2889e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2612e-05\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0475 - metrics_pearsonr: 3.2873e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2617e-05\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0475 - metrics_pearsonr: 3.2859e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2627e-05\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0475 - metrics_pearsonr: 3.2844e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2645e-05\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0476 - metrics_pearsonr: 3.2834e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2669e-05\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0476 - metrics_pearsonr: 3.2824e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2701e-05\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0476 - metrics_pearsonr: 3.2816e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2731e-05\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0476 - metrics_pearsonr: 3.2809e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2755e-05\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0476 - metrics_pearsonr: 3.2802e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2771e-05\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0475 - metrics_pearsonr: 3.2794e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2771e-05\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0475 - metrics_pearsonr: 3.2786e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2766e-05\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0475 - metrics_pearsonr: 3.2779e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2749e-05\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0474 - metrics_pearsonr: 3.2773e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2739e-05\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0474 - metrics_pearsonr: 3.2765e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 6.2728e-05\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0474 - metrics_pearsonr: 3.2756e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 6.2731e-05\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0475 - metrics_pearsonr: 3.2748e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2736e-05\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0476 - metrics_pearsonr: 3.2737e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2758e-05\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0476 - metrics_pearsonr: 3.2728e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.2784e-05\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0477 - metrics_pearsonr: 3.2714e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.2806e-05\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0477 - metrics_pearsonr: 3.2700e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.2831e-05\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0477 - metrics_pearsonr: 3.2681e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.2839e-05\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0476 - metrics_pearsonr: 3.2661e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.2847e-05\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0476 - metrics_pearsonr: 3.2639e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.2828e-05\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0475 - metrics_pearsonr: 3.2617e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.2822e-05\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0474 - metrics_pearsonr: 3.2595e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.2795e-05\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0474 - metrics_pearsonr: 3.2575e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 6.2785e-05\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0474 - metrics_pearsonr: 3.2559e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2765e-05\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0474 - metrics_pearsonr: 3.2543e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2770e-05\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0475 - metrics_pearsonr: 3.2536e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 6.2777e-05\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0476 - metrics_pearsonr: 3.2526e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.2803e-05\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0478 - metrics_pearsonr: 3.2524e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.2836e-05\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0481 - metrics_pearsonr: 3.2522e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.2889e-05\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0484 - metrics_pearsonr: 3.2526e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 6.2952e-05\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0488 - metrics_pearsonr: 3.2531e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 6.3032e-05\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0491 - metrics_pearsonr: 3.2537e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 6.3124e-05\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0494 - metrics_pearsonr: 3.2550e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 6.3226e-05\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0496 - metrics_pearsonr: 3.2560e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 6.3326e-05\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0497 - metrics_pearsonr: 3.2572e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 6.3423e-05\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0496 - metrics_pearsonr: 3.2586e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 6.3505e-05\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0494 - metrics_pearsonr: 3.2597e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 6.3565e-05\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0492 - metrics_pearsonr: 3.2617e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 6.3600e-05\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0489 - metrics_pearsonr: 3.2634e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 6.3596e-05\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0488 - metrics_pearsonr: 3.2659e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 6.3569e-05\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0487 - metrics_pearsonr: 3.2693e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 6.3511e-05\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0489 - metrics_pearsonr: 3.2742e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3458e-05\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0494 - metrics_pearsonr: 3.2813e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.3416e-05\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0503 - metrics_pearsonr: 3.2903e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 6.3439e-05\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0515 - metrics_pearsonr: 3.3031e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 6.3553e-05\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0532 - metrics_pearsonr: 3.3179e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 6.3796e-05\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0551 - metrics_pearsonr: 3.3361e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 6.4220e-05\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0572 - metrics_pearsonr: 3.3553e-05 - val_loss: 0.0866 - val_metrics_pearsonr: 6.4789e-05\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0591 - metrics_pearsonr: 3.3743e-05 - val_loss: 0.0917 - val_metrics_pearsonr: 6.5463e-05\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0604 - metrics_pearsonr: 3.3897e-05 - val_loss: 0.0956 - val_metrics_pearsonr: 6.6019e-05\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0606 - metrics_pearsonr: 3.3985e-05 - val_loss: 0.0962 - val_metrics_pearsonr: 6.6219e-05\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0594 - metrics_pearsonr: 3.3985e-05 - val_loss: 0.0919 - val_metrics_pearsonr: 6.5866e-05\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0572 - metrics_pearsonr: 3.3943e-05 - val_loss: 0.0840 - val_metrics_pearsonr: 6.5173e-05\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0553 - metrics_pearsonr: 3.3917e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 6.4702e-05\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0552 - metrics_pearsonr: 3.4020e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 6.4998e-05\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0573 - metrics_pearsonr: 3.4189e-05 - val_loss: 0.0809 - val_metrics_pearsonr: 6.6084e-05\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0607 - metrics_pearsonr: 3.4380e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 6.7294e-05\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0638 - metrics_pearsonr: 3.4475e-05 - val_loss: 0.0968 - val_metrics_pearsonr: 6.7708e-05\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0655 - metrics_pearsonr: 3.4486e-05 - val_loss: 0.0971 - val_metrics_pearsonr: 6.6784e-05\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0657 - metrics_pearsonr: 3.4366e-05 - val_loss: 0.0948 - val_metrics_pearsonr: 6.5247e-05\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0658 - metrics_pearsonr: 3.4172e-05 - val_loss: 0.0969 - val_metrics_pearsonr: 6.4527e-05\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0665 - metrics_pearsonr: 3.4069e-05 - val_loss: 0.1025 - val_metrics_pearsonr: 6.5070e-05\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0667 - metrics_pearsonr: 3.4147e-05 - val_loss: 0.1017 - val_metrics_pearsonr: 6.5454e-05\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0642 - metrics_pearsonr: 3.4150e-05 - val_loss: 0.0895 - val_metrics_pearsonr: 6.4397e-05\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0604 - metrics_pearsonr: 3.3930e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 6.3493e-05\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0598 - metrics_pearsonr: 3.3753e-05 - val_loss: 0.0801 - val_metrics_pearsonr: 6.5376e-05\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0631 - metrics_pearsonr: 3.4056e-05 - val_loss: 0.0914 - val_metrics_pearsonr: 6.8816e-05\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0665 - metrics_pearsonr: 3.4632e-05 - val_loss: 0.0969 - val_metrics_pearsonr: 6.8250e-05\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0681 - metrics_pearsonr: 3.4550e-05 - val_loss: 0.0985 - val_metrics_pearsonr: 6.4558e-05\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0720 - metrics_pearsonr: 3.4497e-05 - val_loss: 0.1101 - val_metrics_pearsonr: 6.6041e-05\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0771 - metrics_pearsonr: 3.5225e-05 - val_loss: 0.1197 - val_metrics_pearsonr: 6.9023e-05\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0774 - metrics_pearsonr: 3.5718e-05 - val_loss: 0.1104 - val_metrics_pearsonr: 6.5906e-05\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0718 - metrics_pearsonr: 3.4551e-05 - val_loss: 0.0977 - val_metrics_pearsonr: 6.4574e-05\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0668 - metrics_pearsonr: 3.3556e-05 - val_loss: 0.0888 - val_metrics_pearsonr: 6.6280e-05\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0657 - metrics_pearsonr: 3.3583e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 6.4796e-05\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0667 - metrics_pearsonr: 3.3144e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 6.4175e-05\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0719 - metrics_pearsonr: 3.3144e-05 - val_loss: 0.1126 - val_metrics_pearsonr: 6.4179e-05\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0776 - metrics_pearsonr: 3.3173e-05 - val_loss: 0.1261 - val_metrics_pearsonr: 6.4940e-05\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0777 - metrics_pearsonr: 3.3190e-05 - val_loss: 0.1191 - val_metrics_pearsonr: 6.8294e-05\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0738 - metrics_pearsonr: 3.3960e-05 - val_loss: 0.0912 - val_metrics_pearsonr: 6.6316e-05\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - metrics_pearsonr: 3.3556e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 6.3572e-05\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0647 - metrics_pearsonr: 3.2973e-05 - val_loss: 0.0876 - val_metrics_pearsonr: 6.4365e-05\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0691 - metrics_pearsonr: 3.3166e-05 - val_loss: 0.1070 - val_metrics_pearsonr: 6.4118e-05\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0713 - metrics_pearsonr: 3.2926e-05 - val_loss: 0.1082 - val_metrics_pearsonr: 6.4749e-05\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0676 - metrics_pearsonr: 3.2740e-05 - val_loss: 0.0924 - val_metrics_pearsonr: 6.5173e-05\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0624 - metrics_pearsonr: 3.2752e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 6.4062e-05\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0593 - metrics_pearsonr: 3.2558e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 6.3826e-05\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0592 - metrics_pearsonr: 3.2375e-05 - val_loss: 0.0872 - val_metrics_pearsonr: 6.3664e-05\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0597 - metrics_pearsonr: 3.2354e-05 - val_loss: 0.0910 - val_metrics_pearsonr: 6.4314e-05\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0589 - metrics_pearsonr: 3.2346e-05 - val_loss: 0.0866 - val_metrics_pearsonr: 6.4375e-05\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0564 - metrics_pearsonr: 3.2381e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 6.3704e-05\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0538 - metrics_pearsonr: 3.2415e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 6.3507e-05\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0528 - metrics_pearsonr: 3.2367e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 6.3810e-05\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0529 - metrics_pearsonr: 3.2334e-05 - val_loss: 0.0827 - val_metrics_pearsonr: 6.4403e-05\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0523 - metrics_pearsonr: 3.2245e-05 - val_loss: 0.0800 - val_metrics_pearsonr: 6.4317e-05\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0507 - metrics_pearsonr: 3.2111e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 6.3553e-05\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0494 - metrics_pearsonr: 3.1936e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3371e-05\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0492 - metrics_pearsonr: 3.1859e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 6.3455e-05\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0495 - metrics_pearsonr: 3.1843e-05 - val_loss: 0.0773 - val_metrics_pearsonr: 6.3623e-05\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0491 - metrics_pearsonr: 3.1795e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 6.3610e-05\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0484 - metrics_pearsonr: 3.1778e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3430e-05\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0478 - metrics_pearsonr: 3.1762e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3435e-05\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0477 - metrics_pearsonr: 3.1721e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 6.3461e-05\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0478 - metrics_pearsonr: 3.1680e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 6.3494e-05\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0476 - metrics_pearsonr: 3.1634e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 6.3415e-05\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0472 - metrics_pearsonr: 3.1584e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3276e-05\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0469 - metrics_pearsonr: 3.1545e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.3234e-05\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0468 - metrics_pearsonr: 3.1520e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3239e-05\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0469 - metrics_pearsonr: 3.1502e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 6.3331e-05\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0469 - metrics_pearsonr: 3.1481e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.3381e-05\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0468 - metrics_pearsonr: 3.1476e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.3366e-05\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0467 - metrics_pearsonr: 3.1462e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.3293e-05\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0465 - metrics_pearsonr: 3.1442e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.3235e-05\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0465 - metrics_pearsonr: 3.1423e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3221e-05\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0466 - metrics_pearsonr: 3.1413e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.3244e-05\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0465 - metrics_pearsonr: 3.1399e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3281e-05\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0464 - metrics_pearsonr: 3.1377e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3285e-05\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0462 - metrics_pearsonr: 3.1356e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.3302e-05\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0462 - metrics_pearsonr: 3.1332e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3299e-05\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0463 - metrics_pearsonr: 3.1318e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3311e-05\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0463 - metrics_pearsonr: 3.1305e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3332e-05\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0463 - metrics_pearsonr: 3.1295e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3345e-05\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0463 - metrics_pearsonr: 3.1286e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.3320e-05\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0462 - metrics_pearsonr: 3.1278e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.3301e-05\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0462 - metrics_pearsonr: 3.1270e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 6.3285e-05\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0462 - metrics_pearsonr: 3.1263e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3297e-05\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0462 - metrics_pearsonr: 3.1251e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3316e-05\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0461 - metrics_pearsonr: 3.1236e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3338e-05\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0461 - metrics_pearsonr: 3.1216e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.3335e-05\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0460 - metrics_pearsonr: 3.1197e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.3335e-05\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0460 - metrics_pearsonr: 3.1176e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.3323e-05\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0460 - metrics_pearsonr: 3.1162e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3336e-05\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0460 - metrics_pearsonr: 3.1148e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3356e-05\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0461 - metrics_pearsonr: 3.1138e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3386e-05\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0461 - metrics_pearsonr: 3.1128e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3399e-05\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0461 - metrics_pearsonr: 3.1119e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3397e-05\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0460 - metrics_pearsonr: 3.1112e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3384e-05\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0460 - metrics_pearsonr: 3.1102e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.3380e-05\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0460 - metrics_pearsonr: 3.1093e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3375e-05\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0460 - metrics_pearsonr: 3.1084e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3390e-05\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0460 - metrics_pearsonr: 3.1073e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3392e-05\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0460 - metrics_pearsonr: 3.1058e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3398e-05\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0460 - metrics_pearsonr: 3.1043e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.3391e-05\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0459 - metrics_pearsonr: 3.1028e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.3398e-05\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0458 - metrics_pearsonr: 3.1010e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.3395e-05\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0458 - metrics_pearsonr: 3.0992e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3415e-05\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0459 - metrics_pearsonr: 3.0976e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3426e-05\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0460 - metrics_pearsonr: 3.0962e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 6.3454e-05\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0461 - metrics_pearsonr: 3.0950e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 6.3462e-05\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0461 - metrics_pearsonr: 3.0942e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 6.3481e-05\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0461 - metrics_pearsonr: 3.0932e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 6.3471e-05\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0461 - metrics_pearsonr: 3.0925e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 6.3483e-05\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0460 - metrics_pearsonr: 3.0918e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.3461e-05\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0460 - metrics_pearsonr: 3.0912e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.3471e-05\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0460 - metrics_pearsonr: 3.0906e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3449e-05\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0462 - metrics_pearsonr: 3.0902e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 6.3473e-05\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0463 - metrics_pearsonr: 3.0893e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.3458e-05\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0465 - metrics_pearsonr: 3.0888e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 6.3488e-05\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0465 - metrics_pearsonr: 3.0876e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 6.3472e-05\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0464 - metrics_pearsonr: 3.0861e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.3495e-05\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0462 - metrics_pearsonr: 3.0843e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 6.3471e-05\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0460 - metrics_pearsonr: 3.0820e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3489e-05\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0460 - metrics_pearsonr: 3.0801e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 6.3476e-05\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0461 - metrics_pearsonr: 3.0782e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 6.3516e-05\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0465 - metrics_pearsonr: 3.0769e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 6.3529e-05\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0469 - metrics_pearsonr: 3.0758e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 6.3602e-05\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0474 - metrics_pearsonr: 3.0752e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 6.3640e-05\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0477 - metrics_pearsonr: 3.0751e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 6.3716e-05\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0477 - metrics_pearsonr: 3.0750e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 6.3720e-05\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0475 - metrics_pearsonr: 3.0753e-05 - val_loss: 0.0758 - val_metrics_pearsonr: 6.3748e-05\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0472 - metrics_pearsonr: 3.0754e-05 - val_loss: 0.0744 - val_metrics_pearsonr: 6.3693e-05\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0470 - metrics_pearsonr: 3.0762e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 6.3683e-05\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0471 - metrics_pearsonr: 3.0767e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 6.3630e-05\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0476 - metrics_pearsonr: 3.0780e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 6.3645e-05\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0486 - metrics_pearsonr: 3.0803e-05 - val_loss: 0.0761 - val_metrics_pearsonr: 6.3660e-05\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0500 - metrics_pearsonr: 3.0825e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 6.3734e-05\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0513 - metrics_pearsonr: 3.0852e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 6.3806e-05\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0521 - metrics_pearsonr: 3.0865e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 6.3873e-05\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0523 - metrics_pearsonr: 3.0872e-05 - val_loss: 0.0845 - val_metrics_pearsonr: 6.3914e-05\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0516 - metrics_pearsonr: 3.0853e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 6.3893e-05\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0505 - metrics_pearsonr: 3.0825e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 6.3854e-05\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0495 - metrics_pearsonr: 3.0797e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 6.3786e-05\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0493 - metrics_pearsonr: 3.0771e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 6.3757e-05\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0505 - metrics_pearsonr: 3.0769e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 6.3778e-05\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0532 - metrics_pearsonr: 3.0771e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 6.3929e-05\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0569 - metrics_pearsonr: 3.0805e-05 - val_loss: 0.0909 - val_metrics_pearsonr: 6.4175e-05\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0607 - metrics_pearsonr: 3.0847e-05 - val_loss: 0.1006 - val_metrics_pearsonr: 6.4524e-05\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0634 - metrics_pearsonr: 3.0912e-05 - val_loss: 0.1066 - val_metrics_pearsonr: 6.4841e-05\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0640 - metrics_pearsonr: 3.0985e-05 - val_loss: 0.1055 - val_metrics_pearsonr: 6.5082e-05\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0625 - metrics_pearsonr: 3.1061e-05 - val_loss: 0.0963 - val_metrics_pearsonr: 6.5080e-05\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0599 - metrics_pearsonr: 3.1153e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 6.4942e-05\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0581 - metrics_pearsonr: 3.1200e-05 - val_loss: 0.0747 - val_metrics_pearsonr: 6.4609e-05\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0596 - metrics_pearsonr: 3.1277e-05 - val_loss: 0.0789 - val_metrics_pearsonr: 6.4493e-05\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0652 - metrics_pearsonr: 3.1320e-05 - val_loss: 0.0976 - val_metrics_pearsonr: 6.4649e-05\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0736 - metrics_pearsonr: 3.1478e-05 - val_loss: 0.1218 - val_metrics_pearsonr: 6.5204e-05\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0801 - metrics_pearsonr: 3.1667e-05 - val_loss: 0.1343 - val_metrics_pearsonr: 6.5506e-05\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0803 - metrics_pearsonr: 3.1711e-05 - val_loss: 0.1216 - val_metrics_pearsonr: 6.5402e-05\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0736 - metrics_pearsonr: 3.1581e-05 - val_loss: 0.0928 - val_metrics_pearsonr: 6.5000e-05\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0667 - metrics_pearsonr: 3.1417e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 6.4996e-05\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0663 - metrics_pearsonr: 3.1363e-05 - val_loss: 0.0882 - val_metrics_pearsonr: 6.5140e-05\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0719 - metrics_pearsonr: 3.1294e-05 - val_loss: 0.1173 - val_metrics_pearsonr: 6.5232e-05\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0776 - metrics_pearsonr: 3.1298e-05 - val_loss: 0.1282 - val_metrics_pearsonr: 6.5215e-05\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0766 - metrics_pearsonr: 3.1416e-05 - val_loss: 0.1055 - val_metrics_pearsonr: 6.4864e-05\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0688 - metrics_pearsonr: 3.1354e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 6.4318e-05\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0633 - metrics_pearsonr: 3.1308e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 6.4640e-05\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0645 - metrics_pearsonr: 3.1280e-05 - val_loss: 0.1010 - val_metrics_pearsonr: 6.5340e-05\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0661 - metrics_pearsonr: 3.1171e-05 - val_loss: 0.1047 - val_metrics_pearsonr: 6.5346e-05\n",
      "Epoch 1002/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0632 - metrics_pearsonr: 3.1128e-05 - val_loss: 0.0865 - val_metrics_pearsonr: 6.4699e-05\n",
      "Epoch 1003/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0577 - metrics_pearsonr: 3.0994e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 6.4389e-05\n",
      "Epoch 1/5000\n",
      "3/3 [==============================] - 2s 371ms/step - loss: 0.0794 - metrics_pearsonr: 5.7345e-05 - val_loss: 0.0494 - val_metrics_pearsonr: 4.5701e-05\n",
      "Epoch 2/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0753 - metrics_pearsonr: 5.6944e-05 - val_loss: 0.0540 - val_metrics_pearsonr: 4.6932e-05\n",
      "Epoch 3/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0749 - metrics_pearsonr: 5.6629e-05 - val_loss: 0.0599 - val_metrics_pearsonr: 4.7672e-05\n",
      "Epoch 4/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0757 - metrics_pearsonr: 5.6150e-05 - val_loss: 0.0644 - val_metrics_pearsonr: 4.8157e-05\n",
      "Epoch 5/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0761 - metrics_pearsonr: 5.5595e-05 - val_loss: 0.0654 - val_metrics_pearsonr: 4.8825e-05\n",
      "Epoch 6/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0755 - metrics_pearsonr: 5.5178e-05 - val_loss: 0.0625 - val_metrics_pearsonr: 4.9428e-05\n",
      "Epoch 7/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0746 - metrics_pearsonr: 5.4822e-05 - val_loss: 0.0573 - val_metrics_pearsonr: 5.0077e-05\n",
      "Epoch 8/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0739 - metrics_pearsonr: 5.4474e-05 - val_loss: 0.0528 - val_metrics_pearsonr: 5.0542e-05\n",
      "Epoch 9/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0745 - metrics_pearsonr: 5.4232e-05 - val_loss: 0.0531 - val_metrics_pearsonr: 5.1132e-05\n",
      "Epoch 10/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0770 - metrics_pearsonr: 5.3884e-05 - val_loss: 0.0603 - val_metrics_pearsonr: 5.1919e-05\n",
      "Epoch 11/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0816 - metrics_pearsonr: 5.3705e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 5.2747e-05\n",
      "Epoch 12/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0866 - metrics_pearsonr: 5.3523e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 5.3468e-05\n",
      "Epoch 13/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0900 - metrics_pearsonr: 5.3382e-05 - val_loss: 0.0922 - val_metrics_pearsonr: 5.4052e-05\n",
      "Epoch 14/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0899 - metrics_pearsonr: 5.3242e-05 - val_loss: 0.0873 - val_metrics_pearsonr: 5.4343e-05\n",
      "Epoch 15/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0861 - metrics_pearsonr: 5.3027e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 5.4335e-05\n",
      "Epoch 16/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0811 - metrics_pearsonr: 5.2784e-05 - val_loss: 0.0590 - val_metrics_pearsonr: 5.4412e-05\n",
      "Epoch 17/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0784 - metrics_pearsonr: 5.2590e-05 - val_loss: 0.0575 - val_metrics_pearsonr: 5.4721e-05\n",
      "Epoch 18/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0805 - metrics_pearsonr: 5.2511e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 5.5319e-05\n",
      "Epoch 19/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0859 - metrics_pearsonr: 5.2493e-05 - val_loss: 0.0912 - val_metrics_pearsonr: 5.5967e-05\n",
      "Epoch 20/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0903 - metrics_pearsonr: 5.2474e-05 - val_loss: 0.1008 - val_metrics_pearsonr: 5.6408e-05\n",
      "Epoch 21/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0900 - metrics_pearsonr: 5.2318e-05 - val_loss: 0.0914 - val_metrics_pearsonr: 5.6844e-05\n",
      "Epoch 22/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0859 - metrics_pearsonr: 5.2346e-05 - val_loss: 0.0708 - val_metrics_pearsonr: 5.7078e-05\n",
      "Epoch 23/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0815 - metrics_pearsonr: 5.2348e-05 - val_loss: 0.0577 - val_metrics_pearsonr: 5.6942e-05\n",
      "Epoch 24/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0803 - metrics_pearsonr: 5.2084e-05 - val_loss: 0.0647 - val_metrics_pearsonr: 5.6994e-05\n",
      "Epoch 25/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0835 - metrics_pearsonr: 5.1801e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 5.7613e-05\n",
      "Epoch 26/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0876 - metrics_pearsonr: 5.1729e-05 - val_loss: 0.0926 - val_metrics_pearsonr: 5.8032e-05\n",
      "Epoch 27/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0870 - metrics_pearsonr: 5.1600e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 5.7722e-05\n",
      "Epoch 28/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0813 - metrics_pearsonr: 5.1236e-05 - val_loss: 0.0621 - val_metrics_pearsonr: 5.7212e-05\n",
      "Epoch 29/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0760 - metrics_pearsonr: 5.0882e-05 - val_loss: 0.0570 - val_metrics_pearsonr: 5.7132e-05\n",
      "Epoch 30/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0749 - metrics_pearsonr: 5.0652e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 5.7465e-05\n",
      "Epoch 31/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0767 - metrics_pearsonr: 5.0533e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 5.7909e-05\n",
      "Epoch 32/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0773 - metrics_pearsonr: 5.0491e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 5.8031e-05\n",
      "Epoch 33/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0749 - metrics_pearsonr: 5.0371e-05 - val_loss: 0.0633 - val_metrics_pearsonr: 5.7892e-05\n",
      "Epoch 34/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0718 - metrics_pearsonr: 5.0173e-05 - val_loss: 0.0575 - val_metrics_pearsonr: 5.8012e-05\n",
      "Epoch 35/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0710 - metrics_pearsonr: 5.0004e-05 - val_loss: 0.0623 - val_metrics_pearsonr: 5.8376e-05\n",
      "Epoch 36/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0717 - metrics_pearsonr: 4.9865e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 5.8557e-05\n",
      "Epoch 37/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0717 - metrics_pearsonr: 4.9738e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 5.8469e-05\n",
      "Epoch 38/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0702 - metrics_pearsonr: 4.9586e-05 - val_loss: 0.0608 - val_metrics_pearsonr: 5.8316e-05\n",
      "Epoch 39/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0681 - metrics_pearsonr: 4.9405e-05 - val_loss: 0.0572 - val_metrics_pearsonr: 5.8296e-05\n",
      "Epoch 40/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0670 - metrics_pearsonr: 4.9241e-05 - val_loss: 0.0595 - val_metrics_pearsonr: 5.8428e-05\n",
      "Epoch 41/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0671 - metrics_pearsonr: 4.9116e-05 - val_loss: 0.0631 - val_metrics_pearsonr: 5.8613e-05\n",
      "Epoch 42/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0673 - metrics_pearsonr: 4.9015e-05 - val_loss: 0.0633 - val_metrics_pearsonr: 5.8797e-05\n",
      "Epoch 43/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0667 - metrics_pearsonr: 4.8913e-05 - val_loss: 0.0603 - val_metrics_pearsonr: 5.8968e-05\n",
      "Epoch 44/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0658 - metrics_pearsonr: 4.8824e-05 - val_loss: 0.0580 - val_metrics_pearsonr: 5.9117e-05\n",
      "Epoch 45/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0654 - metrics_pearsonr: 4.8739e-05 - val_loss: 0.0585 - val_metrics_pearsonr: 5.9224e-05\n",
      "Epoch 46/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0655 - metrics_pearsonr: 4.8646e-05 - val_loss: 0.0601 - val_metrics_pearsonr: 5.9301e-05\n",
      "Epoch 47/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0656 - metrics_pearsonr: 4.8558e-05 - val_loss: 0.0605 - val_metrics_pearsonr: 5.9344e-05\n",
      "Epoch 48/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0653 - metrics_pearsonr: 4.8467e-05 - val_loss: 0.0593 - val_metrics_pearsonr: 5.9369e-05\n",
      "Epoch 49/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0647 - metrics_pearsonr: 4.8365e-05 - val_loss: 0.0580 - val_metrics_pearsonr: 5.9402e-05\n",
      "Epoch 50/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0643 - metrics_pearsonr: 4.8256e-05 - val_loss: 0.0582 - val_metrics_pearsonr: 5.9470e-05\n",
      "Epoch 51/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0642 - metrics_pearsonr: 4.8163e-05 - val_loss: 0.0594 - val_metrics_pearsonr: 5.9582e-05\n",
      "Epoch 52/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0643 - metrics_pearsonr: 4.8092e-05 - val_loss: 0.0604 - val_metrics_pearsonr: 5.9723e-05\n",
      "Epoch 53/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0644 - metrics_pearsonr: 4.8032e-05 - val_loss: 0.0603 - val_metrics_pearsonr: 5.9859e-05\n",
      "Epoch 54/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0641 - metrics_pearsonr: 4.7971e-05 - val_loss: 0.0596 - val_metrics_pearsonr: 5.9989e-05\n",
      "Epoch 55/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0639 - metrics_pearsonr: 4.7908e-05 - val_loss: 0.0590 - val_metrics_pearsonr: 6.0113e-05\n",
      "Epoch 56/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0637 - metrics_pearsonr: 4.7835e-05 - val_loss: 0.0591 - val_metrics_pearsonr: 6.0213e-05\n",
      "Epoch 57/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0636 - metrics_pearsonr: 4.7750e-05 - val_loss: 0.0594 - val_metrics_pearsonr: 6.0299e-05\n",
      "Epoch 58/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0636 - metrics_pearsonr: 4.7666e-05 - val_loss: 0.0595 - val_metrics_pearsonr: 6.0381e-05\n",
      "Epoch 59/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0634 - metrics_pearsonr: 4.7586e-05 - val_loss: 0.0591 - val_metrics_pearsonr: 6.0462e-05\n",
      "Epoch 60/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0632 - metrics_pearsonr: 4.7504e-05 - val_loss: 0.0587 - val_metrics_pearsonr: 6.0548e-05\n",
      "Epoch 61/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0629 - metrics_pearsonr: 4.7421e-05 - val_loss: 0.0586 - val_metrics_pearsonr: 6.0638e-05\n",
      "Epoch 62/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0628 - metrics_pearsonr: 4.7340e-05 - val_loss: 0.0590 - val_metrics_pearsonr: 6.0733e-05\n",
      "Epoch 63/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0627 - metrics_pearsonr: 4.7259e-05 - val_loss: 0.0595 - val_metrics_pearsonr: 6.0832e-05\n",
      "Epoch 64/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0627 - metrics_pearsonr: 4.7181e-05 - val_loss: 0.0599 - val_metrics_pearsonr: 6.0948e-05\n",
      "Epoch 65/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0627 - metrics_pearsonr: 4.7111e-05 - val_loss: 0.0599 - val_metrics_pearsonr: 6.1070e-05\n",
      "Epoch 66/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0626 - metrics_pearsonr: 4.7048e-05 - val_loss: 0.0597 - val_metrics_pearsonr: 6.1185e-05\n",
      "Epoch 67/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0625 - metrics_pearsonr: 4.6988e-05 - val_loss: 0.0595 - val_metrics_pearsonr: 6.1268e-05\n",
      "Epoch 68/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0625 - metrics_pearsonr: 4.6931e-05 - val_loss: 0.0594 - val_metrics_pearsonr: 6.1323e-05\n",
      "Epoch 69/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0625 - metrics_pearsonr: 4.6873e-05 - val_loss: 0.0594 - val_metrics_pearsonr: 6.1362e-05\n",
      "Epoch 70/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0626 - metrics_pearsonr: 4.6815e-05 - val_loss: 0.0596 - val_metrics_pearsonr: 6.1398e-05\n",
      "Epoch 71/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0627 - metrics_pearsonr: 4.6763e-05 - val_loss: 0.0597 - val_metrics_pearsonr: 6.1451e-05\n",
      "Epoch 72/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0629 - metrics_pearsonr: 4.6715e-05 - val_loss: 0.0599 - val_metrics_pearsonr: 6.1519e-05\n",
      "Epoch 73/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0630 - metrics_pearsonr: 4.6669e-05 - val_loss: 0.0601 - val_metrics_pearsonr: 6.1599e-05\n",
      "Epoch 74/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0631 - metrics_pearsonr: 4.6629e-05 - val_loss: 0.0606 - val_metrics_pearsonr: 6.1691e-05\n",
      "Epoch 75/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0633 - metrics_pearsonr: 4.6592e-05 - val_loss: 0.0613 - val_metrics_pearsonr: 6.1794e-05\n",
      "Epoch 76/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0634 - metrics_pearsonr: 4.6555e-05 - val_loss: 0.0620 - val_metrics_pearsonr: 6.1908e-05\n",
      "Epoch 77/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0635 - metrics_pearsonr: 4.6521e-05 - val_loss: 0.0626 - val_metrics_pearsonr: 6.2036e-05\n",
      "Epoch 78/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0635 - metrics_pearsonr: 4.6485e-05 - val_loss: 0.0629 - val_metrics_pearsonr: 6.2170e-05\n",
      "Epoch 79/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0634 - metrics_pearsonr: 4.6449e-05 - val_loss: 0.0628 - val_metrics_pearsonr: 6.2288e-05\n",
      "Epoch 80/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0631 - metrics_pearsonr: 4.6411e-05 - val_loss: 0.0624 - val_metrics_pearsonr: 6.2372e-05\n",
      "Epoch 81/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0628 - metrics_pearsonr: 4.6365e-05 - val_loss: 0.0618 - val_metrics_pearsonr: 6.2425e-05\n",
      "Epoch 82/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0625 - metrics_pearsonr: 4.6311e-05 - val_loss: 0.0611 - val_metrics_pearsonr: 6.2452e-05\n",
      "Epoch 83/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0623 - metrics_pearsonr: 4.6257e-05 - val_loss: 0.0606 - val_metrics_pearsonr: 6.2488e-05\n",
      "Epoch 84/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0622 - metrics_pearsonr: 4.6199e-05 - val_loss: 0.0604 - val_metrics_pearsonr: 6.2559e-05\n",
      "Epoch 85/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0622 - metrics_pearsonr: 4.6146e-05 - val_loss: 0.0604 - val_metrics_pearsonr: 6.2670e-05\n",
      "Epoch 86/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0623 - metrics_pearsonr: 4.6100e-05 - val_loss: 0.0607 - val_metrics_pearsonr: 6.2822e-05\n",
      "Epoch 87/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0625 - metrics_pearsonr: 4.6055e-05 - val_loss: 0.0613 - val_metrics_pearsonr: 6.2985e-05\n",
      "Epoch 88/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0627 - metrics_pearsonr: 4.6009e-05 - val_loss: 0.0620 - val_metrics_pearsonr: 6.3141e-05\n",
      "Epoch 89/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0629 - metrics_pearsonr: 4.5956e-05 - val_loss: 0.0628 - val_metrics_pearsonr: 6.3264e-05\n",
      "Epoch 90/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0631 - metrics_pearsonr: 4.5890e-05 - val_loss: 0.0636 - val_metrics_pearsonr: 6.3369e-05\n",
      "Epoch 91/5000\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0632 - metrics_pearsonr: 4.5823e-05 - val_loss: 0.0643 - val_metrics_pearsonr: 6.3459e-05\n",
      "Epoch 92/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0632 - metrics_pearsonr: 4.5755e-05 - val_loss: 0.0648 - val_metrics_pearsonr: 6.3539e-05\n",
      "Epoch 93/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0631 - metrics_pearsonr: 4.5697e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.3612e-05\n",
      "Epoch 94/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0630 - metrics_pearsonr: 4.5651e-05 - val_loss: 0.0646 - val_metrics_pearsonr: 6.3661e-05\n",
      "Epoch 95/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0628 - metrics_pearsonr: 4.5617e-05 - val_loss: 0.0638 - val_metrics_pearsonr: 6.3676e-05\n",
      "Epoch 96/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0626 - metrics_pearsonr: 4.5592e-05 - val_loss: 0.0627 - val_metrics_pearsonr: 6.3643e-05\n",
      "Epoch 97/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0627 - metrics_pearsonr: 4.5573e-05 - val_loss: 0.0617 - val_metrics_pearsonr: 6.3570e-05\n",
      "Epoch 98/5000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0630 - metrics_pearsonr: 4.5555e-05 - val_loss: 0.0612 - val_metrics_pearsonr: 6.3497e-05\n",
      "Epoch 99/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0637 - metrics_pearsonr: 4.5548e-05 - val_loss: 0.0617 - val_metrics_pearsonr: 6.3480e-05\n",
      "Epoch 100/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0649 - metrics_pearsonr: 4.5564e-05 - val_loss: 0.0636 - val_metrics_pearsonr: 6.3581e-05\n",
      "Epoch 101/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0666 - metrics_pearsonr: 4.5617e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 6.3825e-05\n",
      "Epoch 102/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0687 - metrics_pearsonr: 4.5705e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 6.4190e-05\n",
      "Epoch 103/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0706 - metrics_pearsonr: 4.5818e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 6.4594e-05\n",
      "Epoch 104/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0720 - metrics_pearsonr: 4.5919e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 6.4907e-05\n",
      "Epoch 105/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0721 - metrics_pearsonr: 4.5967e-05 - val_loss: 0.0794 - val_metrics_pearsonr: 6.5012e-05\n",
      "Epoch 106/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0708 - metrics_pearsonr: 4.5942e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 6.4907e-05\n",
      "Epoch 107/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0687 - metrics_pearsonr: 4.5861e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 6.4727e-05\n",
      "Epoch 108/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0668 - metrics_pearsonr: 4.5787e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 6.4684e-05\n",
      "Epoch 109/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0661 - metrics_pearsonr: 4.5758e-05 - val_loss: 0.0632 - val_metrics_pearsonr: 6.4914e-05\n",
      "Epoch 110/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0671 - metrics_pearsonr: 4.5758e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 6.5390e-05\n",
      "Epoch 111/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0692 - metrics_pearsonr: 4.5757e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 6.5967e-05\n",
      "Epoch 112/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0714 - metrics_pearsonr: 4.5757e-05 - val_loss: 0.0823 - val_metrics_pearsonr: 6.6438e-05\n",
      "Epoch 113/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0727 - metrics_pearsonr: 4.5777e-05 - val_loss: 0.0832 - val_metrics_pearsonr: 6.6552e-05\n",
      "Epoch 114/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0721 - metrics_pearsonr: 4.5767e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 6.6159e-05\n",
      "Epoch 115/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0700 - metrics_pearsonr: 4.5649e-05 - val_loss: 0.0675 - val_metrics_pearsonr: 6.5455e-05\n",
      "Epoch 116/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0679 - metrics_pearsonr: 4.5423e-05 - val_loss: 0.0627 - val_metrics_pearsonr: 6.4946e-05\n",
      "Epoch 117/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0676 - metrics_pearsonr: 4.5229e-05 - val_loss: 0.0662 - val_metrics_pearsonr: 6.4978e-05\n",
      "Epoch 118/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0692 - metrics_pearsonr: 4.5185e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 6.5326e-05\n",
      "Epoch 119/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0709 - metrics_pearsonr: 4.5230e-05 - val_loss: 0.0785 - val_metrics_pearsonr: 6.5494e-05\n",
      "Epoch 120/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0709 - metrics_pearsonr: 4.5225e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 6.5358e-05\n",
      "Epoch 121/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0691 - metrics_pearsonr: 4.5137e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 6.5284e-05\n",
      "Epoch 122/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0669 - metrics_pearsonr: 4.5021e-05 - val_loss: 0.0664 - val_metrics_pearsonr: 6.5495e-05\n",
      "Epoch 123/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0656 - metrics_pearsonr: 4.4901e-05 - val_loss: 0.0668 - val_metrics_pearsonr: 6.5765e-05\n",
      "Epoch 124/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0652 - metrics_pearsonr: 4.4792e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 6.5761e-05\n",
      "Epoch 125/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0651 - metrics_pearsonr: 4.4712e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 6.5481e-05\n",
      "Epoch 126/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0652 - metrics_pearsonr: 4.4645e-05 - val_loss: 0.0664 - val_metrics_pearsonr: 6.5217e-05\n",
      "Epoch 127/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0654 - metrics_pearsonr: 4.4582e-05 - val_loss: 0.0675 - val_metrics_pearsonr: 6.5211e-05\n",
      "Epoch 128/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0661 - metrics_pearsonr: 4.4554e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 6.5391e-05\n",
      "Epoch 129/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0669 - metrics_pearsonr: 4.4551e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 6.5487e-05\n",
      "Epoch 130/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0669 - metrics_pearsonr: 4.4528e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 6.5532e-05\n",
      "Epoch 131/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0659 - metrics_pearsonr: 4.4506e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 6.5855e-05\n",
      "Epoch 132/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0648 - metrics_pearsonr: 4.4589e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 6.6509e-05\n",
      "Epoch 133/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0641 - metrics_pearsonr: 4.4727e-05 - val_loss: 0.0663 - val_metrics_pearsonr: 6.6976e-05\n",
      "Epoch 134/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0640 - metrics_pearsonr: 4.4747e-05 - val_loss: 0.0658 - val_metrics_pearsonr: 6.6716e-05\n",
      "Epoch 135/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0643 - metrics_pearsonr: 4.4596e-05 - val_loss: 0.0661 - val_metrics_pearsonr: 6.5999e-05\n",
      "Epoch 136/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0653 - metrics_pearsonr: 4.4423e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 6.5628e-05\n",
      "Epoch 137/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0670 - metrics_pearsonr: 4.4388e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 6.5986e-05\n",
      "Epoch 138/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0690 - metrics_pearsonr: 4.4473e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 6.6611e-05\n",
      "Epoch 139/5000\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0700 - metrics_pearsonr: 4.4530e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 6.6700e-05\n",
      "Epoch 140/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0692 - metrics_pearsonr: 4.4391e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 6.6153e-05\n",
      "Epoch 141/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0668 - metrics_pearsonr: 4.4097e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.5706e-05\n",
      "Epoch 142/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0646 - metrics_pearsonr: 4.3867e-05 - val_loss: 0.0644 - val_metrics_pearsonr: 6.5789e-05\n",
      "Epoch 143/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0638 - metrics_pearsonr: 4.3791e-05 - val_loss: 0.0636 - val_metrics_pearsonr: 6.6022e-05\n",
      "Epoch 144/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0648 - metrics_pearsonr: 4.3762e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 6.6014e-05\n",
      "Epoch 145/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0671 - metrics_pearsonr: 4.3697e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 6.5921e-05\n",
      "Epoch 146/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0701 - metrics_pearsonr: 4.3648e-05 - val_loss: 0.0824 - val_metrics_pearsonr: 6.6000e-05\n",
      "Epoch 147/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0729 - metrics_pearsonr: 4.3660e-05 - val_loss: 0.0889 - val_metrics_pearsonr: 6.6162e-05\n",
      "Epoch 148/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0741 - metrics_pearsonr: 4.3678e-05 - val_loss: 0.0896 - val_metrics_pearsonr: 6.6227e-05\n",
      "Epoch 149/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0730 - metrics_pearsonr: 4.3652e-05 - val_loss: 0.0831 - val_metrics_pearsonr: 6.6206e-05\n",
      "Epoch 150/5000\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0705 - metrics_pearsonr: 4.3614e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.6250e-05\n",
      "Epoch 151/5000\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0685 - metrics_pearsonr: 4.3633e-05 - val_loss: 0.0651 - val_metrics_pearsonr: 6.6390e-05\n",
      "Epoch 152/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0687 - metrics_pearsonr: 4.3672e-05 - val_loss: 0.0662 - val_metrics_pearsonr: 6.6572e-05\n",
      "Epoch 153/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0716 - metrics_pearsonr: 4.3681e-05 - val_loss: 0.0767 - val_metrics_pearsonr: 6.6796e-05\n",
      "Epoch 154/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0762 - metrics_pearsonr: 4.3673e-05 - val_loss: 0.0911 - val_metrics_pearsonr: 6.7051e-05\n",
      "Epoch 155/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0804 - metrics_pearsonr: 4.3722e-05 - val_loss: 0.1001 - val_metrics_pearsonr: 6.7260e-05\n",
      "Epoch 156/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0816 - metrics_pearsonr: 4.3792e-05 - val_loss: 0.0967 - val_metrics_pearsonr: 6.7275e-05\n",
      "Epoch 157/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0788 - metrics_pearsonr: 4.3787e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 6.7030e-05\n",
      "Epoch 158/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0738 - metrics_pearsonr: 4.3677e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 6.6710e-05\n",
      "Epoch 159/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0708 - metrics_pearsonr: 4.3561e-05 - val_loss: 0.0655 - val_metrics_pearsonr: 6.6625e-05\n",
      "Epoch 160/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0727 - metrics_pearsonr: 4.3542e-05 - val_loss: 0.0795 - val_metrics_pearsonr: 6.6866e-05\n",
      "Epoch 161/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0776 - metrics_pearsonr: 4.3588e-05 - val_loss: 0.0971 - val_metrics_pearsonr: 6.7207e-05\n",
      "Epoch 162/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0808 - metrics_pearsonr: 4.3602e-05 - val_loss: 0.1022 - val_metrics_pearsonr: 6.7492e-05\n",
      "Epoch 163/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0795 - metrics_pearsonr: 4.3626e-05 - val_loss: 0.0905 - val_metrics_pearsonr: 6.7867e-05\n",
      "Epoch 164/5000\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0754 - metrics_pearsonr: 4.3755e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 6.8177e-05\n",
      "Epoch 165/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0720 - metrics_pearsonr: 4.3857e-05 - val_loss: 0.0664 - val_metrics_pearsonr: 6.7838e-05\n",
      "Epoch 166/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0714 - metrics_pearsonr: 4.3684e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 6.7243e-05\n",
      "Epoch 167/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0736 - metrics_pearsonr: 4.3446e-05 - val_loss: 0.0871 - val_metrics_pearsonr: 6.7191e-05\n",
      "Epoch 168/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0756 - metrics_pearsonr: 4.3414e-05 - val_loss: 0.0882 - val_metrics_pearsonr: 6.7318e-05\n",
      "Epoch 169/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0738 - metrics_pearsonr: 4.3349e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 6.7073e-05\n",
      "Epoch 170/5000\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0691 - metrics_pearsonr: 4.3120e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.6628e-05\n",
      "Epoch 171/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0661 - metrics_pearsonr: 4.2876e-05 - val_loss: 0.0660 - val_metrics_pearsonr: 6.6557e-05\n",
      "Epoch 172/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0666 - metrics_pearsonr: 4.2738e-05 - val_loss: 0.0760 - val_metrics_pearsonr: 6.6811e-05\n",
      "Epoch 173/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0681 - metrics_pearsonr: 4.2696e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 6.7000e-05\n",
      "Epoch 174/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0678 - metrics_pearsonr: 4.2683e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 6.6976e-05\n",
      "Epoch 175/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0657 - metrics_pearsonr: 4.2652e-05 - val_loss: 0.0667 - val_metrics_pearsonr: 6.6881e-05\n",
      "Epoch 176/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0637 - metrics_pearsonr: 4.2602e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 6.6872e-05\n",
      "Epoch 177/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0635 - metrics_pearsonr: 4.2535e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 6.6973e-05\n",
      "Epoch 178/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0642 - metrics_pearsonr: 4.2491e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 6.7026e-05\n",
      "Epoch 179/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0641 - metrics_pearsonr: 4.2444e-05 - val_loss: 0.0708 - val_metrics_pearsonr: 6.6916e-05\n",
      "Epoch 180/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0628 - metrics_pearsonr: 4.2372e-05 - val_loss: 0.0657 - val_metrics_pearsonr: 6.6706e-05\n",
      "Epoch 181/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0613 - metrics_pearsonr: 4.2285e-05 - val_loss: 0.0633 - val_metrics_pearsonr: 6.6586e-05\n",
      "Epoch 182/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0607 - metrics_pearsonr: 4.2199e-05 - val_loss: 0.0655 - val_metrics_pearsonr: 6.6630e-05\n",
      "Epoch 183/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0611 - metrics_pearsonr: 4.2149e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.6760e-05\n",
      "Epoch 184/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0614 - metrics_pearsonr: 4.2124e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 6.6840e-05\n",
      "Epoch 185/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0611 - metrics_pearsonr: 4.2095e-05 - val_loss: 0.0666 - val_metrics_pearsonr: 6.6874e-05\n",
      "Epoch 186/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0603 - metrics_pearsonr: 4.2065e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 6.6972e-05\n",
      "Epoch 187/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0599 - metrics_pearsonr: 4.2033e-05 - val_loss: 0.0643 - val_metrics_pearsonr: 6.7079e-05\n",
      "Epoch 188/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0599 - metrics_pearsonr: 4.1996e-05 - val_loss: 0.0660 - val_metrics_pearsonr: 6.7120e-05\n",
      "Epoch 189/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0601 - metrics_pearsonr: 4.1960e-05 - val_loss: 0.0667 - val_metrics_pearsonr: 6.7048e-05\n",
      "Epoch 190/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0599 - metrics_pearsonr: 4.1913e-05 - val_loss: 0.0657 - val_metrics_pearsonr: 6.6939e-05\n",
      "Epoch 191/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0595 - metrics_pearsonr: 4.1865e-05 - val_loss: 0.0641 - val_metrics_pearsonr: 6.6883e-05\n",
      "Epoch 192/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0590 - metrics_pearsonr: 4.1817e-05 - val_loss: 0.0635 - val_metrics_pearsonr: 6.6908e-05\n",
      "Epoch 193/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0588 - metrics_pearsonr: 4.1770e-05 - val_loss: 0.0644 - val_metrics_pearsonr: 6.6962e-05\n",
      "Epoch 194/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0589 - metrics_pearsonr: 4.1738e-05 - val_loss: 0.0656 - val_metrics_pearsonr: 6.7007e-05\n",
      "Epoch 195/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0590 - metrics_pearsonr: 4.1708e-05 - val_loss: 0.0660 - val_metrics_pearsonr: 6.7054e-05\n",
      "Epoch 196/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0589 - metrics_pearsonr: 4.1678e-05 - val_loss: 0.0653 - val_metrics_pearsonr: 6.7135e-05\n",
      "Epoch 197/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0586 - metrics_pearsonr: 4.1653e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.7234e-05\n",
      "Epoch 198/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0585 - metrics_pearsonr: 4.1632e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 6.7298e-05\n",
      "Epoch 199/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0584 - metrics_pearsonr: 4.1602e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.7290e-05\n",
      "Epoch 200/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0585 - metrics_pearsonr: 4.1566e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.7229e-05\n",
      "Epoch 201/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0586 - metrics_pearsonr: 4.1526e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.7198e-05\n",
      "Epoch 202/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0585 - metrics_pearsonr: 4.1497e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.7209e-05\n",
      "Epoch 203/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0583 - metrics_pearsonr: 4.1465e-05 - val_loss: 0.0640 - val_metrics_pearsonr: 6.7244e-05\n",
      "Epoch 204/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0581 - metrics_pearsonr: 4.1434e-05 - val_loss: 0.0639 - val_metrics_pearsonr: 6.7277e-05\n",
      "Epoch 205/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0580 - metrics_pearsonr: 4.1398e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 6.7292e-05\n",
      "Epoch 206/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0579 - metrics_pearsonr: 4.1356e-05 - val_loss: 0.0647 - val_metrics_pearsonr: 6.7313e-05\n",
      "Epoch 207/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0580 - metrics_pearsonr: 4.1315e-05 - val_loss: 0.0651 - val_metrics_pearsonr: 6.7363e-05\n",
      "Epoch 208/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0579 - metrics_pearsonr: 4.1279e-05 - val_loss: 0.0652 - val_metrics_pearsonr: 6.7457e-05\n",
      "Epoch 209/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0579 - metrics_pearsonr: 4.1263e-05 - val_loss: 0.0650 - val_metrics_pearsonr: 6.7560e-05\n",
      "Epoch 210/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0578 - metrics_pearsonr: 4.1251e-05 - val_loss: 0.0647 - val_metrics_pearsonr: 6.7627e-05\n",
      "Epoch 211/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0578 - metrics_pearsonr: 4.1236e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.7623e-05\n",
      "Epoch 212/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0578 - metrics_pearsonr: 4.1209e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.7566e-05\n",
      "Epoch 213/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0579 - metrics_pearsonr: 4.1173e-05 - val_loss: 0.0646 - val_metrics_pearsonr: 6.7518e-05\n",
      "Epoch 214/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0580 - metrics_pearsonr: 4.1144e-05 - val_loss: 0.0647 - val_metrics_pearsonr: 6.7523e-05\n",
      "Epoch 215/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0580 - metrics_pearsonr: 4.1120e-05 - val_loss: 0.0647 - val_metrics_pearsonr: 6.7580e-05\n",
      "Epoch 216/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0580 - metrics_pearsonr: 4.1101e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.7636e-05\n",
      "Epoch 217/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0578 - metrics_pearsonr: 4.1071e-05 - val_loss: 0.0643 - val_metrics_pearsonr: 6.7659e-05\n",
      "Epoch 218/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0576 - metrics_pearsonr: 4.1029e-05 - val_loss: 0.0642 - val_metrics_pearsonr: 6.7649e-05\n",
      "Epoch 219/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0575 - metrics_pearsonr: 4.0977e-05 - val_loss: 0.0644 - val_metrics_pearsonr: 6.7638e-05\n",
      "Epoch 220/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0574 - metrics_pearsonr: 4.0927e-05 - val_loss: 0.0648 - val_metrics_pearsonr: 6.7669e-05\n",
      "Epoch 221/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0574 - metrics_pearsonr: 4.0889e-05 - val_loss: 0.0652 - val_metrics_pearsonr: 6.7752e-05\n",
      "Epoch 222/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0575 - metrics_pearsonr: 4.0869e-05 - val_loss: 0.0656 - val_metrics_pearsonr: 6.7861e-05\n",
      "Epoch 223/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0575 - metrics_pearsonr: 4.0860e-05 - val_loss: 0.0656 - val_metrics_pearsonr: 6.7950e-05\n",
      "Epoch 224/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0575 - metrics_pearsonr: 4.0852e-05 - val_loss: 0.0653 - val_metrics_pearsonr: 6.7981e-05\n",
      "Epoch 225/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0575 - metrics_pearsonr: 4.0835e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.7949e-05\n",
      "Epoch 226/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0575 - metrics_pearsonr: 4.0803e-05 - val_loss: 0.0646 - val_metrics_pearsonr: 6.7886e-05\n",
      "Epoch 227/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0575 - metrics_pearsonr: 4.0772e-05 - val_loss: 0.0646 - val_metrics_pearsonr: 6.7841e-05\n",
      "Epoch 228/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0577 - metrics_pearsonr: 4.0744e-05 - val_loss: 0.0648 - val_metrics_pearsonr: 6.7847e-05\n",
      "Epoch 229/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0579 - metrics_pearsonr: 4.0726e-05 - val_loss: 0.0653 - val_metrics_pearsonr: 6.7897e-05\n",
      "Epoch 230/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0580 - metrics_pearsonr: 4.0712e-05 - val_loss: 0.0656 - val_metrics_pearsonr: 6.7967e-05\n",
      "Epoch 231/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0580 - metrics_pearsonr: 4.0692e-05 - val_loss: 0.0656 - val_metrics_pearsonr: 6.8020e-05\n",
      "Epoch 232/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0579 - metrics_pearsonr: 4.0660e-05 - val_loss: 0.0652 - val_metrics_pearsonr: 6.8032e-05\n",
      "Epoch 233/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0576 - metrics_pearsonr: 4.0612e-05 - val_loss: 0.0648 - val_metrics_pearsonr: 6.8014e-05\n",
      "Epoch 234/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0573 - metrics_pearsonr: 4.0556e-05 - val_loss: 0.0644 - val_metrics_pearsonr: 6.7993e-05\n",
      "Epoch 235/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0571 - metrics_pearsonr: 4.0502e-05 - val_loss: 0.0645 - val_metrics_pearsonr: 6.8009e-05\n",
      "Epoch 236/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0571 - metrics_pearsonr: 4.0462e-05 - val_loss: 0.0651 - val_metrics_pearsonr: 6.8073e-05\n",
      "Epoch 237/5000\n",
      "3/3 [==============================] - 0s 180ms/step - loss: 0.0572 - metrics_pearsonr: 4.0436e-05 - val_loss: 0.0659 - val_metrics_pearsonr: 6.8169e-05\n",
      "Epoch 238/5000\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0575 - metrics_pearsonr: 4.0423e-05 - val_loss: 0.0668 - val_metrics_pearsonr: 6.8273e-05\n",
      "Epoch 239/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0577 - metrics_pearsonr: 4.0416e-05 - val_loss: 0.0673 - val_metrics_pearsonr: 6.8351e-05\n",
      "Epoch 240/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0578 - metrics_pearsonr: 4.0406e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 6.8385e-05\n",
      "Epoch 241/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0578 - metrics_pearsonr: 4.0392e-05 - val_loss: 0.0668 - val_metrics_pearsonr: 6.8368e-05\n",
      "Epoch 242/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0576 - metrics_pearsonr: 4.0370e-05 - val_loss: 0.0660 - val_metrics_pearsonr: 6.8320e-05\n",
      "Epoch 243/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0576 - metrics_pearsonr: 4.0342e-05 - val_loss: 0.0652 - val_metrics_pearsonr: 6.8261e-05\n",
      "Epoch 244/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0576 - metrics_pearsonr: 4.0316e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.8219e-05\n",
      "Epoch 245/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0579 - metrics_pearsonr: 4.0294e-05 - val_loss: 0.0654 - val_metrics_pearsonr: 6.8228e-05\n",
      "Epoch 246/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0585 - metrics_pearsonr: 4.0283e-05 - val_loss: 0.0665 - val_metrics_pearsonr: 6.8285e-05\n",
      "Epoch 247/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0592 - metrics_pearsonr: 4.0281e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 6.8379e-05\n",
      "Epoch 248/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0598 - metrics_pearsonr: 4.0284e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 6.8468e-05\n",
      "Epoch 249/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0602 - metrics_pearsonr: 4.0279e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 6.8533e-05\n",
      "Epoch 250/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0601 - metrics_pearsonr: 4.0255e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 6.8549e-05\n",
      "Epoch 251/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0595 - metrics_pearsonr: 4.0206e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 6.8524e-05\n",
      "Epoch 252/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0587 - metrics_pearsonr: 4.0144e-05 - val_loss: 0.0665 - val_metrics_pearsonr: 6.8484e-05\n",
      "Epoch 253/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0580 - metrics_pearsonr: 4.0083e-05 - val_loss: 0.0651 - val_metrics_pearsonr: 6.8476e-05\n",
      "Epoch 254/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0577 - metrics_pearsonr: 4.0031e-05 - val_loss: 0.0649 - val_metrics_pearsonr: 6.8518e-05\n",
      "Epoch 255/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0581 - metrics_pearsonr: 3.9998e-05 - val_loss: 0.0663 - val_metrics_pearsonr: 6.8609e-05\n",
      "Epoch 256/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0592 - metrics_pearsonr: 3.9980e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 6.8726e-05\n",
      "Epoch 257/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0606 - metrics_pearsonr: 3.9972e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.8848e-05\n",
      "Epoch 258/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0621 - metrics_pearsonr: 3.9967e-05 - val_loss: 0.0766 - val_metrics_pearsonr: 6.8953e-05\n",
      "Epoch 259/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0631 - metrics_pearsonr: 3.9968e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 6.9032e-05\n",
      "Epoch 260/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0636 - metrics_pearsonr: 3.9973e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 6.9072e-05\n",
      "Epoch 261/5000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0633 - metrics_pearsonr: 3.9984e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 6.9067e-05\n",
      "Epoch 262/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0625 - metrics_pearsonr: 3.9992e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 6.9013e-05\n",
      "Epoch 263/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0617 - metrics_pearsonr: 3.9992e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 6.8928e-05\n",
      "Epoch 264/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0617 - metrics_pearsonr: 3.9984e-05 - val_loss: 0.0669 - val_metrics_pearsonr: 6.8860e-05\n",
      "Epoch 265/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0629 - metrics_pearsonr: 3.9979e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 6.8869e-05\n",
      "Epoch 266/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0657 - metrics_pearsonr: 4.0000e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 6.9012e-05\n",
      "Epoch 267/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0698 - metrics_pearsonr: 4.0070e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 6.9268e-05\n",
      "Epoch 268/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0740 - metrics_pearsonr: 4.0173e-05 - val_loss: 0.0946 - val_metrics_pearsonr: 6.9549e-05\n",
      "Epoch 269/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0768 - metrics_pearsonr: 4.0266e-05 - val_loss: 0.0994 - val_metrics_pearsonr: 6.9696e-05\n",
      "Epoch 270/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0767 - metrics_pearsonr: 4.0290e-05 - val_loss: 0.0960 - val_metrics_pearsonr: 6.9664e-05\n",
      "Epoch 271/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0739 - metrics_pearsonr: 4.0236e-05 - val_loss: 0.0853 - val_metrics_pearsonr: 6.9584e-05\n",
      "Epoch 272/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0700 - metrics_pearsonr: 4.0170e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 6.9674e-05\n",
      "Epoch 273/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0678 - metrics_pearsonr: 4.0163e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 6.9974e-05\n",
      "Epoch 274/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0691 - metrics_pearsonr: 4.0195e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.0359e-05\n",
      "Epoch 275/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0739 - metrics_pearsonr: 4.0246e-05 - val_loss: 0.0935 - val_metrics_pearsonr: 7.0724e-05\n",
      "Epoch 276/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0800 - metrics_pearsonr: 4.0368e-05 - val_loss: 0.1099 - val_metrics_pearsonr: 7.0967e-05\n",
      "Epoch 277/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0842 - metrics_pearsonr: 4.0560e-05 - val_loss: 0.1128 - val_metrics_pearsonr: 7.0845e-05\n",
      "Epoch 278/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0837 - metrics_pearsonr: 4.0715e-05 - val_loss: 0.0984 - val_metrics_pearsonr: 7.0371e-05\n",
      "Epoch 279/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0795 - metrics_pearsonr: 4.0724e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 7.0121e-05\n",
      "Epoch 280/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0764 - metrics_pearsonr: 4.0718e-05 - val_loss: 0.0793 - val_metrics_pearsonr: 7.0664e-05\n",
      "Epoch 281/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0774 - metrics_pearsonr: 4.0913e-05 - val_loss: 0.0927 - val_metrics_pearsonr: 7.1550e-05\n",
      "Epoch 282/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0800 - metrics_pearsonr: 4.1198e-05 - val_loss: 0.1004 - val_metrics_pearsonr: 7.1695e-05\n",
      "Epoch 283/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0793 - metrics_pearsonr: 4.1340e-05 - val_loss: 0.0898 - val_metrics_pearsonr: 7.1147e-05\n",
      "Epoch 284/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0750 - metrics_pearsonr: 4.1327e-05 - val_loss: 0.0759 - val_metrics_pearsonr: 7.1268e-05\n",
      "Epoch 285/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0714 - metrics_pearsonr: 4.1248e-05 - val_loss: 0.0784 - val_metrics_pearsonr: 7.2541e-05\n",
      "Epoch 286/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0705 - metrics_pearsonr: 4.1192e-05 - val_loss: 0.0880 - val_metrics_pearsonr: 7.3379e-05\n",
      "Epoch 287/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0699 - metrics_pearsonr: 4.1181e-05 - val_loss: 0.0836 - val_metrics_pearsonr: 7.2434e-05\n",
      "Epoch 288/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0671 - metrics_pearsonr: 4.1046e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.0617e-05\n",
      "Epoch 289/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0639 - metrics_pearsonr: 4.0677e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 7.0147e-05\n",
      "Epoch 290/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0635 - metrics_pearsonr: 4.0494e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.0972e-05\n",
      "Epoch 291/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0643 - metrics_pearsonr: 4.0587e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.1130e-05\n",
      "Epoch 292/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0633 - metrics_pearsonr: 4.0481e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.0364e-05\n",
      "Epoch 293/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0613 - metrics_pearsonr: 4.0119e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 6.9952e-05\n",
      "Epoch 294/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0601 - metrics_pearsonr: 3.9811e-05 - val_loss: 0.0708 - val_metrics_pearsonr: 7.0270e-05\n",
      "Epoch 295/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0596 - metrics_pearsonr: 3.9737e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.0712e-05\n",
      "Epoch 296/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0592 - metrics_pearsonr: 3.9772e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.0905e-05\n",
      "Epoch 297/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0595 - metrics_pearsonr: 3.9757e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.0748e-05\n",
      "Epoch 298/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0598 - metrics_pearsonr: 3.9660e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.0195e-05\n",
      "Epoch 299/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0597 - metrics_pearsonr: 3.9550e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 6.9590e-05\n",
      "Epoch 300/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0592 - metrics_pearsonr: 3.9482e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 6.9564e-05\n",
      "Epoch 301/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0589 - metrics_pearsonr: 3.9509e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.0252e-05\n",
      "Epoch 302/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0588 - metrics_pearsonr: 3.9610e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.0839e-05\n",
      "Epoch 303/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0585 - metrics_pearsonr: 3.9647e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.0525e-05\n",
      "Epoch 304/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0579 - metrics_pearsonr: 3.9520e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 6.9743e-05\n",
      "Epoch 305/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0577 - metrics_pearsonr: 3.9341e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 6.9635e-05\n",
      "Epoch 306/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0579 - metrics_pearsonr: 3.9288e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 7.0364e-05\n",
      "Epoch 307/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0580 - metrics_pearsonr: 3.9368e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.0882e-05\n",
      "Epoch 308/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0578 - metrics_pearsonr: 3.9374e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 7.0514e-05\n",
      "Epoch 309/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0573 - metrics_pearsonr: 3.9218e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 6.9799e-05\n",
      "Epoch 310/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0568 - metrics_pearsonr: 3.9023e-05 - val_loss: 0.0664 - val_metrics_pearsonr: 6.9495e-05\n",
      "Epoch 311/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0567 - metrics_pearsonr: 3.8897e-05 - val_loss: 0.0659 - val_metrics_pearsonr: 6.9587e-05\n",
      "Epoch 312/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0568 - metrics_pearsonr: 3.8831e-05 - val_loss: 0.0666 - val_metrics_pearsonr: 6.9710e-05\n",
      "Epoch 313/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0572 - metrics_pearsonr: 3.8774e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 6.9736e-05\n",
      "Epoch 314/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0576 - metrics_pearsonr: 3.8710e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 6.9743e-05\n",
      "Epoch 315/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0576 - metrics_pearsonr: 3.8653e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 6.9758e-05\n",
      "Epoch 316/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0572 - metrics_pearsonr: 3.8606e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 6.9760e-05\n",
      "Epoch 317/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0567 - metrics_pearsonr: 3.8568e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 6.9733e-05\n",
      "Epoch 318/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0562 - metrics_pearsonr: 3.8530e-05 - val_loss: 0.0661 - val_metrics_pearsonr: 6.9683e-05\n",
      "Epoch 319/5000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0561 - metrics_pearsonr: 3.8499e-05 - val_loss: 0.0660 - val_metrics_pearsonr: 6.9662e-05\n",
      "Epoch 320/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0563 - metrics_pearsonr: 3.8481e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 6.9692e-05\n",
      "Epoch 321/5000\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0568 - metrics_pearsonr: 3.8477e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 6.9758e-05\n",
      "Epoch 322/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0576 - metrics_pearsonr: 3.8482e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 6.9843e-05\n",
      "Epoch 323/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0581 - metrics_pearsonr: 3.8491e-05 - val_loss: 0.0727 - val_metrics_pearsonr: 6.9903e-05\n",
      "Epoch 324/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0582 - metrics_pearsonr: 3.8491e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 6.9930e-05\n",
      "Epoch 325/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0579 - metrics_pearsonr: 3.8483e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 6.9920e-05\n",
      "Epoch 326/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0573 - metrics_pearsonr: 3.8467e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 6.9907e-05\n",
      "Epoch 327/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0568 - metrics_pearsonr: 3.8446e-05 - val_loss: 0.0665 - val_metrics_pearsonr: 6.9913e-05\n",
      "Epoch 328/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0569 - metrics_pearsonr: 3.8429e-05 - val_loss: 0.0665 - val_metrics_pearsonr: 6.9965e-05\n",
      "Epoch 329/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0576 - metrics_pearsonr: 3.8415e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.0066e-05\n",
      "Epoch 330/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0587 - metrics_pearsonr: 3.8413e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 7.0199e-05\n",
      "Epoch 331/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0599 - metrics_pearsonr: 3.8422e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.0334e-05\n",
      "Epoch 332/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0607 - metrics_pearsonr: 3.8432e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.0430e-05\n",
      "Epoch 333/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0606 - metrics_pearsonr: 3.8435e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.0432e-05\n",
      "Epoch 334/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0598 - metrics_pearsonr: 3.8417e-05 - val_loss: 0.0713 - val_metrics_pearsonr: 7.0341e-05\n",
      "Epoch 335/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0585 - metrics_pearsonr: 3.8374e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.0188e-05\n",
      "Epoch 336/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0577 - metrics_pearsonr: 3.8330e-05 - val_loss: 0.0661 - val_metrics_pearsonr: 7.0067e-05\n",
      "Epoch 337/5000\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0579 - metrics_pearsonr: 3.8307e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.0061e-05\n",
      "Epoch 338/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0594 - metrics_pearsonr: 3.8316e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.0209e-05\n",
      "Epoch 339/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0616 - metrics_pearsonr: 3.8353e-05 - val_loss: 0.0787 - val_metrics_pearsonr: 7.0485e-05\n",
      "Epoch 340/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0636 - metrics_pearsonr: 3.8406e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 7.0791e-05\n",
      "Epoch 341/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0647 - metrics_pearsonr: 3.8460e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 7.0996e-05\n",
      "Epoch 342/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0644 - metrics_pearsonr: 3.8505e-05 - val_loss: 0.0828 - val_metrics_pearsonr: 7.1014e-05\n",
      "Epoch 343/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0630 - metrics_pearsonr: 3.8529e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.0855e-05\n",
      "Epoch 344/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0614 - metrics_pearsonr: 3.8515e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.0632e-05\n",
      "Epoch 345/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0607 - metrics_pearsonr: 3.8466e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 7.0526e-05\n",
      "Epoch 346/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0619 - metrics_pearsonr: 3.8425e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.0676e-05\n",
      "Epoch 347/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0650 - metrics_pearsonr: 3.8440e-05 - val_loss: 0.0805 - val_metrics_pearsonr: 7.1049e-05\n",
      "Epoch 348/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0688 - metrics_pearsonr: 3.8494e-05 - val_loss: 0.0903 - val_metrics_pearsonr: 7.1440e-05\n",
      "Epoch 349/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0712 - metrics_pearsonr: 3.8539e-05 - val_loss: 0.0942 - val_metrics_pearsonr: 7.1585e-05\n",
      "Epoch 350/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0707 - metrics_pearsonr: 3.8511e-05 - val_loss: 0.0891 - val_metrics_pearsonr: 7.1388e-05\n",
      "Epoch 351/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0677 - metrics_pearsonr: 3.8418e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 7.1018e-05\n",
      "Epoch 352/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0644 - metrics_pearsonr: 3.8333e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.0739e-05\n",
      "Epoch 353/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0632 - metrics_pearsonr: 3.8295e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.0705e-05\n",
      "Epoch 354/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0654 - metrics_pearsonr: 3.8314e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.0945e-05\n",
      "Epoch 355/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0699 - metrics_pearsonr: 3.8394e-05 - val_loss: 0.0950 - val_metrics_pearsonr: 7.1366e-05\n",
      "Epoch 356/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0739 - metrics_pearsonr: 3.8511e-05 - val_loss: 0.1036 - val_metrics_pearsonr: 7.1573e-05\n",
      "Epoch 357/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0744 - metrics_pearsonr: 3.8551e-05 - val_loss: 0.0973 - val_metrics_pearsonr: 7.1354e-05\n",
      "Epoch 358/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0711 - metrics_pearsonr: 3.8487e-05 - val_loss: 0.0811 - val_metrics_pearsonr: 7.1109e-05\n",
      "Epoch 359/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0672 - metrics_pearsonr: 3.8437e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.1266e-05\n",
      "Epoch 360/5000\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0662 - metrics_pearsonr: 3.8454e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 7.1711e-05\n",
      "Epoch 361/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0685 - metrics_pearsonr: 3.8473e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 7.1986e-05\n",
      "Epoch 362/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0717 - metrics_pearsonr: 3.8434e-05 - val_loss: 0.0962 - val_metrics_pearsonr: 7.1856e-05\n",
      "Epoch 363/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0725 - metrics_pearsonr: 3.8417e-05 - val_loss: 0.0924 - val_metrics_pearsonr: 7.1419e-05\n",
      "Epoch 364/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0699 - metrics_pearsonr: 3.8395e-05 - val_loss: 0.0778 - val_metrics_pearsonr: 7.0953e-05\n",
      "Epoch 365/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0657 - metrics_pearsonr: 3.8283e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 7.0863e-05\n",
      "Epoch 366/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0636 - metrics_pearsonr: 3.8188e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.1235e-05\n",
      "Epoch 367/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0650 - metrics_pearsonr: 3.8205e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 7.1551e-05\n",
      "Epoch 368/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0670 - metrics_pearsonr: 3.8243e-05 - val_loss: 0.0887 - val_metrics_pearsonr: 7.1325e-05\n",
      "Epoch 369/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0663 - metrics_pearsonr: 3.8185e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 7.1203e-05\n",
      "Epoch 370/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0636 - metrics_pearsonr: 3.8182e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.2036e-05\n",
      "Epoch 371/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0618 - metrics_pearsonr: 3.8397e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.2821e-05\n",
      "Epoch 372/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0614 - metrics_pearsonr: 3.8500e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 7.2184e-05\n",
      "Epoch 373/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0614 - metrics_pearsonr: 3.8304e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.1016e-05\n",
      "Epoch 374/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0613 - metrics_pearsonr: 3.8138e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.0759e-05\n",
      "Epoch 375/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0606 - metrics_pearsonr: 3.8135e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.1333e-05\n",
      "Epoch 376/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0591 - metrics_pearsonr: 3.8117e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.1408e-05\n",
      "Epoch 377/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0580 - metrics_pearsonr: 3.7983e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.0818e-05\n",
      "Epoch 378/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0574 - metrics_pearsonr: 3.7735e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.0655e-05\n",
      "Epoch 379/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0572 - metrics_pearsonr: 3.7592e-05 - val_loss: 0.0713 - val_metrics_pearsonr: 7.1156e-05\n",
      "Epoch 380/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0569 - metrics_pearsonr: 3.7589e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.1397e-05\n",
      "Epoch 381/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0565 - metrics_pearsonr: 3.7561e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.1075e-05\n",
      "Epoch 382/5000\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0560 - metrics_pearsonr: 3.7449e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.0677e-05\n",
      "Epoch 383/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0556 - metrics_pearsonr: 3.7328e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 7.0512e-05\n",
      "Epoch 384/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0555 - metrics_pearsonr: 3.7237e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 7.0536e-05\n",
      "Epoch 385/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0555 - metrics_pearsonr: 3.7189e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 7.0614e-05\n",
      "Epoch 386/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0556 - metrics_pearsonr: 3.7138e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.0670e-05\n",
      "Epoch 387/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0554 - metrics_pearsonr: 3.7101e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.0646e-05\n",
      "Epoch 388/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0550 - metrics_pearsonr: 3.7066e-05 - val_loss: 0.0672 - val_metrics_pearsonr: 7.0569e-05\n",
      "Epoch 389/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0545 - metrics_pearsonr: 3.7034e-05 - val_loss: 0.0667 - val_metrics_pearsonr: 7.0523e-05\n",
      "Epoch 390/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0543 - metrics_pearsonr: 3.7014e-05 - val_loss: 0.0672 - val_metrics_pearsonr: 7.0552e-05\n",
      "Epoch 391/5000\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0543 - metrics_pearsonr: 3.6999e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.0657e-05\n",
      "Epoch 392/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0544 - metrics_pearsonr: 3.6988e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.0766e-05\n",
      "Epoch 393/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0543 - metrics_pearsonr: 3.6975e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.0820e-05\n",
      "Epoch 394/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0542 - metrics_pearsonr: 3.6953e-05 - val_loss: 0.0675 - val_metrics_pearsonr: 7.0795e-05\n",
      "Epoch 395/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0541 - metrics_pearsonr: 3.6927e-05 - val_loss: 0.0669 - val_metrics_pearsonr: 7.0709e-05\n",
      "Epoch 396/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0542 - metrics_pearsonr: 3.6893e-05 - val_loss: 0.0669 - val_metrics_pearsonr: 7.0632e-05\n",
      "Epoch 397/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0543 - metrics_pearsonr: 3.6865e-05 - val_loss: 0.0672 - val_metrics_pearsonr: 7.0608e-05\n",
      "Epoch 398/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0544 - metrics_pearsonr: 3.6849e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.0621e-05\n",
      "Epoch 399/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0545 - metrics_pearsonr: 3.6830e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.0624e-05\n",
      "Epoch 400/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0543 - metrics_pearsonr: 3.6806e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 7.0617e-05\n",
      "Epoch 401/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0540 - metrics_pearsonr: 3.6770e-05 - val_loss: 0.0669 - val_metrics_pearsonr: 7.0635e-05\n",
      "Epoch 402/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0537 - metrics_pearsonr: 3.6738e-05 - val_loss: 0.0667 - val_metrics_pearsonr: 7.0672e-05\n",
      "Epoch 403/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0536 - metrics_pearsonr: 3.6709e-05 - val_loss: 0.0669 - val_metrics_pearsonr: 7.0720e-05\n",
      "Epoch 404/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0537 - metrics_pearsonr: 3.6687e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.0754e-05\n",
      "Epoch 405/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0538 - metrics_pearsonr: 3.6668e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.0774e-05\n",
      "Epoch 406/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0539 - metrics_pearsonr: 3.6650e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.0784e-05\n",
      "Epoch 407/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0540 - metrics_pearsonr: 3.6636e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.0785e-05\n",
      "Epoch 408/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0539 - metrics_pearsonr: 3.6621e-05 - val_loss: 0.0675 - val_metrics_pearsonr: 7.0777e-05\n",
      "Epoch 409/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0538 - metrics_pearsonr: 3.6604e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 7.0765e-05\n",
      "Epoch 410/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0539 - metrics_pearsonr: 3.6588e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 7.0753e-05\n",
      "Epoch 411/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0540 - metrics_pearsonr: 3.6571e-05 - val_loss: 0.0674 - val_metrics_pearsonr: 7.0751e-05\n",
      "Epoch 412/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0542 - metrics_pearsonr: 3.6556e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.0767e-05\n",
      "Epoch 413/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0544 - metrics_pearsonr: 3.6544e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.0792e-05\n",
      "Epoch 414/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0544 - metrics_pearsonr: 3.6532e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.0816e-05\n",
      "Epoch 415/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0542 - metrics_pearsonr: 3.6513e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.0828e-05\n",
      "Epoch 416/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0539 - metrics_pearsonr: 3.6486e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 7.0828e-05\n",
      "Epoch 417/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0536 - metrics_pearsonr: 3.6454e-05 - val_loss: 0.0668 - val_metrics_pearsonr: 7.0827e-05\n",
      "Epoch 418/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0535 - metrics_pearsonr: 3.6425e-05 - val_loss: 0.0670 - val_metrics_pearsonr: 7.0843e-05\n",
      "Epoch 419/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0536 - metrics_pearsonr: 3.6400e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.0884e-05\n",
      "Epoch 420/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0539 - metrics_pearsonr: 3.6385e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.0937e-05\n",
      "Epoch 421/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0541 - metrics_pearsonr: 3.6378e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.1001e-05\n",
      "Epoch 422/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0543 - metrics_pearsonr: 3.6374e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.1047e-05\n",
      "Epoch 423/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0543 - metrics_pearsonr: 3.6371e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.1064e-05\n",
      "Epoch 424/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0542 - metrics_pearsonr: 3.6364e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.1044e-05\n",
      "Epoch 425/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0540 - metrics_pearsonr: 3.6350e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.1001e-05\n",
      "Epoch 426/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0540 - metrics_pearsonr: 3.6334e-05 - val_loss: 0.0673 - val_metrics_pearsonr: 7.0960e-05\n",
      "Epoch 427/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0543 - metrics_pearsonr: 3.6316e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.0945e-05\n",
      "Epoch 428/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0548 - metrics_pearsonr: 3.6307e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.0979e-05\n",
      "Epoch 429/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0554 - metrics_pearsonr: 3.6303e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.1045e-05\n",
      "Epoch 430/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0558 - metrics_pearsonr: 3.6304e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.1118e-05\n",
      "Epoch 431/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0560 - metrics_pearsonr: 3.6301e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 7.1175e-05\n",
      "Epoch 432/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0557 - metrics_pearsonr: 3.6286e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.1183e-05\n",
      "Epoch 433/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0551 - metrics_pearsonr: 3.6251e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.1151e-05\n",
      "Epoch 434/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0545 - metrics_pearsonr: 3.6209e-05 - val_loss: 0.0675 - val_metrics_pearsonr: 7.1100e-05\n",
      "Epoch 435/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0541 - metrics_pearsonr: 3.6169e-05 - val_loss: 0.0671 - val_metrics_pearsonr: 7.1075e-05\n",
      "Epoch 436/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0543 - metrics_pearsonr: 3.6141e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.1108e-05\n",
      "Epoch 437/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0550 - metrics_pearsonr: 3.6130e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.1198e-05\n",
      "Epoch 438/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0561 - metrics_pearsonr: 3.6138e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.1331e-05\n",
      "Epoch 439/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0571 - metrics_pearsonr: 3.6153e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.1481e-05\n",
      "Epoch 440/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0578 - metrics_pearsonr: 3.6177e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.1601e-05\n",
      "Epoch 441/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0578 - metrics_pearsonr: 3.6197e-05 - val_loss: 0.0768 - val_metrics_pearsonr: 7.1662e-05\n",
      "Epoch 442/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0574 - metrics_pearsonr: 3.6214e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.1640e-05\n",
      "Epoch 443/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0567 - metrics_pearsonr: 3.6216e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.1532e-05\n",
      "Epoch 444/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0563 - metrics_pearsonr: 3.6202e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.1393e-05\n",
      "Epoch 445/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0566 - metrics_pearsonr: 3.6180e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 7.1296e-05\n",
      "Epoch 446/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0580 - metrics_pearsonr: 3.6166e-05 - val_loss: 0.0713 - val_metrics_pearsonr: 7.1330e-05\n",
      "Epoch 447/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0604 - metrics_pearsonr: 3.6183e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.1512e-05\n",
      "Epoch 448/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0632 - metrics_pearsonr: 3.6237e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 7.1774e-05\n",
      "Epoch 449/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0654 - metrics_pearsonr: 3.6299e-05 - val_loss: 0.0879 - val_metrics_pearsonr: 7.1990e-05\n",
      "Epoch 450/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0660 - metrics_pearsonr: 3.6317e-05 - val_loss: 0.0878 - val_metrics_pearsonr: 7.2043e-05\n",
      "Epoch 451/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0646 - metrics_pearsonr: 3.6270e-05 - val_loss: 0.0826 - val_metrics_pearsonr: 7.1929e-05\n",
      "Epoch 452/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0619 - metrics_pearsonr: 3.6178e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.1774e-05\n",
      "Epoch 453/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0597 - metrics_pearsonr: 3.6102e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.1682e-05\n",
      "Epoch 454/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0594 - metrics_pearsonr: 3.6075e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.1695e-05\n",
      "Epoch 455/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0619 - metrics_pearsonr: 3.6080e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.1823e-05\n",
      "Epoch 456/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0664 - metrics_pearsonr: 3.6108e-05 - val_loss: 0.0904 - val_metrics_pearsonr: 7.2034e-05\n",
      "Epoch 457/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0712 - metrics_pearsonr: 3.6159e-05 - val_loss: 0.1030 - val_metrics_pearsonr: 7.2271e-05\n",
      "Epoch 458/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0742 - metrics_pearsonr: 3.6228e-05 - val_loss: 0.1073 - val_metrics_pearsonr: 7.2399e-05\n",
      "Epoch 459/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0739 - metrics_pearsonr: 3.6289e-05 - val_loss: 0.0998 - val_metrics_pearsonr: 7.2348e-05\n",
      "Epoch 460/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0710 - metrics_pearsonr: 3.6313e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 7.2169e-05\n",
      "Epoch 461/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0678 - metrics_pearsonr: 3.6290e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.1989e-05\n",
      "Epoch 462/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0674 - metrics_pearsonr: 3.6265e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.1972e-05\n",
      "Epoch 463/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0710 - metrics_pearsonr: 3.6257e-05 - val_loss: 0.0902 - val_metrics_pearsonr: 7.2202e-05\n",
      "Epoch 464/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0766 - metrics_pearsonr: 3.6292e-05 - val_loss: 0.1068 - val_metrics_pearsonr: 7.2525e-05\n",
      "Epoch 465/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0799 - metrics_pearsonr: 3.6347e-05 - val_loss: 0.1100 - val_metrics_pearsonr: 7.2642e-05\n",
      "Epoch 466/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0779 - metrics_pearsonr: 3.6303e-05 - val_loss: 0.0960 - val_metrics_pearsonr: 7.2516e-05\n",
      "Epoch 467/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0723 - metrics_pearsonr: 3.6206e-05 - val_loss: 0.0779 - val_metrics_pearsonr: 7.2475e-05\n",
      "Epoch 468/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0680 - metrics_pearsonr: 3.6167e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.2630e-05\n",
      "Epoch 469/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0681 - metrics_pearsonr: 3.6153e-05 - val_loss: 0.0858 - val_metrics_pearsonr: 7.2814e-05\n",
      "Epoch 470/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0712 - metrics_pearsonr: 3.6163e-05 - val_loss: 0.0999 - val_metrics_pearsonr: 7.2871e-05\n",
      "Epoch 471/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0733 - metrics_pearsonr: 3.6241e-05 - val_loss: 0.0994 - val_metrics_pearsonr: 7.2698e-05\n",
      "Epoch 472/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0718 - metrics_pearsonr: 3.6305e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 7.2285e-05\n",
      "Epoch 473/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0678 - metrics_pearsonr: 3.6265e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.2019e-05\n",
      "Epoch 474/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0656 - metrics_pearsonr: 3.6228e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.2179e-05\n",
      "Epoch 475/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0663 - metrics_pearsonr: 3.6287e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 7.2381e-05\n",
      "Epoch 476/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0663 - metrics_pearsonr: 3.6242e-05 - val_loss: 0.0844 - val_metrics_pearsonr: 7.2251e-05\n",
      "Epoch 477/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0634 - metrics_pearsonr: 3.6165e-05 - val_loss: 0.0748 - val_metrics_pearsonr: 7.2178e-05\n",
      "Epoch 478/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0600 - metrics_pearsonr: 3.6074e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.2550e-05\n",
      "Epoch 479/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0586 - metrics_pearsonr: 3.6023e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.3106e-05\n",
      "Epoch 480/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0585 - metrics_pearsonr: 3.5991e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.3092e-05\n",
      "Epoch 481/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0583 - metrics_pearsonr: 3.5936e-05 - val_loss: 0.0753 - val_metrics_pearsonr: 7.2521e-05\n",
      "Epoch 482/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0572 - metrics_pearsonr: 3.5853e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 7.1940e-05\n",
      "Epoch 483/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0561 - metrics_pearsonr: 3.5757e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.1907e-05\n",
      "Epoch 484/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0559 - metrics_pearsonr: 3.5750e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.2196e-05\n",
      "Epoch 485/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0560 - metrics_pearsonr: 3.5792e-05 - val_loss: 0.0722 - val_metrics_pearsonr: 7.2206e-05\n",
      "Epoch 486/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0553 - metrics_pearsonr: 3.5734e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.1875e-05\n",
      "Epoch 487/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0541 - metrics_pearsonr: 3.5579e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1749e-05\n",
      "Epoch 488/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0532 - metrics_pearsonr: 3.5462e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.2055e-05\n",
      "Epoch 489/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0531 - metrics_pearsonr: 3.5435e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.2415e-05\n",
      "Epoch 490/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0531 - metrics_pearsonr: 3.5419e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.2398e-05\n",
      "Epoch 491/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0530 - metrics_pearsonr: 3.5360e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2020e-05\n",
      "Epoch 492/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0528 - metrics_pearsonr: 3.5273e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1645e-05\n",
      "Epoch 493/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0527 - metrics_pearsonr: 3.5204e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.1536e-05\n",
      "Epoch 494/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0528 - metrics_pearsonr: 3.5179e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.1601e-05\n",
      "Epoch 495/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0528 - metrics_pearsonr: 3.5167e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.1657e-05\n",
      "Epoch 496/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0526 - metrics_pearsonr: 3.5142e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1652e-05\n",
      "Epoch 497/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0523 - metrics_pearsonr: 3.5095e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.1630e-05\n",
      "Epoch 498/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0521 - metrics_pearsonr: 3.5039e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1652e-05\n",
      "Epoch 499/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0520 - metrics_pearsonr: 3.4996e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.1717e-05\n",
      "Epoch 500/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0520 - metrics_pearsonr: 3.4974e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.1778e-05\n",
      "Epoch 501/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0520 - metrics_pearsonr: 3.4964e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 7.1783e-05\n",
      "Epoch 502/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0520 - metrics_pearsonr: 3.4951e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 7.1736e-05\n",
      "Epoch 503/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0520 - metrics_pearsonr: 3.4931e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1663e-05\n",
      "Epoch 504/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0520 - metrics_pearsonr: 3.4905e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1621e-05\n",
      "Epoch 505/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0520 - metrics_pearsonr: 3.4881e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1615e-05\n",
      "Epoch 506/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0520 - metrics_pearsonr: 3.4864e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.1643e-05\n",
      "Epoch 507/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0520 - metrics_pearsonr: 3.4849e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.1679e-05\n",
      "Epoch 508/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0519 - metrics_pearsonr: 3.4833e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.1709e-05\n",
      "Epoch 509/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0518 - metrics_pearsonr: 3.4809e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.1719e-05\n",
      "Epoch 510/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0518 - metrics_pearsonr: 3.4782e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.1705e-05\n",
      "Epoch 511/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0517 - metrics_pearsonr: 3.4753e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1693e-05\n",
      "Epoch 512/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0517 - metrics_pearsonr: 3.4729e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1695e-05\n",
      "Epoch 513/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0517 - metrics_pearsonr: 3.4711e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1724e-05\n",
      "Epoch 514/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0517 - metrics_pearsonr: 3.4701e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.1765e-05\n",
      "Epoch 515/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0517 - metrics_pearsonr: 3.4695e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.1803e-05\n",
      "Epoch 516/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0518 - metrics_pearsonr: 3.4690e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 7.1817e-05\n",
      "Epoch 517/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0518 - metrics_pearsonr: 3.4682e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 7.1805e-05\n",
      "Epoch 518/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0517 - metrics_pearsonr: 3.4668e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.1773e-05\n",
      "Epoch 519/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0517 - metrics_pearsonr: 3.4652e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1750e-05\n",
      "Epoch 520/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0516 - metrics_pearsonr: 3.4633e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.1742e-05\n",
      "Epoch 521/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0516 - metrics_pearsonr: 3.4615e-05 - val_loss: 0.0676 - val_metrics_pearsonr: 7.1761e-05\n",
      "Epoch 522/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0516 - metrics_pearsonr: 3.4599e-05 - val_loss: 0.0677 - val_metrics_pearsonr: 7.1793e-05\n",
      "Epoch 523/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0516 - metrics_pearsonr: 3.4583e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1836e-05\n",
      "Epoch 524/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0516 - metrics_pearsonr: 3.4562e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1862e-05\n",
      "Epoch 525/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0516 - metrics_pearsonr: 3.4539e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1870e-05\n",
      "Epoch 526/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0515 - metrics_pearsonr: 3.4511e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1867e-05\n",
      "Epoch 527/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0515 - metrics_pearsonr: 3.4482e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1851e-05\n",
      "Epoch 528/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0514 - metrics_pearsonr: 3.4457e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1846e-05\n",
      "Epoch 529/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0514 - metrics_pearsonr: 3.4436e-05 - val_loss: 0.0678 - val_metrics_pearsonr: 7.1850e-05\n",
      "Epoch 530/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0514 - metrics_pearsonr: 3.4421e-05 - val_loss: 0.0679 - val_metrics_pearsonr: 7.1860e-05\n",
      "Epoch 531/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0514 - metrics_pearsonr: 3.4411e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 7.1872e-05\n",
      "Epoch 532/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0514 - metrics_pearsonr: 3.4404e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.1878e-05\n",
      "Epoch 533/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0515 - metrics_pearsonr: 3.4396e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.1877e-05\n",
      "Epoch 534/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0515 - metrics_pearsonr: 3.4386e-05 - val_loss: 0.0683 - val_metrics_pearsonr: 7.1873e-05\n",
      "Epoch 535/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0516 - metrics_pearsonr: 3.4375e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.1866e-05\n",
      "Epoch 536/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0516 - metrics_pearsonr: 3.4364e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.1860e-05\n",
      "Epoch 537/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0517 - metrics_pearsonr: 3.4351e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.1864e-05\n",
      "Epoch 538/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0517 - metrics_pearsonr: 3.4338e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.1872e-05\n",
      "Epoch 539/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0517 - metrics_pearsonr: 3.4322e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.1880e-05\n",
      "Epoch 540/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0517 - metrics_pearsonr: 3.4306e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.1893e-05\n",
      "Epoch 541/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0516 - metrics_pearsonr: 3.4284e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.1903e-05\n",
      "Epoch 542/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0516 - metrics_pearsonr: 3.4264e-05 - val_loss: 0.0682 - val_metrics_pearsonr: 7.1912e-05\n",
      "Epoch 543/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0515 - metrics_pearsonr: 3.4244e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 7.1926e-05\n",
      "Epoch 544/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0515 - metrics_pearsonr: 3.4225e-05 - val_loss: 0.0680 - val_metrics_pearsonr: 7.1944e-05\n",
      "Epoch 545/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0516 - metrics_pearsonr: 3.4208e-05 - val_loss: 0.0681 - val_metrics_pearsonr: 7.1970e-05\n",
      "Epoch 546/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0518 - metrics_pearsonr: 3.4191e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2006e-05\n",
      "Epoch 547/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0519 - metrics_pearsonr: 3.4180e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.2054e-05\n",
      "Epoch 548/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0521 - metrics_pearsonr: 3.4168e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2100e-05\n",
      "Epoch 549/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0522 - metrics_pearsonr: 3.4159e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.2151e-05\n",
      "Epoch 550/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0522 - metrics_pearsonr: 3.4147e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2198e-05\n",
      "Epoch 551/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0522 - metrics_pearsonr: 3.4137e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2241e-05\n",
      "Epoch 552/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0521 - metrics_pearsonr: 3.4124e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2269e-05\n",
      "Epoch 553/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0519 - metrics_pearsonr: 3.4112e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2281e-05\n",
      "Epoch 554/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0518 - metrics_pearsonr: 3.4100e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2282e-05\n",
      "Epoch 555/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0517 - metrics_pearsonr: 3.4093e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2266e-05\n",
      "Epoch 556/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0517 - metrics_pearsonr: 3.4088e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2242e-05\n",
      "Epoch 557/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0519 - metrics_pearsonr: 3.4092e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.2208e-05\n",
      "Epoch 558/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0522 - metrics_pearsonr: 3.4106e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2184e-05\n",
      "Epoch 559/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0527 - metrics_pearsonr: 3.4133e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2177e-05\n",
      "Epoch 560/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0534 - metrics_pearsonr: 3.4175e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.2222e-05\n",
      "Epoch 561/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0542 - metrics_pearsonr: 3.4236e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 7.2321e-05\n",
      "Epoch 562/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0551 - metrics_pearsonr: 3.4316e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.2492e-05\n",
      "Epoch 563/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0561 - metrics_pearsonr: 3.4409e-05 - val_loss: 0.0754 - val_metrics_pearsonr: 7.2736e-05\n",
      "Epoch 564/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0571 - metrics_pearsonr: 3.4508e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.3024e-05\n",
      "Epoch 565/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0577 - metrics_pearsonr: 3.4604e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 7.3318e-05\n",
      "Epoch 566/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0580 - metrics_pearsonr: 3.4682e-05 - val_loss: 0.0807 - val_metrics_pearsonr: 7.3551e-05\n",
      "Epoch 567/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0577 - metrics_pearsonr: 3.4736e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 7.3664e-05\n",
      "Epoch 568/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0570 - metrics_pearsonr: 3.4770e-05 - val_loss: 0.0783 - val_metrics_pearsonr: 7.3653e-05\n",
      "Epoch 569/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0559 - metrics_pearsonr: 3.4790e-05 - val_loss: 0.0751 - val_metrics_pearsonr: 7.3574e-05\n",
      "Epoch 570/5000\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0550 - metrics_pearsonr: 3.4821e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 7.3553e-05\n",
      "Epoch 571/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0547 - metrics_pearsonr: 3.4873e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 7.3717e-05\n",
      "Epoch 572/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0553 - metrics_pearsonr: 3.4946e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 7.4095e-05\n",
      "Epoch 573/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0568 - metrics_pearsonr: 3.5027e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.4630e-05\n",
      "Epoch 574/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0589 - metrics_pearsonr: 3.5094e-05 - val_loss: 0.0790 - val_metrics_pearsonr: 7.5142e-05\n",
      "Epoch 575/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0612 - metrics_pearsonr: 3.5140e-05 - val_loss: 0.0835 - val_metrics_pearsonr: 7.5432e-05\n",
      "Epoch 576/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0631 - metrics_pearsonr: 3.5162e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 7.5327e-05\n",
      "Epoch 577/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0644 - metrics_pearsonr: 3.5152e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 7.4783e-05\n",
      "Epoch 578/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0652 - metrics_pearsonr: 3.5108e-05 - val_loss: 0.0846 - val_metrics_pearsonr: 7.4005e-05\n",
      "Epoch 579/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0660 - metrics_pearsonr: 3.5061e-05 - val_loss: 0.0850 - val_metrics_pearsonr: 7.3441e-05\n",
      "Epoch 580/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0674 - metrics_pearsonr: 3.5092e-05 - val_loss: 0.0890 - val_metrics_pearsonr: 7.3488e-05\n",
      "Epoch 581/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0694 - metrics_pearsonr: 3.5274e-05 - val_loss: 0.0949 - val_metrics_pearsonr: 7.4183e-05\n",
      "Epoch 582/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0709 - metrics_pearsonr: 3.5539e-05 - val_loss: 0.0978 - val_metrics_pearsonr: 7.4952e-05\n",
      "Epoch 583/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0705 - metrics_pearsonr: 3.5681e-05 - val_loss: 0.0930 - val_metrics_pearsonr: 7.5006e-05\n",
      "Epoch 584/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0675 - metrics_pearsonr: 3.5507e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 7.4102e-05\n",
      "Epoch 585/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0644 - metrics_pearsonr: 3.5071e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 7.3086e-05\n",
      "Epoch 586/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0645 - metrics_pearsonr: 3.4655e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.2949e-05\n",
      "Epoch 587/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0692 - metrics_pearsonr: 3.4463e-05 - val_loss: 0.0894 - val_metrics_pearsonr: 7.3510e-05\n",
      "Epoch 588/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0762 - metrics_pearsonr: 3.4443e-05 - val_loss: 0.1084 - val_metrics_pearsonr: 7.3871e-05\n",
      "Epoch 589/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0825 - metrics_pearsonr: 3.4504e-05 - val_loss: 0.1233 - val_metrics_pearsonr: 7.3888e-05\n",
      "Epoch 590/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0859 - metrics_pearsonr: 3.4652e-05 - val_loss: 0.1276 - val_metrics_pearsonr: 7.4145e-05\n",
      "Epoch 591/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0851 - metrics_pearsonr: 3.4871e-05 - val_loss: 0.1191 - val_metrics_pearsonr: 7.4774e-05\n",
      "Epoch 592/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0805 - metrics_pearsonr: 3.5097e-05 - val_loss: 0.1011 - val_metrics_pearsonr: 7.4987e-05\n",
      "Epoch 593/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0751 - metrics_pearsonr: 3.5246e-05 - val_loss: 0.0833 - val_metrics_pearsonr: 7.4430e-05\n",
      "Epoch 594/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0731 - metrics_pearsonr: 3.5339e-05 - val_loss: 0.0782 - val_metrics_pearsonr: 7.4314e-05\n",
      "Epoch 595/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0765 - metrics_pearsonr: 3.5504e-05 - val_loss: 0.0923 - val_metrics_pearsonr: 7.5745e-05\n",
      "Epoch 596/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0830 - metrics_pearsonr: 3.5691e-05 - val_loss: 0.1167 - val_metrics_pearsonr: 7.7566e-05\n",
      "Epoch 597/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0877 - metrics_pearsonr: 3.5760e-05 - val_loss: 0.1298 - val_metrics_pearsonr: 7.7560e-05\n",
      "Epoch 598/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0866 - metrics_pearsonr: 3.5633e-05 - val_loss: 0.1161 - val_metrics_pearsonr: 7.5910e-05\n",
      "Epoch 599/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0800 - metrics_pearsonr: 3.5384e-05 - val_loss: 0.0863 - val_metrics_pearsonr: 7.4276e-05\n",
      "Epoch 600/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0728 - metrics_pearsonr: 3.5047e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.3686e-05\n",
      "Epoch 601/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0707 - metrics_pearsonr: 3.4773e-05 - val_loss: 0.0886 - val_metrics_pearsonr: 7.4043e-05\n",
      "Epoch 602/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0742 - metrics_pearsonr: 3.4745e-05 - val_loss: 0.1110 - val_metrics_pearsonr: 7.4431e-05\n",
      "Epoch 603/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0764 - metrics_pearsonr: 3.4759e-05 - val_loss: 0.1058 - val_metrics_pearsonr: 7.4136e-05\n",
      "Epoch 604/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0717 - metrics_pearsonr: 3.4562e-05 - val_loss: 0.0816 - val_metrics_pearsonr: 7.3657e-05\n",
      "Epoch 605/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0655 - metrics_pearsonr: 3.4346e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.3898e-05\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0638 - metrics_pearsonr: 3.4309e-05 - val_loss: 0.0818 - val_metrics_pearsonr: 7.4151e-05\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0642 - metrics_pearsonr: 3.4203e-05 - val_loss: 0.0880 - val_metrics_pearsonr: 7.3574e-05\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0630 - metrics_pearsonr: 3.4064e-05 - val_loss: 0.0812 - val_metrics_pearsonr: 7.2695e-05\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0600 - metrics_pearsonr: 3.4005e-05 - val_loss: 0.0721 - val_metrics_pearsonr: 7.2598e-05\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0574 - metrics_pearsonr: 3.3993e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.3178e-05\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0566 - metrics_pearsonr: 3.4024e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.3311e-05\n",
      "Epoch 612/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0562 - metrics_pearsonr: 3.3941e-05 - val_loss: 0.0757 - val_metrics_pearsonr: 7.2834e-05\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0548 - metrics_pearsonr: 3.3787e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 7.3171e-05\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0538 - metrics_pearsonr: 3.3856e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.4216e-05\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0537 - metrics_pearsonr: 3.4033e-05 - val_loss: 0.0728 - val_metrics_pearsonr: 7.3931e-05\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0532 - metrics_pearsonr: 3.3933e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.2525e-05\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0525 - metrics_pearsonr: 3.3675e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2218e-05\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0522 - metrics_pearsonr: 3.3634e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2799e-05\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0518 - metrics_pearsonr: 3.3649e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2813e-05\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0512 - metrics_pearsonr: 3.3511e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2497e-05\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0507 - metrics_pearsonr: 3.3335e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2731e-05\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0506 - metrics_pearsonr: 3.3302e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3070e-05\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0507 - metrics_pearsonr: 3.3304e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.2766e-05\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0506 - metrics_pearsonr: 3.3217e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2306e-05\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0505 - metrics_pearsonr: 3.3133e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2194e-05\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0504 - metrics_pearsonr: 3.3086e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2303e-05\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0503 - metrics_pearsonr: 3.3044e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2407e-05\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0502 - metrics_pearsonr: 3.2999e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2495e-05\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0501 - metrics_pearsonr: 3.2967e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2524e-05\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0501 - metrics_pearsonr: 3.2945e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2459e-05\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0500 - metrics_pearsonr: 3.2916e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2353e-05\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0499 - metrics_pearsonr: 3.2892e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2290e-05\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0499 - metrics_pearsonr: 3.2878e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2286e-05\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0499 - metrics_pearsonr: 3.2862e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2328e-05\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0499 - metrics_pearsonr: 3.2843e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2402e-05\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0498 - metrics_pearsonr: 3.2828e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2469e-05\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0498 - metrics_pearsonr: 3.2814e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2482e-05\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0498 - metrics_pearsonr: 3.2798e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2438e-05\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0498 - metrics_pearsonr: 3.2781e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2378e-05\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0498 - metrics_pearsonr: 3.2764e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2347e-05\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0498 - metrics_pearsonr: 3.2749e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2350e-05\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0498 - metrics_pearsonr: 3.2734e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2379e-05\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0497 - metrics_pearsonr: 3.2718e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2413e-05\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0497 - metrics_pearsonr: 3.2700e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2435e-05\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0496 - metrics_pearsonr: 3.2684e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2447e-05\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0496 - metrics_pearsonr: 3.2666e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2453e-05\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0496 - metrics_pearsonr: 3.2652e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2452e-05\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0496 - metrics_pearsonr: 3.2639e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2449e-05\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0496 - metrics_pearsonr: 3.2626e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2447e-05\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0496 - metrics_pearsonr: 3.2613e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2447e-05\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0496 - metrics_pearsonr: 3.2600e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2448e-05\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0496 - metrics_pearsonr: 3.2586e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2449e-05\n",
      "Epoch 653/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0496 - metrics_pearsonr: 3.2573e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2453e-05\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0496 - metrics_pearsonr: 3.2558e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2457e-05\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0496 - metrics_pearsonr: 3.2542e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2457e-05\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0496 - metrics_pearsonr: 3.2527e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2457e-05\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0495 - metrics_pearsonr: 3.2510e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2459e-05\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0495 - metrics_pearsonr: 3.2492e-05 - val_loss: 0.0684 - val_metrics_pearsonr: 7.2464e-05\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0494 - metrics_pearsonr: 3.2476e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2476e-05\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0494 - metrics_pearsonr: 3.2460e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2489e-05\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0494 - metrics_pearsonr: 3.2445e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2500e-05\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0494 - metrics_pearsonr: 3.2433e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2509e-05\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0494 - metrics_pearsonr: 3.2419e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2518e-05\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0494 - metrics_pearsonr: 3.2406e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2523e-05\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0494 - metrics_pearsonr: 3.2393e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2527e-05\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0494 - metrics_pearsonr: 3.2381e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2529e-05\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0494 - metrics_pearsonr: 3.2366e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2531e-05\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0494 - metrics_pearsonr: 3.2354e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2531e-05\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0494 - metrics_pearsonr: 3.2340e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2535e-05\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0495 - metrics_pearsonr: 3.2330e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2534e-05\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0495 - metrics_pearsonr: 3.2316e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2540e-05\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0495 - metrics_pearsonr: 3.2304e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2543e-05\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0494 - metrics_pearsonr: 3.2290e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2540e-05\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0494 - metrics_pearsonr: 3.2273e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2537e-05\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0493 - metrics_pearsonr: 3.2255e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2537e-05\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0493 - metrics_pearsonr: 3.2235e-05 - val_loss: 0.0685 - val_metrics_pearsonr: 7.2541e-05\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0492 - metrics_pearsonr: 3.2217e-05 - val_loss: 0.0686 - val_metrics_pearsonr: 7.2549e-05\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0492 - metrics_pearsonr: 3.2199e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2561e-05\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0492 - metrics_pearsonr: 3.2185e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2587e-05\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0492 - metrics_pearsonr: 3.2173e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2613e-05\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0492 - metrics_pearsonr: 3.2163e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2638e-05\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0493 - metrics_pearsonr: 3.2153e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2656e-05\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0493 - metrics_pearsonr: 3.2144e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2661e-05\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0493 - metrics_pearsonr: 3.2133e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2656e-05\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0493 - metrics_pearsonr: 3.2122e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2642e-05\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0493 - metrics_pearsonr: 3.2111e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.2618e-05\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0493 - metrics_pearsonr: 3.2101e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2601e-05\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0494 - metrics_pearsonr: 3.2093e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2594e-05\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0495 - metrics_pearsonr: 3.2088e-05 - val_loss: 0.0688 - val_metrics_pearsonr: 7.2599e-05\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0497 - metrics_pearsonr: 3.2086e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2615e-05\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0499 - metrics_pearsonr: 3.2085e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2645e-05\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0500 - metrics_pearsonr: 3.2083e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2667e-05\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0501 - metrics_pearsonr: 3.2077e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.2689e-05\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0501 - metrics_pearsonr: 3.2063e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.2694e-05\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0499 - metrics_pearsonr: 3.2043e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2687e-05\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0497 - metrics_pearsonr: 3.2015e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2666e-05\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0495 - metrics_pearsonr: 3.1982e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2645e-05\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0493 - metrics_pearsonr: 3.1953e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2636e-05\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0492 - metrics_pearsonr: 3.1928e-05 - val_loss: 0.0687 - val_metrics_pearsonr: 7.2645e-05\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0492 - metrics_pearsonr: 3.1911e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2678e-05\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0494 - metrics_pearsonr: 3.1904e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2737e-05\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0498 - metrics_pearsonr: 3.1906e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.2821e-05\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0502 - metrics_pearsonr: 3.1913e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 7.2916e-05\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0507 - metrics_pearsonr: 3.1924e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 7.3020e-05\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0511 - metrics_pearsonr: 3.1936e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.3119e-05\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0515 - metrics_pearsonr: 3.1946e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 7.3203e-05\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0516 - metrics_pearsonr: 3.1955e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.3259e-05\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0516 - metrics_pearsonr: 3.1959e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.3277e-05\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0514 - metrics_pearsonr: 3.1959e-05 - val_loss: 0.0741 - val_metrics_pearsonr: 7.3251e-05\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0511 - metrics_pearsonr: 3.1957e-05 - val_loss: 0.0729 - val_metrics_pearsonr: 7.3173e-05\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0509 - metrics_pearsonr: 3.1952e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 7.3054e-05\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0508 - metrics_pearsonr: 3.1948e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 7.2929e-05\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0512 - metrics_pearsonr: 3.1953e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2830e-05\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0521 - metrics_pearsonr: 3.1974e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.2802e-05\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0538 - metrics_pearsonr: 3.2017e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 7.2884e-05\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0562 - metrics_pearsonr: 3.2092e-05 - val_loss: 0.0749 - val_metrics_pearsonr: 7.3089e-05\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0593 - metrics_pearsonr: 3.2194e-05 - val_loss: 0.0804 - val_metrics_pearsonr: 7.3408e-05\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0628 - metrics_pearsonr: 3.2316e-05 - val_loss: 0.0873 - val_metrics_pearsonr: 7.3770e-05\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0661 - metrics_pearsonr: 3.2431e-05 - val_loss: 0.0943 - val_metrics_pearsonr: 7.4069e-05\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0685 - metrics_pearsonr: 3.2502e-05 - val_loss: 0.0996 - val_metrics_pearsonr: 7.4187e-05\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0691 - metrics_pearsonr: 3.2490e-05 - val_loss: 0.1010 - val_metrics_pearsonr: 7.4075e-05\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0676 - metrics_pearsonr: 3.2394e-05 - val_loss: 0.0974 - val_metrics_pearsonr: 7.3871e-05\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0645 - metrics_pearsonr: 3.2280e-05 - val_loss: 0.0895 - val_metrics_pearsonr: 7.3828e-05\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0613 - metrics_pearsonr: 3.2254e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 7.4097e-05\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0600 - metrics_pearsonr: 3.2357e-05 - val_loss: 0.0737 - val_metrics_pearsonr: 7.4478e-05\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0616 - metrics_pearsonr: 3.2498e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.4624e-05\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0665 - metrics_pearsonr: 3.2581e-05 - val_loss: 0.0839 - val_metrics_pearsonr: 7.4418e-05\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0746 - metrics_pearsonr: 3.2593e-05 - val_loss: 0.1051 - val_metrics_pearsonr: 7.4303e-05\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0848 - metrics_pearsonr: 3.2696e-05 - val_loss: 0.1329 - val_metrics_pearsonr: 7.4736e-05\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0944 - metrics_pearsonr: 3.2955e-05 - val_loss: 0.1540 - val_metrics_pearsonr: 7.5396e-05\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0982 - metrics_pearsonr: 3.3166e-05 - val_loss: 0.1502 - val_metrics_pearsonr: 7.5429e-05\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0934 - metrics_pearsonr: 3.3088e-05 - val_loss: 0.1187 - val_metrics_pearsonr: 7.4852e-05\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0845 - metrics_pearsonr: 3.2913e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 7.4815e-05\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0810 - metrics_pearsonr: 3.2983e-05 - val_loss: 0.0830 - val_metrics_pearsonr: 7.5624e-05\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0859 - metrics_pearsonr: 3.3155e-05 - val_loss: 0.1165 - val_metrics_pearsonr: 7.6141e-05\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0937 - metrics_pearsonr: 3.3159e-05 - val_loss: 0.1450 - val_metrics_pearsonr: 7.5857e-05\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0958 - metrics_pearsonr: 3.3309e-05 - val_loss: 0.1279 - val_metrics_pearsonr: 7.5163e-05\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0873 - metrics_pearsonr: 3.3478e-05 - val_loss: 0.0849 - val_metrics_pearsonr: 7.4637e-05\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0754 - metrics_pearsonr: 3.3259e-05 - val_loss: 0.0771 - val_metrics_pearsonr: 7.5107e-05\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0726 - metrics_pearsonr: 3.3202e-05 - val_loss: 0.1029 - val_metrics_pearsonr: 7.5500e-05\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0744 - metrics_pearsonr: 3.3250e-05 - val_loss: 0.1048 - val_metrics_pearsonr: 7.4812e-05\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0700 - metrics_pearsonr: 3.3074e-05 - val_loss: 0.0848 - val_metrics_pearsonr: 7.6261e-05\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0646 - metrics_pearsonr: 3.3417e-05 - val_loss: 0.0798 - val_metrics_pearsonr: 7.8379e-05\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0617 - metrics_pearsonr: 3.3811e-05 - val_loss: 0.0819 - val_metrics_pearsonr: 7.5544e-05\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0594 - metrics_pearsonr: 3.3236e-05 - val_loss: 0.0780 - val_metrics_pearsonr: 7.3206e-05\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0577 - metrics_pearsonr: 3.2942e-05 - val_loss: 0.0755 - val_metrics_pearsonr: 7.4699e-05\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0556 - metrics_pearsonr: 3.3028e-05 - val_loss: 0.0739 - val_metrics_pearsonr: 7.4285e-05\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0535 - metrics_pearsonr: 3.2645e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.3377e-05\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0521 - metrics_pearsonr: 3.2185e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.4814e-05\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0518 - metrics_pearsonr: 3.2228e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.4424e-05\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0512 - metrics_pearsonr: 3.1956e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 7.2902e-05\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0507 - metrics_pearsonr: 3.1620e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.2854e-05\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0501 - metrics_pearsonr: 3.1545e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2815e-05\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0497 - metrics_pearsonr: 3.1439e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.2959e-05\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0496 - metrics_pearsonr: 3.1355e-05 - val_loss: 0.0708 - val_metrics_pearsonr: 7.3234e-05\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0494 - metrics_pearsonr: 3.1341e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3027e-05\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0490 - metrics_pearsonr: 3.1305e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2843e-05\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0488 - metrics_pearsonr: 3.1273e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2815e-05\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0487 - metrics_pearsonr: 3.1249e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2833e-05\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0486 - metrics_pearsonr: 3.1234e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3000e-05\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0485 - metrics_pearsonr: 3.1223e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3048e-05\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0485 - metrics_pearsonr: 3.1186e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2914e-05\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0484 - metrics_pearsonr: 3.1151e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2825e-05\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0484 - metrics_pearsonr: 3.1132e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2773e-05\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0483 - metrics_pearsonr: 3.1101e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2783e-05\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0482 - metrics_pearsonr: 3.1067e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2856e-05\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0481 - metrics_pearsonr: 3.1048e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2904e-05\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0481 - metrics_pearsonr: 3.1031e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2877e-05\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0481 - metrics_pearsonr: 3.1011e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2828e-05\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0481 - metrics_pearsonr: 3.1002e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2796e-05\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0481 - metrics_pearsonr: 3.0993e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2815e-05\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0481 - metrics_pearsonr: 3.0986e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2852e-05\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0481 - metrics_pearsonr: 3.0973e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2868e-05\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0481 - metrics_pearsonr: 3.0958e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2855e-05\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0481 - metrics_pearsonr: 3.0941e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2841e-05\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0480 - metrics_pearsonr: 3.0925e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2838e-05\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0480 - metrics_pearsonr: 3.0909e-05 - val_loss: 0.0689 - val_metrics_pearsonr: 7.2850e-05\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0479 - metrics_pearsonr: 3.0892e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2872e-05\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0479 - metrics_pearsonr: 3.0876e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2895e-05\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0479 - metrics_pearsonr: 3.0859e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2900e-05\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0479 - metrics_pearsonr: 3.0846e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2894e-05\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0479 - metrics_pearsonr: 3.0833e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2893e-05\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0479 - metrics_pearsonr: 3.0820e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2890e-05\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0479 - metrics_pearsonr: 3.0809e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2884e-05\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0479 - metrics_pearsonr: 3.0798e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2880e-05\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0479 - metrics_pearsonr: 3.0786e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2871e-05\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0479 - metrics_pearsonr: 3.0776e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2860e-05\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0479 - metrics_pearsonr: 3.0765e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2864e-05\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0479 - metrics_pearsonr: 3.0755e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2866e-05\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0479 - metrics_pearsonr: 3.0742e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2877e-05\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0478 - metrics_pearsonr: 3.0728e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2892e-05\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0478 - metrics_pearsonr: 3.0715e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2902e-05\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0478 - metrics_pearsonr: 3.0702e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2910e-05\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0477 - metrics_pearsonr: 3.0689e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2919e-05\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0477 - metrics_pearsonr: 3.0675e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2928e-05\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0477 - metrics_pearsonr: 3.0662e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2940e-05\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0477 - metrics_pearsonr: 3.0646e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2950e-05\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0477 - metrics_pearsonr: 3.0633e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2957e-05\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0477 - metrics_pearsonr: 3.0619e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2958e-05\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0477 - metrics_pearsonr: 3.0606e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2957e-05\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0477 - metrics_pearsonr: 3.0592e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2951e-05\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0477 - metrics_pearsonr: 3.0578e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2943e-05\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0477 - metrics_pearsonr: 3.0566e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2939e-05\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0476 - metrics_pearsonr: 3.0553e-05 - val_loss: 0.0690 - val_metrics_pearsonr: 7.2933e-05\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0476 - metrics_pearsonr: 3.0541e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2929e-05\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0477 - metrics_pearsonr: 3.0532e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.2929e-05\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0477 - metrics_pearsonr: 3.0522e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.2929e-05\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0477 - metrics_pearsonr: 3.0513e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2937e-05\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0477 - metrics_pearsonr: 3.0505e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.2940e-05\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0478 - metrics_pearsonr: 3.0498e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2950e-05\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0478 - metrics_pearsonr: 3.0491e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2958e-05\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0478 - metrics_pearsonr: 3.0483e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2965e-05\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0478 - metrics_pearsonr: 3.0473e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2968e-05\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0478 - metrics_pearsonr: 3.0463e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.2974e-05\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0478 - metrics_pearsonr: 3.0451e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.2976e-05\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0478 - metrics_pearsonr: 3.0439e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.2977e-05\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0477 - metrics_pearsonr: 3.0424e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.2981e-05\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0476 - metrics_pearsonr: 3.0411e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.2988e-05\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0476 - metrics_pearsonr: 3.0395e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.3001e-05\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0475 - metrics_pearsonr: 3.0380e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.3015e-05\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0475 - metrics_pearsonr: 3.0365e-05 - val_loss: 0.0691 - val_metrics_pearsonr: 7.3036e-05\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0475 - metrics_pearsonr: 3.0349e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.3060e-05\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0475 - metrics_pearsonr: 3.0336e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.3089e-05\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0475 - metrics_pearsonr: 3.0323e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.3116e-05\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0475 - metrics_pearsonr: 3.0310e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3144e-05\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0475 - metrics_pearsonr: 3.0297e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3170e-05\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0476 - metrics_pearsonr: 3.0285e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3190e-05\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0476 - metrics_pearsonr: 3.0273e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3199e-05\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0476 - metrics_pearsonr: 3.0262e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3207e-05\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0476 - metrics_pearsonr: 3.0250e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3198e-05\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0475 - metrics_pearsonr: 3.0240e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3175e-05\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0475 - metrics_pearsonr: 3.0230e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.3143e-05\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0476 - metrics_pearsonr: 3.0224e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.3111e-05\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0476 - metrics_pearsonr: 3.0221e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.3083e-05\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0478 - metrics_pearsonr: 3.0221e-05 - val_loss: 0.0692 - val_metrics_pearsonr: 7.3061e-05\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0480 - metrics_pearsonr: 3.0227e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.3046e-05\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0482 - metrics_pearsonr: 3.0238e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3042e-05\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0486 - metrics_pearsonr: 3.0255e-05 - val_loss: 0.0699 - val_metrics_pearsonr: 7.3061e-05\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0489 - metrics_pearsonr: 3.0280e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 7.3088e-05\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0493 - metrics_pearsonr: 3.0309e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.3138e-05\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0498 - metrics_pearsonr: 3.0341e-05 - val_loss: 0.0717 - val_metrics_pearsonr: 7.3212e-05\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0502 - metrics_pearsonr: 3.0379e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 7.3305e-05\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0506 - metrics_pearsonr: 3.0417e-05 - val_loss: 0.0733 - val_metrics_pearsonr: 7.3419e-05\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0510 - metrics_pearsonr: 3.0455e-05 - val_loss: 0.0743 - val_metrics_pearsonr: 7.3555e-05\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0513 - metrics_pearsonr: 3.0491e-05 - val_loss: 0.0752 - val_metrics_pearsonr: 7.3699e-05\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0516 - metrics_pearsonr: 3.0526e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.3851e-05\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0517 - metrics_pearsonr: 3.0553e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.3999e-05\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0517 - metrics_pearsonr: 3.0575e-05 - val_loss: 0.0775 - val_metrics_pearsonr: 7.4117e-05\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0516 - metrics_pearsonr: 3.0592e-05 - val_loss: 0.0776 - val_metrics_pearsonr: 7.4203e-05\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0513 - metrics_pearsonr: 3.0603e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.4244e-05\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0510 - metrics_pearsonr: 3.0615e-05 - val_loss: 0.0762 - val_metrics_pearsonr: 7.4242e-05\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0506 - metrics_pearsonr: 3.0632e-05 - val_loss: 0.0750 - val_metrics_pearsonr: 7.4219e-05\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0504 - metrics_pearsonr: 3.0661e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.4194e-05\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0505 - metrics_pearsonr: 3.0706e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 7.4222e-05\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0511 - metrics_pearsonr: 3.0773e-05 - val_loss: 0.0723 - val_metrics_pearsonr: 7.4346e-05\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0523 - metrics_pearsonr: 3.0868e-05 - val_loss: 0.0735 - val_metrics_pearsonr: 7.4611e-05\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0541 - metrics_pearsonr: 3.0987e-05 - val_loss: 0.0764 - val_metrics_pearsonr: 7.5046e-05\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0566 - metrics_pearsonr: 3.1130e-05 - val_loss: 0.0810 - val_metrics_pearsonr: 7.5638e-05\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0594 - metrics_pearsonr: 3.1282e-05 - val_loss: 0.0869 - val_metrics_pearsonr: 7.6297e-05\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0620 - metrics_pearsonr: 3.1426e-05 - val_loss: 0.0923 - val_metrics_pearsonr: 7.6836e-05\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0640 - metrics_pearsonr: 3.1536e-05 - val_loss: 0.0951 - val_metrics_pearsonr: 7.6991e-05\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0647 - metrics_pearsonr: 3.1594e-05 - val_loss: 0.0936 - val_metrics_pearsonr: 7.6569e-05\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0644 - metrics_pearsonr: 3.1588e-05 - val_loss: 0.0885 - val_metrics_pearsonr: 7.5666e-05\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0639 - metrics_pearsonr: 3.1548e-05 - val_loss: 0.0842 - val_metrics_pearsonr: 7.4791e-05\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0644 - metrics_pearsonr: 3.1541e-05 - val_loss: 0.0859 - val_metrics_pearsonr: 7.4576e-05\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0666 - metrics_pearsonr: 3.1677e-05 - val_loss: 0.0949 - val_metrics_pearsonr: 7.5301e-05\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0696 - metrics_pearsonr: 3.1997e-05 - val_loss: 0.1046 - val_metrics_pearsonr: 7.6469e-05\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0711 - metrics_pearsonr: 3.2349e-05 - val_loss: 0.1038 - val_metrics_pearsonr: 7.6869e-05\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0687 - metrics_pearsonr: 3.2393e-05 - val_loss: 0.0889 - val_metrics_pearsonr: 7.5840e-05\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0639 - metrics_pearsonr: 3.2013e-05 - val_loss: 0.0740 - val_metrics_pearsonr: 7.4557e-05\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0622 - metrics_pearsonr: 3.1552e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.4696e-05\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0656 - metrics_pearsonr: 3.1323e-05 - val_loss: 0.0950 - val_metrics_pearsonr: 7.5967e-05\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0703 - metrics_pearsonr: 3.1278e-05 - val_loss: 0.1086 - val_metrics_pearsonr: 7.6687e-05\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0724 - metrics_pearsonr: 3.1316e-05 - val_loss: 0.1088 - val_metrics_pearsonr: 7.6237e-05\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0716 - metrics_pearsonr: 3.1269e-05 - val_loss: 0.1038 - val_metrics_pearsonr: 7.5541e-05\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0693 - metrics_pearsonr: 3.1116e-05 - val_loss: 0.1004 - val_metrics_pearsonr: 7.5394e-05\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0663 - metrics_pearsonr: 3.1038e-05 - val_loss: 0.0922 - val_metrics_pearsonr: 7.5110e-05\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0627 - metrics_pearsonr: 3.0989e-05 - val_loss: 0.0777 - val_metrics_pearsonr: 7.4466e-05\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0604 - metrics_pearsonr: 3.0891e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 7.4594e-05\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0624 - metrics_pearsonr: 3.0873e-05 - val_loss: 0.0838 - val_metrics_pearsonr: 7.5590e-05\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0680 - metrics_pearsonr: 3.0937e-05 - val_loss: 0.1021 - val_metrics_pearsonr: 7.6090e-05\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0727 - metrics_pearsonr: 3.0909e-05 - val_loss: 0.1123 - val_metrics_pearsonr: 7.5551e-05\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0736 - metrics_pearsonr: 3.0735e-05 - val_loss: 0.1098 - val_metrics_pearsonr: 7.4754e-05\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0705 - metrics_pearsonr: 3.0566e-05 - val_loss: 0.0954 - val_metrics_pearsonr: 7.4281e-05\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0655 - metrics_pearsonr: 3.0458e-05 - val_loss: 0.0770 - val_metrics_pearsonr: 7.3961e-05\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0619 - metrics_pearsonr: 3.0362e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 7.3753e-05\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0632 - metrics_pearsonr: 3.0290e-05 - val_loss: 0.0891 - val_metrics_pearsonr: 7.4069e-05\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0690 - metrics_pearsonr: 3.0354e-05 - val_loss: 0.1123 - val_metrics_pearsonr: 7.4654e-05\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0733 - metrics_pearsonr: 3.0474e-05 - val_loss: 0.1148 - val_metrics_pearsonr: 7.4582e-05\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0709 - metrics_pearsonr: 3.0434e-05 - val_loss: 0.0941 - val_metrics_pearsonr: 7.4370e-05\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0650 - metrics_pearsonr: 3.0442e-05 - val_loss: 0.0763 - val_metrics_pearsonr: 7.5224e-05\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0622 - metrics_pearsonr: 3.0697e-05 - val_loss: 0.0781 - val_metrics_pearsonr: 7.5920e-05\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0627 - metrics_pearsonr: 3.0784e-05 - val_loss: 0.0901 - val_metrics_pearsonr: 7.5083e-05\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0638 - metrics_pearsonr: 3.0673e-05 - val_loss: 0.0946 - val_metrics_pearsonr: 7.4196e-05\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0634 - metrics_pearsonr: 3.0733e-05 - val_loss: 0.0860 - val_metrics_pearsonr: 7.4593e-05\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0599 - metrics_pearsonr: 3.0824e-05 - val_loss: 0.0746 - val_metrics_pearsonr: 7.5092e-05\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0560 - metrics_pearsonr: 3.0810e-05 - val_loss: 0.0724 - val_metrics_pearsonr: 7.4344e-05\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0548 - metrics_pearsonr: 3.0548e-05 - val_loss: 0.0786 - val_metrics_pearsonr: 7.3782e-05\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0552 - metrics_pearsonr: 3.0305e-05 - val_loss: 0.0841 - val_metrics_pearsonr: 7.4802e-05\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0550 - metrics_pearsonr: 3.0335e-05 - val_loss: 0.0817 - val_metrics_pearsonr: 7.5389e-05\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0534 - metrics_pearsonr: 3.0336e-05 - val_loss: 0.0742 - val_metrics_pearsonr: 7.4317e-05\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0515 - metrics_pearsonr: 3.0082e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.3426e-05\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0508 - metrics_pearsonr: 2.9868e-05 - val_loss: 0.0726 - val_metrics_pearsonr: 7.3527e-05\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0512 - metrics_pearsonr: 2.9816e-05 - val_loss: 0.0756 - val_metrics_pearsonr: 7.3642e-05\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0511 - metrics_pearsonr: 2.9758e-05 - val_loss: 0.0745 - val_metrics_pearsonr: 7.3480e-05\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0499 - metrics_pearsonr: 2.9646e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.3444e-05\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0487 - metrics_pearsonr: 2.9568e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3438e-05\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0484 - metrics_pearsonr: 2.9514e-05 - val_loss: 0.0716 - val_metrics_pearsonr: 7.3319e-05\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0487 - metrics_pearsonr: 2.9475e-05 - val_loss: 0.0736 - val_metrics_pearsonr: 7.3229e-05\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0488 - metrics_pearsonr: 2.9448e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.3245e-05\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0484 - metrics_pearsonr: 2.9440e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.3261e-05\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0479 - metrics_pearsonr: 2.9429e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3275e-05\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0477 - metrics_pearsonr: 2.9404e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 7.3307e-05\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0478 - metrics_pearsonr: 2.9377e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.3313e-05\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0478 - metrics_pearsonr: 2.9354e-05 - val_loss: 0.0711 - val_metrics_pearsonr: 7.3235e-05\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0476 - metrics_pearsonr: 2.9323e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 7.3141e-05\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0472 - metrics_pearsonr: 2.9298e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.3103e-05\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0469 - metrics_pearsonr: 2.9274e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3137e-05\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0469 - metrics_pearsonr: 2.9257e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.3212e-05\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0470 - metrics_pearsonr: 2.9249e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 7.3255e-05\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0471 - metrics_pearsonr: 2.9243e-05 - val_loss: 0.0709 - val_metrics_pearsonr: 7.3251e-05\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0470 - metrics_pearsonr: 2.9234e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.3245e-05\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0468 - metrics_pearsonr: 2.9221e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3245e-05\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0468 - metrics_pearsonr: 2.9209e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3247e-05\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0468 - metrics_pearsonr: 2.9198e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 7.3219e-05\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0469 - metrics_pearsonr: 2.9179e-05 - val_loss: 0.0702 - val_metrics_pearsonr: 7.3195e-05\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0468 - metrics_pearsonr: 2.9166e-05 - val_loss: 0.0699 - val_metrics_pearsonr: 7.3171e-05\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0467 - metrics_pearsonr: 2.9151e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3160e-05\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0465 - metrics_pearsonr: 2.9136e-05 - val_loss: 0.0693 - val_metrics_pearsonr: 7.3159e-05\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0464 - metrics_pearsonr: 2.9121e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3179e-05\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0464 - metrics_pearsonr: 2.9107e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.3223e-05\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0465 - metrics_pearsonr: 2.9097e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.3270e-05\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0465 - metrics_pearsonr: 2.9088e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 7.3288e-05\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0465 - metrics_pearsonr: 2.9082e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.3279e-05\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0465 - metrics_pearsonr: 2.9074e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3246e-05\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0464 - metrics_pearsonr: 2.9064e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3217e-05\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0465 - metrics_pearsonr: 2.9051e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3211e-05\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0466 - metrics_pearsonr: 2.9041e-05 - val_loss: 0.0699 - val_metrics_pearsonr: 7.3219e-05\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0466 - metrics_pearsonr: 2.9032e-05 - val_loss: 0.0699 - val_metrics_pearsonr: 7.3222e-05\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0466 - metrics_pearsonr: 2.9020e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3215e-05\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0464 - metrics_pearsonr: 2.9002e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3199e-05\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0463 - metrics_pearsonr: 2.8984e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.3189e-05\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0462 - metrics_pearsonr: 2.8967e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3196e-05\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0462 - metrics_pearsonr: 2.8953e-05 - val_loss: 0.0699 - val_metrics_pearsonr: 7.3213e-05\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0463 - metrics_pearsonr: 2.8943e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 7.3240e-05\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0464 - metrics_pearsonr: 2.8935e-05 - val_loss: 0.0706 - val_metrics_pearsonr: 7.3271e-05\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0464 - metrics_pearsonr: 2.8930e-05 - val_loss: 0.0705 - val_metrics_pearsonr: 7.3292e-05\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0464 - metrics_pearsonr: 2.8923e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.3293e-05\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0463 - metrics_pearsonr: 2.8914e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3280e-05\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0463 - metrics_pearsonr: 2.8904e-05 - val_loss: 0.0696 - val_metrics_pearsonr: 7.3266e-05\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0464 - metrics_pearsonr: 2.8896e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3253e-05\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0465 - metrics_pearsonr: 2.8888e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 7.3247e-05\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0467 - metrics_pearsonr: 2.8883e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.3247e-05\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0467 - metrics_pearsonr: 2.8877e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.3245e-05\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0467 - metrics_pearsonr: 2.8866e-05 - val_loss: 0.0701 - val_metrics_pearsonr: 7.3238e-05\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0465 - metrics_pearsonr: 2.8850e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3227e-05\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0463 - metrics_pearsonr: 2.8831e-05 - val_loss: 0.0694 - val_metrics_pearsonr: 7.3211e-05\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0461 - metrics_pearsonr: 2.8811e-05 - val_loss: 0.0695 - val_metrics_pearsonr: 7.3217e-05\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0462 - metrics_pearsonr: 2.8795e-05 - val_loss: 0.0700 - val_metrics_pearsonr: 7.3240e-05\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0463 - metrics_pearsonr: 2.8784e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 7.3283e-05\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0465 - metrics_pearsonr: 2.8778e-05 - val_loss: 0.0715 - val_metrics_pearsonr: 7.3336e-05\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0467 - metrics_pearsonr: 2.8774e-05 - val_loss: 0.0719 - val_metrics_pearsonr: 7.3386e-05\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0468 - metrics_pearsonr: 2.8772e-05 - val_loss: 0.0718 - val_metrics_pearsonr: 7.3422e-05\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0467 - metrics_pearsonr: 2.8770e-05 - val_loss: 0.0712 - val_metrics_pearsonr: 7.3426e-05\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0466 - metrics_pearsonr: 2.8765e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 7.3398e-05\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0465 - metrics_pearsonr: 2.8759e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3358e-05\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0467 - metrics_pearsonr: 2.8752e-05 - val_loss: 0.0698 - val_metrics_pearsonr: 7.3323e-05\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0470 - metrics_pearsonr: 2.8750e-05 - val_loss: 0.0703 - val_metrics_pearsonr: 7.3312e-05\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0475 - metrics_pearsonr: 2.8755e-05 - val_loss: 0.0714 - val_metrics_pearsonr: 7.3330e-05\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0480 - metrics_pearsonr: 2.8766e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 7.3366e-05\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0484 - metrics_pearsonr: 2.8776e-05 - val_loss: 0.0731 - val_metrics_pearsonr: 7.3399e-05\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0484 - metrics_pearsonr: 2.8777e-05 - val_loss: 0.0730 - val_metrics_pearsonr: 7.3406e-05\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0481 - metrics_pearsonr: 2.8764e-05 - val_loss: 0.0720 - val_metrics_pearsonr: 7.3379e-05\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.0475 - metrics_pearsonr: 2.8737e-05 - val_loss: 0.0707 - val_metrics_pearsonr: 7.3326e-05\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0470 - metrics_pearsonr: 2.8703e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3285e-05\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0468 - metrics_pearsonr: 2.8674e-05 - val_loss: 0.0697 - val_metrics_pearsonr: 7.3288e-05\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0471 - metrics_pearsonr: 2.8659e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.3348e-05\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0480 - metrics_pearsonr: 2.8656e-05 - val_loss: 0.0734 - val_metrics_pearsonr: 7.3463e-05\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0491 - metrics_pearsonr: 2.8667e-05 - val_loss: 0.0765 - val_metrics_pearsonr: 7.3619e-05\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0501 - metrics_pearsonr: 2.8684e-05 - val_loss: 0.0791 - val_metrics_pearsonr: 7.3778e-05\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0507 - metrics_pearsonr: 2.8707e-05 - val_loss: 0.0803 - val_metrics_pearsonr: 7.3902e-05\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0508 - metrics_pearsonr: 2.8728e-05 - val_loss: 0.0797 - val_metrics_pearsonr: 7.3966e-05\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0503 - metrics_pearsonr: 2.8746e-05 - val_loss: 0.0772 - val_metrics_pearsonr: 7.3948e-05\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0496 - metrics_pearsonr: 2.8756e-05 - val_loss: 0.0738 - val_metrics_pearsonr: 7.3849e-05\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0492 - metrics_pearsonr: 2.8758e-05 - val_loss: 0.0710 - val_metrics_pearsonr: 7.3702e-05\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0495 - metrics_pearsonr: 2.8753e-05 - val_loss: 0.0704 - val_metrics_pearsonr: 7.3588e-05\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0510 - metrics_pearsonr: 2.8758e-05 - val_loss: 0.0732 - val_metrics_pearsonr: 7.3576e-05\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0536 - metrics_pearsonr: 2.8798e-05 - val_loss: 0.0792 - val_metrics_pearsonr: 7.3718e-05\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0569 - metrics_pearsonr: 2.8877e-05 - val_loss: 0.0867 - val_metrics_pearsonr: 7.3966e-05\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0598 - metrics_pearsonr: 2.8973e-05 - val_loss: 0.0929 - val_metrics_pearsonr: 7.4206e-05\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0612 - metrics_pearsonr: 2.9036e-05 - val_loss: 0.0944 - val_metrics_pearsonr: 7.4292e-05\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0602 - metrics_pearsonr: 2.9019e-05 - val_loss: 0.0898 - val_metrics_pearsonr: 7.4154e-05\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0573 - metrics_pearsonr: 2.8933e-05 - val_loss: 0.0808 - val_metrics_pearsonr: 7.3896e-05\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0544 - metrics_pearsonr: 2.8843e-05 - val_loss: 0.0725 - val_metrics_pearsonr: 7.3743e-05\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0536 - metrics_pearsonr: 2.8814e-05 - val_loss: 0.0708 - val_metrics_pearsonr: 7.3804e-05\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0560 - metrics_pearsonr: 2.8842e-05 - val_loss: 0.0788 - val_metrics_pearsonr: 7.4015e-05\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0613 - metrics_pearsonr: 2.8895e-05 - val_loss: 0.0949 - val_metrics_pearsonr: 7.4302e-05\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0675 - metrics_pearsonr: 2.8965e-05 - val_loss: 0.1121 - val_metrics_pearsonr: 7.4614e-05\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0718 - metrics_pearsonr: 2.9062e-05 - val_loss: 0.1195 - val_metrics_pearsonr: 7.4825e-05\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0719 - metrics_pearsonr: 2.9130e-05 - val_loss: 0.1102 - val_metrics_pearsonr: 7.4760e-05\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0677 - metrics_pearsonr: 2.9133e-05 - val_loss: 0.0892 - val_metrics_pearsonr: 7.4504e-05\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1/1 [==============================] - 0s 234ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002414DFA2040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "相关系数 0.9973752900898462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_1\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_2\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_3\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_4\\assets\n",
      "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215_5\\assets\n"
     ]
    }
   ],
   "source": [
    "model,predicty,testy,r,p,weights=Auto_Transformer(vy,vx,6,[['transformer'],['fc',7]],test_size=0.2,valid_size=0.1,k_fold=5,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=1,key_dim=1,ifdropout='no',trans_dropout_rate=0.0,trans_units=256,trans_activation='tanh',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='Adam',metrics='Pearsonr',if_early_stopping=1000,learning_rate=0.0001,epochs=5000,batch_size=5000,ifrandom_split='yes',ifweight='no',ifmute='no',ifsave='yes',savepath='E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_1215',device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3f567a-a1dd-44d8-ae75-32e5c3444498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23345578\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(np.abs(testy-predicty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b3ea65-a427-49f2-8c0a-8c13eb49f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3519, 7) (3519, 7)\n"
     ]
    }
   ],
   "source": [
    "print(testy.shape,predicty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37c8da8d-a175-4d49-a95b-fe7772942950",
   "metadata": {},
   "outputs": [],
   "source": [
    "times=np.arange(3519)\n",
    "testy_u=testy\n",
    "predicty_u=predicty\n",
    "levels=[1000,925,850,700,600,500,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96deff50-b780-48c5-b826-5a0b87e142ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times', 'levels')\n",
    "\n",
    "\n",
    "testy_u_da = xr.DataArray(\n",
    "    data=testy_u,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='testy_u' \n",
    ")\n",
    "\n",
    "\n",
    "predicty_u_da = xr.DataArray(\n",
    "    data=predicty_u,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_u'\n",
    ")\n",
    "\n",
    "testy_u_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_u_onestation_1215.nc')\n",
    "predicty_u_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_u_onestation_1215.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da782789-c599-4b53-b10c-c6c3133369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "testy_u_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_u_onestation_1215.nc')\n",
    "predicty_u_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_u_onestation_1215.nc')\n",
    "testy_u=np.array(testy_u_file['testy_u'])\n",
    "predicty_u=np.array(predicty_u_file['predicty_u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f862ec-d92c-46f0-8cd2-402f35c377aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CDF匹配\n",
    "def Auto_cdf_matching(vx,vy):\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    if np.array(vx).ndim==1:\n",
    "        vx_cdf = (np.arange(len(vx)) +  1) / (len(vx))\n",
    "        vy_cdf = (np.arange(len(vy)) +  1) / (len(vy))\n",
    "        \n",
    "        spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx))\n",
    "        vx_interp = spl(vy_cdf)\n",
    "        \n",
    "        def func(x, a, b, c, d):\n",
    "            return a*x + b*x**2 + c*x**3 + d\n",
    "        \n",
    "        popt = curve_fit(func, vx_interp, np.sort(vy))[0]\n",
    "        \n",
    "        matched_vx = func(vx, *popt)\n",
    "    elif np.array(vx).ndim==2:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            vx_cdf = (np.arange(len(vx[:,i])) +  1) / (len(vx[:,i]))\n",
    "            vy_cdf = (np.arange(len(vy[:,i])) +  1) / (len(vy[:,i]))\n",
    "            \n",
    "            spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i]))\n",
    "            vx_interp = spl(vy_cdf)\n",
    "            \n",
    "            def func(x, a, b, c, d):\n",
    "                return a*x + b*x**2 + c*x**3 + d\n",
    "            \n",
    "            popt = curve_fit(func, vx_interp, np.sort(vy[:,i]))[0]\n",
    "            \n",
    "            matched_vx[:,i] = func(vx[:,i], *popt)\n",
    "    elif np.array(vx).ndim==3:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                vx_cdf = (np.arange(len(vx[:,i,j])) +  1) / (len(vx[:,i,j]))\n",
    "                vy_cdf = (np.arange(len(vy[:,i,j])) +  1) / (len(vy[:,i,j]))\n",
    "                \n",
    "                spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j]))\n",
    "                vx_interp = spl(vy_cdf)\n",
    "                \n",
    "                def func(x, a, b, c, d):\n",
    "                    return a*x + b*x**2 + c*x**3 + d\n",
    "                \n",
    "                popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j]))[0]\n",
    "                \n",
    "                matched_vx[:,i,j] = func(vx[:,i,j], *popt)\n",
    "    elif np.array(vx).ndim==4:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2],vx.shape[3]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                for k in range(vx.shape[3]):\n",
    "                    vx_cdf = (np.arange(len(vx[:,i,j,k])) +  1) / (len(vx[:,i,j,k]))\n",
    "                    vy_cdf = (np.arange(len(vy[:,i,j,k])) +  1) / (len(vy[:,i,j,k]))\n",
    "                    \n",
    "                    spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j,k]))\n",
    "                    vx_interp = spl(vy_cdf)\n",
    "                    \n",
    "                    def func(x, a, b, c, d):\n",
    "                        return a*x + b*x**2 + c*x**3 + d\n",
    "                    \n",
    "                    popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j,k]))[0]\n",
    "                    \n",
    "                    matched_vx[:,i,j,k] = func(vx[:,i,j,k], *popt)\n",
    "\n",
    "    return matched_vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd141a83-bd3f-4bf4-aa3a-53fc576e7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import Auto_paint_self\n",
    "np.random.seed(25)\n",
    "trainy,testy,trainx,testx = train_test_split(np.array(vy),vx,test_size=0.2,random_state=25)\n",
    "predicty_u=Auto_cdf_matching(np.array(predicty_u),trainy[np.random.randint(0,trainy.shape[0], predicty_u.shape[0]),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67a2b5b3-4679-4e1b-89c3-5a0b3d9e71d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 368.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from metpy.calc import wind_direction,wind_speed\n",
    "from metpy.units import units\n",
    "u_rmse=np.zeros((predicty_u.shape[1]))\n",
    "u_mae=np.zeros((predicty_u.shape[1]))\n",
    "u_pearson=np.zeros((predicty_u.shape[1]))\n",
    "u_mape=np.zeros((predicty_u.shape[1]))\n",
    "for i in tqdm(range(predicty_u.shape[1])):\n",
    "    u_rmse[i]=mean_squared_error(testy_u[:,i],predicty_u[:,i])\n",
    "    u_pearson[i],_=pearsonr(testy_u[:,i],predicty_u[:,i])\n",
    "    u_mae[i]=mean_absolute_error(testy_u[:,i],predicty_u[:,i])\n",
    "    u_mape[i]=mean_absolute_percentage_error(testy_u[:,i],predicty_u[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5312b1cf-880f-49cd-9c25-a78afc4f5bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20492403 0.21454887 0.31788547 0.32719542 0.22408389 0.35730374\n",
      " 0.34316497]\n",
      "0.28415805560141505\n"
     ]
    }
   ],
   "source": [
    "print(u_mae)\n",
    "print(np.nanmean(u_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2511a33f-1e5a-4bed-bade-a1a97d95a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07889903 0.09051962 0.18163563 0.1982766  0.13411196 0.22415997\n",
      " 0.25895895]\n",
      "0.16665167922017257\n"
     ]
    }
   ],
   "source": [
    "print(u_rmse)\n",
    "print(np.nanmean(u_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec04903-de35-4c66-92f3-c76447a7e1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01628886 0.01244248 0.01069731 0.00890145 0.01859406 0.01026337\n",
      " 0.01093139]\n",
      "0.012588417855985051\n"
     ]
    }
   ],
   "source": [
    "u_p=np.sqrt(u_rmse)/(np.nanmax(testy_u,axis=0)-np.nanmin(testy_u,axis=0))\n",
    "#v_p=np.sqrt(v_rmse)/(np.nanmax(testy_v,axis=0)-np.nanmin(testy_v,axis=0))\n",
    "#wind_p=np.sqrt(wind_rmse)/(np.nanmax(np.sqrt(testy_u**2+testy_v**2),axis=0)-np.nanmin(np.sqrt(testy_u**2+testy_v**2),axis=0))\n",
    "print(u_p)\n",
    "print(np.nanmean(u_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1efbcb-42c8-49c3-ac71-f9e20cf8d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times', 'levels')\n",
    "\n",
    "predicty_u_da_cdf = xr.DataArray(\n",
    "    data=predicty_u,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_u'\n",
    ")\n",
    "\n",
    "predicty_u_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_u_cdf_onestation_1215.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d01d0e-dc73-40e8-a3c4-9373a1aa0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
