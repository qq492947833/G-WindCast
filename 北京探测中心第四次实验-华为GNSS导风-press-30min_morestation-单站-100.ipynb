{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd95e3a4-ec22-4572-904c-cfc063048129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载原始数据文件...\n",
      "文件加载完毕。\n",
      "正在对原始数据进行预处理...\n",
      "预处理完成。\n",
      "\n",
      "--- 开始筛选站点 (新逻辑) ---\n",
      "目标风场站点: 58557\n",
      "使用预设的目标站点经纬度: Lon=120.0717, Lat=29.3619\n",
      "在GNSS数据文件中找到 1215 个可用站点。\n",
      "在CSV和GNSS数据文件中共有 1215 个共同站点。\n",
      "找到的最近 45 个GNSS站点: ['H992830', 'H998276', 'H11705423', 'H11705435', 'H792737', 'H892451', 'H992254', 'H11705447', 'H11705440', 'H892504', 'H998585', 'H997648', 'H992221', 'H998596', 'H11705442', 'H11705404', 'H798684', 'H997915', 'H997714', 'H11705408', 'H892866', 'H992792', 'H992154', 'H991217', 'H998172', 'H997618', 'H992023', 'H756621', 'H999268', 'H990477', 'H999166', 'H756021', 'H996453', 'H990638', 'H998429', 'H990413', 'H999194', 'H991454', 'H999941', 'H999072', 'H990004', 'H799390', 'H990379', 'H999070', 'H990896']\n",
      "站点筛选完成。\n",
      "\n",
      "--- 正在根据筛选结果过滤数据集 ---\n",
      "数据集过滤完成。\n",
      "  - 过滤后GNSS数据站点数: 45\n",
      "  - 过滤后风场数据站点数: 1\n",
      "\n",
      "--- 开始调用数据准备函数 ---\n",
      "Pass 1: 正在扫描有效的连续序列 (稳健模式)...\n",
      "GNSS 时间 dtype: datetime64[ns], Wind 时间 dtype: datetime64[ns]\n",
      "Pass 1 完成. 共找到 17594 个有效样本。耗时: 19.20 秒。\n",
      "正在预分配内存...\n",
      "Pass 2: 正在填充数据...\n",
      "Pass 2 完成. 数据填充完毕。耗时: 10.72 秒。\n",
      "正在创建最终的 xarray.DataArray...\n",
      "所有处理完成！总耗时: 29.93 秒。\n",
      "\n",
      "--- 处理后结果 ---\n",
      "输入变量 vx:\n",
      "  - 形状: (17594, 6, 45)\n",
      "  - 维度: ('sample', 'timesteps', 'station')\n",
      "  - 站点: ['H992830' 'H998276' 'H11705423' 'H11705435' 'H792737' 'H892451' 'H992254'\n",
      " 'H11705447' 'H11705440' 'H892504' 'H998585' 'H997648' 'H992221' 'H998596'\n",
      " 'H11705442' 'H11705404' 'H798684' 'H997915' 'H997714' 'H11705408'\n",
      " 'H892866' 'H992792' 'H992154' 'H991217' 'H998172' 'H997618' 'H992023'\n",
      " 'H756621' 'H999268' 'H990477' 'H999166' 'H756021' 'H996453' 'H990638'\n",
      " 'H998429' 'H990413' 'H999194' 'H991454' 'H999941' 'H999072' 'H990004'\n",
      " 'H799390' 'H990379' 'H999070' 'H990896']\n",
      "  - 内存占用: 19.00 MB\n",
      "\n",
      "目标变量 vy:\n",
      "  - 形状: (17594, 7)\n",
      "  - 维度: ('sample', 'station_press_flat')\n",
      "  - 站点: [58557]\n",
      "  - 内存占用: 0.49 MB\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    使用Haversine公式计算两个经纬度点之间的距离（单位：公里）。\n",
    "    \"\"\"\n",
    "    # 将十进制度数转化为弧度\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine公式\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371 # 地球平均半径，单位为公里\n",
    "    return c * r\n",
    "\n",
    "def prepare_transformer_inputs_mem_efficient_robust(gnss_ds: xr.Dataset, wind_ds: xr.Dataset):\n",
    "    \"\"\"\n",
    "    更稳健的版本，处理时间戳 dtype 不匹配的问题。\n",
    "    (此函数无需任何修改)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    gnss_ztd = gnss_ds['ztd']\n",
    "    wind_u = wind_ds['U']\n",
    "    \n",
    "    sequence_length = 6\n",
    "    time_step = pd.to_timedelta('5min')\n",
    "    expected_duration = time_step * (sequence_length - 1)\n",
    "\n",
    "    num_gnss_times = len(gnss_ztd.time)\n",
    "    \n",
    "    # --- Pass 1: 扫描并找到所有有效样本的起始索引 ---\n",
    "    print(\"Pass 1: 正在扫描有效的连续序列 (稳健模式)...\")\n",
    "    \n",
    "    gnss_dtype = gnss_ztd.time.dtype\n",
    "    wind_dtype = wind_u.Datetime.dtype\n",
    "    print(f\"GNSS 时间 dtype: {gnss_dtype}, Wind 时间 dtype: {wind_dtype}\")\n",
    "    wind_dtype_unit = np.datetime_data(wind_dtype)[0]\n",
    "\n",
    "    valid_start_indices = []\n",
    "    wind_times_set = set(wind_u.Datetime.values)\n",
    "\n",
    "    for i in range(num_gnss_times - sequence_length + 1):\n",
    "        window_times = gnss_ztd.time[i : i + sequence_length]\n",
    "        \n",
    "        actual_duration = window_times[-1].values - window_times[0].values\n",
    "        if np.abs(actual_duration - expected_duration) < pd.to_timedelta('1s'):\n",
    "            \n",
    "            target_wind_time_raw = window_times[-1].values + 6*time_step\n",
    "            target_wind_time_converted = np.datetime64(target_wind_time_raw, wind_dtype_unit)\n",
    "\n",
    "            if target_wind_time_converted in wind_times_set:\n",
    "                valid_start_indices.append(i)\n",
    "    \n",
    "    num_samples = len(valid_start_indices)\n",
    "    print(f\"Pass 1 完成. 共找到 {num_samples} 个有效样本。耗时: {time.time() - start_time:.2f} 秒。\")\n",
    "\n",
    "    if num_samples == 0:\n",
    "        print(\"在稳健模式下仍然未找到任何有效序列。请检查数据本身，例如风场数据是否覆盖了GNSS数据的时间范围。\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 内存分配 (Pass 2) ---\n",
    "    print(\"正在预分配内存...\")\n",
    "    num_stations_gnss = len(gnss_ztd.station)\n",
    "    num_stations_wind = len(wind_u.station)\n",
    "    num_press_levels = len(wind_u.PRESS)\n",
    "    \n",
    "    vx_data = np.empty((num_samples, sequence_length, num_stations_gnss), dtype=np.float32)\n",
    "    vy_data = np.empty((num_samples, num_stations_wind * num_press_levels), dtype=np.float32)\n",
    "\n",
    "    print(\"Pass 2: 正在填充数据...\")\n",
    "    fill_start_time = time.time()\n",
    "    gnss_ztd_values = gnss_ztd.values\n",
    "    \n",
    "    for k, start_idx in enumerate(valid_start_indices):\n",
    "        end_idx = start_idx + sequence_length\n",
    "        vx_data[k, :, :] = gnss_ztd_values[start_idx:end_idx, :]\n",
    "        \n",
    "        last_gnss_time = gnss_ztd.time[end_idx - 1]\n",
    "        target_wind_time = last_gnss_time.values + 6*time_step\n",
    "        \n",
    "        target_wind_time_converted = np.datetime64(target_wind_time, wind_dtype_unit)\n",
    "        vy_slice_values = wind_u.sel(Datetime=target_wind_time_converted).values\n",
    "        vy_data[k, :] = vy_slice_values.flatten()\n",
    "        \n",
    "    print(f\"Pass 2 完成. 数据填充完毕。耗时: {time.time() - fill_start_time:.2f} 秒。\")\n",
    "\n",
    "    print(\"正在创建最终的 xarray.DataArray...\")\n",
    "    sample_coords = gnss_ztd.time.values[valid_start_indices]\n",
    "    vx = xr.DataArray(\n",
    "        vx_data,\n",
    "        dims=('sample', 'timesteps', 'station'),\n",
    "        coords={'sample': sample_coords, 'timesteps': np.arange(sequence_length), 'station': gnss_ztd.station.values}\n",
    "    )\n",
    "\n",
    "    vy_flat_coords = wind_u.stack(station_press_flat=('station', 'PRESS')).coords['station_press_flat']\n",
    "    vy = xr.DataArray(\n",
    "        vy_data,\n",
    "        dims=('sample', 'station_press_flat'),\n",
    "        coords={'sample': sample_coords, 'station_press_flat': vy_flat_coords}\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"所有处理完成！总耗时: {total_time:.2f} 秒。\")\n",
    "    return vx, vy\n",
    "\n",
    "# --- 主程序 ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. 定义文件路径和目标站点信息\n",
    "    gnss_nc_path = r'E:/gnss_ztd_combined_robust_morestation.nc'\n",
    "    wind_nc_path = r'E:/merged_stations_6min_common_period_float32_no_nan_press.nc'\n",
    "    gnss_info_path = r'E:\\huawei_gnss_morestation\\zj_allid.csv'\n",
    "    \n",
    "    target_wind_station_id = 58557 \n",
    "    target_wind_station_lon = 120.0717\n",
    "    target_wind_station_lat = 29.3619\n",
    "    \n",
    "    num_nearest_stations = 45 \n",
    "\n",
    "    # 2. 加载原始数据文件\n",
    "    print(\"正在加载原始数据文件...\")\n",
    "    gnss_file = xr.open_dataset(gnss_nc_path)\n",
    "    wind_file = xr.open_dataset(wind_nc_path)\n",
    "    gnss_info_df = pd.read_csv(gnss_info_path)\n",
    "    print(\"文件加载完毕。\")\n",
    "\n",
    "    # 3. 对原始数据进行预处理（插值、填充等）\n",
    "    print(\"正在对原始数据进行预处理...\")\n",
    "    wind_new_time = pd.date_range(wind_file.Datetime.values[0], wind_file.Datetime.values[-1], freq='5min')\n",
    "    wind_file = wind_file.interp(Datetime=wind_new_time)\n",
    "    gnss_file = gnss_file.interpolate_na(dim='time')\n",
    "    gnss_file = gnss_file.ffill(dim='time').bfill(dim='time')\n",
    "    print(\"预处理完成。\")\n",
    "\n",
    "    # 4. MODIFIED LOGIC: 寻找实际存在于数据中的最近10个GNSS站点\n",
    "    print(\"\\n--- 开始筛选站点 (新逻辑) ---\")\n",
    "    print(f\"目标风场站点: {target_wind_station_id}\")\n",
    "    print(f\"使用预设的目标站点经纬度: Lon={target_wind_station_lon}, Lat={target_wind_station_lat}\")\n",
    "\n",
    "    # 步骤 4.1: 获取gnss数据文件中实际存在的所有站点ID\n",
    "    available_gnss_in_nc = gnss_file.station.values\n",
    "    print(f\"在GNSS数据文件中找到 {len(available_gnss_in_nc)} 个可用站点。\")\n",
    "\n",
    "    # 步骤 4.2: 从CSV站点信息中，只保留那些实际存在于gnss数据文件中的站点\n",
    "    gnss_info_df['id'] = gnss_info_df['id'].astype(str)\n",
    "    # 使用.copy()避免SettingWithCopyWarning\n",
    "    valid_stations_info_df = gnss_info_df[gnss_info_df['id'].isin(available_gnss_in_nc)].copy()\n",
    "    if valid_stations_info_df.empty:\n",
    "        raise ValueError(\"CSV站点信息文件和GNSS数据文件之间没有共同的站点。\")\n",
    "    print(f\"在CSV和GNSS数据文件中共有 {len(valid_stations_info_df)} 个共同站点。\")\n",
    "\n",
    "\n",
    "    # 步骤 4.3: 在这个有效站点子集上计算到目标的距离\n",
    "    valid_stations_info_df['distance_km'] = valid_stations_info_df.apply(\n",
    "        lambda row: haversine(target_wind_station_lon, target_wind_station_lat, row['lon'], row['lat']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 步骤 4.4: 按距离排序并选出最近的N个\n",
    "    # 检查可用站点是否少于期望数量\n",
    "    if len(valid_stations_info_df) < num_nearest_stations:\n",
    "        print(f\"警告: 可用站点总数 ({len(valid_stations_info_df)}) 小于期望的数量 ({num_nearest_stations})。将使用所有可用的站点。\")\n",
    "        num_to_select = len(valid_stations_info_df)\n",
    "    else:\n",
    "        num_to_select = num_nearest_stations\n",
    "\n",
    "    nearest_stations_df = valid_stations_info_df.sort_values(by='distance_km').head(num_to_select)\n",
    "    final_gnss_selection = nearest_stations_df['id'].tolist()\n",
    "    \n",
    "    print(f\"找到的最近 {len(final_gnss_selection)} 个GNSS站点: {final_gnss_selection}\")\n",
    "    print(\"站点筛选完成。\")\n",
    "\n",
    "\n",
    "    # 5. 根据筛选出的站点ID来过滤xarray数据集\n",
    "    print(\"\\n--- 正在根据筛选结果过滤数据集 ---\")\n",
    "    \n",
    "    # 确保目标站点存在于wind_file中\n",
    "    if target_wind_station_id not in wind_file.station.values:\n",
    "        raise ValueError(f\"目标站点 {target_wind_station_id} 在风场数据中未找到!\")\n",
    "\n",
    "    gnss_file_filtered = gnss_file.sel(station=final_gnss_selection)\n",
    "    wind_file_filtered = wind_file.sel(station=[target_wind_station_id])\n",
    "\n",
    "    print(\"数据集过滤完成。\")\n",
    "    print(f\"  - 过滤后GNSS数据站点数: {len(gnss_file_filtered.station)}\")\n",
    "    print(f\"  - 过滤后风场数据站点数: {len(wind_file_filtered.station)}\")\n",
    "\n",
    "    # 6. 调用核心处理函数\n",
    "    print(\"\\n--- 开始调用数据准备函数 ---\")\n",
    "    vx, vy = prepare_transformer_inputs_mem_efficient_robust(gnss_file_filtered, wind_file_filtered)\n",
    "\n",
    "    # 7. 打印最终结果\n",
    "    if vx is not None and vy is not None:\n",
    "        print(\"\\n--- 处理后结果 ---\")\n",
    "        print(\"输入变量 vx:\")\n",
    "        print(f\"  - 形状: {vx.shape}\")\n",
    "        print(f\"  - 维度: {vx.dims}\")\n",
    "        print(f\"  - 站点: {vx.station.values}\")\n",
    "        print(f\"  - 内存占用: {vx.nbytes / 1e6:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n目标变量 vy:\")\n",
    "        print(f\"  - 形状: {vy.shape}\")\n",
    "        print(f\"  - 维度: {vy.dims}\")\n",
    "        vy_station = vy.station_press_flat.to_index().get_level_values('station').unique().to_list()\n",
    "        print(f\"  - 站点: {vy_station}\")\n",
    "        print(f\"  - 内存占用: {vy.nbytes / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28420690-6159-40b4-97b6-977a409e4c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer网络\n",
    "def Auto_Transformer(vy,vx,timestep,model_list,test_size=0.2,valid_size=0.1,k_fold=None,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=2,key_dim=2,ifdropout='no',trans_dropout_rate=0.0,trans_units=64,trans_activation='sigmoid',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='SGD',metrics='default',if_early_stopping=None,learning_rate=0.01,epochs=2000,batch_size=20,ifrandom_split='yes',ifweight='yes',ifmute='no',ifsave='no',savepath=None,device='cpu'):\n",
    "    import tensorflow as tf\n",
    "    if device=='gpu':\n",
    "        gpus = tf.config.list_physical_devices('GPU')\n",
    "        if gpus:\n",
    "            try:\n",
    "                # 设置只使用 GPU 0\n",
    "                tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "                # 设置 GPU 0 的内存动态增长\n",
    "                tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "    from keras.models import Sequential,Model\n",
    "    from keras.layers.core import Activation,Dropout,Dense\n",
    "    from keras.layers import Input,BatchNormalization,LayerNormalization,Embedding,Add,MultiHeadAttention,Flatten\n",
    "    from keras.initializers import TruncatedNormal,RandomNormal,RandomUniform\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import KFold\n",
    "    import numpy as np\n",
    "    from tensorflow.keras.optimizers import SGD,Adam\n",
    "    import keras\n",
    "    from scipy.stats import pearsonr\n",
    "    import os\n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "    from keras.models import load_model\n",
    "    import sklearn\n",
    "    import copy\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    from tensorflow.keras import backend as K\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    if embedding_num==None:\n",
    "        embedding_num=timestep+1\n",
    "    if task_mode=='regression':\n",
    "        if loss_function=='default' or loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanSquaredError':\n",
    "            loss=tf.keras.losses.MeanSquaredError()\n",
    "        elif loss_function=='MeanAbsoluteError':\n",
    "            loss=tf.keras.losses.MeanAbsoluteError()\n",
    "        elif loss_function=='MeanAbsolutePercentageError':\n",
    "            loss=tf.keras.losses.MeanAbsolutePercentageError()\n",
    "        elif loss_function=='MeanSquaredLogarithmicError':\n",
    "            loss=tf.keras.losses.MeanSquaredLogarithmicError()\n",
    "        elif loss_function=='CosineSimilarity':\n",
    "            loss=tf.keras.losses.CosineSimilarity()\n",
    "        elif loss_function=='Huber':\n",
    "            loss=tf.keras.losses.Huber()\n",
    "        elif loss_function=='LogCosh':\n",
    "            loss=tf.keras.losses.LogCosh()\n",
    "        elif loss_function=='Pearsonr':\n",
    "            def loss_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            loss=loss_pearsonr\n",
    "        if metrics=='default' or metrics=='MeanSquaredError':\n",
    "            metric=tf.keras.metrics.MeanSquaredError()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='MeanAbsolutePercentageError':\n",
    "            metric=tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "        elif metrics=='MeanSquaredLogarithmicError':\n",
    "            metric=tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "        elif metrics=='CosineSimilarity':\n",
    "            metric=tf.keras.metrics.CosineSimilarity()\n",
    "        elif metrics=='LogCoshError':\n",
    "            metric=tf.keras.metrics.LogCoshError()\n",
    "        elif metrics=='Pearsonr':\n",
    "            def metrics_pearsonr(y_true,y_pred):\n",
    "                import tensorflow as tf\n",
    "                y_true_mean=tf.reduce_mean(y_true,axis=0)\n",
    "                y_pred_mean=tf.reduce_mean(y_pred,axis=0)\n",
    "                cov=tf.reduce_sum((y_true-y_true_mean)*(y_pred-y_pred_mean),axis=0)\n",
    "                y_true_v=tf.reduce_sum(tf.square((y_true-y_true_mean)),axis=0)\n",
    "                y_pred_v=tf.reduce_sum(tf.square((y_pred-y_pred_mean)),axis=0)\n",
    "                y_true_v=tf.sqrt(y_true_v)\n",
    "                y_pred_v=tf.sqrt(y_pred_v)\n",
    "                pearson=cov/(y_true_v*y_pred_v)\n",
    "                return (1-pearson)**1.5\n",
    "            metric=metrics_pearsonr\n",
    "    elif task_mode=='binary_classify':\n",
    "        if loss_function=='default' or loss_function=='BinaryCrossentropy':\n",
    "            loss=tf.keras.losses.BinaryCrossentropy()\n",
    "        elif loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        elif loss_function=='f1':\n",
    "            def loss_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return 1 - f1\n",
    "            loss=loss_f1\n",
    "        if metrics=='default' or metrics=='BinaryAccuracy':\n",
    "            metric=tf.keras.metrics.BinaryAccuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='BinaryCrossentropy':\n",
    "            metric=tf.keras.metrics.BinaryCrossentropy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "        elif metrics=='AUC':\n",
    "            metric=tf.keras.metrics.AUC()\n",
    "        elif metrics=='Precision':\n",
    "            metric=tf.keras.metrics.Precision()\n",
    "        elif metrics=='Recall':\n",
    "            metric=tf.keras.metrics.Recall()\n",
    "        elif metrics=='TruePositives':\n",
    "            metric=tf.keras.metrics.TruePositives()\n",
    "        elif metrics=='TrueNegatives':\n",
    "            metric=tf.keras.metrics.TrueNegatives()\n",
    "        elif metrics=='FalsePositives':\n",
    "            metric=tf.keras.metrics.FalsePositives()\n",
    "        elif metrics=='FalseNegatives':\n",
    "            metric=tf.keras.metrics.FalseNegatives()\n",
    "        elif metrics=='PrecisionAtRecall':\n",
    "            metric=tf.keras.metrics.PrecisionAtRecall()\n",
    "        elif metrics=='SensitivityAtSpecificity':\n",
    "            metric=tf.keras.metrics.SensitivityAtSpecificity()\n",
    "        elif metrics=='SpecificityAtSensitivity':\n",
    "            metric=tf.keras.metrics.SpecificityAtSensitivity()\n",
    "        elif metrics=='f1':\n",
    "            def metric_f1(y_true, y_pred):\n",
    "                y_true = K.cast(y_true, 'float32')\n",
    "                y_pred = K.cast(y_pred, 'float32')\n",
    "                \n",
    "                tp = K.sum(y_true * y_pred)\n",
    "                fp = K.sum((1 - y_true) * y_pred)\n",
    "                fn = K.sum(y_true * (1 - y_pred))\n",
    "                \n",
    "                precision = tp / (tp + fp + K.epsilon())\n",
    "                recall = tp / (tp + fn + K.epsilon())\n",
    "                \n",
    "                f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "                \n",
    "                return f1\n",
    "            metric=metric_f1\n",
    "    elif task_mode=='multi_classify':\n",
    "        if loss_function=='default' or loss_function=='CategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.CategoricalCrossentropy()\n",
    "        elif loss_function=='SparseCategoricalCrossentropy':\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        elif loss_function=='Poisson':\n",
    "            loss=tf.keras.losses.Poisson()\n",
    "        elif loss_function=='KLDivergence':\n",
    "            loss=tf.keras.losses.KLDivergence()\n",
    "        if metrics=='default' or metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='MeanAbsoluteError':\n",
    "            metric=tf.keras.metrics.MeanAbsoluteError()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='TopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.TopKCategoricalAccuracy()\n",
    "        elif metrics=='SparseTopKCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
    "        elif metrics=='CategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.CategoricalCrossentropy()\n",
    "        elif metrics=='SparseCategoricalCrossentropy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "        elif metrics=='Accuracy':\n",
    "            metric=tf.keras.metrics.Accuracy()\n",
    "        elif metrics=='CategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.CategoricalAccuracy()\n",
    "        elif metrics=='SparseCategoricalAccuracy':\n",
    "            metric=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        elif metrics=='KLDivergence':\n",
    "            metric=tf.keras.metrics.KLDivergence()\n",
    "        elif metrics=='Poisson':\n",
    "            metric=tf.keras.metrics.Poisson()\n",
    "    weights=0\n",
    "    model=0\n",
    "    if vy.ndim==1:\n",
    "        vy=vy.reshape(vy.shape[0],1)\n",
    "    if ifrandom_split=='yes':\n",
    "        trainy,testy,trainx,testx = train_test_split(vy,vx,test_size=test_size,random_state=25)\n",
    "    else:\n",
    "        index=int((1-test_size)*vy.shape[0])\n",
    "        trainy=vy[:index]\n",
    "        testy=vy[index:]\n",
    "        trainx=vx[:index,:,:]\n",
    "        testx=vx[index:,:,:]\n",
    "    train_position=np.zeros((trainx.shape[0],trainx.shape[1]))\n",
    "    test_position=np.zeros((testx.shape[0],testx.shape[1]))\n",
    "    for i in range(trainx.shape[0]):\n",
    "        train_position[i,:]=np.arange(0,timestep,1)\n",
    "    for i in range(testx.shape[0]):\n",
    "        test_position[i,:]=np.arange(0,timestep,1)\n",
    "    if task_mode!='regression':\n",
    "        def create_sample_weights_for_batch_multitask(y_batch_multitask, list_of_task_weights_dicts):\n",
    "            batch_size, num_tasks = y_batch_multitask.shape\n",
    "            \n",
    "            if len(list_of_task_weights_dicts) != num_tasks:\n",
    "                raise ValueError(f\"Number of tasks in y_batch_multitask ({num_tasks}) \"\n",
    "                                 f\"must match length of list_of_task_weights_dicts ({len(list_of_task_weights_dicts)}).\")\n",
    "        \n",
    "            sample_weight_batch = np.ones_like(y_batch_multitask, dtype=np.float32)\n",
    "        \n",
    "            for i in range(num_tasks):\n",
    "                task_labels_current_channel = y_batch_multitask[:, i] \n",
    "                weights_dict_for_task_i = list_of_task_weights_dicts[i]\n",
    "                \n",
    "                weight_for_0 = weights_dict_for_task_i.get(0, 1.0)\n",
    "                weight_for_1 = weights_dict_for_task_i.get(1, 1.0)\n",
    "                \n",
    "                current_task_weights = sample_weight_batch[:, i] \n",
    "                current_task_weights[task_labels_current_channel == 0] = weight_for_0\n",
    "                current_task_weights[task_labels_current_channel == 1] = weight_for_1\n",
    "                sample_weight_batch[:, i] = current_task_weights\n",
    "                \n",
    "            return sample_weight_batch\n",
    "        def compute_unified_class_weights(y, task_mode=task_mode):\n",
    "            if task_mode == 'binary_classify':\n",
    "                if y.ndim == 2 and y.shape[-1] > 1:\n",
    "                    num_tasks = y.shape[-1]\n",
    "                    list_of_task_weights_dicts = []\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    for i in range(num_tasks):\n",
    "                        y_task_i_flat = y[:, i].ravel()\n",
    "                        if len(y_task_i_flat) == 0:\n",
    "                            weights_dict_task_i = {0: 1.0, 1: 1.0} \n",
    "                        else:\n",
    "                            valid_labels_mask = np.isin(y_task_i_flat, possible_binary_classes)\n",
    "                            if not np.all(valid_labels_mask) and np.any(valid_labels_mask): \n",
    "                                y_task_i_flat_filtered = y_task_i_flat[valid_labels_mask]\n",
    "                                if len(y_task_i_flat_filtered) == 0 : y_task_i_flat_filtered = np.array([0]) \n",
    "                            elif not np.any(valid_labels_mask): \n",
    "                                 y_task_i_flat_filtered = np.array([0]) \n",
    "                            else:\n",
    "                                y_task_i_flat_filtered = y_task_i_flat\n",
    "                            class_weights_arr = compute_class_weight(\n",
    "                                class_weight='balanced',\n",
    "                                classes=possible_binary_classes, \n",
    "                                y=y_task_i_flat_filtered\n",
    "                            )\n",
    "                            weights_dict_task_i = dict(zip(possible_binary_classes, class_weights_arr))\n",
    "                        list_of_task_weights_dicts.append(weights_dict_task_i)\n",
    "                    return list_of_task_weights_dicts \n",
    "        \n",
    "                else: \n",
    "                    y_flat = y.ravel()\n",
    "                    possible_binary_classes = np.array([0, 1])\n",
    "                    valid_labels_mask = np.isin(y_flat, possible_binary_classes)\n",
    "                    if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                        y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                        if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0])\n",
    "                    elif not np.any(valid_labels_mask):\n",
    "                         y_flat_filtered = np.array([0])\n",
    "                    else:\n",
    "                        y_flat_filtered = y_flat\n",
    "        \n",
    "                    class_weights_arr = compute_class_weight(\n",
    "                        class_weight='balanced',\n",
    "                        classes=possible_binary_classes,\n",
    "                        y=y_flat_filtered\n",
    "                    )\n",
    "                    return dict(zip(possible_binary_classes, class_weights_arr)) \n",
    "        \n",
    "            elif task_mode == 'multi_classify':\n",
    "                y_flat = y.ravel()\n",
    "                possible_multiclass_classes = np.arange(int(np.max(y)+1))\n",
    "                valid_labels_mask = np.isin(y_flat, possible_multiclass_classes)\n",
    "                if not np.all(valid_labels_mask) and np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = y_flat[valid_labels_mask]\n",
    "                    if len(y_flat_filtered) == 0 : y_flat_filtered = np.array([0]) \n",
    "                elif not np.any(valid_labels_mask):\n",
    "                    y_flat_filtered = np.array([0]) \n",
    "                else:\n",
    "                    y_flat_filtered = y_flat\n",
    "                class_weights_arr = compute_class_weight(\n",
    "                    class_weight='balanced',\n",
    "                    classes=possible_multiclass_classes,\n",
    "                    y=y_flat_filtered\n",
    "                )\n",
    "                return dict(zip(possible_multiclass_classes, class_weights_arr)) \n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported task_mode: {task_mode}\")\n",
    "        def create_unified_sample_weights_for_batch(y_batch, unified_class_weights):\n",
    "            if isinstance(unified_class_weights, list):\n",
    "                if not (y_batch.ndim == 2 and y_batch.shape[-1] == len(unified_class_weights)):\n",
    "                     raise ValueError(f\"Shape mismatch for multi-task binary weights. \"\n",
    "                                      f\"y_batch shape: {y_batch.shape}, num_weight_dicts: {len(unified_class_weights)}\")\n",
    "                return create_sample_weights_for_batch_multitask(y_batch, unified_class_weights)\n",
    "            elif isinstance(unified_class_weights, dict):\n",
    "                y_int_labels_for_weights = y_batch\n",
    "                if y_batch.ndim == 2 and y_batch.shape[-1] == 1: \n",
    "                    y_int_labels_for_weights = np.squeeze(y_batch, axis=-1)\n",
    "                sample_weight_for_batch = np.ones_like(y_int_labels_for_weights, dtype=np.float32)\n",
    "                for class_label, weight in unified_class_weights.items():\n",
    "                    sample_weight_for_batch[y_int_labels_for_weights == class_label] = weight\n",
    "                \n",
    "                return sample_weight_for_batch\n",
    "            else:\n",
    "                raise TypeError(f\"unified_class_weights has unexpected type: {type(unified_class_weights)}. Expected dict or list.\")\n",
    "        def train_data_generator(x,position, y, batch_size, task_mode=task_mode):\n",
    "            num_samples = x.shape[0]\n",
    "            global_unified_weights = compute_unified_class_weights(y, task_mode)\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    if len(batch_indices) == 0:\n",
    "                        continue\n",
    "        \n",
    "                    x_batch = x[batch_indices]\n",
    "                    position_batch = position[batch_indices]\n",
    "                    y_batch = y[batch_indices] \n",
    "                    sample_weight_batch = create_unified_sample_weights_for_batch(\n",
    "                        y_batch, \n",
    "                        global_unified_weights\n",
    "                    )\n",
    "                    yield {\"input_1\": x_batch, \"input_2\": position_batch}, y_batch, sample_weight_batch\n",
    "    else:\n",
    "        def train_data_generator(x, position, y, batch_size):\n",
    "            num_samples = x.shape[0]\n",
    "            while True:\n",
    "                indices = np.arange(num_samples)\n",
    "                \n",
    "                for start in range(0, num_samples, batch_size):\n",
    "                    end = min(start + batch_size, num_samples)\n",
    "                    batch_indices = indices[start:end]\n",
    "                    \n",
    "                    x_batch = x[batch_indices]  \n",
    "                    position_batch = position[batch_indices]   \n",
    "                    y_batch = y[batch_indices]      \n",
    "                    \n",
    "                    yield ({\"input_1\": x_batch, \"input_2\": position_batch}, y_batch)\n",
    "    def test_data_generator(x, position, batch_size):\n",
    "        num_samples = x.shape[0]\n",
    "        while True:\n",
    "            indices = np.arange(num_samples)\n",
    "            \n",
    "            for start in range(0, num_samples, batch_size):\n",
    "                end = min(start + batch_size, num_samples)\n",
    "                batch_indices = indices[start:end]\n",
    "                \n",
    "                x_batch = x[batch_indices]  # 第一个输入特征\n",
    "                position_batch = position[batch_indices]\n",
    "                \n",
    "                yield ({\"input_1\": x_batch, \"input_2\": position_batch})\n",
    "    if if_best_mode=='no':\n",
    "        inputshape1=(None,timestep,trainx.shape[2])\n",
    "        inputshape2=(None,timestep)\n",
    "        inputs1=Input(shape=(timestep,trainx.shape[2]))\n",
    "        inputs2=Input(shape=(timestep))\n",
    "        for i in range(len(model_list)):\n",
    "            if model_list[i][0] == 'transformer':\n",
    "                position_embedding=Embedding(embedding_num,trainx.shape[2],input_length=timestep,input_shape=inputshape2)(inputs2)\n",
    "                add=Add(input_shape=inputshape1)([inputs1,position_embedding])\n",
    "                for j in range(encoder_deep):\n",
    "                    if j ==0:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(add,add,add)')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([add,en_multihead'+str(j+1)+'])')\n",
    "                    else:\n",
    "                        exec('en_multihead'+str(j+1)+'=MultiHeadAttention(num_heads=num_heads,key_dim=key_dim,dropout=trans_dropout_rate,attention_axes=1)(en_layernormalization'+str(j)+',en_layernormalization'+str(j)+',en_layernormalization'+str(j)+')')\n",
    "                        exec('en_add'+str(j+1)+'=Add()([en_layernormalization'+str(j)+',en_multihead'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                    if ifdropout=='yes':\n",
    "                        exec('en_dropout'+str(j+1)+'=Dropout(trans_dropout_rate)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_dropout'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    else:\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trans_units,activation=trans_activation)(en_layernormalization'+str(j+1)+')')\n",
    "                        exec('en_fc'+str(j+1)+'=Dense(trainx.shape[2],activation=trans_activation)(en_fc'+str(j+1)+')')\n",
    "                    exec('en_add'+str(j+1)+'=Add()([en_fc'+str(j+1)+',en_layernormalization'+str(j+1)+'])')\n",
    "                    exec('en_layernormalization'+str(j+1)+'=LayerNormalization()(en_add'+str(j+1)+')')\n",
    "                exec('en_fla=Flatten()(en_layernormalization'+str(j+1)+')')\n",
    "            elif model_list[i][0] == 'batchnormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=BatchNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'layernormalization':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('norm'+str(i+1)+'=LayerNormalization(axis=-1)(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'activation':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('act'+str(i+1)+'=Activation(model_list[i][1])(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'flatten':\n",
    "                if model_list[i-1][0]=='transformer':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(en_fla)')\n",
    "                elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(norm'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='activation':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(act'+str(i)+')')\n",
    "                elif model_list[i-1][0]=='dropout':\n",
    "                    exec('fla'+str(i+1)+'=Flatten()(drop'+str(i)+')')\n",
    "            elif model_list[i][0] =='fc':\n",
    "                if if_weight_initialize=='no':\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            outputs=eval('Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            outputs=eval('Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            outputs=eval('Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            outputs=eval('Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            outputs=eval('Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            exec('fc'+str(i+1)+'=Dense(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if i==len(model_list)-1:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                outputs=eval('Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                    else:\n",
    "                        if model_list[i-1][0]=='transformer':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(en_fla)')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(en_fla)')\n",
    "                        elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(norm'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='activation':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(act'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='dropout':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(drop'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='fc':   \n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fc'+str(i)+')')\n",
    "                        elif model_list[i-1][0]=='flatten':\n",
    "                            if weight_initialize_method=='RandomNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='RandomUniform':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = RandomUniform(minval=weight_initialize_parameter1,maxval=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "                            elif weight_initialize_method=='TruncatedNormal':\n",
    "                                exec('fc'+str(i+1)+'=Dense(model_list[i][1],kernel_initializer = TruncatedNormal(mean=weight_initialize_parameter1,stddev=weight_initialize_parameter2))(fla'+str(i)+')')\n",
    "            elif model_list[i][0] == 'dropout':\n",
    "                if i==len(model_list)-1:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        outputs=eval('Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        outputs=eval('Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "                else:\n",
    "                    if model_list[i-1][0]=='transformer':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(en_fla)')\n",
    "                    elif model_list[i-1][0]=='batchnormalization' or model_list[i-1][0]=='layernormalization':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(norm'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='activation':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(act'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='dropout' :\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(drop'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='fc':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fc'+str(i)+')')\n",
    "                    elif model_list[i-1][0]=='flatten':\n",
    "                        exec('drop'+str(i+1)+'=Dropout(model_list[i][1])(fla'+str(i)+')')\n",
    "        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "        if optimizer == 'SGD':\n",
    "            opt = SGD(lr = learning_rate)\n",
    "        elif optimizer == 'Adam':\n",
    "            opt = Adam(lr = learning_rate)\n",
    "        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "    elif if_best_mode=='yes' or if_best_mode=='load':\n",
    "        if k_fold!=None:\n",
    "            models=[]\n",
    "            for i in range(k_fold):\n",
    "                models.append(load_model(modelpath+'_'+str(i+1)))\n",
    "        else:\n",
    "            model=load_model(modelpath)\n",
    "    if if_print_model=='yes':\n",
    "        if k_fold!=None:\n",
    "            if if_best_mode=='yes' or if_best_mode=='load':\n",
    "                print(models[0].summary())\n",
    "            else:\n",
    "                print(model.summary())\n",
    "        else:\n",
    "            print(model.summary())\n",
    "    if epochs!=0:\n",
    "        if valid_size!=None or k_fold !=None:\n",
    "            if k_fold!=None:\n",
    "                if if_best_mode=='no' :\n",
    "                    models = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        model=eval('Model(inputs=[inputs1,inputs2], outputs=outputs)')\n",
    "                        model.compile(loss=loss,optimizer=opt,metrics=[metric])\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = model.fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models.append(model)\n",
    "                else:\n",
    "                    models_new = []\n",
    "                    if ifrandom_split=='yes':\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=True, random_state=25)\n",
    "                    else:\n",
    "                        kf = KFold(n_splits=k_fold, shuffle=False)\n",
    "                    for fold_no, (train_idx, val_idx) in enumerate(kf.split(trainx, trainy)):\n",
    "                        X_train_fold, y_train_fold, position_train_fold = trainx[train_idx], trainy[train_idx], train_position[train_idx]\n",
    "                        X_val_fold, y_val_fold, position_val_fold = trainx[val_idx], trainy[val_idx], train_position[val_idx]\n",
    "                        if if_early_stopping!=None:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                        else:\n",
    "                            H = models[fold_no].fit(train_data_generator(X_train_fold,position_train_fold,y_train_fold,batch_size),steps_per_epoch=(len(X_train_fold) // batch_size+(1 if len(X_train_fold) % batch_size != 0 else 0)),validation_data=train_data_generator(X_val_fold,position_val_fold,y_val_fold,batch_size),validation_steps=(len(X_val_fold) // batch_size+(1 if len(X_val_fold) % batch_size != 0 else 0)),epochs = epochs)\n",
    "                        models_new.append(models[fold_no])\n",
    "                    models=models_new\n",
    "            else:\n",
    "                if ifrandom_split=='yes':\n",
    "                    trainy,validy,trainx,validx,train_position,valid_position = train_test_split(trainy,trainx,train_position,test_size=valid_size/(1-test_size),random_state=25)\n",
    "                else:\n",
    "                    index=int((1-valid_size/(1-test_size))*trainy.shape[0])\n",
    "                    validy=trainy[index:]\n",
    "                    trainy=trainy[:index]\n",
    "                    validx=trainx[index:]\n",
    "                    trainx=trainx[:index]\n",
    "                    valid_position=train_position[index:]\n",
    "                    train_position=train_position[:index]\n",
    "                if if_early_stopping!=None:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "                else:\n",
    "                    H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(validx,valid_position,validy,batch_size),validation_steps=(len(validx) // batch_size+(1 if len(validx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "        else:\n",
    "            if if_early_stopping!=None:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=if_early_stopping,restore_best_weights=True)])\n",
    "            else:\n",
    "                H = model.fit(train_data_generator(trainx,train_position,trainy,batch_size),steps_per_epoch=(len(trainx) // batch_size+(1 if len(trainx) % batch_size != 0 else 0)),validation_data=train_data_generator(testx,test_position,testy,batch_size),validation_steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)),epochs = epochs)\n",
    "    if k_fold!=None:\n",
    "        predicty = [model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0))) for model in models]\n",
    "        predicty=np.nanmean(predicty,axis=0)\n",
    "    else:\n",
    "        predicty = model.predict(test_data_generator(testx,test_position,batch_size),steps=(len(testx) // batch_size+(1 if len(testx) % batch_size != 0 else 0)))\n",
    "    predicty = np.nan_to_num(predicty,nan=0)\n",
    "    if task_mode=='regression':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        p=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i],p[i] = pearsonr(predicty[:,i],testy[:,i])\n",
    "            r=np.nan_to_num(r,nan=0)\n",
    "    elif task_mode=='binary_classify':\n",
    "        accuracy=np.zeros((testy.shape[1]))\n",
    "        recall=np.zeros((testy.shape[1]))\n",
    "        precision=np.zeros((testy.shape[1]))\n",
    "        f1=np.zeros((testy.shape[1]))\n",
    "        for i in range(predicty.shape[1]):\n",
    "            predicty[:,i]=[int(round(predicty[j,i],0)) for j in range(predicty.shape[0])]\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            if metrics=='Recall':\n",
    "                r[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            elif metrics=='Precision':\n",
    "                r[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            else:\n",
    "                r[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            recall[i]=recall_score(testy[:,i], predicty[:,i])\n",
    "            precision[i]=precision_score(testy[:,i], predicty[:,i])\n",
    "            accuracy[i]=accuracy_score(testy[:,i], predicty[:,i])\n",
    "            f1[i]=f1_score(testy[:,i], predicty[:,i])\n",
    "        p=0\n",
    "    elif task_mode=='multi_classify':\n",
    "        r=np.zeros((testy.shape[1]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            r[i]=accuracy_score(testy[:,i], np.argmax(predicty,axis=1))\n",
    "        p=0\n",
    "    if ifmute == 'no':\n",
    "        if task_mode=='regression':\n",
    "            print('相关系数',np.nanmean(r))\n",
    "        elif task_mode=='binary_classify':\n",
    "            print('召回率+精确率',np.nanmean(f1),'准确率',np.nanmean(accuracy),'召回率',np.nanmean(recall),'精确率',np.nanmean(precision))\n",
    "        elif task_mode=='multi_classify':\n",
    "            print('准确率',np.nanmean(r))\n",
    "    if ifweight=='yes':\n",
    "        weights=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        weight_more=np.zeros((testy.shape[1],testx.shape[2]))\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                testx_new=copy.deepcopy(testx)\n",
    "                weight=[]\n",
    "                for k in range(10):\n",
    "                    per=np.random.permutation(testx.shape[0])\n",
    "                    testx_shuffle=testx[per,:,j]\n",
    "                    testx_new[:,:,j]=testx_shuffle\n",
    "                    if k_fold!=None:\n",
    "                        predicty_new = [model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0))) for model in models]\n",
    "                        predicty_new=np.nanmean(predicty_new,axis=0)\n",
    "                    else:\n",
    "                        predicty_new = model.predict(test_data_generator(testx_new,test_position,batch_size),steps=(len(testx_new) // batch_size+(1 if len(testx_new) % batch_size != 0 else 0)))\n",
    "                    if task_mode=='regression':\n",
    "                        weight.append(sklearn.metrics.mean_squared_error(testy[:,i],predicty_new[:,i])-sklearn.metrics.mean_squared_error(testy[:,i],predicty[:,i]))\n",
    "                    elif task_mode=='multi_classify':\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,:])-sklearn.metrics.log_loss(testy[:,i],predicty[:,:]))\n",
    "                    else:\n",
    "                        weight.append(sklearn.metrics.log_loss(testy[:,i],predicty_new[:,i])-sklearn.metrics.log_loss(testy[:,i],predicty[:,i]))\n",
    "                weight_more[i,j]=np.nanmean(weight)\n",
    "        for i in range(testy.shape[1]):\n",
    "            for j in range(testx.shape[2]):\n",
    "                weights[i,j]=(weight_more[i,j]/np.nansum(weight_more[i,:]))*100\n",
    "                print('预报因子',j+1,'对预报值',i+1,'的贡献：',np.array(weights[i,j]),'％')\n",
    "            print('\\n')\n",
    "    if ifsave=='yes':\n",
    "        if k_fold!=None:\n",
    "            for i, model in enumerate(models):\n",
    "                model.save(savepath+'_'+str(i+1))\n",
    "        else:\n",
    "            model.save(savepath)\n",
    "    if k_fold!=None:\n",
    "        return models,predicty,testy,r,p,weights\n",
    "    else:\n",
    "        return model,predicty,testy,r,p,weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694aac2-581f-4745-8d73-80163b988f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 6, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 6, 45)        315         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 6, 45)        0           ['input_1[0][0]',                \n",
      "                                                                  'embedding[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 6, 45)       228         ['add[0][0]',                    \n",
      " dAttention)                                                      'add[0][0]',                    \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 6, 45)        0           ['add[0][0]',                    \n",
      "                                                                  'multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 6, 45)       90          ['add_1[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6, 256)       11776       ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6, 45)        11565       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 6, 45)        0           ['dense_1[0][0]',                \n",
      "                                                                  'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 6, 45)       90          ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 270)          0           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 7)            1897        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,961\n",
      "Trainable params: 25,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "3/3 [==============================] - 2s 187ms/step - loss: 90.2947 - metrics_pearsonr: 0.9948 - val_loss: 88.5735 - val_metrics_pearsonr: 0.9879\n",
      "Epoch 2/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 87.5484 - metrics_pearsonr: 0.9984 - val_loss: 85.9067 - val_metrics_pearsonr: 0.9919\n",
      "Epoch 3/5000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 84.9332 - metrics_pearsonr: 1.0019 - val_loss: 83.3756 - val_metrics_pearsonr: 0.9957\n",
      "Epoch 4/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 82.4541 - metrics_pearsonr: 1.0051 - val_loss: 80.9820 - val_metrics_pearsonr: 0.9992\n",
      "Epoch 5/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 80.1121 - metrics_pearsonr: 1.0078 - val_loss: 78.7248 - val_metrics_pearsonr: 1.0021\n",
      "Epoch 6/5000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 77.9059 - metrics_pearsonr: 1.0101 - val_loss: 76.6018 - val_metrics_pearsonr: 1.0046\n",
      "Epoch 7/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 75.8331 - metrics_pearsonr: 1.0118 - val_loss: 74.6099 - val_metrics_pearsonr: 1.0064\n",
      "Epoch 8/5000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 73.8904 - metrics_pearsonr: 1.0130 - val_loss: 72.7454 - val_metrics_pearsonr: 1.0078\n",
      "Epoch 9/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 72.0739 - metrics_pearsonr: 1.0136 - val_loss: 71.0043 - val_metrics_pearsonr: 1.0084\n",
      "Epoch 10/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 70.3796 - metrics_pearsonr: 1.0136 - val_loss: 69.3834 - val_metrics_pearsonr: 1.0085\n",
      "Epoch 11/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 68.8043 - metrics_pearsonr: 1.0130 - val_loss: 67.8799 - val_metrics_pearsonr: 1.0078\n",
      "Epoch 12/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 67.3454 - metrics_pearsonr: 1.0117 - val_loss: 66.4921 - val_metrics_pearsonr: 1.0064\n",
      "Epoch 13/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 66.0011 - metrics_pearsonr: 1.0098 - val_loss: 65.2182 - val_metrics_pearsonr: 1.0045\n",
      "Epoch 14/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 64.7695 - metrics_pearsonr: 1.0074 - val_loss: 64.0560 - val_metrics_pearsonr: 1.0020\n",
      "Epoch 15/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 63.6478 - metrics_pearsonr: 1.0046 - val_loss: 63.0020 - val_metrics_pearsonr: 0.9992\n",
      "Epoch 16/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 62.6322 - metrics_pearsonr: 1.0015 - val_loss: 62.0511 - val_metrics_pearsonr: 0.9960\n",
      "Epoch 17/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 61.7173 - metrics_pearsonr: 0.9982 - val_loss: 61.1968 - val_metrics_pearsonr: 0.9926\n",
      "Epoch 18/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 60.8961 - metrics_pearsonr: 0.9948 - val_loss: 60.4312 - val_metrics_pearsonr: 0.9891\n",
      "Epoch 19/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 60.1605 - metrics_pearsonr: 0.9912 - val_loss: 59.7455 - val_metrics_pearsonr: 0.9854\n",
      "Epoch 20/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 59.5018 - metrics_pearsonr: 0.9876 - val_loss: 59.1305 - val_metrics_pearsonr: 0.9816\n",
      "Epoch 21/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 58.9107 - metrics_pearsonr: 0.9839 - val_loss: 58.5771 - val_metrics_pearsonr: 0.9777\n",
      "Epoch 22/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 58.3784 - metrics_pearsonr: 0.9800 - val_loss: 58.0767 - val_metrics_pearsonr: 0.9737\n",
      "Epoch 23/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 57.8967 - metrics_pearsonr: 0.9761 - val_loss: 57.6217 - val_metrics_pearsonr: 0.9697\n",
      "Epoch 24/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 57.4583 - metrics_pearsonr: 0.9721 - val_loss: 57.2055 - val_metrics_pearsonr: 0.9655\n",
      "Epoch 25/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 57.0572 - metrics_pearsonr: 0.9681 - val_loss: 56.8226 - val_metrics_pearsonr: 0.9614\n",
      "Epoch 26/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 56.6880 - metrics_pearsonr: 0.9640 - val_loss: 56.4686 - val_metrics_pearsonr: 0.9572\n",
      "Epoch 27/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 56.3466 - metrics_pearsonr: 0.9599 - val_loss: 56.1398 - val_metrics_pearsonr: 0.9530\n",
      "Epoch 28/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 56.0295 - metrics_pearsonr: 0.9557 - val_loss: 55.8332 - val_metrics_pearsonr: 0.9488\n",
      "Epoch 29/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 55.7337 - metrics_pearsonr: 0.9516 - val_loss: 55.5463 - val_metrics_pearsonr: 0.9446\n",
      "Epoch 30/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 55.4569 - metrics_pearsonr: 0.9475 - val_loss: 55.2770 - val_metrics_pearsonr: 0.9404\n",
      "Epoch 31/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 55.1971 - metrics_pearsonr: 0.9434 - val_loss: 55.0236 - val_metrics_pearsonr: 0.9363\n",
      "Epoch 32/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 54.9525 - metrics_pearsonr: 0.9393 - val_loss: 54.7843 - val_metrics_pearsonr: 0.9322\n",
      "Epoch 33/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 54.7216 - metrics_pearsonr: 0.9353 - val_loss: 54.5581 - val_metrics_pearsonr: 0.9281\n",
      "Epoch 34/5000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 54.5033 - metrics_pearsonr: 0.9313 - val_loss: 54.3436 - val_metrics_pearsonr: 0.9241\n",
      "Epoch 35/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 54.2963 - metrics_pearsonr: 0.9273 - val_loss: 54.1399 - val_metrics_pearsonr: 0.9202\n",
      "Epoch 36/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 54.0997 - metrics_pearsonr: 0.9234 - val_loss: 53.9461 - val_metrics_pearsonr: 0.9163\n",
      "Epoch 37/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 53.9127 - metrics_pearsonr: 0.9195 - val_loss: 53.7613 - val_metrics_pearsonr: 0.9124\n",
      "Epoch 38/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 53.7346 - metrics_pearsonr: 0.9157 - val_loss: 53.5851 - val_metrics_pearsonr: 0.9086\n",
      "Epoch 39/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 53.5646 - metrics_pearsonr: 0.9119 - val_loss: 53.4167 - val_metrics_pearsonr: 0.9048\n",
      "Epoch 40/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 53.4024 - metrics_pearsonr: 0.9082 - val_loss: 53.2556 - val_metrics_pearsonr: 0.9010\n",
      "Epoch 41/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 53.2473 - metrics_pearsonr: 0.9045 - val_loss: 53.1015 - val_metrics_pearsonr: 0.8974\n",
      "Epoch 42/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 53.0989 - metrics_pearsonr: 0.9009 - val_loss: 52.9539 - val_metrics_pearsonr: 0.8937\n",
      "Epoch 43/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 52.9569 - metrics_pearsonr: 0.8973 - val_loss: 52.8124 - val_metrics_pearsonr: 0.8901\n",
      "Epoch 44/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 52.8208 - metrics_pearsonr: 0.8937 - val_loss: 52.6768 - val_metrics_pearsonr: 0.8865\n",
      "Epoch 45/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 52.6904 - metrics_pearsonr: 0.8902 - val_loss: 52.5466 - val_metrics_pearsonr: 0.8830\n",
      "Epoch 46/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 52.5654 - metrics_pearsonr: 0.8867 - val_loss: 52.4217 - val_metrics_pearsonr: 0.8795\n",
      "Epoch 47/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 52.4454 - metrics_pearsonr: 0.8832 - val_loss: 52.3018 - val_metrics_pearsonr: 0.8760\n",
      "Epoch 48/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 52.3303 - metrics_pearsonr: 0.8798 - val_loss: 52.1866 - val_metrics_pearsonr: 0.8725\n",
      "Epoch 49/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 52.2198 - metrics_pearsonr: 0.8763 - val_loss: 52.0760 - val_metrics_pearsonr: 0.8691\n",
      "Epoch 50/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 52.1137 - metrics_pearsonr: 0.8729 - val_loss: 51.9696 - val_metrics_pearsonr: 0.8657\n",
      "Epoch 51/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 52.0118 - metrics_pearsonr: 0.8696 - val_loss: 51.8674 - val_metrics_pearsonr: 0.8623\n",
      "Epoch 52/5000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 51.9139 - metrics_pearsonr: 0.8662 - val_loss: 51.7690 - val_metrics_pearsonr: 0.8589\n",
      "Epoch 53/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 51.8198 - metrics_pearsonr: 0.8629 - val_loss: 51.6745 - val_metrics_pearsonr: 0.8556\n",
      "Epoch 54/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 51.7293 - metrics_pearsonr: 0.8596 - val_loss: 51.5835 - val_metrics_pearsonr: 0.8523\n",
      "Epoch 55/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 51.6423 - metrics_pearsonr: 0.8563 - val_loss: 51.4959 - val_metrics_pearsonr: 0.8490\n",
      "Epoch 56/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 51.5586 - metrics_pearsonr: 0.8531 - val_loss: 51.4116 - val_metrics_pearsonr: 0.8457\n",
      "Epoch 57/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 51.4781 - metrics_pearsonr: 0.8498 - val_loss: 51.3304 - val_metrics_pearsonr: 0.8424\n",
      "Epoch 58/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 51.4006 - metrics_pearsonr: 0.8466 - val_loss: 51.2523 - val_metrics_pearsonr: 0.8391\n",
      "Epoch 59/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 51.3260 - metrics_pearsonr: 0.8433 - val_loss: 51.1769 - val_metrics_pearsonr: 0.8358\n",
      "Epoch 60/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 51.2541 - metrics_pearsonr: 0.8401 - val_loss: 51.1043 - val_metrics_pearsonr: 0.8326\n",
      "Epoch 61/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 51.1848 - metrics_pearsonr: 0.8368 - val_loss: 51.0342 - val_metrics_pearsonr: 0.8293\n",
      "Epoch 62/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 51.1179 - metrics_pearsonr: 0.8336 - val_loss: 50.9666 - val_metrics_pearsonr: 0.8261\n",
      "Epoch 63/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 51.0534 - metrics_pearsonr: 0.8304 - val_loss: 50.9012 - val_metrics_pearsonr: 0.8228\n",
      "Epoch 64/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.9911 - metrics_pearsonr: 0.8271 - val_loss: 50.8381 - val_metrics_pearsonr: 0.8195\n",
      "Epoch 65/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 50.9309 - metrics_pearsonr: 0.8239 - val_loss: 50.7770 - val_metrics_pearsonr: 0.8163\n",
      "Epoch 66/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.8726 - metrics_pearsonr: 0.8206 - val_loss: 50.7179 - val_metrics_pearsonr: 0.8130\n",
      "Epoch 67/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.8161 - metrics_pearsonr: 0.8174 - val_loss: 50.6605 - val_metrics_pearsonr: 0.8097\n",
      "Epoch 68/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 50.7613 - metrics_pearsonr: 0.8141 - val_loss: 50.6049 - val_metrics_pearsonr: 0.8063\n",
      "Epoch 69/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 50.7080 - metrics_pearsonr: 0.8108 - val_loss: 50.5508 - val_metrics_pearsonr: 0.8030\n",
      "Epoch 70/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.6562 - metrics_pearsonr: 0.8074 - val_loss: 50.4981 - val_metrics_pearsonr: 0.7996\n",
      "Epoch 71/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 50.6057 - metrics_pearsonr: 0.8040 - val_loss: 50.4467 - val_metrics_pearsonr: 0.7962\n",
      "Epoch 72/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.5563 - metrics_pearsonr: 0.8006 - val_loss: 50.3965 - val_metrics_pearsonr: 0.7928\n",
      "Epoch 73/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.5080 - metrics_pearsonr: 0.7972 - val_loss: 50.3473 - val_metrics_pearsonr: 0.7893\n",
      "Epoch 74/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 50.4605 - metrics_pearsonr: 0.7937 - val_loss: 50.2989 - val_metrics_pearsonr: 0.7858\n",
      "Epoch 75/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 50.4138 - metrics_pearsonr: 0.7901 - val_loss: 50.2514 - val_metrics_pearsonr: 0.7822\n",
      "Epoch 76/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.3677 - metrics_pearsonr: 0.7865 - val_loss: 50.2044 - val_metrics_pearsonr: 0.7785\n",
      "Epoch 77/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 50.3220 - metrics_pearsonr: 0.7828 - val_loss: 50.1578 - val_metrics_pearsonr: 0.7749\n",
      "Epoch 78/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 50.2765 - metrics_pearsonr: 0.7791 - val_loss: 50.1115 - val_metrics_pearsonr: 0.7711\n",
      "Epoch 79/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 50.2311 - metrics_pearsonr: 0.7753 - val_loss: 50.0654 - val_metrics_pearsonr: 0.7673\n",
      "Epoch 80/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 50.1857 - metrics_pearsonr: 0.7714 - val_loss: 50.0191 - val_metrics_pearsonr: 0.7634\n",
      "Epoch 81/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 50.1400 - metrics_pearsonr: 0.7675 - val_loss: 49.9727 - val_metrics_pearsonr: 0.7594\n",
      "Epoch 82/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 50.0939 - metrics_pearsonr: 0.7635 - val_loss: 49.9258 - val_metrics_pearsonr: 0.7554\n",
      "Epoch 83/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 50.0471 - metrics_pearsonr: 0.7593 - val_loss: 49.8783 - val_metrics_pearsonr: 0.7512\n",
      "Epoch 84/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 49.9995 - metrics_pearsonr: 0.7551 - val_loss: 49.8299 - val_metrics_pearsonr: 0.7470\n",
      "Epoch 85/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 49.9508 - metrics_pearsonr: 0.7509 - val_loss: 49.7806 - val_metrics_pearsonr: 0.7427\n",
      "Epoch 86/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 49.9008 - metrics_pearsonr: 0.7465 - val_loss: 49.7300 - val_metrics_pearsonr: 0.7384\n",
      "Epoch 87/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 49.8493 - metrics_pearsonr: 0.7420 - val_loss: 49.6780 - val_metrics_pearsonr: 0.7339\n",
      "Epoch 88/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 49.7961 - metrics_pearsonr: 0.7375 - val_loss: 49.6243 - val_metrics_pearsonr: 0.7294\n",
      "Epoch 89/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 49.7410 - metrics_pearsonr: 0.7328 - val_loss: 49.5689 - val_metrics_pearsonr: 0.7248\n",
      "Epoch 90/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 49.6837 - metrics_pearsonr: 0.7282 - val_loss: 49.5114 - val_metrics_pearsonr: 0.7202\n",
      "Epoch 91/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 49.6241 - metrics_pearsonr: 0.7234 - val_loss: 49.4519 - val_metrics_pearsonr: 0.7156\n",
      "Epoch 92/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 49.5622 - metrics_pearsonr: 0.7187 - val_loss: 49.3902 - val_metrics_pearsonr: 0.7109\n",
      "Epoch 93/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 49.4977 - metrics_pearsonr: 0.7140 - val_loss: 49.3264 - val_metrics_pearsonr: 0.7064\n",
      "Epoch 94/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 49.4308 - metrics_pearsonr: 0.7093 - val_loss: 49.2605 - val_metrics_pearsonr: 0.7019\n",
      "Epoch 95/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 49.3615 - metrics_pearsonr: 0.7048 - val_loss: 49.1927 - val_metrics_pearsonr: 0.6976\n",
      "Epoch 96/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 49.2901 - metrics_pearsonr: 0.7003 - val_loss: 49.1234 - val_metrics_pearsonr: 0.6935\n",
      "Epoch 97/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 49.2169 - metrics_pearsonr: 0.6961 - val_loss: 49.0530 - val_metrics_pearsonr: 0.6896\n",
      "Epoch 98/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 49.1425 - metrics_pearsonr: 0.6921 - val_loss: 48.9821 - val_metrics_pearsonr: 0.6859\n",
      "Epoch 99/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 49.0674 - metrics_pearsonr: 0.6883 - val_loss: 48.9113 - val_metrics_pearsonr: 0.6825\n",
      "Epoch 100/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 48.9925 - metrics_pearsonr: 0.6847 - val_loss: 48.8413 - val_metrics_pearsonr: 0.6793\n",
      "Epoch 101/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 48.9183 - metrics_pearsonr: 0.6813 - val_loss: 48.7725 - val_metrics_pearsonr: 0.6762\n",
      "Epoch 102/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 48.8454 - metrics_pearsonr: 0.6781 - val_loss: 48.7050 - val_metrics_pearsonr: 0.6732\n",
      "Epoch 103/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 48.7739 - metrics_pearsonr: 0.6749 - val_loss: 48.6384 - val_metrics_pearsonr: 0.6703\n",
      "Epoch 104/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 48.7034 - metrics_pearsonr: 0.6717 - val_loss: 48.5719 - val_metrics_pearsonr: 0.6673\n",
      "Epoch 105/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 48.6331 - metrics_pearsonr: 0.6684 - val_loss: 48.5048 - val_metrics_pearsonr: 0.6641\n",
      "Epoch 106/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 48.5626 - metrics_pearsonr: 0.6651 - val_loss: 48.4368 - val_metrics_pearsonr: 0.6608\n",
      "Epoch 107/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 48.4916 - metrics_pearsonr: 0.6616 - val_loss: 48.3681 - val_metrics_pearsonr: 0.6574\n",
      "Epoch 108/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 48.4203 - metrics_pearsonr: 0.6581 - val_loss: 48.2993 - val_metrics_pearsonr: 0.6540\n",
      "Epoch 109/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 48.3490 - metrics_pearsonr: 0.6546 - val_loss: 48.2306 - val_metrics_pearsonr: 0.6507\n",
      "Epoch 110/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 48.2778 - metrics_pearsonr: 0.6512 - val_loss: 48.1622 - val_metrics_pearsonr: 0.6475\n",
      "Epoch 111/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 48.2067 - metrics_pearsonr: 0.6480 - val_loss: 48.0940 - val_metrics_pearsonr: 0.6445\n",
      "Epoch 112/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 48.1356 - metrics_pearsonr: 0.6449 - val_loss: 48.0260 - val_metrics_pearsonr: 0.6417\n",
      "Epoch 113/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 48.0644 - metrics_pearsonr: 0.6420 - val_loss: 47.9581 - val_metrics_pearsonr: 0.6391\n",
      "Epoch 114/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.9933 - metrics_pearsonr: 0.6393 - val_loss: 47.8904 - val_metrics_pearsonr: 0.6366\n",
      "Epoch 115/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 47.9222 - metrics_pearsonr: 0.6367 - val_loss: 47.8228 - val_metrics_pearsonr: 0.6342\n",
      "Epoch 116/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.8512 - metrics_pearsonr: 0.6341 - val_loss: 47.7554 - val_metrics_pearsonr: 0.6318\n",
      "Epoch 117/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.7803 - metrics_pearsonr: 0.6316 - val_loss: 47.6880 - val_metrics_pearsonr: 0.6295\n",
      "Epoch 118/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 47.7096 - metrics_pearsonr: 0.6291 - val_loss: 47.6206 - val_metrics_pearsonr: 0.6271\n",
      "Epoch 119/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.6389 - metrics_pearsonr: 0.6266 - val_loss: 47.5534 - val_metrics_pearsonr: 0.6248\n",
      "Epoch 120/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 47.5683 - metrics_pearsonr: 0.6241 - val_loss: 47.4863 - val_metrics_pearsonr: 0.6224\n",
      "Epoch 121/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 47.4978 - metrics_pearsonr: 0.6217 - val_loss: 47.4194 - val_metrics_pearsonr: 0.6202\n",
      "Epoch 122/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.4274 - metrics_pearsonr: 0.6193 - val_loss: 47.3529 - val_metrics_pearsonr: 0.6179\n",
      "Epoch 123/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 47.3572 - metrics_pearsonr: 0.6169 - val_loss: 47.2866 - val_metrics_pearsonr: 0.6157\n",
      "Epoch 124/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 47.2872 - metrics_pearsonr: 0.6146 - val_loss: 47.2207 - val_metrics_pearsonr: 0.6136\n",
      "Epoch 125/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 47.2173 - metrics_pearsonr: 0.6123 - val_loss: 47.1550 - val_metrics_pearsonr: 0.6115\n",
      "Epoch 126/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 47.1477 - metrics_pearsonr: 0.6101 - val_loss: 47.0896 - val_metrics_pearsonr: 0.6094\n",
      "Epoch 127/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 47.0784 - metrics_pearsonr: 0.6078 - val_loss: 47.0244 - val_metrics_pearsonr: 0.6074\n",
      "Epoch 128/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 47.0093 - metrics_pearsonr: 0.6056 - val_loss: 46.9595 - val_metrics_pearsonr: 0.6053\n",
      "Epoch 129/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 46.9406 - metrics_pearsonr: 0.6034 - val_loss: 46.8949 - val_metrics_pearsonr: 0.6033\n",
      "Epoch 130/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 46.8721 - metrics_pearsonr: 0.6012 - val_loss: 46.8306 - val_metrics_pearsonr: 0.6013\n",
      "Epoch 131/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 46.8039 - metrics_pearsonr: 0.5991 - val_loss: 46.7667 - val_metrics_pearsonr: 0.5993\n",
      "Epoch 132/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 46.7360 - metrics_pearsonr: 0.5970 - val_loss: 46.7032 - val_metrics_pearsonr: 0.5973\n",
      "Epoch 133/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 46.6685 - metrics_pearsonr: 0.5949 - val_loss: 46.6401 - val_metrics_pearsonr: 0.5954\n",
      "Epoch 134/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 46.6013 - metrics_pearsonr: 0.5928 - val_loss: 46.5773 - val_metrics_pearsonr: 0.5935\n",
      "Epoch 135/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 46.5344 - metrics_pearsonr: 0.5907 - val_loss: 46.5149 - val_metrics_pearsonr: 0.5916\n",
      "Epoch 136/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 46.4679 - metrics_pearsonr: 0.5887 - val_loss: 46.4529 - val_metrics_pearsonr: 0.5897\n",
      "Epoch 137/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 46.4013 - metrics_pearsonr: 0.5866 - val_loss: 46.3913 - val_metrics_pearsonr: 0.5879\n",
      "Epoch 138/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 46.3340 - metrics_pearsonr: 0.5845 - val_loss: 46.3302 - val_metrics_pearsonr: 0.5860\n",
      "Epoch 139/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 46.2664 - metrics_pearsonr: 0.5823 - val_loss: 46.2694 - val_metrics_pearsonr: 0.5842\n",
      "Epoch 140/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 46.2011 - metrics_pearsonr: 0.5803 - val_loss: 46.2089 - val_metrics_pearsonr: 0.5824\n",
      "Epoch 141/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 46.1370 - metrics_pearsonr: 0.5783 - val_loss: 46.1488 - val_metrics_pearsonr: 0.5806\n",
      "Epoch 142/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 46.0729 - metrics_pearsonr: 0.5764 - val_loss: 46.0892 - val_metrics_pearsonr: 0.5788\n",
      "Epoch 143/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 46.0089 - metrics_pearsonr: 0.5745 - val_loss: 46.0300 - val_metrics_pearsonr: 0.5770\n",
      "Epoch 144/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 45.9453 - metrics_pearsonr: 0.5726 - val_loss: 45.9714 - val_metrics_pearsonr: 0.5753\n",
      "Epoch 145/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 45.8820 - metrics_pearsonr: 0.5707 - val_loss: 45.9131 - val_metrics_pearsonr: 0.5736\n",
      "Epoch 146/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 45.8192 - metrics_pearsonr: 0.5689 - val_loss: 45.8552 - val_metrics_pearsonr: 0.5719\n",
      "Epoch 147/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 45.7569 - metrics_pearsonr: 0.5670 - val_loss: 45.7976 - val_metrics_pearsonr: 0.5702\n",
      "Epoch 148/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 45.6950 - metrics_pearsonr: 0.5652 - val_loss: 45.7403 - val_metrics_pearsonr: 0.5686\n",
      "Epoch 149/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 45.6335 - metrics_pearsonr: 0.5634 - val_loss: 45.6835 - val_metrics_pearsonr: 0.5669\n",
      "Epoch 150/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 45.5723 - metrics_pearsonr: 0.5616 - val_loss: 45.6270 - val_metrics_pearsonr: 0.5653\n",
      "Epoch 151/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 45.5114 - metrics_pearsonr: 0.5599 - val_loss: 45.5708 - val_metrics_pearsonr: 0.5637\n",
      "Epoch 152/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 45.4509 - metrics_pearsonr: 0.5581 - val_loss: 45.5150 - val_metrics_pearsonr: 0.5621\n",
      "Epoch 153/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 45.3908 - metrics_pearsonr: 0.5564 - val_loss: 45.4594 - val_metrics_pearsonr: 0.5605\n",
      "Epoch 154/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 45.3309 - metrics_pearsonr: 0.5547 - val_loss: 45.4042 - val_metrics_pearsonr: 0.5589\n",
      "Epoch 155/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 45.2714 - metrics_pearsonr: 0.5530 - val_loss: 45.3493 - val_metrics_pearsonr: 0.5573\n",
      "Epoch 156/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 45.2122 - metrics_pearsonr: 0.5513 - val_loss: 45.2948 - val_metrics_pearsonr: 0.5558\n",
      "Epoch 157/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 45.1532 - metrics_pearsonr: 0.5496 - val_loss: 45.2405 - val_metrics_pearsonr: 0.5543\n",
      "Epoch 158/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 45.0945 - metrics_pearsonr: 0.5479 - val_loss: 45.1864 - val_metrics_pearsonr: 0.5527\n",
      "Epoch 159/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 45.0360 - metrics_pearsonr: 0.5463 - val_loss: 45.1326 - val_metrics_pearsonr: 0.5512\n",
      "Epoch 160/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 44.9778 - metrics_pearsonr: 0.5447 - val_loss: 45.0790 - val_metrics_pearsonr: 0.5497\n",
      "Epoch 161/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 44.9199 - metrics_pearsonr: 0.5430 - val_loss: 45.0257 - val_metrics_pearsonr: 0.5482\n",
      "Epoch 162/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 44.8621 - metrics_pearsonr: 0.5414 - val_loss: 44.9726 - val_metrics_pearsonr: 0.5468\n",
      "Epoch 163/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 44.8046 - metrics_pearsonr: 0.5398 - val_loss: 44.9197 - val_metrics_pearsonr: 0.5453\n",
      "Epoch 164/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 44.7472 - metrics_pearsonr: 0.5382 - val_loss: 44.8670 - val_metrics_pearsonr: 0.5438\n",
      "Epoch 165/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 44.6901 - metrics_pearsonr: 0.5367 - val_loss: 44.8145 - val_metrics_pearsonr: 0.5424\n",
      "Epoch 166/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 44.6331 - metrics_pearsonr: 0.5351 - val_loss: 44.7621 - val_metrics_pearsonr: 0.5409\n",
      "Epoch 167/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 44.5762 - metrics_pearsonr: 0.5335 - val_loss: 44.7099 - val_metrics_pearsonr: 0.5395\n",
      "Epoch 168/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 44.5196 - metrics_pearsonr: 0.5320 - val_loss: 44.6578 - val_metrics_pearsonr: 0.5381\n",
      "Epoch 169/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 44.4630 - metrics_pearsonr: 0.5305 - val_loss: 44.6059 - val_metrics_pearsonr: 0.5367\n",
      "Epoch 170/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 44.4066 - metrics_pearsonr: 0.5289 - val_loss: 44.5541 - val_metrics_pearsonr: 0.5353\n",
      "Epoch 171/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 44.3502 - metrics_pearsonr: 0.5274 - val_loss: 44.5024 - val_metrics_pearsonr: 0.5339\n",
      "Epoch 172/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 44.2940 - metrics_pearsonr: 0.5259 - val_loss: 44.4507 - val_metrics_pearsonr: 0.5325\n",
      "Epoch 173/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 44.2378 - metrics_pearsonr: 0.5244 - val_loss: 44.3992 - val_metrics_pearsonr: 0.5311\n",
      "Epoch 174/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 44.1818 - metrics_pearsonr: 0.5229 - val_loss: 44.3477 - val_metrics_pearsonr: 0.5297\n",
      "Epoch 175/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 44.1258 - metrics_pearsonr: 0.5214 - val_loss: 44.2963 - val_metrics_pearsonr: 0.5284\n",
      "Epoch 176/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 44.0698 - metrics_pearsonr: 0.5200 - val_loss: 44.2450 - val_metrics_pearsonr: 0.5270\n",
      "Epoch 177/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 44.0139 - metrics_pearsonr: 0.5185 - val_loss: 44.1937 - val_metrics_pearsonr: 0.5257\n",
      "Epoch 178/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 43.9580 - metrics_pearsonr: 0.5170 - val_loss: 44.1424 - val_metrics_pearsonr: 0.5243\n",
      "Epoch 179/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 43.9021 - metrics_pearsonr: 0.5156 - val_loss: 44.0912 - val_metrics_pearsonr: 0.5230\n",
      "Epoch 180/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 43.8463 - metrics_pearsonr: 0.5141 - val_loss: 44.0399 - val_metrics_pearsonr: 0.5217\n",
      "Epoch 181/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 43.7905 - metrics_pearsonr: 0.5127 - val_loss: 43.9887 - val_metrics_pearsonr: 0.5203\n",
      "Epoch 182/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 43.7347 - metrics_pearsonr: 0.5113 - val_loss: 43.9375 - val_metrics_pearsonr: 0.5190\n",
      "Epoch 183/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 43.6789 - metrics_pearsonr: 0.5098 - val_loss: 43.8863 - val_metrics_pearsonr: 0.5177\n",
      "Epoch 184/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 43.6231 - metrics_pearsonr: 0.5084 - val_loss: 43.8352 - val_metrics_pearsonr: 0.5164\n",
      "Epoch 185/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 43.5673 - metrics_pearsonr: 0.5070 - val_loss: 43.7840 - val_metrics_pearsonr: 0.5151\n",
      "Epoch 186/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 43.5115 - metrics_pearsonr: 0.5056 - val_loss: 43.7329 - val_metrics_pearsonr: 0.5138\n",
      "Epoch 187/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 43.4557 - metrics_pearsonr: 0.5042 - val_loss: 43.6817 - val_metrics_pearsonr: 0.5125\n",
      "Epoch 188/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 43.4000 - metrics_pearsonr: 0.5028 - val_loss: 43.6306 - val_metrics_pearsonr: 0.5113\n",
      "Epoch 189/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 43.3442 - metrics_pearsonr: 0.5014 - val_loss: 43.5795 - val_metrics_pearsonr: 0.5100\n",
      "Epoch 190/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 43.2885 - metrics_pearsonr: 0.5000 - val_loss: 43.5285 - val_metrics_pearsonr: 0.5087\n",
      "Epoch 191/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 43.2328 - metrics_pearsonr: 0.4987 - val_loss: 43.4775 - val_metrics_pearsonr: 0.5075\n",
      "Epoch 192/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 43.1772 - metrics_pearsonr: 0.4973 - val_loss: 43.4266 - val_metrics_pearsonr: 0.5062\n",
      "Epoch 193/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 43.1216 - metrics_pearsonr: 0.4960 - val_loss: 43.3757 - val_metrics_pearsonr: 0.5050\n",
      "Epoch 194/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 43.0661 - metrics_pearsonr: 0.4946 - val_loss: 43.3249 - val_metrics_pearsonr: 0.5038\n",
      "Epoch 195/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 43.0106 - metrics_pearsonr: 0.4933 - val_loss: 43.2742 - val_metrics_pearsonr: 0.5025\n",
      "Epoch 196/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.9552 - metrics_pearsonr: 0.4920 - val_loss: 43.2235 - val_metrics_pearsonr: 0.5013\n",
      "Epoch 197/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.9000 - metrics_pearsonr: 0.4906 - val_loss: 43.1730 - val_metrics_pearsonr: 0.5001\n",
      "Epoch 198/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 42.8448 - metrics_pearsonr: 0.4893 - val_loss: 43.1225 - val_metrics_pearsonr: 0.4989\n",
      "Epoch 199/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.7897 - metrics_pearsonr: 0.4880 - val_loss: 43.0722 - val_metrics_pearsonr: 0.4977\n",
      "Epoch 200/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 42.7347 - metrics_pearsonr: 0.4868 - val_loss: 43.0219 - val_metrics_pearsonr: 0.4966\n",
      "Epoch 201/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 42.6798 - metrics_pearsonr: 0.4855 - val_loss: 42.9718 - val_metrics_pearsonr: 0.4954\n",
      "Epoch 202/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 42.6250 - metrics_pearsonr: 0.4842 - val_loss: 42.9218 - val_metrics_pearsonr: 0.4942\n",
      "Epoch 203/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.5703 - metrics_pearsonr: 0.4830 - val_loss: 42.8718 - val_metrics_pearsonr: 0.4931\n",
      "Epoch 204/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 42.5158 - metrics_pearsonr: 0.4817 - val_loss: 42.8220 - val_metrics_pearsonr: 0.4919\n",
      "Epoch 205/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 42.4613 - metrics_pearsonr: 0.4805 - val_loss: 42.7722 - val_metrics_pearsonr: 0.4908\n",
      "Epoch 206/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.4069 - metrics_pearsonr: 0.4793 - val_loss: 42.7225 - val_metrics_pearsonr: 0.4897\n",
      "Epoch 207/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 42.3527 - metrics_pearsonr: 0.4780 - val_loss: 42.6729 - val_metrics_pearsonr: 0.4886\n",
      "Epoch 208/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 42.2985 - metrics_pearsonr: 0.4768 - val_loss: 42.6234 - val_metrics_pearsonr: 0.4875\n",
      "Epoch 209/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 42.2444 - metrics_pearsonr: 0.4756 - val_loss: 42.5739 - val_metrics_pearsonr: 0.4863\n",
      "Epoch 210/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 42.1903 - metrics_pearsonr: 0.4744 - val_loss: 42.5244 - val_metrics_pearsonr: 0.4852\n",
      "Epoch 211/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.1364 - metrics_pearsonr: 0.4732 - val_loss: 42.4750 - val_metrics_pearsonr: 0.4841\n",
      "Epoch 212/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 42.0824 - metrics_pearsonr: 0.4721 - val_loss: 42.4257 - val_metrics_pearsonr: 0.4831\n",
      "Epoch 213/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 42.0285 - metrics_pearsonr: 0.4709 - val_loss: 42.3763 - val_metrics_pearsonr: 0.4820\n",
      "Epoch 214/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 41.9747 - metrics_pearsonr: 0.4697 - val_loss: 42.3270 - val_metrics_pearsonr: 0.4809\n",
      "Epoch 215/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 41.9209 - metrics_pearsonr: 0.4686 - val_loss: 42.2777 - val_metrics_pearsonr: 0.4798\n",
      "Epoch 216/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 41.8671 - metrics_pearsonr: 0.4674 - val_loss: 42.2284 - val_metrics_pearsonr: 0.4787\n",
      "Epoch 217/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 41.8133 - metrics_pearsonr: 0.4663 - val_loss: 42.1791 - val_metrics_pearsonr: 0.4777\n",
      "Epoch 218/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 41.7596 - metrics_pearsonr: 0.4651 - val_loss: 42.1298 - val_metrics_pearsonr: 0.4766\n",
      "Epoch 219/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 41.7059 - metrics_pearsonr: 0.4640 - val_loss: 42.0805 - val_metrics_pearsonr: 0.4755\n",
      "Epoch 220/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 41.6522 - metrics_pearsonr: 0.4628 - val_loss: 42.0313 - val_metrics_pearsonr: 0.4745\n",
      "Epoch 221/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 41.5986 - metrics_pearsonr: 0.4617 - val_loss: 41.9821 - val_metrics_pearsonr: 0.4734\n",
      "Epoch 222/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 41.5450 - metrics_pearsonr: 0.4606 - val_loss: 41.9329 - val_metrics_pearsonr: 0.4724\n",
      "Epoch 223/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 41.4915 - metrics_pearsonr: 0.4595 - val_loss: 41.8839 - val_metrics_pearsonr: 0.4713\n",
      "Epoch 224/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 41.4382 - metrics_pearsonr: 0.4583 - val_loss: 41.8349 - val_metrics_pearsonr: 0.4703\n",
      "Epoch 225/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 41.3850 - metrics_pearsonr: 0.4572 - val_loss: 41.7861 - val_metrics_pearsonr: 0.4692\n",
      "Epoch 226/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 41.3319 - metrics_pearsonr: 0.4561 - val_loss: 41.7375 - val_metrics_pearsonr: 0.4682\n",
      "Epoch 227/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 41.2791 - metrics_pearsonr: 0.4550 - val_loss: 41.6892 - val_metrics_pearsonr: 0.4672\n",
      "Epoch 228/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 41.2266 - metrics_pearsonr: 0.4539 - val_loss: 41.6411 - val_metrics_pearsonr: 0.4661\n",
      "Epoch 229/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 41.1743 - metrics_pearsonr: 0.4529 - val_loss: 41.5933 - val_metrics_pearsonr: 0.4651\n",
      "Epoch 230/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 41.1224 - metrics_pearsonr: 0.4518 - val_loss: 41.5459 - val_metrics_pearsonr: 0.4641\n",
      "Epoch 231/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 41.0709 - metrics_pearsonr: 0.4507 - val_loss: 41.4988 - val_metrics_pearsonr: 0.4632\n",
      "Epoch 232/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 41.0197 - metrics_pearsonr: 0.4497 - val_loss: 41.4522 - val_metrics_pearsonr: 0.4622\n",
      "Epoch 233/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 40.9690 - metrics_pearsonr: 0.4487 - val_loss: 41.4060 - val_metrics_pearsonr: 0.4612\n",
      "Epoch 234/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 40.9188 - metrics_pearsonr: 0.4477 - val_loss: 41.3602 - val_metrics_pearsonr: 0.4603\n",
      "Epoch 235/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 40.8690 - metrics_pearsonr: 0.4467 - val_loss: 41.3150 - val_metrics_pearsonr: 0.4594\n",
      "Epoch 236/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 40.8197 - metrics_pearsonr: 0.4457 - val_loss: 41.2702 - val_metrics_pearsonr: 0.4584\n",
      "Epoch 237/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 40.7710 - metrics_pearsonr: 0.4447 - val_loss: 41.2259 - val_metrics_pearsonr: 0.4575\n",
      "Epoch 238/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 40.7227 - metrics_pearsonr: 0.4437 - val_loss: 41.1821 - val_metrics_pearsonr: 0.4567\n",
      "Epoch 239/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 40.6749 - metrics_pearsonr: 0.4428 - val_loss: 41.1388 - val_metrics_pearsonr: 0.4558\n",
      "Epoch 240/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 40.6277 - metrics_pearsonr: 0.4418 - val_loss: 41.0959 - val_metrics_pearsonr: 0.4549\n",
      "Epoch 241/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 40.5809 - metrics_pearsonr: 0.4409 - val_loss: 41.0535 - val_metrics_pearsonr: 0.4541\n",
      "Epoch 242/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 40.5346 - metrics_pearsonr: 0.4400 - val_loss: 41.0116 - val_metrics_pearsonr: 0.4532\n",
      "Epoch 243/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 40.4888 - metrics_pearsonr: 0.4391 - val_loss: 40.9702 - val_metrics_pearsonr: 0.4524\n",
      "Epoch 244/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 40.4435 - metrics_pearsonr: 0.4382 - val_loss: 40.9292 - val_metrics_pearsonr: 0.4516\n",
      "Epoch 245/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 40.3986 - metrics_pearsonr: 0.4374 - val_loss: 40.8886 - val_metrics_pearsonr: 0.4508\n",
      "Epoch 246/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 40.3542 - metrics_pearsonr: 0.4365 - val_loss: 40.8485 - val_metrics_pearsonr: 0.4500\n",
      "Epoch 247/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 40.3103 - metrics_pearsonr: 0.4357 - val_loss: 40.8088 - val_metrics_pearsonr: 0.4492\n",
      "Epoch 248/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 40.2667 - metrics_pearsonr: 0.4348 - val_loss: 40.7695 - val_metrics_pearsonr: 0.4484\n",
      "Epoch 249/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 40.2236 - metrics_pearsonr: 0.4340 - val_loss: 40.7305 - val_metrics_pearsonr: 0.4476\n",
      "Epoch 250/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 40.1810 - metrics_pearsonr: 0.4331 - val_loss: 40.6920 - val_metrics_pearsonr: 0.4468\n",
      "Epoch 251/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 40.1387 - metrics_pearsonr: 0.4323 - val_loss: 40.6539 - val_metrics_pearsonr: 0.4461\n",
      "Epoch 252/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 40.0968 - metrics_pearsonr: 0.4315 - val_loss: 40.6161 - val_metrics_pearsonr: 0.4453\n",
      "Epoch 253/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 40.0553 - metrics_pearsonr: 0.4307 - val_loss: 40.5787 - val_metrics_pearsonr: 0.4446\n",
      "Epoch 254/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 40.0142 - metrics_pearsonr: 0.4299 - val_loss: 40.5416 - val_metrics_pearsonr: 0.4438\n",
      "Epoch 255/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 39.9734 - metrics_pearsonr: 0.4291 - val_loss: 40.5049 - val_metrics_pearsonr: 0.4431\n",
      "Epoch 256/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 39.9331 - metrics_pearsonr: 0.4284 - val_loss: 40.4685 - val_metrics_pearsonr: 0.4423\n",
      "Epoch 257/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 39.8931 - metrics_pearsonr: 0.4276 - val_loss: 40.4325 - val_metrics_pearsonr: 0.4416\n",
      "Epoch 258/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 39.8534 - metrics_pearsonr: 0.4268 - val_loss: 40.3967 - val_metrics_pearsonr: 0.4409\n",
      "Epoch 259/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 39.8141 - metrics_pearsonr: 0.4260 - val_loss: 40.3613 - val_metrics_pearsonr: 0.4402\n",
      "Epoch 260/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 39.7751 - metrics_pearsonr: 0.4253 - val_loss: 40.3262 - val_metrics_pearsonr: 0.4395\n",
      "Epoch 261/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 39.7364 - metrics_pearsonr: 0.4245 - val_loss: 40.2914 - val_metrics_pearsonr: 0.4387\n",
      "Epoch 262/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 39.6981 - metrics_pearsonr: 0.4238 - val_loss: 40.2568 - val_metrics_pearsonr: 0.4380\n",
      "Epoch 263/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 39.6600 - metrics_pearsonr: 0.4230 - val_loss: 40.2226 - val_metrics_pearsonr: 0.4373\n",
      "Epoch 264/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 39.6223 - metrics_pearsonr: 0.4223 - val_loss: 40.1886 - val_metrics_pearsonr: 0.4366\n",
      "Epoch 265/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 39.5849 - metrics_pearsonr: 0.4216 - val_loss: 40.1548 - val_metrics_pearsonr: 0.4359\n",
      "Epoch 266/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 39.5477 - metrics_pearsonr: 0.4208 - val_loss: 40.1213 - val_metrics_pearsonr: 0.4352\n",
      "Epoch 267/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 39.5108 - metrics_pearsonr: 0.4201 - val_loss: 40.0881 - val_metrics_pearsonr: 0.4346\n",
      "Epoch 268/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 39.4742 - metrics_pearsonr: 0.4194 - val_loss: 40.0551 - val_metrics_pearsonr: 0.4339\n",
      "Epoch 269/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 39.4378 - metrics_pearsonr: 0.4187 - val_loss: 40.0223 - val_metrics_pearsonr: 0.4332\n",
      "Epoch 270/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 39.4017 - metrics_pearsonr: 0.4180 - val_loss: 39.9897 - val_metrics_pearsonr: 0.4325\n",
      "Epoch 271/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 39.3658 - metrics_pearsonr: 0.4173 - val_loss: 39.9574 - val_metrics_pearsonr: 0.4318\n",
      "Epoch 272/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 39.3302 - metrics_pearsonr: 0.4166 - val_loss: 39.9252 - val_metrics_pearsonr: 0.4312\n",
      "Epoch 273/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 39.2948 - metrics_pearsonr: 0.4159 - val_loss: 39.8933 - val_metrics_pearsonr: 0.4305\n",
      "Epoch 274/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 39.2596 - metrics_pearsonr: 0.4152 - val_loss: 39.8615 - val_metrics_pearsonr: 0.4298\n",
      "Epoch 275/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 39.2247 - metrics_pearsonr: 0.4145 - val_loss: 39.8300 - val_metrics_pearsonr: 0.4292\n",
      "Epoch 276/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 39.1899 - metrics_pearsonr: 0.4138 - val_loss: 39.7986 - val_metrics_pearsonr: 0.4285\n",
      "Epoch 277/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 39.1554 - metrics_pearsonr: 0.4131 - val_loss: 39.7674 - val_metrics_pearsonr: 0.4278\n",
      "Epoch 278/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 39.1210 - metrics_pearsonr: 0.4124 - val_loss: 39.7363 - val_metrics_pearsonr: 0.4272\n",
      "Epoch 279/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 39.0869 - metrics_pearsonr: 0.4117 - val_loss: 39.7054 - val_metrics_pearsonr: 0.4265\n",
      "Epoch 280/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 39.0529 - metrics_pearsonr: 0.4110 - val_loss: 39.6747 - val_metrics_pearsonr: 0.4259\n",
      "Epoch 281/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 39.0191 - metrics_pearsonr: 0.4104 - val_loss: 39.6441 - val_metrics_pearsonr: 0.4252\n",
      "Epoch 282/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 38.9854 - metrics_pearsonr: 0.4097 - val_loss: 39.6137 - val_metrics_pearsonr: 0.4246\n",
      "Epoch 283/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.9519 - metrics_pearsonr: 0.4090 - val_loss: 39.5834 - val_metrics_pearsonr: 0.4239\n",
      "Epoch 284/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 38.9186 - metrics_pearsonr: 0.4084 - val_loss: 39.5532 - val_metrics_pearsonr: 0.4233\n",
      "Epoch 285/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 38.8855 - metrics_pearsonr: 0.4077 - val_loss: 39.5232 - val_metrics_pearsonr: 0.4226\n",
      "Epoch 286/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 38.8524 - metrics_pearsonr: 0.4070 - val_loss: 39.4932 - val_metrics_pearsonr: 0.4220\n",
      "Epoch 287/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 38.8196 - metrics_pearsonr: 0.4064 - val_loss: 39.4634 - val_metrics_pearsonr: 0.4213\n",
      "Epoch 288/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 38.7868 - metrics_pearsonr: 0.4057 - val_loss: 39.4337 - val_metrics_pearsonr: 0.4207\n",
      "Epoch 289/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 38.7542 - metrics_pearsonr: 0.4050 - val_loss: 39.4042 - val_metrics_pearsonr: 0.4201\n",
      "Epoch 290/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 38.7217 - metrics_pearsonr: 0.4044 - val_loss: 39.3747 - val_metrics_pearsonr: 0.4194\n",
      "Epoch 291/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.6894 - metrics_pearsonr: 0.4037 - val_loss: 39.3453 - val_metrics_pearsonr: 0.4188\n",
      "Epoch 292/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 38.6571 - metrics_pearsonr: 0.4031 - val_loss: 39.3160 - val_metrics_pearsonr: 0.4181\n",
      "Epoch 293/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 38.6250 - metrics_pearsonr: 0.4024 - val_loss: 39.2868 - val_metrics_pearsonr: 0.4175\n",
      "Epoch 294/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 38.5929 - metrics_pearsonr: 0.4018 - val_loss: 39.2577 - val_metrics_pearsonr: 0.4169\n",
      "Epoch 295/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 38.5610 - metrics_pearsonr: 0.4012 - val_loss: 39.2286 - val_metrics_pearsonr: 0.4163\n",
      "Epoch 296/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.5292 - metrics_pearsonr: 0.4005 - val_loss: 39.1997 - val_metrics_pearsonr: 0.4156\n",
      "Epoch 297/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 38.4974 - metrics_pearsonr: 0.3999 - val_loss: 39.1708 - val_metrics_pearsonr: 0.4150\n",
      "Epoch 298/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 38.4658 - metrics_pearsonr: 0.3992 - val_loss: 39.1420 - val_metrics_pearsonr: 0.4144\n",
      "Epoch 299/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 38.4342 - metrics_pearsonr: 0.3986 - val_loss: 39.1133 - val_metrics_pearsonr: 0.4138\n",
      "Epoch 300/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 38.4027 - metrics_pearsonr: 0.3980 - val_loss: 39.0846 - val_metrics_pearsonr: 0.4131\n",
      "Epoch 301/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 38.3713 - metrics_pearsonr: 0.3973 - val_loss: 39.0559 - val_metrics_pearsonr: 0.4125\n",
      "Epoch 302/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 38.3399 - metrics_pearsonr: 0.3967 - val_loss: 39.0274 - val_metrics_pearsonr: 0.4119\n",
      "Epoch 303/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 38.3087 - metrics_pearsonr: 0.3961 - val_loss: 38.9989 - val_metrics_pearsonr: 0.4113\n",
      "Epoch 304/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 38.2775 - metrics_pearsonr: 0.3954 - val_loss: 38.9704 - val_metrics_pearsonr: 0.4107\n",
      "Epoch 305/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.2463 - metrics_pearsonr: 0.3948 - val_loss: 38.9420 - val_metrics_pearsonr: 0.4100\n",
      "Epoch 306/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 38.2152 - metrics_pearsonr: 0.3942 - val_loss: 38.9136 - val_metrics_pearsonr: 0.4094\n",
      "Epoch 307/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.1842 - metrics_pearsonr: 0.3935 - val_loss: 38.8853 - val_metrics_pearsonr: 0.4088\n",
      "Epoch 308/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 38.1532 - metrics_pearsonr: 0.3929 - val_loss: 38.8570 - val_metrics_pearsonr: 0.4082\n",
      "Epoch 309/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 38.1222 - metrics_pearsonr: 0.3923 - val_loss: 38.8287 - val_metrics_pearsonr: 0.4076\n",
      "Epoch 310/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 38.0913 - metrics_pearsonr: 0.3917 - val_loss: 38.8005 - val_metrics_pearsonr: 0.4070\n",
      "Epoch 311/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 38.0605 - metrics_pearsonr: 0.3910 - val_loss: 38.7723 - val_metrics_pearsonr: 0.4063\n",
      "Epoch 312/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 38.0296 - metrics_pearsonr: 0.3904 - val_loss: 38.7441 - val_metrics_pearsonr: 0.4057\n",
      "Epoch 313/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 37.9988 - metrics_pearsonr: 0.3898 - val_loss: 38.7159 - val_metrics_pearsonr: 0.4051\n",
      "Epoch 314/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 37.9681 - metrics_pearsonr: 0.3892 - val_loss: 38.6878 - val_metrics_pearsonr: 0.4045\n",
      "Epoch 315/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 37.9373 - metrics_pearsonr: 0.3885 - val_loss: 38.6597 - val_metrics_pearsonr: 0.4039\n",
      "Epoch 316/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 37.9066 - metrics_pearsonr: 0.3879 - val_loss: 38.6316 - val_metrics_pearsonr: 0.4033\n",
      "Epoch 317/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 37.8759 - metrics_pearsonr: 0.3873 - val_loss: 38.6035 - val_metrics_pearsonr: 0.4027\n",
      "Epoch 318/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 37.8452 - metrics_pearsonr: 0.3867 - val_loss: 38.5754 - val_metrics_pearsonr: 0.4021\n",
      "Epoch 319/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 37.8146 - metrics_pearsonr: 0.3861 - val_loss: 38.5473 - val_metrics_pearsonr: 0.4015\n",
      "Epoch 320/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 37.7839 - metrics_pearsonr: 0.3854 - val_loss: 38.5193 - val_metrics_pearsonr: 0.4009\n",
      "Epoch 321/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 37.7533 - metrics_pearsonr: 0.3848 - val_loss: 38.4912 - val_metrics_pearsonr: 0.4003\n",
      "Epoch 322/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 37.7227 - metrics_pearsonr: 0.3842 - val_loss: 38.4631 - val_metrics_pearsonr: 0.3997\n",
      "Epoch 323/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 37.6920 - metrics_pearsonr: 0.3836 - val_loss: 38.4351 - val_metrics_pearsonr: 0.3990\n",
      "Epoch 324/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 37.6614 - metrics_pearsonr: 0.3830 - val_loss: 38.4070 - val_metrics_pearsonr: 0.3984\n",
      "Epoch 325/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 37.6308 - metrics_pearsonr: 0.3823 - val_loss: 38.3789 - val_metrics_pearsonr: 0.3978\n",
      "Epoch 326/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 37.6002 - metrics_pearsonr: 0.3817 - val_loss: 38.3509 - val_metrics_pearsonr: 0.3972\n",
      "Epoch 327/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 37.5695 - metrics_pearsonr: 0.3811 - val_loss: 38.3228 - val_metrics_pearsonr: 0.3966\n",
      "Epoch 328/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 37.5389 - metrics_pearsonr: 0.3805 - val_loss: 38.2947 - val_metrics_pearsonr: 0.3960\n",
      "Epoch 329/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 37.5082 - metrics_pearsonr: 0.3799 - val_loss: 38.2666 - val_metrics_pearsonr: 0.3954\n",
      "Epoch 330/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 37.4776 - metrics_pearsonr: 0.3793 - val_loss: 38.2384 - val_metrics_pearsonr: 0.3948\n",
      "Epoch 331/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 37.4469 - metrics_pearsonr: 0.3786 - val_loss: 38.2103 - val_metrics_pearsonr: 0.3942\n",
      "Epoch 332/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 37.4162 - metrics_pearsonr: 0.3780 - val_loss: 38.1821 - val_metrics_pearsonr: 0.3936\n",
      "Epoch 333/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 37.3855 - metrics_pearsonr: 0.3774 - val_loss: 38.1539 - val_metrics_pearsonr: 0.3930\n",
      "Epoch 334/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 37.3547 - metrics_pearsonr: 0.3768 - val_loss: 38.1257 - val_metrics_pearsonr: 0.3924\n",
      "Epoch 335/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 37.3240 - metrics_pearsonr: 0.3762 - val_loss: 38.0975 - val_metrics_pearsonr: 0.3918\n",
      "Epoch 336/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 37.2932 - metrics_pearsonr: 0.3756 - val_loss: 38.0692 - val_metrics_pearsonr: 0.3912\n",
      "Epoch 337/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 37.2623 - metrics_pearsonr: 0.3749 - val_loss: 38.0409 - val_metrics_pearsonr: 0.3906\n",
      "Epoch 338/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 37.2315 - metrics_pearsonr: 0.3743 - val_loss: 38.0126 - val_metrics_pearsonr: 0.3900\n",
      "Epoch 339/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 37.2006 - metrics_pearsonr: 0.3737 - val_loss: 37.9842 - val_metrics_pearsonr: 0.3894\n",
      "Epoch 340/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 37.1697 - metrics_pearsonr: 0.3731 - val_loss: 37.9558 - val_metrics_pearsonr: 0.3888\n",
      "Epoch 341/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 37.1387 - metrics_pearsonr: 0.3725 - val_loss: 37.9274 - val_metrics_pearsonr: 0.3882\n",
      "Epoch 342/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 37.1077 - metrics_pearsonr: 0.3718 - val_loss: 37.8989 - val_metrics_pearsonr: 0.3876\n",
      "Epoch 343/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 37.0766 - metrics_pearsonr: 0.3712 - val_loss: 37.8704 - val_metrics_pearsonr: 0.3870\n",
      "Epoch 344/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 37.0455 - metrics_pearsonr: 0.3706 - val_loss: 37.8418 - val_metrics_pearsonr: 0.3864\n",
      "Epoch 345/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 37.0144 - metrics_pearsonr: 0.3700 - val_loss: 37.8132 - val_metrics_pearsonr: 0.3858\n",
      "Epoch 346/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 36.9832 - metrics_pearsonr: 0.3694 - val_loss: 37.7845 - val_metrics_pearsonr: 0.3852\n",
      "Epoch 347/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 36.9520 - metrics_pearsonr: 0.3687 - val_loss: 37.7558 - val_metrics_pearsonr: 0.3846\n",
      "Epoch 348/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 36.9207 - metrics_pearsonr: 0.3681 - val_loss: 37.7271 - val_metrics_pearsonr: 0.3839\n",
      "Epoch 349/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 36.8893 - metrics_pearsonr: 0.3675 - val_loss: 37.6983 - val_metrics_pearsonr: 0.3833\n",
      "Epoch 350/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 36.8579 - metrics_pearsonr: 0.3669 - val_loss: 37.6694 - val_metrics_pearsonr: 0.3827\n",
      "Epoch 351/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 36.8264 - metrics_pearsonr: 0.3663 - val_loss: 37.6405 - val_metrics_pearsonr: 0.3821\n",
      "Epoch 352/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 36.7949 - metrics_pearsonr: 0.3656 - val_loss: 37.6115 - val_metrics_pearsonr: 0.3815\n",
      "Epoch 353/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 36.7633 - metrics_pearsonr: 0.3650 - val_loss: 37.5824 - val_metrics_pearsonr: 0.3809\n",
      "Epoch 354/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 36.7316 - metrics_pearsonr: 0.3644 - val_loss: 37.5533 - val_metrics_pearsonr: 0.3803\n",
      "Epoch 355/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 36.6999 - metrics_pearsonr: 0.3638 - val_loss: 37.5242 - val_metrics_pearsonr: 0.3797\n",
      "Epoch 356/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 36.6681 - metrics_pearsonr: 0.3631 - val_loss: 37.4949 - val_metrics_pearsonr: 0.3791\n",
      "Epoch 357/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 36.6362 - metrics_pearsonr: 0.3625 - val_loss: 37.4657 - val_metrics_pearsonr: 0.3785\n",
      "Epoch 358/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 36.6043 - metrics_pearsonr: 0.3619 - val_loss: 37.4363 - val_metrics_pearsonr: 0.3779\n",
      "Epoch 359/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 36.5723 - metrics_pearsonr: 0.3612 - val_loss: 37.4069 - val_metrics_pearsonr: 0.3773\n",
      "Epoch 360/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 36.5402 - metrics_pearsonr: 0.3606 - val_loss: 37.3774 - val_metrics_pearsonr: 0.3767\n",
      "Epoch 361/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 36.5080 - metrics_pearsonr: 0.3600 - val_loss: 37.3478 - val_metrics_pearsonr: 0.3760\n",
      "Epoch 362/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 36.4758 - metrics_pearsonr: 0.3594 - val_loss: 37.3181 - val_metrics_pearsonr: 0.3754\n",
      "Epoch 363/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 36.4435 - metrics_pearsonr: 0.3587 - val_loss: 37.2884 - val_metrics_pearsonr: 0.3748\n",
      "Epoch 364/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 36.4111 - metrics_pearsonr: 0.3581 - val_loss: 37.2586 - val_metrics_pearsonr: 0.3742\n",
      "Epoch 365/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 36.3787 - metrics_pearsonr: 0.3575 - val_loss: 37.2288 - val_metrics_pearsonr: 0.3736\n",
      "Epoch 366/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 36.3461 - metrics_pearsonr: 0.3568 - val_loss: 37.1988 - val_metrics_pearsonr: 0.3730\n",
      "Epoch 367/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 36.3135 - metrics_pearsonr: 0.3562 - val_loss: 37.1688 - val_metrics_pearsonr: 0.3724\n",
      "Epoch 368/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 36.2808 - metrics_pearsonr: 0.3555 - val_loss: 37.1387 - val_metrics_pearsonr: 0.3717\n",
      "Epoch 369/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 36.2480 - metrics_pearsonr: 0.3549 - val_loss: 37.1085 - val_metrics_pearsonr: 0.3711\n",
      "Epoch 370/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 36.2152 - metrics_pearsonr: 0.3543 - val_loss: 37.0783 - val_metrics_pearsonr: 0.3705\n",
      "Epoch 371/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 36.1822 - metrics_pearsonr: 0.3536 - val_loss: 37.0479 - val_metrics_pearsonr: 0.3699\n",
      "Epoch 372/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 36.1492 - metrics_pearsonr: 0.3530 - val_loss: 37.0175 - val_metrics_pearsonr: 0.3693\n",
      "Epoch 373/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 36.1161 - metrics_pearsonr: 0.3524 - val_loss: 36.9870 - val_metrics_pearsonr: 0.3687\n",
      "Epoch 374/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 36.0830 - metrics_pearsonr: 0.3517 - val_loss: 36.9564 - val_metrics_pearsonr: 0.3680\n",
      "Epoch 375/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 36.0497 - metrics_pearsonr: 0.3511 - val_loss: 36.9258 - val_metrics_pearsonr: 0.3674\n",
      "Epoch 376/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 36.0164 - metrics_pearsonr: 0.3504 - val_loss: 36.8950 - val_metrics_pearsonr: 0.3668\n",
      "Epoch 377/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 35.9830 - metrics_pearsonr: 0.3498 - val_loss: 36.8642 - val_metrics_pearsonr: 0.3662\n",
      "Epoch 378/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 35.9495 - metrics_pearsonr: 0.3491 - val_loss: 36.8333 - val_metrics_pearsonr: 0.3656\n",
      "Epoch 379/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 35.9159 - metrics_pearsonr: 0.3485 - val_loss: 36.8023 - val_metrics_pearsonr: 0.3649\n",
      "Epoch 380/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 35.8823 - metrics_pearsonr: 0.3478 - val_loss: 36.7712 - val_metrics_pearsonr: 0.3643\n",
      "Epoch 381/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 35.8486 - metrics_pearsonr: 0.3472 - val_loss: 36.7400 - val_metrics_pearsonr: 0.3637\n",
      "Epoch 382/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 35.8148 - metrics_pearsonr: 0.3465 - val_loss: 36.7087 - val_metrics_pearsonr: 0.3631\n",
      "Epoch 383/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 35.7809 - metrics_pearsonr: 0.3459 - val_loss: 36.6774 - val_metrics_pearsonr: 0.3624\n",
      "Epoch 384/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 35.7469 - metrics_pearsonr: 0.3452 - val_loss: 36.6459 - val_metrics_pearsonr: 0.3618\n",
      "Epoch 385/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 35.7129 - metrics_pearsonr: 0.3446 - val_loss: 36.6144 - val_metrics_pearsonr: 0.3612\n",
      "Epoch 386/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 35.6788 - metrics_pearsonr: 0.3439 - val_loss: 36.5828 - val_metrics_pearsonr: 0.3605\n",
      "Epoch 387/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 35.6446 - metrics_pearsonr: 0.3433 - val_loss: 36.5511 - val_metrics_pearsonr: 0.3599\n",
      "Epoch 388/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 35.6103 - metrics_pearsonr: 0.3426 - val_loss: 36.5192 - val_metrics_pearsonr: 0.3593\n",
      "Epoch 389/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 35.5759 - metrics_pearsonr: 0.3420 - val_loss: 36.4873 - val_metrics_pearsonr: 0.3586\n",
      "Epoch 390/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 35.5415 - metrics_pearsonr: 0.3413 - val_loss: 36.4553 - val_metrics_pearsonr: 0.3580\n",
      "Epoch 391/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 35.5070 - metrics_pearsonr: 0.3406 - val_loss: 36.4232 - val_metrics_pearsonr: 0.3574\n",
      "Epoch 392/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 35.4724 - metrics_pearsonr: 0.3400 - val_loss: 36.3910 - val_metrics_pearsonr: 0.3567\n",
      "Epoch 393/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 35.4377 - metrics_pearsonr: 0.3393 - val_loss: 36.3587 - val_metrics_pearsonr: 0.3561\n",
      "Epoch 394/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 35.4029 - metrics_pearsonr: 0.3387 - val_loss: 36.3263 - val_metrics_pearsonr: 0.3555\n",
      "Epoch 395/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 35.3680 - metrics_pearsonr: 0.3380 - val_loss: 36.2938 - val_metrics_pearsonr: 0.3548\n",
      "Epoch 396/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 35.3331 - metrics_pearsonr: 0.3373 - val_loss: 36.2612 - val_metrics_pearsonr: 0.3542\n",
      "Epoch 397/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 35.2980 - metrics_pearsonr: 0.3367 - val_loss: 36.2285 - val_metrics_pearsonr: 0.3536\n",
      "Epoch 398/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 35.2629 - metrics_pearsonr: 0.3360 - val_loss: 36.1957 - val_metrics_pearsonr: 0.3529\n",
      "Epoch 399/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 35.2277 - metrics_pearsonr: 0.3353 - val_loss: 36.1628 - val_metrics_pearsonr: 0.3523\n",
      "Epoch 400/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 35.1924 - metrics_pearsonr: 0.3347 - val_loss: 36.1298 - val_metrics_pearsonr: 0.3516\n",
      "Epoch 401/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 35.1570 - metrics_pearsonr: 0.3340 - val_loss: 36.0967 - val_metrics_pearsonr: 0.3510\n",
      "Epoch 402/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 35.1215 - metrics_pearsonr: 0.3333 - val_loss: 36.0634 - val_metrics_pearsonr: 0.3503\n",
      "Epoch 403/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 35.0859 - metrics_pearsonr: 0.3326 - val_loss: 36.0301 - val_metrics_pearsonr: 0.3497\n",
      "Epoch 404/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 35.0503 - metrics_pearsonr: 0.3320 - val_loss: 35.9967 - val_metrics_pearsonr: 0.3490\n",
      "Epoch 405/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 35.0145 - metrics_pearsonr: 0.3313 - val_loss: 35.9631 - val_metrics_pearsonr: 0.3484\n",
      "Epoch 406/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 34.9786 - metrics_pearsonr: 0.3306 - val_loss: 35.9295 - val_metrics_pearsonr: 0.3477\n",
      "Epoch 407/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 34.9427 - metrics_pearsonr: 0.3300 - val_loss: 35.8957 - val_metrics_pearsonr: 0.3471\n",
      "Epoch 408/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 34.9067 - metrics_pearsonr: 0.3293 - val_loss: 35.8618 - val_metrics_pearsonr: 0.3464\n",
      "Epoch 409/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 34.8705 - metrics_pearsonr: 0.3286 - val_loss: 35.8278 - val_metrics_pearsonr: 0.3458\n",
      "Epoch 410/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 34.8343 - metrics_pearsonr: 0.3279 - val_loss: 35.7937 - val_metrics_pearsonr: 0.3451\n",
      "Epoch 411/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 34.7979 - metrics_pearsonr: 0.3272 - val_loss: 35.7595 - val_metrics_pearsonr: 0.3445\n",
      "Epoch 412/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 34.7615 - metrics_pearsonr: 0.3266 - val_loss: 35.7251 - val_metrics_pearsonr: 0.3438\n",
      "Epoch 413/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 34.7250 - metrics_pearsonr: 0.3259 - val_loss: 35.6907 - val_metrics_pearsonr: 0.3432\n",
      "Epoch 414/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 34.6883 - metrics_pearsonr: 0.3252 - val_loss: 35.6561 - val_metrics_pearsonr: 0.3425\n",
      "Epoch 415/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 34.6516 - metrics_pearsonr: 0.3245 - val_loss: 35.6214 - val_metrics_pearsonr: 0.3419\n",
      "Epoch 416/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 34.6148 - metrics_pearsonr: 0.3238 - val_loss: 35.5866 - val_metrics_pearsonr: 0.3412\n",
      "Epoch 417/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 34.5778 - metrics_pearsonr: 0.3231 - val_loss: 35.5517 - val_metrics_pearsonr: 0.3405\n",
      "Epoch 418/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 34.5408 - metrics_pearsonr: 0.3224 - val_loss: 35.5167 - val_metrics_pearsonr: 0.3399\n",
      "Epoch 419/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 34.5036 - metrics_pearsonr: 0.3218 - val_loss: 35.4815 - val_metrics_pearsonr: 0.3392\n",
      "Epoch 420/5000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 34.4664 - metrics_pearsonr: 0.3211 - val_loss: 35.4463 - val_metrics_pearsonr: 0.3385\n",
      "Epoch 421/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 34.4291 - metrics_pearsonr: 0.3204 - val_loss: 35.4109 - val_metrics_pearsonr: 0.3379\n",
      "Epoch 422/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 34.3916 - metrics_pearsonr: 0.3197 - val_loss: 35.3754 - val_metrics_pearsonr: 0.3372\n",
      "Epoch 423/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 34.3540 - metrics_pearsonr: 0.3190 - val_loss: 35.3397 - val_metrics_pearsonr: 0.3365\n",
      "Epoch 424/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 34.3164 - metrics_pearsonr: 0.3183 - val_loss: 35.3039 - val_metrics_pearsonr: 0.3359\n",
      "Epoch 425/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 34.2786 - metrics_pearsonr: 0.3176 - val_loss: 35.2681 - val_metrics_pearsonr: 0.3352\n",
      "Epoch 426/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 34.2407 - metrics_pearsonr: 0.3169 - val_loss: 35.2321 - val_metrics_pearsonr: 0.3345\n",
      "Epoch 427/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 34.2028 - metrics_pearsonr: 0.3162 - val_loss: 35.1959 - val_metrics_pearsonr: 0.3339\n",
      "Epoch 428/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 34.1647 - metrics_pearsonr: 0.3155 - val_loss: 35.1597 - val_metrics_pearsonr: 0.3332\n",
      "Epoch 429/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 34.1265 - metrics_pearsonr: 0.3148 - val_loss: 35.1233 - val_metrics_pearsonr: 0.3325\n",
      "Epoch 430/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 34.0882 - metrics_pearsonr: 0.3141 - val_loss: 35.0868 - val_metrics_pearsonr: 0.3318\n",
      "Epoch 431/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 34.0498 - metrics_pearsonr: 0.3134 - val_loss: 35.0501 - val_metrics_pearsonr: 0.3312\n",
      "Epoch 432/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 34.0112 - metrics_pearsonr: 0.3127 - val_loss: 35.0134 - val_metrics_pearsonr: 0.3305\n",
      "Epoch 433/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 33.9726 - metrics_pearsonr: 0.3120 - val_loss: 34.9765 - val_metrics_pearsonr: 0.3298\n",
      "Epoch 434/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 33.9339 - metrics_pearsonr: 0.3113 - val_loss: 34.9394 - val_metrics_pearsonr: 0.3291\n",
      "Epoch 435/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 33.8950 - metrics_pearsonr: 0.3106 - val_loss: 34.9023 - val_metrics_pearsonr: 0.3285\n",
      "Epoch 436/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 33.8560 - metrics_pearsonr: 0.3099 - val_loss: 34.8650 - val_metrics_pearsonr: 0.3278\n",
      "Epoch 437/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 33.8170 - metrics_pearsonr: 0.3092 - val_loss: 34.8276 - val_metrics_pearsonr: 0.3271\n",
      "Epoch 438/5000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 33.7778 - metrics_pearsonr: 0.3085 - val_loss: 34.7900 - val_metrics_pearsonr: 0.3264\n",
      "Epoch 439/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 33.7384 - metrics_pearsonr: 0.3078 - val_loss: 34.7523 - val_metrics_pearsonr: 0.3257\n",
      "Epoch 440/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 33.6990 - metrics_pearsonr: 0.3071 - val_loss: 34.7145 - val_metrics_pearsonr: 0.3251\n",
      "Epoch 441/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 33.6595 - metrics_pearsonr: 0.3064 - val_loss: 34.6765 - val_metrics_pearsonr: 0.3244\n",
      "Epoch 442/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 33.6198 - metrics_pearsonr: 0.3057 - val_loss: 34.6384 - val_metrics_pearsonr: 0.3237\n",
      "Epoch 443/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 33.5801 - metrics_pearsonr: 0.3049 - val_loss: 34.6002 - val_metrics_pearsonr: 0.3230\n",
      "Epoch 444/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 33.5402 - metrics_pearsonr: 0.3042 - val_loss: 34.5618 - val_metrics_pearsonr: 0.3223\n",
      "Epoch 445/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 33.5002 - metrics_pearsonr: 0.3035 - val_loss: 34.5233 - val_metrics_pearsonr: 0.3216\n",
      "Epoch 446/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 33.4601 - metrics_pearsonr: 0.3028 - val_loss: 34.4847 - val_metrics_pearsonr: 0.3209\n",
      "Epoch 447/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 33.4198 - metrics_pearsonr: 0.3021 - val_loss: 34.4459 - val_metrics_pearsonr: 0.3202\n",
      "Epoch 448/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 33.3795 - metrics_pearsonr: 0.3014 - val_loss: 34.4070 - val_metrics_pearsonr: 0.3195\n",
      "Epoch 449/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 33.3390 - metrics_pearsonr: 0.3007 - val_loss: 34.3679 - val_metrics_pearsonr: 0.3189\n",
      "Epoch 450/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 33.2984 - metrics_pearsonr: 0.2999 - val_loss: 34.3287 - val_metrics_pearsonr: 0.3182\n",
      "Epoch 451/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 33.2577 - metrics_pearsonr: 0.2992 - val_loss: 34.2894 - val_metrics_pearsonr: 0.3175\n",
      "Epoch 452/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 33.2169 - metrics_pearsonr: 0.2985 - val_loss: 34.2499 - val_metrics_pearsonr: 0.3168\n",
      "Epoch 453/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 33.1759 - metrics_pearsonr: 0.2978 - val_loss: 34.2103 - val_metrics_pearsonr: 0.3161\n",
      "Epoch 454/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 33.1348 - metrics_pearsonr: 0.2971 - val_loss: 34.1705 - val_metrics_pearsonr: 0.3154\n",
      "Epoch 455/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 33.0936 - metrics_pearsonr: 0.2963 - val_loss: 34.1306 - val_metrics_pearsonr: 0.3147\n",
      "Epoch 456/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 33.0523 - metrics_pearsonr: 0.2956 - val_loss: 34.0906 - val_metrics_pearsonr: 0.3140\n",
      "Epoch 457/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 33.0108 - metrics_pearsonr: 0.2949 - val_loss: 34.0504 - val_metrics_pearsonr: 0.3133\n",
      "Epoch 458/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 32.9693 - metrics_pearsonr: 0.2942 - val_loss: 34.0101 - val_metrics_pearsonr: 0.3126\n",
      "Epoch 459/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 32.9276 - metrics_pearsonr: 0.2935 - val_loss: 33.9696 - val_metrics_pearsonr: 0.3119\n",
      "Epoch 460/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 32.8857 - metrics_pearsonr: 0.2927 - val_loss: 33.9290 - val_metrics_pearsonr: 0.3112\n",
      "Epoch 461/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 32.8438 - metrics_pearsonr: 0.2920 - val_loss: 33.8882 - val_metrics_pearsonr: 0.3105\n",
      "Epoch 462/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 32.8017 - metrics_pearsonr: 0.2913 - val_loss: 33.8473 - val_metrics_pearsonr: 0.3098\n",
      "Epoch 463/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 32.7595 - metrics_pearsonr: 0.2906 - val_loss: 33.8062 - val_metrics_pearsonr: 0.3091\n",
      "Epoch 464/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 32.7172 - metrics_pearsonr: 0.2898 - val_loss: 33.7650 - val_metrics_pearsonr: 0.3084\n",
      "Epoch 465/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 32.6747 - metrics_pearsonr: 0.2891 - val_loss: 33.7236 - val_metrics_pearsonr: 0.3076\n",
      "Epoch 466/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 32.6321 - metrics_pearsonr: 0.2884 - val_loss: 33.6821 - val_metrics_pearsonr: 0.3069\n",
      "Epoch 467/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 32.5894 - metrics_pearsonr: 0.2876 - val_loss: 33.6405 - val_metrics_pearsonr: 0.3062\n",
      "Epoch 468/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 32.5466 - metrics_pearsonr: 0.2869 - val_loss: 33.5987 - val_metrics_pearsonr: 0.3055\n",
      "Epoch 469/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 32.5036 - metrics_pearsonr: 0.2862 - val_loss: 33.5567 - val_metrics_pearsonr: 0.3048\n",
      "Epoch 470/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 32.4605 - metrics_pearsonr: 0.2855 - val_loss: 33.5146 - val_metrics_pearsonr: 0.3041\n",
      "Epoch 471/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 32.4172 - metrics_pearsonr: 0.2847 - val_loss: 33.4724 - val_metrics_pearsonr: 0.3034\n",
      "Epoch 472/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 32.3739 - metrics_pearsonr: 0.2840 - val_loss: 33.4300 - val_metrics_pearsonr: 0.3027\n",
      "Epoch 473/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 32.3304 - metrics_pearsonr: 0.2833 - val_loss: 33.3874 - val_metrics_pearsonr: 0.3020\n",
      "Epoch 474/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 32.2867 - metrics_pearsonr: 0.2825 - val_loss: 33.3447 - val_metrics_pearsonr: 0.3012\n",
      "Epoch 475/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 32.2429 - metrics_pearsonr: 0.2818 - val_loss: 33.3019 - val_metrics_pearsonr: 0.3005\n",
      "Epoch 476/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 32.1990 - metrics_pearsonr: 0.2811 - val_loss: 33.2589 - val_metrics_pearsonr: 0.2998\n",
      "Epoch 477/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 32.1550 - metrics_pearsonr: 0.2803 - val_loss: 33.2157 - val_metrics_pearsonr: 0.2991\n",
      "Epoch 478/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 32.1108 - metrics_pearsonr: 0.2796 - val_loss: 33.1724 - val_metrics_pearsonr: 0.2984\n",
      "Epoch 479/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 32.0665 - metrics_pearsonr: 0.2788 - val_loss: 33.1290 - val_metrics_pearsonr: 0.2977\n",
      "Epoch 480/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 32.0221 - metrics_pearsonr: 0.2781 - val_loss: 33.0854 - val_metrics_pearsonr: 0.2969\n",
      "Epoch 481/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 31.9775 - metrics_pearsonr: 0.2774 - val_loss: 33.0416 - val_metrics_pearsonr: 0.2962\n",
      "Epoch 482/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 31.9328 - metrics_pearsonr: 0.2766 - val_loss: 32.9977 - val_metrics_pearsonr: 0.2955\n",
      "Epoch 483/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 31.8879 - metrics_pearsonr: 0.2759 - val_loss: 32.9537 - val_metrics_pearsonr: 0.2948\n",
      "Epoch 484/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 31.8429 - metrics_pearsonr: 0.2752 - val_loss: 32.9095 - val_metrics_pearsonr: 0.2941\n",
      "Epoch 485/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 31.7977 - metrics_pearsonr: 0.2744 - val_loss: 32.8651 - val_metrics_pearsonr: 0.2933\n",
      "Epoch 486/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 31.7525 - metrics_pearsonr: 0.2737 - val_loss: 32.8206 - val_metrics_pearsonr: 0.2926\n",
      "Epoch 487/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 31.7070 - metrics_pearsonr: 0.2729 - val_loss: 32.7759 - val_metrics_pearsonr: 0.2919\n",
      "Epoch 488/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 31.6615 - metrics_pearsonr: 0.2722 - val_loss: 32.7311 - val_metrics_pearsonr: 0.2912\n",
      "Epoch 489/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 31.6158 - metrics_pearsonr: 0.2714 - val_loss: 32.6861 - val_metrics_pearsonr: 0.2905\n",
      "Epoch 490/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 31.5699 - metrics_pearsonr: 0.2707 - val_loss: 32.6410 - val_metrics_pearsonr: 0.2897\n",
      "Epoch 491/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 31.5240 - metrics_pearsonr: 0.2700 - val_loss: 32.5957 - val_metrics_pearsonr: 0.2890\n",
      "Epoch 492/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 31.4778 - metrics_pearsonr: 0.2692 - val_loss: 32.5502 - val_metrics_pearsonr: 0.2883\n",
      "Epoch 493/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 31.4316 - metrics_pearsonr: 0.2685 - val_loss: 32.5046 - val_metrics_pearsonr: 0.2876\n",
      "Epoch 494/5000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 31.3851 - metrics_pearsonr: 0.2677 - val_loss: 32.4589 - val_metrics_pearsonr: 0.2868\n",
      "Epoch 495/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 31.3386 - metrics_pearsonr: 0.2670 - val_loss: 32.4130 - val_metrics_pearsonr: 0.2861\n",
      "Epoch 496/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 31.2919 - metrics_pearsonr: 0.2662 - val_loss: 32.3669 - val_metrics_pearsonr: 0.2854\n",
      "Epoch 497/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 31.2450 - metrics_pearsonr: 0.2655 - val_loss: 32.3207 - val_metrics_pearsonr: 0.2846\n",
      "Epoch 498/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 31.1980 - metrics_pearsonr: 0.2648 - val_loss: 32.2743 - val_metrics_pearsonr: 0.2839\n",
      "Epoch 499/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 31.1509 - metrics_pearsonr: 0.2640 - val_loss: 32.2278 - val_metrics_pearsonr: 0.2832\n",
      "Epoch 500/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 31.1036 - metrics_pearsonr: 0.2633 - val_loss: 32.1811 - val_metrics_pearsonr: 0.2825\n",
      "Epoch 501/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 31.0562 - metrics_pearsonr: 0.2625 - val_loss: 32.1343 - val_metrics_pearsonr: 0.2817\n",
      "Epoch 502/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 31.0086 - metrics_pearsonr: 0.2618 - val_loss: 32.0873 - val_metrics_pearsonr: 0.2810\n",
      "Epoch 503/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 30.9608 - metrics_pearsonr: 0.2610 - val_loss: 32.0401 - val_metrics_pearsonr: 0.2803\n",
      "Epoch 504/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 30.9130 - metrics_pearsonr: 0.2603 - val_loss: 31.9928 - val_metrics_pearsonr: 0.2795\n",
      "Epoch 505/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 30.8649 - metrics_pearsonr: 0.2595 - val_loss: 31.9453 - val_metrics_pearsonr: 0.2788\n",
      "Epoch 506/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 30.8167 - metrics_pearsonr: 0.2588 - val_loss: 31.8977 - val_metrics_pearsonr: 0.2781\n",
      "Epoch 507/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 30.7684 - metrics_pearsonr: 0.2580 - val_loss: 31.8499 - val_metrics_pearsonr: 0.2773\n",
      "Epoch 508/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 30.7199 - metrics_pearsonr: 0.2573 - val_loss: 31.8019 - val_metrics_pearsonr: 0.2766\n",
      "Epoch 509/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 30.6713 - metrics_pearsonr: 0.2565 - val_loss: 31.7538 - val_metrics_pearsonr: 0.2759\n",
      "Epoch 510/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 30.6225 - metrics_pearsonr: 0.2558 - val_loss: 31.7055 - val_metrics_pearsonr: 0.2751\n",
      "Epoch 511/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 30.5736 - metrics_pearsonr: 0.2550 - val_loss: 31.6571 - val_metrics_pearsonr: 0.2744\n",
      "Epoch 512/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 30.5245 - metrics_pearsonr: 0.2543 - val_loss: 31.6085 - val_metrics_pearsonr: 0.2737\n",
      "Epoch 513/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 30.4753 - metrics_pearsonr: 0.2535 - val_loss: 31.5597 - val_metrics_pearsonr: 0.2729\n",
      "Epoch 514/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 30.4259 - metrics_pearsonr: 0.2528 - val_loss: 31.5108 - val_metrics_pearsonr: 0.2722\n",
      "Epoch 515/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 30.3764 - metrics_pearsonr: 0.2520 - val_loss: 31.4618 - val_metrics_pearsonr: 0.2714\n",
      "Epoch 516/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 30.3267 - metrics_pearsonr: 0.2513 - val_loss: 31.4125 - val_metrics_pearsonr: 0.2707\n",
      "Epoch 517/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 30.2769 - metrics_pearsonr: 0.2505 - val_loss: 31.3631 - val_metrics_pearsonr: 0.2700\n",
      "Epoch 518/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 30.2269 - metrics_pearsonr: 0.2498 - val_loss: 31.3136 - val_metrics_pearsonr: 0.2692\n",
      "Epoch 519/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 30.1768 - metrics_pearsonr: 0.2490 - val_loss: 31.2639 - val_metrics_pearsonr: 0.2685\n",
      "Epoch 520/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 30.1265 - metrics_pearsonr: 0.2483 - val_loss: 31.2141 - val_metrics_pearsonr: 0.2678\n",
      "Epoch 521/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 30.0761 - metrics_pearsonr: 0.2475 - val_loss: 31.1641 - val_metrics_pearsonr: 0.2670\n",
      "Epoch 522/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 30.0256 - metrics_pearsonr: 0.2468 - val_loss: 31.1139 - val_metrics_pearsonr: 0.2663\n",
      "Epoch 523/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 29.9749 - metrics_pearsonr: 0.2460 - val_loss: 31.0636 - val_metrics_pearsonr: 0.2655\n",
      "Epoch 524/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 29.9241 - metrics_pearsonr: 0.2453 - val_loss: 31.0132 - val_metrics_pearsonr: 0.2648\n",
      "Epoch 525/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 29.8732 - metrics_pearsonr: 0.2445 - val_loss: 30.9626 - val_metrics_pearsonr: 0.2641\n",
      "Epoch 526/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 29.8221 - metrics_pearsonr: 0.2437 - val_loss: 30.9119 - val_metrics_pearsonr: 0.2633\n",
      "Epoch 527/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 29.7709 - metrics_pearsonr: 0.2430 - val_loss: 30.8610 - val_metrics_pearsonr: 0.2626\n",
      "Epoch 528/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 29.7196 - metrics_pearsonr: 0.2422 - val_loss: 30.8100 - val_metrics_pearsonr: 0.2618\n",
      "Epoch 529/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 29.6682 - metrics_pearsonr: 0.2415 - val_loss: 30.7588 - val_metrics_pearsonr: 0.2611\n",
      "Epoch 530/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 29.6166 - metrics_pearsonr: 0.2407 - val_loss: 30.7075 - val_metrics_pearsonr: 0.2604\n",
      "Epoch 531/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 29.5649 - metrics_pearsonr: 0.2400 - val_loss: 30.6561 - val_metrics_pearsonr: 0.2596\n",
      "Epoch 532/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 29.5131 - metrics_pearsonr: 0.2393 - val_loss: 30.6046 - val_metrics_pearsonr: 0.2589\n",
      "Epoch 533/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 29.4612 - metrics_pearsonr: 0.2385 - val_loss: 30.5529 - val_metrics_pearsonr: 0.2581\n",
      "Epoch 534/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 29.4092 - metrics_pearsonr: 0.2378 - val_loss: 30.5011 - val_metrics_pearsonr: 0.2574\n",
      "Epoch 535/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 29.3571 - metrics_pearsonr: 0.2370 - val_loss: 30.4492 - val_metrics_pearsonr: 0.2567\n",
      "Epoch 536/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 29.3049 - metrics_pearsonr: 0.2363 - val_loss: 30.3972 - val_metrics_pearsonr: 0.2559\n",
      "Epoch 537/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 29.2525 - metrics_pearsonr: 0.2355 - val_loss: 30.3450 - val_metrics_pearsonr: 0.2552\n",
      "Epoch 538/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 29.2001 - metrics_pearsonr: 0.2348 - val_loss: 30.2928 - val_metrics_pearsonr: 0.2544\n",
      "Epoch 539/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 29.1475 - metrics_pearsonr: 0.2340 - val_loss: 30.2404 - val_metrics_pearsonr: 0.2537\n",
      "Epoch 540/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 29.0949 - metrics_pearsonr: 0.2333 - val_loss: 30.1879 - val_metrics_pearsonr: 0.2530\n",
      "Epoch 541/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 29.0421 - metrics_pearsonr: 0.2325 - val_loss: 30.1353 - val_metrics_pearsonr: 0.2522\n",
      "Epoch 542/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 28.9893 - metrics_pearsonr: 0.2318 - val_loss: 30.0826 - val_metrics_pearsonr: 0.2515\n",
      "Epoch 543/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 28.9364 - metrics_pearsonr: 0.2311 - val_loss: 30.0298 - val_metrics_pearsonr: 0.2508\n",
      "Epoch 544/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 28.8833 - metrics_pearsonr: 0.2303 - val_loss: 29.9769 - val_metrics_pearsonr: 0.2500\n",
      "Epoch 545/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 28.8302 - metrics_pearsonr: 0.2296 - val_loss: 29.9238 - val_metrics_pearsonr: 0.2493\n",
      "Epoch 546/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 28.7770 - metrics_pearsonr: 0.2289 - val_loss: 29.8707 - val_metrics_pearsonr: 0.2486\n",
      "Epoch 547/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 28.7237 - metrics_pearsonr: 0.2281 - val_loss: 29.8175 - val_metrics_pearsonr: 0.2478\n",
      "Epoch 548/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 28.6703 - metrics_pearsonr: 0.2274 - val_loss: 29.7642 - val_metrics_pearsonr: 0.2471\n",
      "Epoch 549/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 28.6168 - metrics_pearsonr: 0.2267 - val_loss: 29.7107 - val_metrics_pearsonr: 0.2464\n",
      "Epoch 550/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 28.5632 - metrics_pearsonr: 0.2259 - val_loss: 29.6572 - val_metrics_pearsonr: 0.2456\n",
      "Epoch 551/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 28.5095 - metrics_pearsonr: 0.2252 - val_loss: 29.6036 - val_metrics_pearsonr: 0.2449\n",
      "Epoch 552/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 28.4557 - metrics_pearsonr: 0.2245 - val_loss: 29.5499 - val_metrics_pearsonr: 0.2442\n",
      "Epoch 553/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 28.4018 - metrics_pearsonr: 0.2237 - val_loss: 29.4960 - val_metrics_pearsonr: 0.2435\n",
      "Epoch 554/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 28.3479 - metrics_pearsonr: 0.2230 - val_loss: 29.4421 - val_metrics_pearsonr: 0.2427\n",
      "Epoch 555/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 28.2938 - metrics_pearsonr: 0.2223 - val_loss: 29.3881 - val_metrics_pearsonr: 0.2420\n",
      "Epoch 556/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 28.2397 - metrics_pearsonr: 0.2215 - val_loss: 29.3340 - val_metrics_pearsonr: 0.2413\n",
      "Epoch 557/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 28.1854 - metrics_pearsonr: 0.2208 - val_loss: 29.2797 - val_metrics_pearsonr: 0.2406\n",
      "Epoch 558/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 28.1311 - metrics_pearsonr: 0.2201 - val_loss: 29.2254 - val_metrics_pearsonr: 0.2398\n",
      "Epoch 559/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 28.0766 - metrics_pearsonr: 0.2194 - val_loss: 29.1710 - val_metrics_pearsonr: 0.2391\n",
      "Epoch 560/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 28.0221 - metrics_pearsonr: 0.2187 - val_loss: 29.1165 - val_metrics_pearsonr: 0.2384\n",
      "Epoch 561/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 27.9674 - metrics_pearsonr: 0.2179 - val_loss: 29.0618 - val_metrics_pearsonr: 0.2377\n",
      "Epoch 562/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 27.9127 - metrics_pearsonr: 0.2172 - val_loss: 29.0071 - val_metrics_pearsonr: 0.2369\n",
      "Epoch 563/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 27.8579 - metrics_pearsonr: 0.2165 - val_loss: 28.9523 - val_metrics_pearsonr: 0.2362\n",
      "Epoch 564/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 27.8029 - metrics_pearsonr: 0.2158 - val_loss: 28.8973 - val_metrics_pearsonr: 0.2355\n",
      "Epoch 565/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 27.7479 - metrics_pearsonr: 0.2151 - val_loss: 28.8423 - val_metrics_pearsonr: 0.2348\n",
      "Epoch 566/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 27.6928 - metrics_pearsonr: 0.2143 - val_loss: 28.7871 - val_metrics_pearsonr: 0.2341\n",
      "Epoch 567/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 27.6375 - metrics_pearsonr: 0.2136 - val_loss: 28.7319 - val_metrics_pearsonr: 0.2333\n",
      "Epoch 568/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 27.5822 - metrics_pearsonr: 0.2129 - val_loss: 28.6765 - val_metrics_pearsonr: 0.2326\n",
      "Epoch 569/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 27.5268 - metrics_pearsonr: 0.2122 - val_loss: 28.6210 - val_metrics_pearsonr: 0.2319\n",
      "Epoch 570/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 27.4712 - metrics_pearsonr: 0.2115 - val_loss: 28.5655 - val_metrics_pearsonr: 0.2312\n",
      "Epoch 571/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 27.4156 - metrics_pearsonr: 0.2108 - val_loss: 28.5098 - val_metrics_pearsonr: 0.2305\n",
      "Epoch 572/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 27.3598 - metrics_pearsonr: 0.2101 - val_loss: 28.4540 - val_metrics_pearsonr: 0.2298\n",
      "Epoch 573/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 27.3040 - metrics_pearsonr: 0.2094 - val_loss: 28.3981 - val_metrics_pearsonr: 0.2291\n",
      "Epoch 574/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 27.2480 - metrics_pearsonr: 0.2086 - val_loss: 28.3420 - val_metrics_pearsonr: 0.2283\n",
      "Epoch 575/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 27.1920 - metrics_pearsonr: 0.2079 - val_loss: 28.2859 - val_metrics_pearsonr: 0.2276\n",
      "Epoch 576/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 27.1358 - metrics_pearsonr: 0.2072 - val_loss: 28.2296 - val_metrics_pearsonr: 0.2269\n",
      "Epoch 577/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 27.0795 - metrics_pearsonr: 0.2065 - val_loss: 28.1733 - val_metrics_pearsonr: 0.2262\n",
      "Epoch 578/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 27.0231 - metrics_pearsonr: 0.2058 - val_loss: 28.1168 - val_metrics_pearsonr: 0.2255\n",
      "Epoch 579/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 26.9666 - metrics_pearsonr: 0.2051 - val_loss: 28.0602 - val_metrics_pearsonr: 0.2248\n",
      "Epoch 580/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 26.9100 - metrics_pearsonr: 0.2044 - val_loss: 28.0035 - val_metrics_pearsonr: 0.2241\n",
      "Epoch 581/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 26.8533 - metrics_pearsonr: 0.2037 - val_loss: 27.9466 - val_metrics_pearsonr: 0.2234\n",
      "Epoch 582/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 26.7964 - metrics_pearsonr: 0.2030 - val_loss: 27.8897 - val_metrics_pearsonr: 0.2226\n",
      "Epoch 583/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 26.7395 - metrics_pearsonr: 0.2023 - val_loss: 27.8326 - val_metrics_pearsonr: 0.2219\n",
      "Epoch 584/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 26.6824 - metrics_pearsonr: 0.2016 - val_loss: 27.7754 - val_metrics_pearsonr: 0.2212\n",
      "Epoch 585/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 26.6253 - metrics_pearsonr: 0.2009 - val_loss: 27.7180 - val_metrics_pearsonr: 0.2205\n",
      "Epoch 586/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 26.5680 - metrics_pearsonr: 0.2002 - val_loss: 27.6606 - val_metrics_pearsonr: 0.2198\n",
      "Epoch 587/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 26.5106 - metrics_pearsonr: 0.1995 - val_loss: 27.6030 - val_metrics_pearsonr: 0.2191\n",
      "Epoch 588/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 26.4531 - metrics_pearsonr: 0.1988 - val_loss: 27.5453 - val_metrics_pearsonr: 0.2184\n",
      "Epoch 589/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 26.3954 - metrics_pearsonr: 0.1981 - val_loss: 27.4875 - val_metrics_pearsonr: 0.2177\n",
      "Epoch 590/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 26.3377 - metrics_pearsonr: 0.1974 - val_loss: 27.4295 - val_metrics_pearsonr: 0.2170\n",
      "Epoch 591/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 26.2798 - metrics_pearsonr: 0.1967 - val_loss: 27.3714 - val_metrics_pearsonr: 0.2163\n",
      "Epoch 592/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 26.2218 - metrics_pearsonr: 0.1960 - val_loss: 27.3132 - val_metrics_pearsonr: 0.2156\n",
      "Epoch 593/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 26.1638 - metrics_pearsonr: 0.1953 - val_loss: 27.2549 - val_metrics_pearsonr: 0.2148\n",
      "Epoch 594/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 26.1056 - metrics_pearsonr: 0.1947 - val_loss: 27.1964 - val_metrics_pearsonr: 0.2141\n",
      "Epoch 595/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 26.0472 - metrics_pearsonr: 0.1940 - val_loss: 27.1378 - val_metrics_pearsonr: 0.2134\n",
      "Epoch 596/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 25.9888 - metrics_pearsonr: 0.1933 - val_loss: 27.0790 - val_metrics_pearsonr: 0.2127\n",
      "Epoch 597/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 25.9302 - metrics_pearsonr: 0.1926 - val_loss: 27.0201 - val_metrics_pearsonr: 0.2120\n",
      "Epoch 598/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 25.8715 - metrics_pearsonr: 0.1919 - val_loss: 26.9611 - val_metrics_pearsonr: 0.2113\n",
      "Epoch 599/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 25.8128 - metrics_pearsonr: 0.1912 - val_loss: 26.9020 - val_metrics_pearsonr: 0.2106\n",
      "Epoch 600/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 25.7538 - metrics_pearsonr: 0.1905 - val_loss: 26.8427 - val_metrics_pearsonr: 0.2099\n",
      "Epoch 601/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 25.6948 - metrics_pearsonr: 0.1898 - val_loss: 26.7833 - val_metrics_pearsonr: 0.2092\n",
      "Epoch 602/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 25.6357 - metrics_pearsonr: 0.1891 - val_loss: 26.7238 - val_metrics_pearsonr: 0.2085\n",
      "Epoch 603/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 25.5764 - metrics_pearsonr: 0.1885 - val_loss: 26.6641 - val_metrics_pearsonr: 0.2078\n",
      "Epoch 604/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 25.5170 - metrics_pearsonr: 0.1878 - val_loss: 26.6043 - val_metrics_pearsonr: 0.2071\n",
      "Epoch 605/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 25.4575 - metrics_pearsonr: 0.1871 - val_loss: 26.5443 - val_metrics_pearsonr: 0.2064\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 25.3979 - metrics_pearsonr: 0.1864 - val_loss: 26.4842 - val_metrics_pearsonr: 0.2057\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 25.3382 - metrics_pearsonr: 0.1857 - val_loss: 26.4240 - val_metrics_pearsonr: 0.2050\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 25.2784 - metrics_pearsonr: 0.1851 - val_loss: 26.3637 - val_metrics_pearsonr: 0.2043\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 25.2184 - metrics_pearsonr: 0.1844 - val_loss: 26.3032 - val_metrics_pearsonr: 0.2036\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 25.1584 - metrics_pearsonr: 0.1837 - val_loss: 26.2426 - val_metrics_pearsonr: 0.2029\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 25.0982 - metrics_pearsonr: 0.1830 - val_loss: 26.1818 - val_metrics_pearsonr: 0.2022\n",
      "Epoch 612/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 25.0379 - metrics_pearsonr: 0.1823 - val_loss: 26.1209 - val_metrics_pearsonr: 0.2015\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 24.9775 - metrics_pearsonr: 0.1817 - val_loss: 26.0599 - val_metrics_pearsonr: 0.2008\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 24.9170 - metrics_pearsonr: 0.1810 - val_loss: 25.9987 - val_metrics_pearsonr: 0.2001\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 24.8564 - metrics_pearsonr: 0.1803 - val_loss: 25.9375 - val_metrics_pearsonr: 0.1994\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 24.7956 - metrics_pearsonr: 0.1797 - val_loss: 25.8761 - val_metrics_pearsonr: 0.1987\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 24.7348 - metrics_pearsonr: 0.1790 - val_loss: 25.8145 - val_metrics_pearsonr: 0.1980\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 24.6738 - metrics_pearsonr: 0.1783 - val_loss: 25.7529 - val_metrics_pearsonr: 0.1973\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 24.6128 - metrics_pearsonr: 0.1776 - val_loss: 25.6911 - val_metrics_pearsonr: 0.1966\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 24.5516 - metrics_pearsonr: 0.1770 - val_loss: 25.6292 - val_metrics_pearsonr: 0.1959\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 24.4904 - metrics_pearsonr: 0.1763 - val_loss: 25.5671 - val_metrics_pearsonr: 0.1952\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 24.4290 - metrics_pearsonr: 0.1756 - val_loss: 25.5050 - val_metrics_pearsonr: 0.1945\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 24.3676 - metrics_pearsonr: 0.1750 - val_loss: 25.4427 - val_metrics_pearsonr: 0.1938\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 24.3060 - metrics_pearsonr: 0.1743 - val_loss: 25.3803 - val_metrics_pearsonr: 0.1931\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 24.2444 - metrics_pearsonr: 0.1737 - val_loss: 25.3178 - val_metrics_pearsonr: 0.1924\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 24.1826 - metrics_pearsonr: 0.1730 - val_loss: 25.2552 - val_metrics_pearsonr: 0.1917\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 24.1208 - metrics_pearsonr: 0.1723 - val_loss: 25.1924 - val_metrics_pearsonr: 0.1910\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 24.0589 - metrics_pearsonr: 0.1717 - val_loss: 25.1296 - val_metrics_pearsonr: 0.1903\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 23.9969 - metrics_pearsonr: 0.1710 - val_loss: 25.0666 - val_metrics_pearsonr: 0.1896\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 23.9347 - metrics_pearsonr: 0.1704 - val_loss: 25.0035 - val_metrics_pearsonr: 0.1889\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 23.8726 - metrics_pearsonr: 0.1697 - val_loss: 24.9404 - val_metrics_pearsonr: 0.1882\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 23.8103 - metrics_pearsonr: 0.1691 - val_loss: 24.8771 - val_metrics_pearsonr: 0.1875\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 23.7479 - metrics_pearsonr: 0.1684 - val_loss: 24.8137 - val_metrics_pearsonr: 0.1868\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 23.6855 - metrics_pearsonr: 0.1678 - val_loss: 24.7502 - val_metrics_pearsonr: 0.1861\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 23.6230 - metrics_pearsonr: 0.1671 - val_loss: 24.6867 - val_metrics_pearsonr: 0.1854\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 23.5604 - metrics_pearsonr: 0.1665 - val_loss: 24.6230 - val_metrics_pearsonr: 0.1848\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 23.4978 - metrics_pearsonr: 0.1658 - val_loss: 24.5593 - val_metrics_pearsonr: 0.1841\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 23.4350 - metrics_pearsonr: 0.1652 - val_loss: 24.4954 - val_metrics_pearsonr: 0.1834\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 23.3722 - metrics_pearsonr: 0.1645 - val_loss: 24.4315 - val_metrics_pearsonr: 0.1827\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 23.3094 - metrics_pearsonr: 0.1639 - val_loss: 24.3675 - val_metrics_pearsonr: 0.1820\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 23.2465 - metrics_pearsonr: 0.1632 - val_loss: 24.3034 - val_metrics_pearsonr: 0.1813\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 23.1835 - metrics_pearsonr: 0.1626 - val_loss: 24.2393 - val_metrics_pearsonr: 0.1806\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 23.1205 - metrics_pearsonr: 0.1620 - val_loss: 24.1750 - val_metrics_pearsonr: 0.1800\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 23.0574 - metrics_pearsonr: 0.1613 - val_loss: 24.1107 - val_metrics_pearsonr: 0.1793\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 22.9942 - metrics_pearsonr: 0.1607 - val_loss: 24.0463 - val_metrics_pearsonr: 0.1786\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 22.9311 - metrics_pearsonr: 0.1601 - val_loss: 23.9819 - val_metrics_pearsonr: 0.1779\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 22.8678 - metrics_pearsonr: 0.1594 - val_loss: 23.9174 - val_metrics_pearsonr: 0.1773\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 22.8045 - metrics_pearsonr: 0.1588 - val_loss: 23.8528 - val_metrics_pearsonr: 0.1766\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 22.7412 - metrics_pearsonr: 0.1582 - val_loss: 23.7882 - val_metrics_pearsonr: 0.1759\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 22.6779 - metrics_pearsonr: 0.1576 - val_loss: 23.7235 - val_metrics_pearsonr: 0.1752\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 22.6145 - metrics_pearsonr: 0.1569 - val_loss: 23.6587 - val_metrics_pearsonr: 0.1746\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 22.5511 - metrics_pearsonr: 0.1563 - val_loss: 23.5939 - val_metrics_pearsonr: 0.1739\n",
      "Epoch 653/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 22.4876 - metrics_pearsonr: 0.1557 - val_loss: 23.5291 - val_metrics_pearsonr: 0.1732\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 22.4241 - metrics_pearsonr: 0.1551 - val_loss: 23.4642 - val_metrics_pearsonr: 0.1726\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 22.3606 - metrics_pearsonr: 0.1545 - val_loss: 23.3992 - val_metrics_pearsonr: 0.1719\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 22.2971 - metrics_pearsonr: 0.1539 - val_loss: 23.3343 - val_metrics_pearsonr: 0.1712\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 22.2335 - metrics_pearsonr: 0.1533 - val_loss: 23.2692 - val_metrics_pearsonr: 0.1706\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 22.1700 - metrics_pearsonr: 0.1526 - val_loss: 23.2042 - val_metrics_pearsonr: 0.1699\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 22.1064 - metrics_pearsonr: 0.1520 - val_loss: 23.1391 - val_metrics_pearsonr: 0.1693\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 22.0428 - metrics_pearsonr: 0.1514 - val_loss: 23.0740 - val_metrics_pearsonr: 0.1686\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 21.9792 - metrics_pearsonr: 0.1508 - val_loss: 23.0088 - val_metrics_pearsonr: 0.1680\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 21.9156 - metrics_pearsonr: 0.1502 - val_loss: 22.9437 - val_metrics_pearsonr: 0.1673\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 21.8520 - metrics_pearsonr: 0.1496 - val_loss: 22.8785 - val_metrics_pearsonr: 0.1666\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 21.7884 - metrics_pearsonr: 0.1490 - val_loss: 22.8133 - val_metrics_pearsonr: 0.1660\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 21.7248 - metrics_pearsonr: 0.1485 - val_loss: 22.7480 - val_metrics_pearsonr: 0.1654\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 21.6612 - metrics_pearsonr: 0.1479 - val_loss: 22.6828 - val_metrics_pearsonr: 0.1647\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 21.5976 - metrics_pearsonr: 0.1473 - val_loss: 22.6175 - val_metrics_pearsonr: 0.1641\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 21.5340 - metrics_pearsonr: 0.1467 - val_loss: 22.5523 - val_metrics_pearsonr: 0.1634\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 21.4705 - metrics_pearsonr: 0.1461 - val_loss: 22.4870 - val_metrics_pearsonr: 0.1628\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 21.4069 - metrics_pearsonr: 0.1455 - val_loss: 22.4217 - val_metrics_pearsonr: 0.1621\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 21.3434 - metrics_pearsonr: 0.1449 - val_loss: 22.3565 - val_metrics_pearsonr: 0.1615\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 21.2799 - metrics_pearsonr: 0.1444 - val_loss: 22.2912 - val_metrics_pearsonr: 0.1609\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 21.2164 - metrics_pearsonr: 0.1438 - val_loss: 22.2259 - val_metrics_pearsonr: 0.1602\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 21.1530 - metrics_pearsonr: 0.1432 - val_loss: 22.1607 - val_metrics_pearsonr: 0.1596\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 21.0896 - metrics_pearsonr: 0.1426 - val_loss: 22.0954 - val_metrics_pearsonr: 0.1590\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 21.0262 - metrics_pearsonr: 0.1421 - val_loss: 22.0302 - val_metrics_pearsonr: 0.1584\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 20.9629 - metrics_pearsonr: 0.1415 - val_loss: 21.9650 - val_metrics_pearsonr: 0.1577\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 20.8995 - metrics_pearsonr: 0.1409 - val_loss: 21.8998 - val_metrics_pearsonr: 0.1571\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 20.8363 - metrics_pearsonr: 0.1404 - val_loss: 21.8346 - val_metrics_pearsonr: 0.1565\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 20.7731 - metrics_pearsonr: 0.1398 - val_loss: 21.7695 - val_metrics_pearsonr: 0.1559\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 20.7099 - metrics_pearsonr: 0.1393 - val_loss: 21.7044 - val_metrics_pearsonr: 0.1553\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 20.6467 - metrics_pearsonr: 0.1387 - val_loss: 21.6393 - val_metrics_pearsonr: 0.1546\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 20.5837 - metrics_pearsonr: 0.1382 - val_loss: 21.5742 - val_metrics_pearsonr: 0.1540\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 20.5207 - metrics_pearsonr: 0.1376 - val_loss: 21.5092 - val_metrics_pearsonr: 0.1534\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 20.4577 - metrics_pearsonr: 0.1371 - val_loss: 21.4443 - val_metrics_pearsonr: 0.1528\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 20.3948 - metrics_pearsonr: 0.1365 - val_loss: 21.3793 - val_metrics_pearsonr: 0.1522\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 20.3319 - metrics_pearsonr: 0.1360 - val_loss: 21.3144 - val_metrics_pearsonr: 0.1516\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 20.2691 - metrics_pearsonr: 0.1354 - val_loss: 21.2496 - val_metrics_pearsonr: 0.1510\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 20.2064 - metrics_pearsonr: 0.1349 - val_loss: 21.1848 - val_metrics_pearsonr: 0.1504\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 20.1438 - metrics_pearsonr: 0.1344 - val_loss: 21.1201 - val_metrics_pearsonr: 0.1498\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 20.0812 - metrics_pearsonr: 0.1338 - val_loss: 21.0554 - val_metrics_pearsonr: 0.1492\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 20.0187 - metrics_pearsonr: 0.1333 - val_loss: 20.9908 - val_metrics_pearsonr: 0.1486\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 19.9563 - metrics_pearsonr: 0.1328 - val_loss: 20.9262 - val_metrics_pearsonr: 0.1481\n",
      "Epoch 694/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 19.8939 - metrics_pearsonr: 0.1323 - val_loss: 20.8617 - val_metrics_pearsonr: 0.1475\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 19.8317 - metrics_pearsonr: 0.1317 - val_loss: 20.7973 - val_metrics_pearsonr: 0.1469\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 19.7695 - metrics_pearsonr: 0.1312 - val_loss: 20.7330 - val_metrics_pearsonr: 0.1463\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 19.7074 - metrics_pearsonr: 0.1307 - val_loss: 20.6687 - val_metrics_pearsonr: 0.1457\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 19.6454 - metrics_pearsonr: 0.1302 - val_loss: 20.6045 - val_metrics_pearsonr: 0.1452\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 19.5835 - metrics_pearsonr: 0.1297 - val_loss: 20.5404 - val_metrics_pearsonr: 0.1446\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 19.5216 - metrics_pearsonr: 0.1292 - val_loss: 20.4763 - val_metrics_pearsonr: 0.1440\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 19.4599 - metrics_pearsonr: 0.1287 - val_loss: 20.4124 - val_metrics_pearsonr: 0.1435\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 19.3983 - metrics_pearsonr: 0.1281 - val_loss: 20.3485 - val_metrics_pearsonr: 0.1429\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 19.3367 - metrics_pearsonr: 0.1276 - val_loss: 20.2848 - val_metrics_pearsonr: 0.1423\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 19.2753 - metrics_pearsonr: 0.1271 - val_loss: 20.2211 - val_metrics_pearsonr: 0.1418\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 19.2140 - metrics_pearsonr: 0.1267 - val_loss: 20.1575 - val_metrics_pearsonr: 0.1412\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 19.1527 - metrics_pearsonr: 0.1262 - val_loss: 20.0940 - val_metrics_pearsonr: 0.1407\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 19.0916 - metrics_pearsonr: 0.1257 - val_loss: 20.0306 - val_metrics_pearsonr: 0.1401\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 19.0306 - metrics_pearsonr: 0.1252 - val_loss: 19.9674 - val_metrics_pearsonr: 0.1396\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 18.9697 - metrics_pearsonr: 0.1247 - val_loss: 19.9042 - val_metrics_pearsonr: 0.1390\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 18.9090 - metrics_pearsonr: 0.1242 - val_loss: 19.8412 - val_metrics_pearsonr: 0.1385\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 18.8483 - metrics_pearsonr: 0.1237 - val_loss: 19.7782 - val_metrics_pearsonr: 0.1379\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 18.7878 - metrics_pearsonr: 0.1232 - val_loss: 19.7154 - val_metrics_pearsonr: 0.1374\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 18.7274 - metrics_pearsonr: 0.1228 - val_loss: 19.6528 - val_metrics_pearsonr: 0.1369\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 18.6671 - metrics_pearsonr: 0.1223 - val_loss: 19.5902 - val_metrics_pearsonr: 0.1363\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 18.6069 - metrics_pearsonr: 0.1218 - val_loss: 19.5278 - val_metrics_pearsonr: 0.1358\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 18.5469 - metrics_pearsonr: 0.1214 - val_loss: 19.4655 - val_metrics_pearsonr: 0.1353\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 18.4870 - metrics_pearsonr: 0.1209 - val_loss: 19.4033 - val_metrics_pearsonr: 0.1347\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 18.4272 - metrics_pearsonr: 0.1204 - val_loss: 19.3413 - val_metrics_pearsonr: 0.1342\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 18.3676 - metrics_pearsonr: 0.1200 - val_loss: 19.2794 - val_metrics_pearsonr: 0.1337\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 18.3081 - metrics_pearsonr: 0.1195 - val_loss: 19.2176 - val_metrics_pearsonr: 0.1332\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 18.2487 - metrics_pearsonr: 0.1191 - val_loss: 19.1560 - val_metrics_pearsonr: 0.1327\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 18.1895 - metrics_pearsonr: 0.1186 - val_loss: 19.0946 - val_metrics_pearsonr: 0.1322\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 18.1305 - metrics_pearsonr: 0.1182 - val_loss: 19.0333 - val_metrics_pearsonr: 0.1317\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 18.0716 - metrics_pearsonr: 0.1177 - val_loss: 18.9722 - val_metrics_pearsonr: 0.1312\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 18.0128 - metrics_pearsonr: 0.1173 - val_loss: 18.9112 - val_metrics_pearsonr: 0.1307\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 17.9542 - metrics_pearsonr: 0.1168 - val_loss: 18.8504 - val_metrics_pearsonr: 0.1302\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 17.8957 - metrics_pearsonr: 0.1164 - val_loss: 18.7897 - val_metrics_pearsonr: 0.1297\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 17.8374 - metrics_pearsonr: 0.1159 - val_loss: 18.7292 - val_metrics_pearsonr: 0.1292\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 17.7793 - metrics_pearsonr: 0.1155 - val_loss: 18.6689 - val_metrics_pearsonr: 0.1287\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 17.7213 - metrics_pearsonr: 0.1151 - val_loss: 18.6087 - val_metrics_pearsonr: 0.1282\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 17.6635 - metrics_pearsonr: 0.1146 - val_loss: 18.5487 - val_metrics_pearsonr: 0.1277\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 17.6058 - metrics_pearsonr: 0.1142 - val_loss: 18.4889 - val_metrics_pearsonr: 0.1272\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 17.5483 - metrics_pearsonr: 0.1138 - val_loss: 18.4293 - val_metrics_pearsonr: 0.1268\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 17.4910 - metrics_pearsonr: 0.1134 - val_loss: 18.3698 - val_metrics_pearsonr: 0.1263\n",
      "Epoch 735/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 17.4338 - metrics_pearsonr: 0.1130 - val_loss: 18.3105 - val_metrics_pearsonr: 0.1258\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 17.3768 - metrics_pearsonr: 0.1125 - val_loss: 18.2514 - val_metrics_pearsonr: 0.1253\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 17.3200 - metrics_pearsonr: 0.1121 - val_loss: 18.1925 - val_metrics_pearsonr: 0.1249\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 17.2633 - metrics_pearsonr: 0.1117 - val_loss: 18.1338 - val_metrics_pearsonr: 0.1244\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 17.2069 - metrics_pearsonr: 0.1113 - val_loss: 18.0753 - val_metrics_pearsonr: 0.1240\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 17.1506 - metrics_pearsonr: 0.1109 - val_loss: 18.0169 - val_metrics_pearsonr: 0.1235\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 17.0944 - metrics_pearsonr: 0.1105 - val_loss: 17.9587 - val_metrics_pearsonr: 0.1230\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 17.0385 - metrics_pearsonr: 0.1101 - val_loss: 17.9008 - val_metrics_pearsonr: 0.1226\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 16.9827 - metrics_pearsonr: 0.1097 - val_loss: 17.8430 - val_metrics_pearsonr: 0.1221\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 16.9272 - metrics_pearsonr: 0.1093 - val_loss: 17.7854 - val_metrics_pearsonr: 0.1217\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 16.8718 - metrics_pearsonr: 0.1089 - val_loss: 17.7280 - val_metrics_pearsonr: 0.1213\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 16.8166 - metrics_pearsonr: 0.1085 - val_loss: 17.6708 - val_metrics_pearsonr: 0.1208\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 16.7615 - metrics_pearsonr: 0.1081 - val_loss: 17.6138 - val_metrics_pearsonr: 0.1204\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 16.7067 - metrics_pearsonr: 0.1077 - val_loss: 17.5570 - val_metrics_pearsonr: 0.1199\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 16.6521 - metrics_pearsonr: 0.1073 - val_loss: 17.5004 - val_metrics_pearsonr: 0.1195\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 16.5976 - metrics_pearsonr: 0.1070 - val_loss: 17.4440 - val_metrics_pearsonr: 0.1191\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 16.5433 - metrics_pearsonr: 0.1066 - val_loss: 17.3878 - val_metrics_pearsonr: 0.1186\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 16.4892 - metrics_pearsonr: 0.1062 - val_loss: 17.3318 - val_metrics_pearsonr: 0.1182\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 16.4353 - metrics_pearsonr: 0.1058 - val_loss: 17.2760 - val_metrics_pearsonr: 0.1178\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 16.3816 - metrics_pearsonr: 0.1055 - val_loss: 17.2204 - val_metrics_pearsonr: 0.1174\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 16.3281 - metrics_pearsonr: 0.1051 - val_loss: 17.1650 - val_metrics_pearsonr: 0.1170\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 16.2748 - metrics_pearsonr: 0.1047 - val_loss: 17.1098 - val_metrics_pearsonr: 0.1165\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 16.2217 - metrics_pearsonr: 0.1043 - val_loss: 17.0548 - val_metrics_pearsonr: 0.1161\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 16.1688 - metrics_pearsonr: 0.1040 - val_loss: 17.0000 - val_metrics_pearsonr: 0.1157\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 16.1160 - metrics_pearsonr: 0.1036 - val_loss: 16.9454 - val_metrics_pearsonr: 0.1153\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 16.0635 - metrics_pearsonr: 0.1033 - val_loss: 16.8911 - val_metrics_pearsonr: 0.1149\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 16.0112 - metrics_pearsonr: 0.1029 - val_loss: 16.8369 - val_metrics_pearsonr: 0.1145\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 15.9590 - metrics_pearsonr: 0.1025 - val_loss: 16.7829 - val_metrics_pearsonr: 0.1141\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 15.9071 - metrics_pearsonr: 0.1022 - val_loss: 16.7292 - val_metrics_pearsonr: 0.1137\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 15.8553 - metrics_pearsonr: 0.1018 - val_loss: 16.6757 - val_metrics_pearsonr: 0.1133\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 15.8038 - metrics_pearsonr: 0.1015 - val_loss: 16.6223 - val_metrics_pearsonr: 0.1129\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 15.7525 - metrics_pearsonr: 0.1011 - val_loss: 16.5692 - val_metrics_pearsonr: 0.1125\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 15.7013 - metrics_pearsonr: 0.1008 - val_loss: 16.5163 - val_metrics_pearsonr: 0.1122\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 15.6504 - metrics_pearsonr: 0.1005 - val_loss: 16.4636 - val_metrics_pearsonr: 0.1118\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 15.5996 - metrics_pearsonr: 0.1001 - val_loss: 16.4111 - val_metrics_pearsonr: 0.1114\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 15.5491 - metrics_pearsonr: 0.0998 - val_loss: 16.3588 - val_metrics_pearsonr: 0.1110\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 15.4987 - metrics_pearsonr: 0.0994 - val_loss: 16.3067 - val_metrics_pearsonr: 0.1106\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 15.4485 - metrics_pearsonr: 0.0991 - val_loss: 16.2549 - val_metrics_pearsonr: 0.1102\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 15.3986 - metrics_pearsonr: 0.0988 - val_loss: 16.2032 - val_metrics_pearsonr: 0.1099\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 15.3488 - metrics_pearsonr: 0.0984 - val_loss: 16.1517 - val_metrics_pearsonr: 0.1095\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 15.2993 - metrics_pearsonr: 0.0981 - val_loss: 16.1005 - val_metrics_pearsonr: 0.1091\n",
      "Epoch 776/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 15.2499 - metrics_pearsonr: 0.0978 - val_loss: 16.0495 - val_metrics_pearsonr: 0.1088\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 15.2008 - metrics_pearsonr: 0.0975 - val_loss: 15.9986 - val_metrics_pearsonr: 0.1084\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 15.1518 - metrics_pearsonr: 0.0971 - val_loss: 15.9480 - val_metrics_pearsonr: 0.1080\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 15.1030 - metrics_pearsonr: 0.0968 - val_loss: 15.8976 - val_metrics_pearsonr: 0.1077\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 15.0545 - metrics_pearsonr: 0.0965 - val_loss: 15.8474 - val_metrics_pearsonr: 0.1073\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 15.0061 - metrics_pearsonr: 0.0962 - val_loss: 15.7974 - val_metrics_pearsonr: 0.1070\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 14.9580 - metrics_pearsonr: 0.0959 - val_loss: 15.7476 - val_metrics_pearsonr: 0.1066\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 14.9100 - metrics_pearsonr: 0.0956 - val_loss: 15.6980 - val_metrics_pearsonr: 0.1063\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 14.8622 - metrics_pearsonr: 0.0952 - val_loss: 15.6487 - val_metrics_pearsonr: 0.1059\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 14.8146 - metrics_pearsonr: 0.0949 - val_loss: 15.5995 - val_metrics_pearsonr: 0.1056\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 14.7673 - metrics_pearsonr: 0.0946 - val_loss: 15.5505 - val_metrics_pearsonr: 0.1052\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 14.7201 - metrics_pearsonr: 0.0943 - val_loss: 15.5018 - val_metrics_pearsonr: 0.1049\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 14.6731 - metrics_pearsonr: 0.0940 - val_loss: 15.4532 - val_metrics_pearsonr: 0.1045\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 14.6263 - metrics_pearsonr: 0.0937 - val_loss: 15.4049 - val_metrics_pearsonr: 0.1042\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 14.5797 - metrics_pearsonr: 0.0934 - val_loss: 15.3567 - val_metrics_pearsonr: 0.1039\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 14.5333 - metrics_pearsonr: 0.0931 - val_loss: 15.3088 - val_metrics_pearsonr: 0.1035\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 14.4871 - metrics_pearsonr: 0.0928 - val_loss: 15.2611 - val_metrics_pearsonr: 0.1032\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 14.4411 - metrics_pearsonr: 0.0925 - val_loss: 15.2135 - val_metrics_pearsonr: 0.1029\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 14.3953 - metrics_pearsonr: 0.0922 - val_loss: 15.1662 - val_metrics_pearsonr: 0.1025\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 14.3497 - metrics_pearsonr: 0.0919 - val_loss: 15.1191 - val_metrics_pearsonr: 0.1022\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 14.3043 - metrics_pearsonr: 0.0917 - val_loss: 15.0721 - val_metrics_pearsonr: 0.1019\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 14.2590 - metrics_pearsonr: 0.0914 - val_loss: 15.0254 - val_metrics_pearsonr: 0.1016\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 14.2140 - metrics_pearsonr: 0.0911 - val_loss: 14.9789 - val_metrics_pearsonr: 0.1012\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 14.1692 - metrics_pearsonr: 0.0908 - val_loss: 14.9326 - val_metrics_pearsonr: 0.1009\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 14.1245 - metrics_pearsonr: 0.0905 - val_loss: 14.8864 - val_metrics_pearsonr: 0.1006\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 14.0800 - metrics_pearsonr: 0.0902 - val_loss: 14.8405 - val_metrics_pearsonr: 0.1003\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 14.0358 - metrics_pearsonr: 0.0899 - val_loss: 14.7948 - val_metrics_pearsonr: 0.1000\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 13.9917 - metrics_pearsonr: 0.0897 - val_loss: 14.7492 - val_metrics_pearsonr: 0.0996\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 13.9478 - metrics_pearsonr: 0.0894 - val_loss: 14.7039 - val_metrics_pearsonr: 0.0993\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.9041 - metrics_pearsonr: 0.0891 - val_loss: 14.6588 - val_metrics_pearsonr: 0.0990\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 13.8606 - metrics_pearsonr: 0.0888 - val_loss: 14.6138 - val_metrics_pearsonr: 0.0987\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.8172 - metrics_pearsonr: 0.0886 - val_loss: 14.5691 - val_metrics_pearsonr: 0.0984\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.7741 - metrics_pearsonr: 0.0883 - val_loss: 14.5245 - val_metrics_pearsonr: 0.0981\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 13.7311 - metrics_pearsonr: 0.0880 - val_loss: 14.4802 - val_metrics_pearsonr: 0.0978\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.6884 - metrics_pearsonr: 0.0878 - val_loss: 14.4360 - val_metrics_pearsonr: 0.0975\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 13.6458 - metrics_pearsonr: 0.0875 - val_loss: 14.3921 - val_metrics_pearsonr: 0.0972\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 13.6034 - metrics_pearsonr: 0.0872 - val_loss: 14.3483 - val_metrics_pearsonr: 0.0969\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 13.5612 - metrics_pearsonr: 0.0870 - val_loss: 14.3047 - val_metrics_pearsonr: 0.0966\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 13.5192 - metrics_pearsonr: 0.0867 - val_loss: 14.2614 - val_metrics_pearsonr: 0.0963\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 13.4774 - metrics_pearsonr: 0.0864 - val_loss: 14.2182 - val_metrics_pearsonr: 0.0960\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 13.4357 - metrics_pearsonr: 0.0862 - val_loss: 14.1752 - val_metrics_pearsonr: 0.0957\n",
      "Epoch 817/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 13.3943 - metrics_pearsonr: 0.0859 - val_loss: 14.1324 - val_metrics_pearsonr: 0.0954\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 13.3530 - metrics_pearsonr: 0.0857 - val_loss: 14.0898 - val_metrics_pearsonr: 0.0952\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.3119 - metrics_pearsonr: 0.0854 - val_loss: 14.0474 - val_metrics_pearsonr: 0.0949\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 13.2710 - metrics_pearsonr: 0.0852 - val_loss: 14.0052 - val_metrics_pearsonr: 0.0946\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 13.2303 - metrics_pearsonr: 0.0849 - val_loss: 13.9631 - val_metrics_pearsonr: 0.0943\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 13.1898 - metrics_pearsonr: 0.0847 - val_loss: 13.9213 - val_metrics_pearsonr: 0.0940\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 13.1494 - metrics_pearsonr: 0.0844 - val_loss: 13.8797 - val_metrics_pearsonr: 0.0937\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 13.1093 - metrics_pearsonr: 0.0842 - val_loss: 13.8382 - val_metrics_pearsonr: 0.0935\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 13.0693 - metrics_pearsonr: 0.0839 - val_loss: 13.7969 - val_metrics_pearsonr: 0.0932\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 13.0295 - metrics_pearsonr: 0.0837 - val_loss: 13.7559 - val_metrics_pearsonr: 0.0929\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 12.9899 - metrics_pearsonr: 0.0834 - val_loss: 13.7150 - val_metrics_pearsonr: 0.0926\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 12.9504 - metrics_pearsonr: 0.0832 - val_loss: 13.6743 - val_metrics_pearsonr: 0.0924\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 12.9112 - metrics_pearsonr: 0.0829 - val_loss: 13.6338 - val_metrics_pearsonr: 0.0921\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 12.8721 - metrics_pearsonr: 0.0827 - val_loss: 13.5934 - val_metrics_pearsonr: 0.0918\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 12.8332 - metrics_pearsonr: 0.0825 - val_loss: 13.5533 - val_metrics_pearsonr: 0.0916\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 12.7945 - metrics_pearsonr: 0.0822 - val_loss: 13.5134 - val_metrics_pearsonr: 0.0913\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 12.7560 - metrics_pearsonr: 0.0820 - val_loss: 13.4736 - val_metrics_pearsonr: 0.0910\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 12.7176 - metrics_pearsonr: 0.0817 - val_loss: 13.4340 - val_metrics_pearsonr: 0.0908\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 12.6795 - metrics_pearsonr: 0.0815 - val_loss: 13.3947 - val_metrics_pearsonr: 0.0905\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 12.6415 - metrics_pearsonr: 0.0813 - val_loss: 13.3555 - val_metrics_pearsonr: 0.0902\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 12.6037 - metrics_pearsonr: 0.0810 - val_loss: 13.3165 - val_metrics_pearsonr: 0.0900\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 12.5661 - metrics_pearsonr: 0.0808 - val_loss: 13.2776 - val_metrics_pearsonr: 0.0897\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 12.5286 - metrics_pearsonr: 0.0806 - val_loss: 13.2390 - val_metrics_pearsonr: 0.0895\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 12.4914 - metrics_pearsonr: 0.0804 - val_loss: 13.2005 - val_metrics_pearsonr: 0.0892\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 12.4543 - metrics_pearsonr: 0.0801 - val_loss: 13.1623 - val_metrics_pearsonr: 0.0890\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 12.4174 - metrics_pearsonr: 0.0799 - val_loss: 13.1242 - val_metrics_pearsonr: 0.0887\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 12.3807 - metrics_pearsonr: 0.0797 - val_loss: 13.0863 - val_metrics_pearsonr: 0.0885\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 12.3441 - metrics_pearsonr: 0.0795 - val_loss: 13.0486 - val_metrics_pearsonr: 0.0882\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 12.3077 - metrics_pearsonr: 0.0792 - val_loss: 13.0110 - val_metrics_pearsonr: 0.0880\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 12.2715 - metrics_pearsonr: 0.0790 - val_loss: 12.9737 - val_metrics_pearsonr: 0.0877\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 12.2355 - metrics_pearsonr: 0.0788 - val_loss: 12.9365 - val_metrics_pearsonr: 0.0875\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 12.1997 - metrics_pearsonr: 0.0786 - val_loss: 12.8995 - val_metrics_pearsonr: 0.0872\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 12.1640 - metrics_pearsonr: 0.0784 - val_loss: 12.8627 - val_metrics_pearsonr: 0.0870\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 12.1285 - metrics_pearsonr: 0.0781 - val_loss: 12.8261 - val_metrics_pearsonr: 0.0867\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 12.0932 - metrics_pearsonr: 0.0779 - val_loss: 12.7897 - val_metrics_pearsonr: 0.0865\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 12.0581 - metrics_pearsonr: 0.0777 - val_loss: 12.7534 - val_metrics_pearsonr: 0.0863\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 12.0231 - metrics_pearsonr: 0.0775 - val_loss: 12.7173 - val_metrics_pearsonr: 0.0860\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 11.9884 - metrics_pearsonr: 0.0773 - val_loss: 12.6814 - val_metrics_pearsonr: 0.0858\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 11.9538 - metrics_pearsonr: 0.0771 - val_loss: 12.6457 - val_metrics_pearsonr: 0.0856\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 11.9193 - metrics_pearsonr: 0.0769 - val_loss: 12.6102 - val_metrics_pearsonr: 0.0853\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 11.8851 - metrics_pearsonr: 0.0767 - val_loss: 12.5748 - val_metrics_pearsonr: 0.0851\n",
      "Epoch 858/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 11.8510 - metrics_pearsonr: 0.0765 - val_loss: 12.5396 - val_metrics_pearsonr: 0.0849\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 11.8171 - metrics_pearsonr: 0.0763 - val_loss: 12.5046 - val_metrics_pearsonr: 0.0846\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 11.7833 - metrics_pearsonr: 0.0761 - val_loss: 12.4698 - val_metrics_pearsonr: 0.0844\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 11.7497 - metrics_pearsonr: 0.0759 - val_loss: 12.4351 - val_metrics_pearsonr: 0.0842\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 11.7163 - metrics_pearsonr: 0.0757 - val_loss: 12.4007 - val_metrics_pearsonr: 0.0840\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 11.6831 - metrics_pearsonr: 0.0755 - val_loss: 12.3664 - val_metrics_pearsonr: 0.0837\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 11.6501 - metrics_pearsonr: 0.0753 - val_loss: 12.3322 - val_metrics_pearsonr: 0.0835\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 11.6172 - metrics_pearsonr: 0.0751 - val_loss: 12.2983 - val_metrics_pearsonr: 0.0833\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 11.5845 - metrics_pearsonr: 0.0749 - val_loss: 12.2645 - val_metrics_pearsonr: 0.0831\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 11.5519 - metrics_pearsonr: 0.0747 - val_loss: 12.2309 - val_metrics_pearsonr: 0.0829\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 11.5195 - metrics_pearsonr: 0.0745 - val_loss: 12.1975 - val_metrics_pearsonr: 0.0826\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 11.4873 - metrics_pearsonr: 0.0743 - val_loss: 12.1642 - val_metrics_pearsonr: 0.0824\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 11.4553 - metrics_pearsonr: 0.0741 - val_loss: 12.1311 - val_metrics_pearsonr: 0.0822\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 11.4234 - metrics_pearsonr: 0.0739 - val_loss: 12.0982 - val_metrics_pearsonr: 0.0820\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 11.3917 - metrics_pearsonr: 0.0737 - val_loss: 12.0655 - val_metrics_pearsonr: 0.0818\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 11.3601 - metrics_pearsonr: 0.0735 - val_loss: 12.0329 - val_metrics_pearsonr: 0.0816\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 11.3288 - metrics_pearsonr: 0.0733 - val_loss: 12.0005 - val_metrics_pearsonr: 0.0814\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 11.2975 - metrics_pearsonr: 0.0731 - val_loss: 11.9682 - val_metrics_pearsonr: 0.0811\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 11.2665 - metrics_pearsonr: 0.0729 - val_loss: 11.9362 - val_metrics_pearsonr: 0.0809\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 11.2356 - metrics_pearsonr: 0.0728 - val_loss: 11.9043 - val_metrics_pearsonr: 0.0807\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 11.2049 - metrics_pearsonr: 0.0726 - val_loss: 11.8725 - val_metrics_pearsonr: 0.0805\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 11.1743 - metrics_pearsonr: 0.0724 - val_loss: 11.8410 - val_metrics_pearsonr: 0.0803\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 11.1439 - metrics_pearsonr: 0.0722 - val_loss: 11.8096 - val_metrics_pearsonr: 0.0801\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 11.1137 - metrics_pearsonr: 0.0720 - val_loss: 11.7783 - val_metrics_pearsonr: 0.0799\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 11.0836 - metrics_pearsonr: 0.0718 - val_loss: 11.7473 - val_metrics_pearsonr: 0.0797\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 11.0537 - metrics_pearsonr: 0.0717 - val_loss: 11.7163 - val_metrics_pearsonr: 0.0795\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 11.0239 - metrics_pearsonr: 0.0715 - val_loss: 11.6856 - val_metrics_pearsonr: 0.0793\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 10.9943 - metrics_pearsonr: 0.0713 - val_loss: 11.6550 - val_metrics_pearsonr: 0.0791\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 10.9649 - metrics_pearsonr: 0.0711 - val_loss: 11.6246 - val_metrics_pearsonr: 0.0789\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 10.9356 - metrics_pearsonr: 0.0710 - val_loss: 11.5943 - val_metrics_pearsonr: 0.0787\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 10.9064 - metrics_pearsonr: 0.0708 - val_loss: 11.5642 - val_metrics_pearsonr: 0.0785\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 10.8774 - metrics_pearsonr: 0.0706 - val_loss: 11.5342 - val_metrics_pearsonr: 0.0783\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 10.8486 - metrics_pearsonr: 0.0704 - val_loss: 11.5045 - val_metrics_pearsonr: 0.0781\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 10.8199 - metrics_pearsonr: 0.0703 - val_loss: 11.4748 - val_metrics_pearsonr: 0.0780\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 10.7914 - metrics_pearsonr: 0.0701 - val_loss: 11.4453 - val_metrics_pearsonr: 0.0778\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 10.7631 - metrics_pearsonr: 0.0699 - val_loss: 11.4160 - val_metrics_pearsonr: 0.0776\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 10.7348 - metrics_pearsonr: 0.0698 - val_loss: 11.3868 - val_metrics_pearsonr: 0.0774\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 10.7068 - metrics_pearsonr: 0.0696 - val_loss: 11.3578 - val_metrics_pearsonr: 0.0772\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 10.6789 - metrics_pearsonr: 0.0694 - val_loss: 11.3290 - val_metrics_pearsonr: 0.0770\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 10.6511 - metrics_pearsonr: 0.0693 - val_loss: 11.3002 - val_metrics_pearsonr: 0.0768\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 10.6235 - metrics_pearsonr: 0.0691 - val_loss: 11.2717 - val_metrics_pearsonr: 0.0767\n",
      "Epoch 899/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 10.5960 - metrics_pearsonr: 0.0689 - val_loss: 11.2433 - val_metrics_pearsonr: 0.0765\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 10.5687 - metrics_pearsonr: 0.0688 - val_loss: 11.2150 - val_metrics_pearsonr: 0.0763\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 10.5415 - metrics_pearsonr: 0.0686 - val_loss: 11.1869 - val_metrics_pearsonr: 0.0761\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 10.5144 - metrics_pearsonr: 0.0684 - val_loss: 11.1589 - val_metrics_pearsonr: 0.0759\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 10.4876 - metrics_pearsonr: 0.0683 - val_loss: 11.1311 - val_metrics_pearsonr: 0.0758\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 10.4608 - metrics_pearsonr: 0.0681 - val_loss: 11.1034 - val_metrics_pearsonr: 0.0756\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 10.4342 - metrics_pearsonr: 0.0680 - val_loss: 11.0759 - val_metrics_pearsonr: 0.0754\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 10.4077 - metrics_pearsonr: 0.0678 - val_loss: 11.0485 - val_metrics_pearsonr: 0.0752\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 10.3814 - metrics_pearsonr: 0.0677 - val_loss: 11.0212 - val_metrics_pearsonr: 0.0751\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 10.3552 - metrics_pearsonr: 0.0675 - val_loss: 10.9941 - val_metrics_pearsonr: 0.0749\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 10.3292 - metrics_pearsonr: 0.0673 - val_loss: 10.9672 - val_metrics_pearsonr: 0.0747\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 10.3033 - metrics_pearsonr: 0.0672 - val_loss: 10.9403 - val_metrics_pearsonr: 0.0745\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 10.2775 - metrics_pearsonr: 0.0670 - val_loss: 10.9137 - val_metrics_pearsonr: 0.0744\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 10.2519 - metrics_pearsonr: 0.0669 - val_loss: 10.8871 - val_metrics_pearsonr: 0.0742\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 10.2264 - metrics_pearsonr: 0.0667 - val_loss: 10.8607 - val_metrics_pearsonr: 0.0740\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 10.2010 - metrics_pearsonr: 0.0666 - val_loss: 10.8344 - val_metrics_pearsonr: 0.0739\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 10.1758 - metrics_pearsonr: 0.0664 - val_loss: 10.8083 - val_metrics_pearsonr: 0.0737\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 10.1507 - metrics_pearsonr: 0.0663 - val_loss: 10.7823 - val_metrics_pearsonr: 0.0735\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 10.1258 - metrics_pearsonr: 0.0661 - val_loss: 10.7564 - val_metrics_pearsonr: 0.0734\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 10.1009 - metrics_pearsonr: 0.0660 - val_loss: 10.7307 - val_metrics_pearsonr: 0.0732\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 10.0762 - metrics_pearsonr: 0.0659 - val_loss: 10.7051 - val_metrics_pearsonr: 0.0731\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 10.0517 - metrics_pearsonr: 0.0657 - val_loss: 10.6796 - val_metrics_pearsonr: 0.0729\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 10.0272 - metrics_pearsonr: 0.0656 - val_loss: 10.6543 - val_metrics_pearsonr: 0.0727\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 10.0029 - metrics_pearsonr: 0.0654 - val_loss: 10.6291 - val_metrics_pearsonr: 0.0726\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 9.9788 - metrics_pearsonr: 0.0653 - val_loss: 10.6040 - val_metrics_pearsonr: 0.0724\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 9.9547 - metrics_pearsonr: 0.0651 - val_loss: 10.5790 - val_metrics_pearsonr: 0.0723\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 9.9308 - metrics_pearsonr: 0.0650 - val_loss: 10.5542 - val_metrics_pearsonr: 0.0721\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 9.9070 - metrics_pearsonr: 0.0649 - val_loss: 10.5295 - val_metrics_pearsonr: 0.0719\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 9.8833 - metrics_pearsonr: 0.0647 - val_loss: 10.5049 - val_metrics_pearsonr: 0.0718\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 9.8598 - metrics_pearsonr: 0.0646 - val_loss: 10.4805 - val_metrics_pearsonr: 0.0716\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 9.8363 - metrics_pearsonr: 0.0644 - val_loss: 10.4562 - val_metrics_pearsonr: 0.0715\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 9.8130 - metrics_pearsonr: 0.0643 - val_loss: 10.4320 - val_metrics_pearsonr: 0.0713\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 9.7899 - metrics_pearsonr: 0.0642 - val_loss: 10.4079 - val_metrics_pearsonr: 0.0712\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 9.7668 - metrics_pearsonr: 0.0640 - val_loss: 10.3839 - val_metrics_pearsonr: 0.0710\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 9.7439 - metrics_pearsonr: 0.0639 - val_loss: 10.3601 - val_metrics_pearsonr: 0.0709\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 9.7210 - metrics_pearsonr: 0.0638 - val_loss: 10.3363 - val_metrics_pearsonr: 0.0707\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 9.6983 - metrics_pearsonr: 0.0636 - val_loss: 10.3127 - val_metrics_pearsonr: 0.0706\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 9.6757 - metrics_pearsonr: 0.0635 - val_loss: 10.2893 - val_metrics_pearsonr: 0.0704\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 9.6533 - metrics_pearsonr: 0.0634 - val_loss: 10.2659 - val_metrics_pearsonr: 0.0703\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 9.6309 - metrics_pearsonr: 0.0632 - val_loss: 10.2426 - val_metrics_pearsonr: 0.0701\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 9.6087 - metrics_pearsonr: 0.0631 - val_loss: 10.2195 - val_metrics_pearsonr: 0.0700\n",
      "Epoch 940/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 9.5866 - metrics_pearsonr: 0.0630 - val_loss: 10.1965 - val_metrics_pearsonr: 0.0699\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 9.5646 - metrics_pearsonr: 0.0628 - val_loss: 10.1736 - val_metrics_pearsonr: 0.0697\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 9.5427 - metrics_pearsonr: 0.0627 - val_loss: 10.1508 - val_metrics_pearsonr: 0.0696\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 9.5209 - metrics_pearsonr: 0.0626 - val_loss: 10.1281 - val_metrics_pearsonr: 0.0694\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 9.4992 - metrics_pearsonr: 0.0625 - val_loss: 10.1055 - val_metrics_pearsonr: 0.0693\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 9.4777 - metrics_pearsonr: 0.0623 - val_loss: 10.0831 - val_metrics_pearsonr: 0.0691\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 9.4562 - metrics_pearsonr: 0.0622 - val_loss: 10.0607 - val_metrics_pearsonr: 0.0690\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 9.4349 - metrics_pearsonr: 0.0621 - val_loss: 10.0385 - val_metrics_pearsonr: 0.0689\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 9.4136 - metrics_pearsonr: 0.0620 - val_loss: 10.0164 - val_metrics_pearsonr: 0.0687\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 9.3925 - metrics_pearsonr: 0.0618 - val_loss: 9.9943 - val_metrics_pearsonr: 0.0686\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 9.3715 - metrics_pearsonr: 0.0617 - val_loss: 9.9724 - val_metrics_pearsonr: 0.0684\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 9.3506 - metrics_pearsonr: 0.0616 - val_loss: 9.9506 - val_metrics_pearsonr: 0.0683\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 9.3298 - metrics_pearsonr: 0.0615 - val_loss: 9.9289 - val_metrics_pearsonr: 0.0682\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 9.3091 - metrics_pearsonr: 0.0613 - val_loss: 9.9073 - val_metrics_pearsonr: 0.0680\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 9.2885 - metrics_pearsonr: 0.0612 - val_loss: 9.8858 - val_metrics_pearsonr: 0.0679\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 9.2680 - metrics_pearsonr: 0.0611 - val_loss: 9.8644 - val_metrics_pearsonr: 0.0678\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 9.2476 - metrics_pearsonr: 0.0610 - val_loss: 9.8431 - val_metrics_pearsonr: 0.0676\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 9.2273 - metrics_pearsonr: 0.0609 - val_loss: 9.8219 - val_metrics_pearsonr: 0.0675\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 9.2071 - metrics_pearsonr: 0.0607 - val_loss: 9.8008 - val_metrics_pearsonr: 0.0674\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 9.1871 - metrics_pearsonr: 0.0606 - val_loss: 9.7798 - val_metrics_pearsonr: 0.0672\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 9.1671 - metrics_pearsonr: 0.0605 - val_loss: 9.7589 - val_metrics_pearsonr: 0.0671\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 9.1472 - metrics_pearsonr: 0.0604 - val_loss: 9.7381 - val_metrics_pearsonr: 0.0670\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 9.1274 - metrics_pearsonr: 0.0603 - val_loss: 9.7175 - val_metrics_pearsonr: 0.0669\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 9.1077 - metrics_pearsonr: 0.0602 - val_loss: 9.6969 - val_metrics_pearsonr: 0.0667\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 9.0881 - metrics_pearsonr: 0.0601 - val_loss: 9.6764 - val_metrics_pearsonr: 0.0666\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 9.0686 - metrics_pearsonr: 0.0599 - val_loss: 9.6560 - val_metrics_pearsonr: 0.0665\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 9.0492 - metrics_pearsonr: 0.0598 - val_loss: 9.6357 - val_metrics_pearsonr: 0.0663\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 9.0299 - metrics_pearsonr: 0.0597 - val_loss: 9.6154 - val_metrics_pearsonr: 0.0662\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 9.0107 - metrics_pearsonr: 0.0596 - val_loss: 9.5953 - val_metrics_pearsonr: 0.0661\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 8.9916 - metrics_pearsonr: 0.0595 - val_loss: 9.5753 - val_metrics_pearsonr: 0.0660\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 8.9726 - metrics_pearsonr: 0.0594 - val_loss: 9.5554 - val_metrics_pearsonr: 0.0658\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 8.9536 - metrics_pearsonr: 0.0593 - val_loss: 9.5355 - val_metrics_pearsonr: 0.0657\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 8.9348 - metrics_pearsonr: 0.0592 - val_loss: 9.5158 - val_metrics_pearsonr: 0.0656\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.9160 - metrics_pearsonr: 0.0590 - val_loss: 9.4961 - val_metrics_pearsonr: 0.0655\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.8974 - metrics_pearsonr: 0.0589 - val_loss: 9.4765 - val_metrics_pearsonr: 0.0654\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.8788 - metrics_pearsonr: 0.0588 - val_loss: 9.4570 - val_metrics_pearsonr: 0.0652\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8.8603 - metrics_pearsonr: 0.0587 - val_loss: 9.4376 - val_metrics_pearsonr: 0.0651\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.8419 - metrics_pearsonr: 0.0586 - val_loss: 9.4183 - val_metrics_pearsonr: 0.0650\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 8.8236 - metrics_pearsonr: 0.0585 - val_loss: 9.3991 - val_metrics_pearsonr: 0.0649\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8.8054 - metrics_pearsonr: 0.0584 - val_loss: 9.3800 - val_metrics_pearsonr: 0.0648\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 8.7873 - metrics_pearsonr: 0.0583 - val_loss: 9.3609 - val_metrics_pearsonr: 0.0646\n",
      "Epoch 981/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 8.7692 - metrics_pearsonr: 0.0582 - val_loss: 9.3420 - val_metrics_pearsonr: 0.0645\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8.7513 - metrics_pearsonr: 0.0581 - val_loss: 9.3231 - val_metrics_pearsonr: 0.0644\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8.7334 - metrics_pearsonr: 0.0580 - val_loss: 9.3043 - val_metrics_pearsonr: 0.0643\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 8.7156 - metrics_pearsonr: 0.0579 - val_loss: 9.2856 - val_metrics_pearsonr: 0.0642\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8.6979 - metrics_pearsonr: 0.0578 - val_loss: 9.2670 - val_metrics_pearsonr: 0.0641\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 8.6803 - metrics_pearsonr: 0.0577 - val_loss: 9.2484 - val_metrics_pearsonr: 0.0639\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 8.6627 - metrics_pearsonr: 0.0576 - val_loss: 9.2300 - val_metrics_pearsonr: 0.0638\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 8.6452 - metrics_pearsonr: 0.0575 - val_loss: 9.2116 - val_metrics_pearsonr: 0.0637\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 8.6279 - metrics_pearsonr: 0.0574 - val_loss: 9.1933 - val_metrics_pearsonr: 0.0636\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 8.6105 - metrics_pearsonr: 0.0573 - val_loss: 9.1750 - val_metrics_pearsonr: 0.0635\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8.5933 - metrics_pearsonr: 0.0571 - val_loss: 9.1569 - val_metrics_pearsonr: 0.0634\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.5762 - metrics_pearsonr: 0.0570 - val_loss: 9.1388 - val_metrics_pearsonr: 0.0633\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 8.5591 - metrics_pearsonr: 0.0569 - val_loss: 9.1208 - val_metrics_pearsonr: 0.0631\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 8.5421 - metrics_pearsonr: 0.0568 - val_loss: 9.1029 - val_metrics_pearsonr: 0.0630\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8.5252 - metrics_pearsonr: 0.0567 - val_loss: 9.0851 - val_metrics_pearsonr: 0.0629\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 8.5084 - metrics_pearsonr: 0.0566 - val_loss: 9.0673 - val_metrics_pearsonr: 0.0628\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 8.4916 - metrics_pearsonr: 0.0566 - val_loss: 9.0496 - val_metrics_pearsonr: 0.0627\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 8.4749 - metrics_pearsonr: 0.0565 - val_loss: 9.0320 - val_metrics_pearsonr: 0.0626\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.4583 - metrics_pearsonr: 0.0564 - val_loss: 9.0145 - val_metrics_pearsonr: 0.0625\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 8.4418 - metrics_pearsonr: 0.0563 - val_loss: 8.9970 - val_metrics_pearsonr: 0.0624\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.4253 - metrics_pearsonr: 0.0562 - val_loss: 8.9797 - val_metrics_pearsonr: 0.0623\n",
      "Epoch 1002/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 8.4089 - metrics_pearsonr: 0.0561 - val_loss: 8.9623 - val_metrics_pearsonr: 0.0622\n",
      "Epoch 1003/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 8.3926 - metrics_pearsonr: 0.0560 - val_loss: 8.9451 - val_metrics_pearsonr: 0.0620\n",
      "Epoch 1004/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.3763 - metrics_pearsonr: 0.0559 - val_loss: 8.9279 - val_metrics_pearsonr: 0.0619\n",
      "Epoch 1005/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 8.3602 - metrics_pearsonr: 0.0558 - val_loss: 8.9108 - val_metrics_pearsonr: 0.0618\n",
      "Epoch 1006/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 8.3440 - metrics_pearsonr: 0.0557 - val_loss: 8.8938 - val_metrics_pearsonr: 0.0617\n",
      "Epoch 1007/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 8.3280 - metrics_pearsonr: 0.0556 - val_loss: 8.8768 - val_metrics_pearsonr: 0.0616\n",
      "Epoch 1008/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8.3120 - metrics_pearsonr: 0.0555 - val_loss: 8.8600 - val_metrics_pearsonr: 0.0615\n",
      "Epoch 1009/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8.2961 - metrics_pearsonr: 0.0554 - val_loss: 8.8431 - val_metrics_pearsonr: 0.0614\n",
      "Epoch 1010/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 8.2803 - metrics_pearsonr: 0.0553 - val_loss: 8.8264 - val_metrics_pearsonr: 0.0613\n",
      "Epoch 1011/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 8.2646 - metrics_pearsonr: 0.0552 - val_loss: 8.8097 - val_metrics_pearsonr: 0.0612\n",
      "Epoch 1012/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 8.2489 - metrics_pearsonr: 0.0551 - val_loss: 8.7931 - val_metrics_pearsonr: 0.0611\n",
      "Epoch 1013/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 8.2332 - metrics_pearsonr: 0.0550 - val_loss: 8.7765 - val_metrics_pearsonr: 0.0610\n",
      "Epoch 1014/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 8.2177 - metrics_pearsonr: 0.0549 - val_loss: 8.7601 - val_metrics_pearsonr: 0.0609\n",
      "Epoch 1015/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 8.2022 - metrics_pearsonr: 0.0548 - val_loss: 8.7436 - val_metrics_pearsonr: 0.0608\n",
      "Epoch 1016/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 8.1868 - metrics_pearsonr: 0.0547 - val_loss: 8.7273 - val_metrics_pearsonr: 0.0607\n",
      "Epoch 1017/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 8.1714 - metrics_pearsonr: 0.0547 - val_loss: 8.7110 - val_metrics_pearsonr: 0.0606\n",
      "Epoch 1018/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.1561 - metrics_pearsonr: 0.0546 - val_loss: 8.6948 - val_metrics_pearsonr: 0.0605\n",
      "Epoch 1019/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 8.1409 - metrics_pearsonr: 0.0545 - val_loss: 8.6786 - val_metrics_pearsonr: 0.0604\n",
      "Epoch 1020/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 8.1257 - metrics_pearsonr: 0.0544 - val_loss: 8.6625 - val_metrics_pearsonr: 0.0603\n",
      "Epoch 1021/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 8.1106 - metrics_pearsonr: 0.0543 - val_loss: 8.6465 - val_metrics_pearsonr: 0.0602\n",
      "Epoch 1022/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 8.0955 - metrics_pearsonr: 0.0542 - val_loss: 8.6305 - val_metrics_pearsonr: 0.0601\n",
      "Epoch 1023/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.0806 - metrics_pearsonr: 0.0541 - val_loss: 8.6146 - val_metrics_pearsonr: 0.0600\n",
      "Epoch 1024/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 8.0656 - metrics_pearsonr: 0.0540 - val_loss: 8.5988 - val_metrics_pearsonr: 0.0599\n",
      "Epoch 1025/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 8.0508 - metrics_pearsonr: 0.0539 - val_loss: 8.5830 - val_metrics_pearsonr: 0.0598\n",
      "Epoch 1026/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 8.0360 - metrics_pearsonr: 0.0539 - val_loss: 8.5673 - val_metrics_pearsonr: 0.0597\n",
      "Epoch 1027/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 8.0212 - metrics_pearsonr: 0.0538 - val_loss: 8.5516 - val_metrics_pearsonr: 0.0596\n",
      "Epoch 1028/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 8.0066 - metrics_pearsonr: 0.0537 - val_loss: 8.5360 - val_metrics_pearsonr: 0.0595\n",
      "Epoch 1029/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.9919 - metrics_pearsonr: 0.0536 - val_loss: 8.5205 - val_metrics_pearsonr: 0.0594\n",
      "Epoch 1030/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 7.9774 - metrics_pearsonr: 0.0535 - val_loss: 8.5050 - val_metrics_pearsonr: 0.0593\n",
      "Epoch 1031/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 7.9629 - metrics_pearsonr: 0.0534 - val_loss: 8.4896 - val_metrics_pearsonr: 0.0592\n",
      "Epoch 1032/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 7.9484 - metrics_pearsonr: 0.0533 - val_loss: 8.4742 - val_metrics_pearsonr: 0.0591\n",
      "Epoch 1033/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.9340 - metrics_pearsonr: 0.0532 - val_loss: 8.4589 - val_metrics_pearsonr: 0.0590\n",
      "Epoch 1034/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 7.9197 - metrics_pearsonr: 0.0532 - val_loss: 8.4437 - val_metrics_pearsonr: 0.0589\n",
      "Epoch 1035/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.9054 - metrics_pearsonr: 0.0531 - val_loss: 8.4285 - val_metrics_pearsonr: 0.0588\n",
      "Epoch 1036/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 7.8912 - metrics_pearsonr: 0.0530 - val_loss: 8.4134 - val_metrics_pearsonr: 0.0587\n",
      "Epoch 1037/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 7.8771 - metrics_pearsonr: 0.0529 - val_loss: 8.3983 - val_metrics_pearsonr: 0.0586\n",
      "Epoch 1038/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 7.8630 - metrics_pearsonr: 0.0528 - val_loss: 8.3833 - val_metrics_pearsonr: 0.0585\n",
      "Epoch 1039/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 7.8489 - metrics_pearsonr: 0.0527 - val_loss: 8.3683 - val_metrics_pearsonr: 0.0585\n",
      "Epoch 1040/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 7.8349 - metrics_pearsonr: 0.0527 - val_loss: 8.3534 - val_metrics_pearsonr: 0.0584\n",
      "Epoch 1041/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 7.8210 - metrics_pearsonr: 0.0526 - val_loss: 8.3386 - val_metrics_pearsonr: 0.0583\n",
      "Epoch 1042/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.8071 - metrics_pearsonr: 0.0525 - val_loss: 8.3238 - val_metrics_pearsonr: 0.0582\n",
      "Epoch 1043/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 7.7933 - metrics_pearsonr: 0.0524 - val_loss: 8.3090 - val_metrics_pearsonr: 0.0581\n",
      "Epoch 1044/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 7.7795 - metrics_pearsonr: 0.0523 - val_loss: 8.2943 - val_metrics_pearsonr: 0.0580\n",
      "Epoch 1045/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 7.7657 - metrics_pearsonr: 0.0522 - val_loss: 8.2797 - val_metrics_pearsonr: 0.0579\n",
      "Epoch 1046/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.7521 - metrics_pearsonr: 0.0522 - val_loss: 8.2651 - val_metrics_pearsonr: 0.0578\n",
      "Epoch 1047/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 7.7384 - metrics_pearsonr: 0.0521 - val_loss: 8.2506 - val_metrics_pearsonr: 0.0577\n",
      "Epoch 1048/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.7249 - metrics_pearsonr: 0.0520 - val_loss: 8.2361 - val_metrics_pearsonr: 0.0576\n",
      "Epoch 1049/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 7.7114 - metrics_pearsonr: 0.0519 - val_loss: 8.2217 - val_metrics_pearsonr: 0.0575\n",
      "Epoch 1050/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 7.6979 - metrics_pearsonr: 0.0518 - val_loss: 8.2073 - val_metrics_pearsonr: 0.0574\n",
      "Epoch 1051/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 7.6845 - metrics_pearsonr: 0.0517 - val_loss: 8.1929 - val_metrics_pearsonr: 0.0574\n",
      "Epoch 1052/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.6711 - metrics_pearsonr: 0.0517 - val_loss: 8.1787 - val_metrics_pearsonr: 0.0573\n",
      "Epoch 1053/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 7.6578 - metrics_pearsonr: 0.0516 - val_loss: 8.1644 - val_metrics_pearsonr: 0.0572\n",
      "Epoch 1054/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 7.6445 - metrics_pearsonr: 0.0515 - val_loss: 8.1503 - val_metrics_pearsonr: 0.0571\n",
      "Epoch 1055/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 7.6313 - metrics_pearsonr: 0.0514 - val_loss: 8.1361 - val_metrics_pearsonr: 0.0570\n",
      "Epoch 1056/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 7.6181 - metrics_pearsonr: 0.0513 - val_loss: 8.1221 - val_metrics_pearsonr: 0.0569\n",
      "Epoch 1057/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 7.6050 - metrics_pearsonr: 0.0513 - val_loss: 8.1080 - val_metrics_pearsonr: 0.0568\n",
      "Epoch 1058/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 7.5919 - metrics_pearsonr: 0.0512 - val_loss: 8.0941 - val_metrics_pearsonr: 0.0567\n",
      "Epoch 1059/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 7.5789 - metrics_pearsonr: 0.0511 - val_loss: 8.0801 - val_metrics_pearsonr: 0.0566\n",
      "Epoch 1060/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 7.5659 - metrics_pearsonr: 0.0510 - val_loss: 8.0663 - val_metrics_pearsonr: 0.0566\n",
      "Epoch 1061/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 7.5530 - metrics_pearsonr: 0.0509 - val_loss: 8.0524 - val_metrics_pearsonr: 0.0565\n",
      "Epoch 1062/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.5401 - metrics_pearsonr: 0.0509 - val_loss: 8.0386 - val_metrics_pearsonr: 0.0564\n",
      "Epoch 1063/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 7.5272 - metrics_pearsonr: 0.0508 - val_loss: 8.0249 - val_metrics_pearsonr: 0.0563\n",
      "Epoch 1064/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 7.5144 - metrics_pearsonr: 0.0507 - val_loss: 8.0112 - val_metrics_pearsonr: 0.0562\n",
      "Epoch 1065/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 7.5017 - metrics_pearsonr: 0.0506 - val_loss: 7.9976 - val_metrics_pearsonr: 0.0561\n",
      "Epoch 1066/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 7.4890 - metrics_pearsonr: 0.0506 - val_loss: 7.9840 - val_metrics_pearsonr: 0.0560\n",
      "Epoch 1067/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.4763 - metrics_pearsonr: 0.0505 - val_loss: 7.9704 - val_metrics_pearsonr: 0.0560\n",
      "Epoch 1068/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.4637 - metrics_pearsonr: 0.0504 - val_loss: 7.9569 - val_metrics_pearsonr: 0.0559\n",
      "Epoch 1069/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 7.4511 - metrics_pearsonr: 0.0503 - val_loss: 7.9434 - val_metrics_pearsonr: 0.0558\n",
      "Epoch 1070/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 7.4386 - metrics_pearsonr: 0.0503 - val_loss: 7.9300 - val_metrics_pearsonr: 0.0557\n",
      "Epoch 1071/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 7.4261 - metrics_pearsonr: 0.0502 - val_loss: 7.9166 - val_metrics_pearsonr: 0.0556\n",
      "Epoch 1072/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 7.4137 - metrics_pearsonr: 0.0501 - val_loss: 7.9033 - val_metrics_pearsonr: 0.0555\n",
      "Epoch 1073/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 7.4013 - metrics_pearsonr: 0.0500 - val_loss: 7.8900 - val_metrics_pearsonr: 0.0555\n",
      "Epoch 1074/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 7.3889 - metrics_pearsonr: 0.0500 - val_loss: 7.8768 - val_metrics_pearsonr: 0.0554\n",
      "Epoch 1075/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.3766 - metrics_pearsonr: 0.0499 - val_loss: 7.8636 - val_metrics_pearsonr: 0.0553\n",
      "Epoch 1076/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 7.3643 - metrics_pearsonr: 0.0498 - val_loss: 7.8504 - val_metrics_pearsonr: 0.0552\n",
      "Epoch 1077/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.3521 - metrics_pearsonr: 0.0497 - val_loss: 7.8373 - val_metrics_pearsonr: 0.0551\n",
      "Epoch 1078/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 7.3399 - metrics_pearsonr: 0.0497 - val_loss: 7.8243 - val_metrics_pearsonr: 0.0550\n",
      "Epoch 1079/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 7.3278 - metrics_pearsonr: 0.0496 - val_loss: 7.8112 - val_metrics_pearsonr: 0.0550\n",
      "Epoch 1080/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 7.3157 - metrics_pearsonr: 0.0495 - val_loss: 7.7983 - val_metrics_pearsonr: 0.0549\n",
      "Epoch 1081/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 7.3036 - metrics_pearsonr: 0.0494 - val_loss: 7.7853 - val_metrics_pearsonr: 0.0548\n",
      "Epoch 1082/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 7.2916 - metrics_pearsonr: 0.0494 - val_loss: 7.7724 - val_metrics_pearsonr: 0.0547\n",
      "Epoch 1083/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 7.2796 - metrics_pearsonr: 0.0493 - val_loss: 7.7596 - val_metrics_pearsonr: 0.0546\n",
      "Epoch 1084/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.2676 - metrics_pearsonr: 0.0492 - val_loss: 7.7467 - val_metrics_pearsonr: 0.0546\n",
      "Epoch 1085/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.2557 - metrics_pearsonr: 0.0491 - val_loss: 7.7340 - val_metrics_pearsonr: 0.0545\n",
      "Epoch 1086/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 7.2439 - metrics_pearsonr: 0.0491 - val_loss: 7.7212 - val_metrics_pearsonr: 0.0544\n",
      "Epoch 1087/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 7.2320 - metrics_pearsonr: 0.0490 - val_loss: 7.7085 - val_metrics_pearsonr: 0.0543\n",
      "Epoch 1088/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 7.2203 - metrics_pearsonr: 0.0489 - val_loss: 7.6959 - val_metrics_pearsonr: 0.0542\n",
      "Epoch 1089/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 7.2085 - metrics_pearsonr: 0.0488 - val_loss: 7.6833 - val_metrics_pearsonr: 0.0542\n",
      "Epoch 1090/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.1968 - metrics_pearsonr: 0.0488 - val_loss: 7.6707 - val_metrics_pearsonr: 0.0541\n",
      "Epoch 1091/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 7.1851 - metrics_pearsonr: 0.0487 - val_loss: 7.6582 - val_metrics_pearsonr: 0.0540\n",
      "Epoch 1092/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.1735 - metrics_pearsonr: 0.0486 - val_loss: 7.6457 - val_metrics_pearsonr: 0.0539\n",
      "Epoch 1093/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.1619 - metrics_pearsonr: 0.0486 - val_loss: 7.6332 - val_metrics_pearsonr: 0.0538\n",
      "Epoch 1094/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 7.1503 - metrics_pearsonr: 0.0485 - val_loss: 7.6208 - val_metrics_pearsonr: 0.0538\n",
      "Epoch 1095/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 7.1388 - metrics_pearsonr: 0.0484 - val_loss: 7.6084 - val_metrics_pearsonr: 0.0537\n",
      "Epoch 1096/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 7.1273 - metrics_pearsonr: 0.0483 - val_loss: 7.5961 - val_metrics_pearsonr: 0.0536\n",
      "Epoch 1097/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 7.1159 - metrics_pearsonr: 0.0483 - val_loss: 7.5838 - val_metrics_pearsonr: 0.0535\n",
      "Epoch 1098/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 7.1045 - metrics_pearsonr: 0.0482 - val_loss: 7.5715 - val_metrics_pearsonr: 0.0534\n",
      "Epoch 1099/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 7.0931 - metrics_pearsonr: 0.0481 - val_loss: 7.5593 - val_metrics_pearsonr: 0.0534\n",
      "Epoch 1100/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 7.0817 - metrics_pearsonr: 0.0481 - val_loss: 7.5471 - val_metrics_pearsonr: 0.0533\n",
      "Epoch 1101/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 7.0704 - metrics_pearsonr: 0.0480 - val_loss: 7.5349 - val_metrics_pearsonr: 0.0532\n",
      "Epoch 1102/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 7.0592 - metrics_pearsonr: 0.0479 - val_loss: 7.5228 - val_metrics_pearsonr: 0.0531\n",
      "Epoch 1103/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 7.0479 - metrics_pearsonr: 0.0479 - val_loss: 7.5107 - val_metrics_pearsonr: 0.0531\n",
      "Epoch 1104/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 7.0367 - metrics_pearsonr: 0.0478 - val_loss: 7.4987 - val_metrics_pearsonr: 0.0530\n",
      "Epoch 1105/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 7.0255 - metrics_pearsonr: 0.0477 - val_loss: 7.4867 - val_metrics_pearsonr: 0.0529\n",
      "Epoch 1106/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 7.0144 - metrics_pearsonr: 0.0476 - val_loss: 7.4747 - val_metrics_pearsonr: 0.0528\n",
      "Epoch 1107/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 7.0033 - metrics_pearsonr: 0.0476 - val_loss: 7.4628 - val_metrics_pearsonr: 0.0528\n",
      "Epoch 1108/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.9922 - metrics_pearsonr: 0.0475 - val_loss: 7.4509 - val_metrics_pearsonr: 0.0527\n",
      "Epoch 1109/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.9812 - metrics_pearsonr: 0.0474 - val_loss: 7.4390 - val_metrics_pearsonr: 0.0526\n",
      "Epoch 1110/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.9702 - metrics_pearsonr: 0.0474 - val_loss: 7.4272 - val_metrics_pearsonr: 0.0525\n",
      "Epoch 1111/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.9593 - metrics_pearsonr: 0.0473 - val_loss: 7.4154 - val_metrics_pearsonr: 0.0525\n",
      "Epoch 1112/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.9483 - metrics_pearsonr: 0.0472 - val_loss: 7.4036 - val_metrics_pearsonr: 0.0524\n",
      "Epoch 1113/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.9374 - metrics_pearsonr: 0.0472 - val_loss: 7.3919 - val_metrics_pearsonr: 0.0523\n",
      "Epoch 1114/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.9266 - metrics_pearsonr: 0.0471 - val_loss: 7.3802 - val_metrics_pearsonr: 0.0522\n",
      "Epoch 1115/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 6.9157 - metrics_pearsonr: 0.0470 - val_loss: 7.3686 - val_metrics_pearsonr: 0.0522\n",
      "Epoch 1116/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.9049 - metrics_pearsonr: 0.0470 - val_loss: 7.3569 - val_metrics_pearsonr: 0.0521\n",
      "Epoch 1117/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 6.8941 - metrics_pearsonr: 0.0469 - val_loss: 7.3453 - val_metrics_pearsonr: 0.0520\n",
      "Epoch 1118/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 6.8834 - metrics_pearsonr: 0.0468 - val_loss: 7.3338 - val_metrics_pearsonr: 0.0519\n",
      "Epoch 1119/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 6.8727 - metrics_pearsonr: 0.0468 - val_loss: 7.3223 - val_metrics_pearsonr: 0.0519\n",
      "Epoch 1120/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.8620 - metrics_pearsonr: 0.0467 - val_loss: 7.3108 - val_metrics_pearsonr: 0.0518\n",
      "Epoch 1121/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 6.8514 - metrics_pearsonr: 0.0466 - val_loss: 7.2993 - val_metrics_pearsonr: 0.0517\n",
      "Epoch 1122/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6.8408 - metrics_pearsonr: 0.0466 - val_loss: 7.2879 - val_metrics_pearsonr: 0.0517\n",
      "Epoch 1123/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.8302 - metrics_pearsonr: 0.0465 - val_loss: 7.2765 - val_metrics_pearsonr: 0.0516\n",
      "Epoch 1124/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.8196 - metrics_pearsonr: 0.0464 - val_loss: 7.2652 - val_metrics_pearsonr: 0.0515\n",
      "Epoch 1125/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 6.8091 - metrics_pearsonr: 0.0464 - val_loss: 7.2538 - val_metrics_pearsonr: 0.0514\n",
      "Epoch 1126/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 6.7986 - metrics_pearsonr: 0.0463 - val_loss: 7.2425 - val_metrics_pearsonr: 0.0514\n",
      "Epoch 1127/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 6.7881 - metrics_pearsonr: 0.0462 - val_loss: 7.2313 - val_metrics_pearsonr: 0.0513\n",
      "Epoch 1128/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 6.7777 - metrics_pearsonr: 0.0462 - val_loss: 7.2201 - val_metrics_pearsonr: 0.0512\n",
      "Epoch 1129/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.7673 - metrics_pearsonr: 0.0461 - val_loss: 7.2089 - val_metrics_pearsonr: 0.0512\n",
      "Epoch 1130/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.7569 - metrics_pearsonr: 0.0460 - val_loss: 7.1977 - val_metrics_pearsonr: 0.0511\n",
      "Epoch 1131/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.7466 - metrics_pearsonr: 0.0460 - val_loss: 7.1866 - val_metrics_pearsonr: 0.0510\n",
      "Epoch 1132/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 6.7363 - metrics_pearsonr: 0.0459 - val_loss: 7.1755 - val_metrics_pearsonr: 0.0509\n",
      "Epoch 1133/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 6.7260 - metrics_pearsonr: 0.0458 - val_loss: 7.1644 - val_metrics_pearsonr: 0.0509\n",
      "Epoch 1134/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 6.7157 - metrics_pearsonr: 0.0458 - val_loss: 7.1533 - val_metrics_pearsonr: 0.0508\n",
      "Epoch 1135/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 6.7055 - metrics_pearsonr: 0.0457 - val_loss: 7.1423 - val_metrics_pearsonr: 0.0507\n",
      "Epoch 1136/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 6.6953 - metrics_pearsonr: 0.0457 - val_loss: 7.1314 - val_metrics_pearsonr: 0.0507\n",
      "Epoch 1137/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 6.6851 - metrics_pearsonr: 0.0456 - val_loss: 7.1204 - val_metrics_pearsonr: 0.0506\n",
      "Epoch 1138/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.6750 - metrics_pearsonr: 0.0455 - val_loss: 7.1095 - val_metrics_pearsonr: 0.0505\n",
      "Epoch 1139/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 6.6649 - metrics_pearsonr: 0.0455 - val_loss: 7.0986 - val_metrics_pearsonr: 0.0504\n",
      "Epoch 1140/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.6548 - metrics_pearsonr: 0.0454 - val_loss: 7.0877 - val_metrics_pearsonr: 0.0504\n",
      "Epoch 1141/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 6.6447 - metrics_pearsonr: 0.0453 - val_loss: 7.0769 - val_metrics_pearsonr: 0.0503\n",
      "Epoch 1142/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 6.6347 - metrics_pearsonr: 0.0453 - val_loss: 7.0661 - val_metrics_pearsonr: 0.0502\n",
      "Epoch 1143/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6.6247 - metrics_pearsonr: 0.0452 - val_loss: 7.0553 - val_metrics_pearsonr: 0.0502\n",
      "Epoch 1144/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.6147 - metrics_pearsonr: 0.0451 - val_loss: 7.0446 - val_metrics_pearsonr: 0.0501\n",
      "Epoch 1145/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.6047 - metrics_pearsonr: 0.0451 - val_loss: 7.0339 - val_metrics_pearsonr: 0.0500\n",
      "Epoch 1146/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 6.5948 - metrics_pearsonr: 0.0450 - val_loss: 7.0232 - val_metrics_pearsonr: 0.0500\n",
      "Epoch 1147/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 6.5849 - metrics_pearsonr: 0.0450 - val_loss: 7.0126 - val_metrics_pearsonr: 0.0499\n",
      "Epoch 1148/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 6.5750 - metrics_pearsonr: 0.0449 - val_loss: 7.0019 - val_metrics_pearsonr: 0.0498\n",
      "Epoch 1149/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.5652 - metrics_pearsonr: 0.0448 - val_loss: 6.9913 - val_metrics_pearsonr: 0.0498\n",
      "Epoch 1150/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 6.5554 - metrics_pearsonr: 0.0448 - val_loss: 6.9808 - val_metrics_pearsonr: 0.0497\n",
      "Epoch 1151/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.5456 - metrics_pearsonr: 0.0447 - val_loss: 6.9702 - val_metrics_pearsonr: 0.0496\n",
      "Epoch 1152/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.5358 - metrics_pearsonr: 0.0446 - val_loss: 6.9597 - val_metrics_pearsonr: 0.0496\n",
      "Epoch 1153/5000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 6.5261 - metrics_pearsonr: 0.0446 - val_loss: 6.9492 - val_metrics_pearsonr: 0.0495\n",
      "Epoch 1154/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.5164 - metrics_pearsonr: 0.0445 - val_loss: 6.9388 - val_metrics_pearsonr: 0.0494\n",
      "Epoch 1155/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.5067 - metrics_pearsonr: 0.0445 - val_loss: 6.9284 - val_metrics_pearsonr: 0.0494\n",
      "Epoch 1156/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.4970 - metrics_pearsonr: 0.0444 - val_loss: 6.9180 - val_metrics_pearsonr: 0.0493\n",
      "Epoch 1157/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.4874 - metrics_pearsonr: 0.0443 - val_loss: 6.9076 - val_metrics_pearsonr: 0.0492\n",
      "Epoch 1158/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 6.4777 - metrics_pearsonr: 0.0443 - val_loss: 6.8972 - val_metrics_pearsonr: 0.0492\n",
      "Epoch 1159/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6.4682 - metrics_pearsonr: 0.0442 - val_loss: 6.8869 - val_metrics_pearsonr: 0.0491\n",
      "Epoch 1160/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.4586 - metrics_pearsonr: 0.0442 - val_loss: 6.8766 - val_metrics_pearsonr: 0.0490\n",
      "Epoch 1161/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.4490 - metrics_pearsonr: 0.0441 - val_loss: 6.8664 - val_metrics_pearsonr: 0.0490\n",
      "Epoch 1162/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.4395 - metrics_pearsonr: 0.0440 - val_loss: 6.8561 - val_metrics_pearsonr: 0.0489\n",
      "Epoch 1163/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.4300 - metrics_pearsonr: 0.0440 - val_loss: 6.8459 - val_metrics_pearsonr: 0.0488\n",
      "Epoch 1164/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.4206 - metrics_pearsonr: 0.0439 - val_loss: 6.8358 - val_metrics_pearsonr: 0.0488\n",
      "Epoch 1165/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.4111 - metrics_pearsonr: 0.0439 - val_loss: 6.8256 - val_metrics_pearsonr: 0.0487\n",
      "Epoch 1166/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 6.4017 - metrics_pearsonr: 0.0438 - val_loss: 6.8155 - val_metrics_pearsonr: 0.0486\n",
      "Epoch 1167/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6.3923 - metrics_pearsonr: 0.0437 - val_loss: 6.8054 - val_metrics_pearsonr: 0.0486\n",
      "Epoch 1168/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 6.3829 - metrics_pearsonr: 0.0437 - val_loss: 6.7953 - val_metrics_pearsonr: 0.0485\n",
      "Epoch 1169/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 6.3736 - metrics_pearsonr: 0.0436 - val_loss: 6.7852 - val_metrics_pearsonr: 0.0484\n",
      "Epoch 1170/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.3643 - metrics_pearsonr: 0.0436 - val_loss: 6.7752 - val_metrics_pearsonr: 0.0484\n",
      "Epoch 1171/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.3550 - metrics_pearsonr: 0.0435 - val_loss: 6.7652 - val_metrics_pearsonr: 0.0483\n",
      "Epoch 1172/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.3457 - metrics_pearsonr: 0.0434 - val_loss: 6.7553 - val_metrics_pearsonr: 0.0482\n",
      "Epoch 1173/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 6.3364 - metrics_pearsonr: 0.0434 - val_loss: 6.7453 - val_metrics_pearsonr: 0.0482\n",
      "Epoch 1174/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.3272 - metrics_pearsonr: 0.0433 - val_loss: 6.7354 - val_metrics_pearsonr: 0.0481\n",
      "Epoch 1175/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 6.3180 - metrics_pearsonr: 0.0433 - val_loss: 6.7255 - val_metrics_pearsonr: 0.0481\n",
      "Epoch 1176/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.3088 - metrics_pearsonr: 0.0432 - val_loss: 6.7156 - val_metrics_pearsonr: 0.0480\n",
      "Epoch 1177/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.2996 - metrics_pearsonr: 0.0431 - val_loss: 6.7058 - val_metrics_pearsonr: 0.0479\n",
      "Epoch 1178/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.2905 - metrics_pearsonr: 0.0431 - val_loss: 6.6960 - val_metrics_pearsonr: 0.0479\n",
      "Epoch 1179/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 6.2814 - metrics_pearsonr: 0.0430 - val_loss: 6.6862 - val_metrics_pearsonr: 0.0478\n",
      "Epoch 1180/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 6.2723 - metrics_pearsonr: 0.0430 - val_loss: 6.6764 - val_metrics_pearsonr: 0.0477\n",
      "Epoch 1181/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.2632 - metrics_pearsonr: 0.0429 - val_loss: 6.6667 - val_metrics_pearsonr: 0.0477\n",
      "Epoch 1182/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.2542 - metrics_pearsonr: 0.0429 - val_loss: 6.6569 - val_metrics_pearsonr: 0.0476\n",
      "Epoch 1183/5000\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 6.2451 - metrics_pearsonr: 0.0428 - val_loss: 6.6472 - val_metrics_pearsonr: 0.0476\n",
      "Epoch 1184/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 6.2361 - metrics_pearsonr: 0.0427 - val_loss: 6.6376 - val_metrics_pearsonr: 0.0475\n",
      "Epoch 1185/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 6.2272 - metrics_pearsonr: 0.0427 - val_loss: 6.6279 - val_metrics_pearsonr: 0.0474\n",
      "Epoch 1186/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.2182 - metrics_pearsonr: 0.0426 - val_loss: 6.6183 - val_metrics_pearsonr: 0.0474\n",
      "Epoch 1187/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.2093 - metrics_pearsonr: 0.0426 - val_loss: 6.6087 - val_metrics_pearsonr: 0.0473\n",
      "Epoch 1188/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 6.2003 - metrics_pearsonr: 0.0425 - val_loss: 6.5991 - val_metrics_pearsonr: 0.0472\n",
      "Epoch 1189/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.1914 - metrics_pearsonr: 0.0425 - val_loss: 6.5896 - val_metrics_pearsonr: 0.0472\n",
      "Epoch 1190/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.1826 - metrics_pearsonr: 0.0424 - val_loss: 6.5801 - val_metrics_pearsonr: 0.0471\n",
      "Epoch 1191/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.1737 - metrics_pearsonr: 0.0423 - val_loss: 6.5706 - val_metrics_pearsonr: 0.0471\n",
      "Epoch 1192/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 6.1649 - metrics_pearsonr: 0.0423 - val_loss: 6.5611 - val_metrics_pearsonr: 0.0470\n",
      "Epoch 1193/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.1561 - metrics_pearsonr: 0.0422 - val_loss: 6.5516 - val_metrics_pearsonr: 0.0469\n",
      "Epoch 1194/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.1473 - metrics_pearsonr: 0.0422 - val_loss: 6.5422 - val_metrics_pearsonr: 0.0469\n",
      "Epoch 1195/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6.1385 - metrics_pearsonr: 0.0421 - val_loss: 6.5328 - val_metrics_pearsonr: 0.0468\n",
      "Epoch 1196/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 6.1298 - metrics_pearsonr: 0.0421 - val_loss: 6.5234 - val_metrics_pearsonr: 0.0468\n",
      "Epoch 1197/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 6.1210 - metrics_pearsonr: 0.0420 - val_loss: 6.5141 - val_metrics_pearsonr: 0.0467\n",
      "Epoch 1198/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 6.1123 - metrics_pearsonr: 0.0419 - val_loss: 6.5047 - val_metrics_pearsonr: 0.0466\n",
      "Epoch 1199/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 6.1037 - metrics_pearsonr: 0.0419 - val_loss: 6.4954 - val_metrics_pearsonr: 0.0466\n",
      "Epoch 1200/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.0950 - metrics_pearsonr: 0.0418 - val_loss: 6.4861 - val_metrics_pearsonr: 0.0465\n",
      "Epoch 1201/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 6.0864 - metrics_pearsonr: 0.0418 - val_loss: 6.4769 - val_metrics_pearsonr: 0.0465\n",
      "Epoch 1202/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.0777 - metrics_pearsonr: 0.0417 - val_loss: 6.4676 - val_metrics_pearsonr: 0.0464\n",
      "Epoch 1203/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 6.0691 - metrics_pearsonr: 0.0417 - val_loss: 6.4584 - val_metrics_pearsonr: 0.0463\n",
      "Epoch 1204/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 6.0605 - metrics_pearsonr: 0.0416 - val_loss: 6.4492 - val_metrics_pearsonr: 0.0463\n",
      "Epoch 1205/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 6.0520 - metrics_pearsonr: 0.0416 - val_loss: 6.4400 - val_metrics_pearsonr: 0.0462\n",
      "Epoch 1206/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 6.0434 - metrics_pearsonr: 0.0415 - val_loss: 6.4309 - val_metrics_pearsonr: 0.0462\n",
      "Epoch 1207/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 6.0349 - metrics_pearsonr: 0.0414 - val_loss: 6.4218 - val_metrics_pearsonr: 0.0461\n",
      "Epoch 1208/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 6.0264 - metrics_pearsonr: 0.0414 - val_loss: 6.4127 - val_metrics_pearsonr: 0.0460\n",
      "Epoch 1209/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 6.0179 - metrics_pearsonr: 0.0413 - val_loss: 6.4036 - val_metrics_pearsonr: 0.0460\n",
      "Epoch 1210/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 6.0095 - metrics_pearsonr: 0.0413 - val_loss: 6.3945 - val_metrics_pearsonr: 0.0459\n",
      "Epoch 1211/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 6.0010 - metrics_pearsonr: 0.0412 - val_loss: 6.3855 - val_metrics_pearsonr: 0.0459\n",
      "Epoch 1212/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.9926 - metrics_pearsonr: 0.0412 - val_loss: 6.3764 - val_metrics_pearsonr: 0.0458\n",
      "Epoch 1213/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.9842 - metrics_pearsonr: 0.0411 - val_loss: 6.3675 - val_metrics_pearsonr: 0.0457\n",
      "Epoch 1214/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.9758 - metrics_pearsonr: 0.0411 - val_loss: 6.3585 - val_metrics_pearsonr: 0.0457\n",
      "Epoch 1215/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 5.9675 - metrics_pearsonr: 0.0410 - val_loss: 6.3495 - val_metrics_pearsonr: 0.0456\n",
      "Epoch 1216/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 5.9591 - metrics_pearsonr: 0.0410 - val_loss: 6.3406 - val_metrics_pearsonr: 0.0456\n",
      "Epoch 1217/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.9508 - metrics_pearsonr: 0.0409 - val_loss: 6.3317 - val_metrics_pearsonr: 0.0455\n",
      "Epoch 1218/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 5.9425 - metrics_pearsonr: 0.0409 - val_loss: 6.3228 - val_metrics_pearsonr: 0.0454\n",
      "Epoch 1219/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 5.9342 - metrics_pearsonr: 0.0408 - val_loss: 6.3140 - val_metrics_pearsonr: 0.0454\n",
      "Epoch 1220/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 5.9260 - metrics_pearsonr: 0.0407 - val_loss: 6.3051 - val_metrics_pearsonr: 0.0453\n",
      "Epoch 1221/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.9177 - metrics_pearsonr: 0.0407 - val_loss: 6.2963 - val_metrics_pearsonr: 0.0453\n",
      "Epoch 1222/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.9095 - metrics_pearsonr: 0.0406 - val_loss: 6.2875 - val_metrics_pearsonr: 0.0452\n",
      "Epoch 1223/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.9013 - metrics_pearsonr: 0.0406 - val_loss: 6.2787 - val_metrics_pearsonr: 0.0452\n",
      "Epoch 1224/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 5.8931 - metrics_pearsonr: 0.0405 - val_loss: 6.2700 - val_metrics_pearsonr: 0.0451\n",
      "Epoch 1225/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.8849 - metrics_pearsonr: 0.0405 - val_loss: 6.2612 - val_metrics_pearsonr: 0.0450\n",
      "Epoch 1226/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.8768 - metrics_pearsonr: 0.0404 - val_loss: 6.2525 - val_metrics_pearsonr: 0.0450\n",
      "Epoch 1227/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.8687 - metrics_pearsonr: 0.0404 - val_loss: 6.2438 - val_metrics_pearsonr: 0.0449\n",
      "Epoch 1228/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.8605 - metrics_pearsonr: 0.0403 - val_loss: 6.2351 - val_metrics_pearsonr: 0.0449\n",
      "Epoch 1229/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.8524 - metrics_pearsonr: 0.0403 - val_loss: 6.2265 - val_metrics_pearsonr: 0.0448\n",
      "Epoch 1230/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.8444 - metrics_pearsonr: 0.0402 - val_loss: 6.2179 - val_metrics_pearsonr: 0.0448\n",
      "Epoch 1231/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.8363 - metrics_pearsonr: 0.0402 - val_loss: 6.2093 - val_metrics_pearsonr: 0.0447\n",
      "Epoch 1232/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 5.8283 - metrics_pearsonr: 0.0401 - val_loss: 6.2007 - val_metrics_pearsonr: 0.0446\n",
      "Epoch 1233/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.8203 - metrics_pearsonr: 0.0401 - val_loss: 6.1921 - val_metrics_pearsonr: 0.0446\n",
      "Epoch 1234/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.8123 - metrics_pearsonr: 0.0400 - val_loss: 6.1836 - val_metrics_pearsonr: 0.0445\n",
      "Epoch 1235/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.8043 - metrics_pearsonr: 0.0400 - val_loss: 6.1750 - val_metrics_pearsonr: 0.0445\n",
      "Epoch 1236/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.7963 - metrics_pearsonr: 0.0399 - val_loss: 6.1665 - val_metrics_pearsonr: 0.0444\n",
      "Epoch 1237/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.7884 - metrics_pearsonr: 0.0399 - val_loss: 6.1581 - val_metrics_pearsonr: 0.0444\n",
      "Epoch 1238/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.7804 - metrics_pearsonr: 0.0398 - val_loss: 6.1496 - val_metrics_pearsonr: 0.0443\n",
      "Epoch 1239/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.7725 - metrics_pearsonr: 0.0398 - val_loss: 6.1411 - val_metrics_pearsonr: 0.0443\n",
      "Epoch 1240/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.7646 - metrics_pearsonr: 0.0397 - val_loss: 6.1327 - val_metrics_pearsonr: 0.0442\n",
      "Epoch 1241/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.7568 - metrics_pearsonr: 0.0397 - val_loss: 6.1243 - val_metrics_pearsonr: 0.0441\n",
      "Epoch 1242/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.7489 - metrics_pearsonr: 0.0396 - val_loss: 6.1159 - val_metrics_pearsonr: 0.0441\n",
      "Epoch 1243/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.7411 - metrics_pearsonr: 0.0396 - val_loss: 6.1076 - val_metrics_pearsonr: 0.0440\n",
      "Epoch 1244/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.7333 - metrics_pearsonr: 0.0395 - val_loss: 6.0992 - val_metrics_pearsonr: 0.0440\n",
      "Epoch 1245/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.7255 - metrics_pearsonr: 0.0394 - val_loss: 6.0909 - val_metrics_pearsonr: 0.0439\n",
      "Epoch 1246/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.7177 - metrics_pearsonr: 0.0394 - val_loss: 6.0826 - val_metrics_pearsonr: 0.0439\n",
      "Epoch 1247/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.7099 - metrics_pearsonr: 0.0393 - val_loss: 6.0743 - val_metrics_pearsonr: 0.0438\n",
      "Epoch 1248/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.7022 - metrics_pearsonr: 0.0393 - val_loss: 6.0661 - val_metrics_pearsonr: 0.0438\n",
      "Epoch 1249/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 5.6944 - metrics_pearsonr: 0.0392 - val_loss: 6.0578 - val_metrics_pearsonr: 0.0437\n",
      "Epoch 1250/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5.6867 - metrics_pearsonr: 0.0392 - val_loss: 6.0496 - val_metrics_pearsonr: 0.0437\n",
      "Epoch 1251/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5.6790 - metrics_pearsonr: 0.0391 - val_loss: 6.0414 - val_metrics_pearsonr: 0.0436\n",
      "Epoch 1252/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.6714 - metrics_pearsonr: 0.0391 - val_loss: 6.0332 - val_metrics_pearsonr: 0.0435\n",
      "Epoch 1253/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.6637 - metrics_pearsonr: 0.0390 - val_loss: 6.0251 - val_metrics_pearsonr: 0.0435\n",
      "Epoch 1254/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.6561 - metrics_pearsonr: 0.0390 - val_loss: 6.0169 - val_metrics_pearsonr: 0.0434\n",
      "Epoch 1255/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5.6484 - metrics_pearsonr: 0.0389 - val_loss: 6.0088 - val_metrics_pearsonr: 0.0434\n",
      "Epoch 1256/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.6408 - metrics_pearsonr: 0.0389 - val_loss: 6.0007 - val_metrics_pearsonr: 0.0433\n",
      "Epoch 1257/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.6332 - metrics_pearsonr: 0.0389 - val_loss: 5.9926 - val_metrics_pearsonr: 0.0433\n",
      "Epoch 1258/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.6257 - metrics_pearsonr: 0.0388 - val_loss: 5.9845 - val_metrics_pearsonr: 0.0432\n",
      "Epoch 1259/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.6181 - metrics_pearsonr: 0.0388 - val_loss: 5.9765 - val_metrics_pearsonr: 0.0432\n",
      "Epoch 1260/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.6106 - metrics_pearsonr: 0.0387 - val_loss: 5.9685 - val_metrics_pearsonr: 0.0431\n",
      "Epoch 1261/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 5.6031 - metrics_pearsonr: 0.0387 - val_loss: 5.9605 - val_metrics_pearsonr: 0.0431\n",
      "Epoch 1262/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 5.5956 - metrics_pearsonr: 0.0386 - val_loss: 5.9525 - val_metrics_pearsonr: 0.0430\n",
      "Epoch 1263/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.5881 - metrics_pearsonr: 0.0386 - val_loss: 5.9445 - val_metrics_pearsonr: 0.0430\n",
      "Epoch 1264/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.5806 - metrics_pearsonr: 0.0385 - val_loss: 5.9366 - val_metrics_pearsonr: 0.0429\n",
      "Epoch 1265/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 5.5731 - metrics_pearsonr: 0.0385 - val_loss: 5.9286 - val_metrics_pearsonr: 0.0429\n",
      "Epoch 1266/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.5657 - metrics_pearsonr: 0.0384 - val_loss: 5.9207 - val_metrics_pearsonr: 0.0428\n",
      "Epoch 1267/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.5583 - metrics_pearsonr: 0.0384 - val_loss: 5.9128 - val_metrics_pearsonr: 0.0427\n",
      "Epoch 1268/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.5509 - metrics_pearsonr: 0.0383 - val_loss: 5.9050 - val_metrics_pearsonr: 0.0427\n",
      "Epoch 1269/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 5.5435 - metrics_pearsonr: 0.0383 - val_loss: 5.8971 - val_metrics_pearsonr: 0.0426\n",
      "Epoch 1270/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 5.5361 - metrics_pearsonr: 0.0382 - val_loss: 5.8893 - val_metrics_pearsonr: 0.0426\n",
      "Epoch 1271/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 5.5288 - metrics_pearsonr: 0.0382 - val_loss: 5.8815 - val_metrics_pearsonr: 0.0425\n",
      "Epoch 1272/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.5215 - metrics_pearsonr: 0.0381 - val_loss: 5.8737 - val_metrics_pearsonr: 0.0425\n",
      "Epoch 1273/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.5141 - metrics_pearsonr: 0.0381 - val_loss: 5.8659 - val_metrics_pearsonr: 0.0424\n",
      "Epoch 1274/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.5068 - metrics_pearsonr: 0.0380 - val_loss: 5.8581 - val_metrics_pearsonr: 0.0424\n",
      "Epoch 1275/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.4996 - metrics_pearsonr: 0.0380 - val_loss: 5.8504 - val_metrics_pearsonr: 0.0423\n",
      "Epoch 1276/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5.4923 - metrics_pearsonr: 0.0379 - val_loss: 5.8427 - val_metrics_pearsonr: 0.0423\n",
      "Epoch 1277/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 5.4850 - metrics_pearsonr: 0.0379 - val_loss: 5.8350 - val_metrics_pearsonr: 0.0422\n",
      "Epoch 1278/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 5.4778 - metrics_pearsonr: 0.0378 - val_loss: 5.8273 - val_metrics_pearsonr: 0.0422\n",
      "Epoch 1279/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 5.4706 - metrics_pearsonr: 0.0378 - val_loss: 5.8196 - val_metrics_pearsonr: 0.0421\n",
      "Epoch 1280/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 5.4634 - metrics_pearsonr: 0.0377 - val_loss: 5.8120 - val_metrics_pearsonr: 0.0421\n",
      "Epoch 1281/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 5.4562 - metrics_pearsonr: 0.0377 - val_loss: 5.8043 - val_metrics_pearsonr: 0.0420\n",
      "Epoch 1282/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.4490 - metrics_pearsonr: 0.0377 - val_loss: 5.7967 - val_metrics_pearsonr: 0.0420\n",
      "Epoch 1283/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.4419 - metrics_pearsonr: 0.0376 - val_loss: 5.7891 - val_metrics_pearsonr: 0.0419\n",
      "Epoch 1284/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 5.4347 - metrics_pearsonr: 0.0376 - val_loss: 5.7816 - val_metrics_pearsonr: 0.0419\n",
      "Epoch 1285/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.4276 - metrics_pearsonr: 0.0375 - val_loss: 5.7740 - val_metrics_pearsonr: 0.0418\n",
      "Epoch 1286/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.4205 - metrics_pearsonr: 0.0375 - val_loss: 5.7665 - val_metrics_pearsonr: 0.0418\n",
      "Epoch 1287/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 5.4134 - metrics_pearsonr: 0.0374 - val_loss: 5.7589 - val_metrics_pearsonr: 0.0417\n",
      "Epoch 1288/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 5.4064 - metrics_pearsonr: 0.0374 - val_loss: 5.7514 - val_metrics_pearsonr: 0.0417\n",
      "Epoch 1289/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.3993 - metrics_pearsonr: 0.0373 - val_loss: 5.7440 - val_metrics_pearsonr: 0.0416\n",
      "Epoch 1290/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 5.3923 - metrics_pearsonr: 0.0373 - val_loss: 5.7365 - val_metrics_pearsonr: 0.0416\n",
      "Epoch 1291/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.3852 - metrics_pearsonr: 0.0372 - val_loss: 5.7291 - val_metrics_pearsonr: 0.0415\n",
      "Epoch 1292/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.3782 - metrics_pearsonr: 0.0372 - val_loss: 5.7216 - val_metrics_pearsonr: 0.0415\n",
      "Epoch 1293/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.3712 - metrics_pearsonr: 0.0371 - val_loss: 5.7142 - val_metrics_pearsonr: 0.0414\n",
      "Epoch 1294/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.3643 - metrics_pearsonr: 0.0371 - val_loss: 5.7068 - val_metrics_pearsonr: 0.0414\n",
      "Epoch 1295/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.3573 - metrics_pearsonr: 0.0371 - val_loss: 5.6995 - val_metrics_pearsonr: 0.0413\n",
      "Epoch 1296/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.3504 - metrics_pearsonr: 0.0370 - val_loss: 5.6921 - val_metrics_pearsonr: 0.0413\n",
      "Epoch 1297/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.3434 - metrics_pearsonr: 0.0370 - val_loss: 5.6848 - val_metrics_pearsonr: 0.0412\n",
      "Epoch 1298/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.3365 - metrics_pearsonr: 0.0369 - val_loss: 5.6774 - val_metrics_pearsonr: 0.0412\n",
      "Epoch 1299/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.3296 - metrics_pearsonr: 0.0369 - val_loss: 5.6701 - val_metrics_pearsonr: 0.0411\n",
      "Epoch 1300/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.3227 - metrics_pearsonr: 0.0368 - val_loss: 5.6629 - val_metrics_pearsonr: 0.0411\n",
      "Epoch 1301/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.3159 - metrics_pearsonr: 0.0368 - val_loss: 5.6556 - val_metrics_pearsonr: 0.0410\n",
      "Epoch 1302/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.3090 - metrics_pearsonr: 0.0367 - val_loss: 5.6483 - val_metrics_pearsonr: 0.0410\n",
      "Epoch 1303/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.3022 - metrics_pearsonr: 0.0367 - val_loss: 5.6411 - val_metrics_pearsonr: 0.0409\n",
      "Epoch 1304/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 5.2954 - metrics_pearsonr: 0.0366 - val_loss: 5.6339 - val_metrics_pearsonr: 0.0409\n",
      "Epoch 1305/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 5.2886 - metrics_pearsonr: 0.0366 - val_loss: 5.6267 - val_metrics_pearsonr: 0.0408\n",
      "Epoch 1306/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.2818 - metrics_pearsonr: 0.0366 - val_loss: 5.6195 - val_metrics_pearsonr: 0.0408\n",
      "Epoch 1307/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.2750 - metrics_pearsonr: 0.0365 - val_loss: 5.6124 - val_metrics_pearsonr: 0.0407\n",
      "Epoch 1308/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.2683 - metrics_pearsonr: 0.0365 - val_loss: 5.6052 - val_metrics_pearsonr: 0.0407\n",
      "Epoch 1309/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.2615 - metrics_pearsonr: 0.0364 - val_loss: 5.5981 - val_metrics_pearsonr: 0.0406\n",
      "Epoch 1310/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.2548 - metrics_pearsonr: 0.0364 - val_loss: 5.5910 - val_metrics_pearsonr: 0.0406\n",
      "Epoch 1311/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.2481 - metrics_pearsonr: 0.0363 - val_loss: 5.5839 - val_metrics_pearsonr: 0.0405\n",
      "Epoch 1312/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.2414 - metrics_pearsonr: 0.0363 - val_loss: 5.5769 - val_metrics_pearsonr: 0.0405\n",
      "Epoch 1313/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.2347 - metrics_pearsonr: 0.0363 - val_loss: 5.5698 - val_metrics_pearsonr: 0.0404\n",
      "Epoch 1314/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.2281 - metrics_pearsonr: 0.0362 - val_loss: 5.5628 - val_metrics_pearsonr: 0.0404\n",
      "Epoch 1315/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.2214 - metrics_pearsonr: 0.0362 - val_loss: 5.5557 - val_metrics_pearsonr: 0.0403\n",
      "Epoch 1316/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.2148 - metrics_pearsonr: 0.0361 - val_loss: 5.5487 - val_metrics_pearsonr: 0.0403\n",
      "Epoch 1317/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.2082 - metrics_pearsonr: 0.0361 - val_loss: 5.5418 - val_metrics_pearsonr: 0.0402\n",
      "Epoch 1318/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.2016 - metrics_pearsonr: 0.0360 - val_loss: 5.5348 - val_metrics_pearsonr: 0.0402\n",
      "Epoch 1319/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 5.1950 - metrics_pearsonr: 0.0360 - val_loss: 5.5278 - val_metrics_pearsonr: 0.0401\n",
      "Epoch 1320/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.1884 - metrics_pearsonr: 0.0359 - val_loss: 5.5209 - val_metrics_pearsonr: 0.0401\n",
      "Epoch 1321/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.1818 - metrics_pearsonr: 0.0359 - val_loss: 5.5140 - val_metrics_pearsonr: 0.0401\n",
      "Epoch 1322/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 5.1753 - metrics_pearsonr: 0.0359 - val_loss: 5.5071 - val_metrics_pearsonr: 0.0400\n",
      "Epoch 1323/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.1688 - metrics_pearsonr: 0.0358 - val_loss: 5.5002 - val_metrics_pearsonr: 0.0400\n",
      "Epoch 1324/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.1623 - metrics_pearsonr: 0.0358 - val_loss: 5.4933 - val_metrics_pearsonr: 0.0399\n",
      "Epoch 1325/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.1558 - metrics_pearsonr: 0.0357 - val_loss: 5.4865 - val_metrics_pearsonr: 0.0399\n",
      "Epoch 1326/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.1493 - metrics_pearsonr: 0.0357 - val_loss: 5.4797 - val_metrics_pearsonr: 0.0398\n",
      "Epoch 1327/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.1428 - metrics_pearsonr: 0.0357 - val_loss: 5.4729 - val_metrics_pearsonr: 0.0398\n",
      "Epoch 1328/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.1364 - metrics_pearsonr: 0.0356 - val_loss: 5.4661 - val_metrics_pearsonr: 0.0397\n",
      "Epoch 1329/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 5.1299 - metrics_pearsonr: 0.0356 - val_loss: 5.4593 - val_metrics_pearsonr: 0.0397\n",
      "Epoch 1330/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 5.1235 - metrics_pearsonr: 0.0355 - val_loss: 5.4525 - val_metrics_pearsonr: 0.0396\n",
      "Epoch 1331/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.1171 - metrics_pearsonr: 0.0355 - val_loss: 5.4458 - val_metrics_pearsonr: 0.0396\n",
      "Epoch 1332/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 5.1107 - metrics_pearsonr: 0.0354 - val_loss: 5.4390 - val_metrics_pearsonr: 0.0395\n",
      "Epoch 1333/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.1043 - metrics_pearsonr: 0.0354 - val_loss: 5.4323 - val_metrics_pearsonr: 0.0395\n",
      "Epoch 1334/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.0980 - metrics_pearsonr: 0.0354 - val_loss: 5.4256 - val_metrics_pearsonr: 0.0395\n",
      "Epoch 1335/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 5.0916 - metrics_pearsonr: 0.0353 - val_loss: 5.4190 - val_metrics_pearsonr: 0.0394\n",
      "Epoch 1336/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.0853 - metrics_pearsonr: 0.0353 - val_loss: 5.4123 - val_metrics_pearsonr: 0.0394\n",
      "Epoch 1337/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.0790 - metrics_pearsonr: 0.0352 - val_loss: 5.4057 - val_metrics_pearsonr: 0.0393\n",
      "Epoch 1338/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 5.0727 - metrics_pearsonr: 0.0352 - val_loss: 5.3990 - val_metrics_pearsonr: 0.0393\n",
      "Epoch 1339/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 5.0664 - metrics_pearsonr: 0.0351 - val_loss: 5.3924 - val_metrics_pearsonr: 0.0392\n",
      "Epoch 1340/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 5.0601 - metrics_pearsonr: 0.0351 - val_loss: 5.3858 - val_metrics_pearsonr: 0.0392\n",
      "Epoch 1341/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.0539 - metrics_pearsonr: 0.0351 - val_loss: 5.3792 - val_metrics_pearsonr: 0.0391\n",
      "Epoch 1342/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 5.0476 - metrics_pearsonr: 0.0350 - val_loss: 5.3727 - val_metrics_pearsonr: 0.0391\n",
      "Epoch 1343/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 5.0414 - metrics_pearsonr: 0.0350 - val_loss: 5.3661 - val_metrics_pearsonr: 0.0390\n",
      "Epoch 1344/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 5.0352 - metrics_pearsonr: 0.0349 - val_loss: 5.3596 - val_metrics_pearsonr: 0.0390\n",
      "Epoch 1345/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 5.0290 - metrics_pearsonr: 0.0349 - val_loss: 5.3531 - val_metrics_pearsonr: 0.0390\n",
      "Epoch 1346/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 5.0228 - metrics_pearsonr: 0.0349 - val_loss: 5.3466 - val_metrics_pearsonr: 0.0389\n",
      "Epoch 1347/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.0166 - metrics_pearsonr: 0.0348 - val_loss: 5.3401 - val_metrics_pearsonr: 0.0389\n",
      "Epoch 1348/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 5.0105 - metrics_pearsonr: 0.0348 - val_loss: 5.3336 - val_metrics_pearsonr: 0.0388\n",
      "Epoch 1349/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 5.0043 - metrics_pearsonr: 0.0347 - val_loss: 5.3272 - val_metrics_pearsonr: 0.0388\n",
      "Epoch 1350/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.9982 - metrics_pearsonr: 0.0347 - val_loss: 5.3208 - val_metrics_pearsonr: 0.0387\n",
      "Epoch 1351/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.9921 - metrics_pearsonr: 0.0347 - val_loss: 5.3143 - val_metrics_pearsonr: 0.0387\n",
      "Epoch 1352/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.9860 - metrics_pearsonr: 0.0346 - val_loss: 5.3079 - val_metrics_pearsonr: 0.0386\n",
      "Epoch 1353/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.9799 - metrics_pearsonr: 0.0346 - val_loss: 5.3016 - val_metrics_pearsonr: 0.0386\n",
      "Epoch 1354/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.9738 - metrics_pearsonr: 0.0345 - val_loss: 5.2952 - val_metrics_pearsonr: 0.0386\n",
      "Epoch 1355/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 4.9677 - metrics_pearsonr: 0.0345 - val_loss: 5.2888 - val_metrics_pearsonr: 0.0385\n",
      "Epoch 1356/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 4.9617 - metrics_pearsonr: 0.0345 - val_loss: 5.2825 - val_metrics_pearsonr: 0.0385\n",
      "Epoch 1357/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.9557 - metrics_pearsonr: 0.0344 - val_loss: 5.2762 - val_metrics_pearsonr: 0.0384\n",
      "Epoch 1358/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.9497 - metrics_pearsonr: 0.0344 - val_loss: 5.2699 - val_metrics_pearsonr: 0.0384\n",
      "Epoch 1359/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.9437 - metrics_pearsonr: 0.0343 - val_loss: 5.2636 - val_metrics_pearsonr: 0.0383\n",
      "Epoch 1360/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 4.9377 - metrics_pearsonr: 0.0343 - val_loss: 5.2573 - val_metrics_pearsonr: 0.0383\n",
      "Epoch 1361/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.9317 - metrics_pearsonr: 0.0343 - val_loss: 5.2510 - val_metrics_pearsonr: 0.0382\n",
      "Epoch 1362/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.9257 - metrics_pearsonr: 0.0342 - val_loss: 5.2448 - val_metrics_pearsonr: 0.0382\n",
      "Epoch 1363/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.9198 - metrics_pearsonr: 0.0342 - val_loss: 5.2386 - val_metrics_pearsonr: 0.0382\n",
      "Epoch 1364/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.9139 - metrics_pearsonr: 0.0341 - val_loss: 5.2323 - val_metrics_pearsonr: 0.0381\n",
      "Epoch 1365/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.9079 - metrics_pearsonr: 0.0341 - val_loss: 5.2261 - val_metrics_pearsonr: 0.0381\n",
      "Epoch 1366/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.9020 - metrics_pearsonr: 0.0341 - val_loss: 5.2199 - val_metrics_pearsonr: 0.0380\n",
      "Epoch 1367/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.8961 - metrics_pearsonr: 0.0340 - val_loss: 5.2138 - val_metrics_pearsonr: 0.0380\n",
      "Epoch 1368/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.8903 - metrics_pearsonr: 0.0340 - val_loss: 5.2076 - val_metrics_pearsonr: 0.0379\n",
      "Epoch 1369/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.8844 - metrics_pearsonr: 0.0339 - val_loss: 5.2015 - val_metrics_pearsonr: 0.0379\n",
      "Epoch 1370/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.8786 - metrics_pearsonr: 0.0339 - val_loss: 5.1954 - val_metrics_pearsonr: 0.0379\n",
      "Epoch 1371/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.8727 - metrics_pearsonr: 0.0339 - val_loss: 5.1892 - val_metrics_pearsonr: 0.0378\n",
      "Epoch 1372/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.8669 - metrics_pearsonr: 0.0338 - val_loss: 5.1832 - val_metrics_pearsonr: 0.0378\n",
      "Epoch 1373/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 4.8611 - metrics_pearsonr: 0.0338 - val_loss: 5.1771 - val_metrics_pearsonr: 0.0377\n",
      "Epoch 1374/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 4.8553 - metrics_pearsonr: 0.0338 - val_loss: 5.1710 - val_metrics_pearsonr: 0.0377\n",
      "Epoch 1375/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 4.8495 - metrics_pearsonr: 0.0337 - val_loss: 5.1650 - val_metrics_pearsonr: 0.0377\n",
      "Epoch 1376/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.8438 - metrics_pearsonr: 0.0337 - val_loss: 5.1589 - val_metrics_pearsonr: 0.0376\n",
      "Epoch 1377/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.8380 - metrics_pearsonr: 0.0336 - val_loss: 5.1529 - val_metrics_pearsonr: 0.0376\n",
      "Epoch 1378/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.8323 - metrics_pearsonr: 0.0336 - val_loss: 5.1469 - val_metrics_pearsonr: 0.0375\n",
      "Epoch 1379/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.8265 - metrics_pearsonr: 0.0336 - val_loss: 5.1409 - val_metrics_pearsonr: 0.0375\n",
      "Epoch 1380/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.8208 - metrics_pearsonr: 0.0335 - val_loss: 5.1350 - val_metrics_pearsonr: 0.0374\n",
      "Epoch 1381/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.8151 - metrics_pearsonr: 0.0335 - val_loss: 5.1290 - val_metrics_pearsonr: 0.0374\n",
      "Epoch 1382/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.8094 - metrics_pearsonr: 0.0335 - val_loss: 5.1231 - val_metrics_pearsonr: 0.0374\n",
      "Epoch 1383/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.8038 - metrics_pearsonr: 0.0334 - val_loss: 5.1171 - val_metrics_pearsonr: 0.0373\n",
      "Epoch 1384/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.7981 - metrics_pearsonr: 0.0334 - val_loss: 5.1112 - val_metrics_pearsonr: 0.0373\n",
      "Epoch 1385/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.7924 - metrics_pearsonr: 0.0333 - val_loss: 5.1053 - val_metrics_pearsonr: 0.0372\n",
      "Epoch 1386/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.7868 - metrics_pearsonr: 0.0333 - val_loss: 5.0994 - val_metrics_pearsonr: 0.0372\n",
      "Epoch 1387/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.7812 - metrics_pearsonr: 0.0333 - val_loss: 5.0935 - val_metrics_pearsonr: 0.0372\n",
      "Epoch 1388/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.7756 - metrics_pearsonr: 0.0332 - val_loss: 5.0877 - val_metrics_pearsonr: 0.0371\n",
      "Epoch 1389/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.7700 - metrics_pearsonr: 0.0332 - val_loss: 5.0819 - val_metrics_pearsonr: 0.0371\n",
      "Epoch 1390/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.7644 - metrics_pearsonr: 0.0332 - val_loss: 5.0760 - val_metrics_pearsonr: 0.0370\n",
      "Epoch 1391/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.7588 - metrics_pearsonr: 0.0331 - val_loss: 5.0702 - val_metrics_pearsonr: 0.0370\n",
      "Epoch 1392/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.7533 - metrics_pearsonr: 0.0331 - val_loss: 5.0644 - val_metrics_pearsonr: 0.0370\n",
      "Epoch 1393/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.7477 - metrics_pearsonr: 0.0330 - val_loss: 5.0586 - val_metrics_pearsonr: 0.0369\n",
      "Epoch 1394/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.7422 - metrics_pearsonr: 0.0330 - val_loss: 5.0529 - val_metrics_pearsonr: 0.0369\n",
      "Epoch 1395/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.7367 - metrics_pearsonr: 0.0330 - val_loss: 5.0471 - val_metrics_pearsonr: 0.0368\n",
      "Epoch 1396/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.7312 - metrics_pearsonr: 0.0329 - val_loss: 5.0414 - val_metrics_pearsonr: 0.0368\n",
      "Epoch 1397/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.7257 - metrics_pearsonr: 0.0329 - val_loss: 5.0357 - val_metrics_pearsonr: 0.0368\n",
      "Epoch 1398/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.7202 - metrics_pearsonr: 0.0329 - val_loss: 5.0300 - val_metrics_pearsonr: 0.0367\n",
      "Epoch 1399/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.7147 - metrics_pearsonr: 0.0328 - val_loss: 5.0243 - val_metrics_pearsonr: 0.0367\n",
      "Epoch 1400/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.7093 - metrics_pearsonr: 0.0328 - val_loss: 5.0186 - val_metrics_pearsonr: 0.0366\n",
      "Epoch 1401/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 4.7039 - metrics_pearsonr: 0.0328 - val_loss: 5.0130 - val_metrics_pearsonr: 0.0366\n",
      "Epoch 1402/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6984 - metrics_pearsonr: 0.0327 - val_loss: 5.0073 - val_metrics_pearsonr: 0.0366\n",
      "Epoch 1403/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.6930 - metrics_pearsonr: 0.0327 - val_loss: 5.0017 - val_metrics_pearsonr: 0.0365\n",
      "Epoch 1404/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.6876 - metrics_pearsonr: 0.0326 - val_loss: 4.9961 - val_metrics_pearsonr: 0.0365\n",
      "Epoch 1405/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.6822 - metrics_pearsonr: 0.0326 - val_loss: 4.9905 - val_metrics_pearsonr: 0.0364\n",
      "Epoch 1406/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6768 - metrics_pearsonr: 0.0326 - val_loss: 4.9849 - val_metrics_pearsonr: 0.0364\n",
      "Epoch 1407/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.6715 - metrics_pearsonr: 0.0325 - val_loss: 4.9793 - val_metrics_pearsonr: 0.0364\n",
      "Epoch 1408/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.6661 - metrics_pearsonr: 0.0325 - val_loss: 4.9738 - val_metrics_pearsonr: 0.0363\n",
      "Epoch 1409/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.6608 - metrics_pearsonr: 0.0325 - val_loss: 4.9682 - val_metrics_pearsonr: 0.0363\n",
      "Epoch 1410/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.6555 - metrics_pearsonr: 0.0324 - val_loss: 4.9627 - val_metrics_pearsonr: 0.0362\n",
      "Epoch 1411/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.6501 - metrics_pearsonr: 0.0324 - val_loss: 4.9572 - val_metrics_pearsonr: 0.0362\n",
      "Epoch 1412/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6448 - metrics_pearsonr: 0.0324 - val_loss: 4.9517 - val_metrics_pearsonr: 0.0362\n",
      "Epoch 1413/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 4.6395 - metrics_pearsonr: 0.0323 - val_loss: 4.9462 - val_metrics_pearsonr: 0.0361\n",
      "Epoch 1414/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.6343 - metrics_pearsonr: 0.0323 - val_loss: 4.9407 - val_metrics_pearsonr: 0.0361\n",
      "Epoch 1415/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.6290 - metrics_pearsonr: 0.0323 - val_loss: 4.9353 - val_metrics_pearsonr: 0.0360\n",
      "Epoch 1416/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.6238 - metrics_pearsonr: 0.0322 - val_loss: 4.9298 - val_metrics_pearsonr: 0.0360\n",
      "Epoch 1417/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.6185 - metrics_pearsonr: 0.0322 - val_loss: 4.9244 - val_metrics_pearsonr: 0.0360\n",
      "Epoch 1418/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 4.6133 - metrics_pearsonr: 0.0322 - val_loss: 4.9190 - val_metrics_pearsonr: 0.0359\n",
      "Epoch 1419/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 4.6081 - metrics_pearsonr: 0.0321 - val_loss: 4.9136 - val_metrics_pearsonr: 0.0359\n",
      "Epoch 1420/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6029 - metrics_pearsonr: 0.0321 - val_loss: 4.9082 - val_metrics_pearsonr: 0.0359\n",
      "Epoch 1421/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.5977 - metrics_pearsonr: 0.0320 - val_loss: 4.9029 - val_metrics_pearsonr: 0.0358\n",
      "Epoch 1422/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.5925 - metrics_pearsonr: 0.0320 - val_loss: 4.8975 - val_metrics_pearsonr: 0.0358\n",
      "Epoch 1423/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.5873 - metrics_pearsonr: 0.0320 - val_loss: 4.8922 - val_metrics_pearsonr: 0.0357\n",
      "Epoch 1424/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.5822 - metrics_pearsonr: 0.0319 - val_loss: 4.8868 - val_metrics_pearsonr: 0.0357\n",
      "Epoch 1425/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.5770 - metrics_pearsonr: 0.0319 - val_loss: 4.8815 - val_metrics_pearsonr: 0.0357\n",
      "Epoch 1426/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.5719 - metrics_pearsonr: 0.0319 - val_loss: 4.8762 - val_metrics_pearsonr: 0.0356\n",
      "Epoch 1427/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.5668 - metrics_pearsonr: 0.0318 - val_loss: 4.8709 - val_metrics_pearsonr: 0.0356\n",
      "Epoch 1428/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.5617 - metrics_pearsonr: 0.0318 - val_loss: 4.8657 - val_metrics_pearsonr: 0.0356\n",
      "Epoch 1429/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.5566 - metrics_pearsonr: 0.0318 - val_loss: 4.8604 - val_metrics_pearsonr: 0.0355\n",
      "Epoch 1430/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.5515 - metrics_pearsonr: 0.0317 - val_loss: 4.8552 - val_metrics_pearsonr: 0.0355\n",
      "Epoch 1431/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.5464 - metrics_pearsonr: 0.0317 - val_loss: 4.8499 - val_metrics_pearsonr: 0.0354\n",
      "Epoch 1432/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.5413 - metrics_pearsonr: 0.0317 - val_loss: 4.8447 - val_metrics_pearsonr: 0.0354\n",
      "Epoch 1433/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.5363 - metrics_pearsonr: 0.0316 - val_loss: 4.8395 - val_metrics_pearsonr: 0.0354\n",
      "Epoch 1434/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.5313 - metrics_pearsonr: 0.0316 - val_loss: 4.8343 - val_metrics_pearsonr: 0.0353\n",
      "Epoch 1435/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.5262 - metrics_pearsonr: 0.0316 - val_loss: 4.8291 - val_metrics_pearsonr: 0.0353\n",
      "Epoch 1436/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.5212 - metrics_pearsonr: 0.0315 - val_loss: 4.8240 - val_metrics_pearsonr: 0.0353\n",
      "Epoch 1437/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.5162 - metrics_pearsonr: 0.0315 - val_loss: 4.8188 - val_metrics_pearsonr: 0.0352\n",
      "Epoch 1438/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.5112 - metrics_pearsonr: 0.0315 - val_loss: 4.8136 - val_metrics_pearsonr: 0.0352\n",
      "Epoch 1439/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.5062 - metrics_pearsonr: 0.0314 - val_loss: 4.8085 - val_metrics_pearsonr: 0.0351\n",
      "Epoch 1440/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.5013 - metrics_pearsonr: 0.0314 - val_loss: 4.8034 - val_metrics_pearsonr: 0.0351\n",
      "Epoch 1441/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.4963 - metrics_pearsonr: 0.0314 - val_loss: 4.7982 - val_metrics_pearsonr: 0.0351\n",
      "Epoch 1442/5000\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.4914 - metrics_pearsonr: 0.0313 - val_loss: 4.7931 - val_metrics_pearsonr: 0.0350\n",
      "Epoch 1443/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.4864 - metrics_pearsonr: 0.0313 - val_loss: 4.7881 - val_metrics_pearsonr: 0.0350\n",
      "Epoch 1444/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.4815 - metrics_pearsonr: 0.0313 - val_loss: 4.7830 - val_metrics_pearsonr: 0.0350\n",
      "Epoch 1445/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 4.4766 - metrics_pearsonr: 0.0312 - val_loss: 4.7779 - val_metrics_pearsonr: 0.0349\n",
      "Epoch 1446/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.4717 - metrics_pearsonr: 0.0312 - val_loss: 4.7728 - val_metrics_pearsonr: 0.0349\n",
      "Epoch 1447/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 4.4668 - metrics_pearsonr: 0.0312 - val_loss: 4.7678 - val_metrics_pearsonr: 0.0349\n",
      "Epoch 1448/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.4619 - metrics_pearsonr: 0.0311 - val_loss: 4.7627 - val_metrics_pearsonr: 0.0348\n",
      "Epoch 1449/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.4571 - metrics_pearsonr: 0.0311 - val_loss: 4.7577 - val_metrics_pearsonr: 0.0348\n",
      "Epoch 1450/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.4522 - metrics_pearsonr: 0.0311 - val_loss: 4.7526 - val_metrics_pearsonr: 0.0348\n",
      "Epoch 1451/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.4474 - metrics_pearsonr: 0.0310 - val_loss: 4.7476 - val_metrics_pearsonr: 0.0347\n",
      "Epoch 1452/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.4425 - metrics_pearsonr: 0.0310 - val_loss: 4.7426 - val_metrics_pearsonr: 0.0347\n",
      "Epoch 1453/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.4377 - metrics_pearsonr: 0.0310 - val_loss: 4.7376 - val_metrics_pearsonr: 0.0346\n",
      "Epoch 1454/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.4329 - metrics_pearsonr: 0.0309 - val_loss: 4.7326 - val_metrics_pearsonr: 0.0346\n",
      "Epoch 1455/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.4281 - metrics_pearsonr: 0.0309 - val_loss: 4.7276 - val_metrics_pearsonr: 0.0346\n",
      "Epoch 1456/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.4233 - metrics_pearsonr: 0.0309 - val_loss: 4.7227 - val_metrics_pearsonr: 0.0345\n",
      "Epoch 1457/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.4185 - metrics_pearsonr: 0.0308 - val_loss: 4.7177 - val_metrics_pearsonr: 0.0345\n",
      "Epoch 1458/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.4137 - metrics_pearsonr: 0.0308 - val_loss: 4.7127 - val_metrics_pearsonr: 0.0345\n",
      "Epoch 1459/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.4090 - metrics_pearsonr: 0.0308 - val_loss: 4.7078 - val_metrics_pearsonr: 0.0344\n",
      "Epoch 1460/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 4.4042 - metrics_pearsonr: 0.0307 - val_loss: 4.7028 - val_metrics_pearsonr: 0.0344\n",
      "Epoch 1461/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.3995 - metrics_pearsonr: 0.0307 - val_loss: 4.6979 - val_metrics_pearsonr: 0.0344\n",
      "Epoch 1462/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.3948 - metrics_pearsonr: 0.0307 - val_loss: 4.6930 - val_metrics_pearsonr: 0.0343\n",
      "Epoch 1463/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.3901 - metrics_pearsonr: 0.0307 - val_loss: 4.6881 - val_metrics_pearsonr: 0.0343\n",
      "Epoch 1464/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.3853 - metrics_pearsonr: 0.0306 - val_loss: 4.6832 - val_metrics_pearsonr: 0.0343\n",
      "Epoch 1465/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.3807 - metrics_pearsonr: 0.0306 - val_loss: 4.6783 - val_metrics_pearsonr: 0.0342\n",
      "Epoch 1466/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.3760 - metrics_pearsonr: 0.0306 - val_loss: 4.6734 - val_metrics_pearsonr: 0.0342\n",
      "Epoch 1467/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.3713 - metrics_pearsonr: 0.0305 - val_loss: 4.6686 - val_metrics_pearsonr: 0.0342\n",
      "Epoch 1468/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.3666 - metrics_pearsonr: 0.0305 - val_loss: 4.6637 - val_metrics_pearsonr: 0.0341\n",
      "Epoch 1469/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.3620 - metrics_pearsonr: 0.0305 - val_loss: 4.6589 - val_metrics_pearsonr: 0.0341\n",
      "Epoch 1470/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.3573 - metrics_pearsonr: 0.0304 - val_loss: 4.6541 - val_metrics_pearsonr: 0.0341\n",
      "Epoch 1471/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.3527 - metrics_pearsonr: 0.0304 - val_loss: 4.6493 - val_metrics_pearsonr: 0.0340\n",
      "Epoch 1472/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.3481 - metrics_pearsonr: 0.0304 - val_loss: 4.6445 - val_metrics_pearsonr: 0.0340\n",
      "Epoch 1473/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.3435 - metrics_pearsonr: 0.0303 - val_loss: 4.6398 - val_metrics_pearsonr: 0.0340\n",
      "Epoch 1474/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.3389 - metrics_pearsonr: 0.0303 - val_loss: 4.6350 - val_metrics_pearsonr: 0.0339\n",
      "Epoch 1475/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 4.3343 - metrics_pearsonr: 0.0303 - val_loss: 4.6303 - val_metrics_pearsonr: 0.0339\n",
      "Epoch 1476/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 4.3297 - metrics_pearsonr: 0.0302 - val_loss: 4.6255 - val_metrics_pearsonr: 0.0339\n",
      "Epoch 1477/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 4.3251 - metrics_pearsonr: 0.0302 - val_loss: 4.6208 - val_metrics_pearsonr: 0.0338\n",
      "Epoch 1478/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 4.3206 - metrics_pearsonr: 0.0302 - val_loss: 4.6162 - val_metrics_pearsonr: 0.0338\n",
      "Epoch 1479/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.3160 - metrics_pearsonr: 0.0302 - val_loss: 4.6115 - val_metrics_pearsonr: 0.0338\n",
      "Epoch 1480/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.3115 - metrics_pearsonr: 0.0301 - val_loss: 4.6068 - val_metrics_pearsonr: 0.0337\n",
      "Epoch 1481/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.3070 - metrics_pearsonr: 0.0301 - val_loss: 4.6022 - val_metrics_pearsonr: 0.0337\n",
      "Epoch 1482/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.3025 - metrics_pearsonr: 0.0301 - val_loss: 4.5976 - val_metrics_pearsonr: 0.0337\n",
      "Epoch 1483/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.2980 - metrics_pearsonr: 0.0300 - val_loss: 4.5930 - val_metrics_pearsonr: 0.0336\n",
      "Epoch 1484/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.2935 - metrics_pearsonr: 0.0300 - val_loss: 4.5884 - val_metrics_pearsonr: 0.0336\n",
      "Epoch 1485/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.2890 - metrics_pearsonr: 0.0300 - val_loss: 4.5838 - val_metrics_pearsonr: 0.0336\n",
      "Epoch 1486/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.2845 - metrics_pearsonr: 0.0299 - val_loss: 4.5793 - val_metrics_pearsonr: 0.0335\n",
      "Epoch 1487/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 4.2801 - metrics_pearsonr: 0.0299 - val_loss: 4.5747 - val_metrics_pearsonr: 0.0335\n",
      "Epoch 1488/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.2756 - metrics_pearsonr: 0.0299 - val_loss: 4.5702 - val_metrics_pearsonr: 0.0335\n",
      "Epoch 1489/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.2712 - metrics_pearsonr: 0.0298 - val_loss: 4.5657 - val_metrics_pearsonr: 0.0334\n",
      "Epoch 1490/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.2668 - metrics_pearsonr: 0.0298 - val_loss: 4.5612 - val_metrics_pearsonr: 0.0334\n",
      "Epoch 1491/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.2624 - metrics_pearsonr: 0.0298 - val_loss: 4.5568 - val_metrics_pearsonr: 0.0334\n",
      "Epoch 1492/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.2580 - metrics_pearsonr: 0.0298 - val_loss: 4.5523 - val_metrics_pearsonr: 0.0333\n",
      "Epoch 1493/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.2536 - metrics_pearsonr: 0.0297 - val_loss: 4.5479 - val_metrics_pearsonr: 0.0333\n",
      "Epoch 1494/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.2492 - metrics_pearsonr: 0.0297 - val_loss: 4.5435 - val_metrics_pearsonr: 0.0333\n",
      "Epoch 1495/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.2448 - metrics_pearsonr: 0.0297 - val_loss: 4.5391 - val_metrics_pearsonr: 0.0332\n",
      "Epoch 1496/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.2405 - metrics_pearsonr: 0.0296 - val_loss: 4.5347 - val_metrics_pearsonr: 0.0332\n",
      "Epoch 1497/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.2362 - metrics_pearsonr: 0.0296 - val_loss: 4.5303 - val_metrics_pearsonr: 0.0332\n",
      "Epoch 1498/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.2318 - metrics_pearsonr: 0.0296 - val_loss: 4.5259 - val_metrics_pearsonr: 0.0331\n",
      "Epoch 1499/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.2275 - metrics_pearsonr: 0.0295 - val_loss: 4.5216 - val_metrics_pearsonr: 0.0331\n",
      "Epoch 1500/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.2232 - metrics_pearsonr: 0.0295 - val_loss: 4.5172 - val_metrics_pearsonr: 0.0331\n",
      "Epoch 1501/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.2189 - metrics_pearsonr: 0.0295 - val_loss: 4.5129 - val_metrics_pearsonr: 0.0330\n",
      "Epoch 1502/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.2147 - metrics_pearsonr: 0.0295 - val_loss: 4.5086 - val_metrics_pearsonr: 0.0330\n",
      "Epoch 1503/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.2104 - metrics_pearsonr: 0.0294 - val_loss: 4.5043 - val_metrics_pearsonr: 0.0330\n",
      "Epoch 1504/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.2061 - metrics_pearsonr: 0.0294 - val_loss: 4.5000 - val_metrics_pearsonr: 0.0329\n",
      "Epoch 1505/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.2019 - metrics_pearsonr: 0.0294 - val_loss: 4.4958 - val_metrics_pearsonr: 0.0329\n",
      "Epoch 1506/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.1977 - metrics_pearsonr: 0.0293 - val_loss: 4.4915 - val_metrics_pearsonr: 0.0329\n",
      "Epoch 1507/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.1934 - metrics_pearsonr: 0.0293 - val_loss: 4.4872 - val_metrics_pearsonr: 0.0328\n",
      "Epoch 1508/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.1892 - metrics_pearsonr: 0.0293 - val_loss: 4.4830 - val_metrics_pearsonr: 0.0328\n",
      "Epoch 1509/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 4.1850 - metrics_pearsonr: 0.0292 - val_loss: 4.4788 - val_metrics_pearsonr: 0.0328\n",
      "Epoch 1510/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.1808 - metrics_pearsonr: 0.0292 - val_loss: 4.4745 - val_metrics_pearsonr: 0.0328\n",
      "Epoch 1511/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.1767 - metrics_pearsonr: 0.0292 - val_loss: 4.4703 - val_metrics_pearsonr: 0.0327\n",
      "Epoch 1512/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.1725 - metrics_pearsonr: 0.0292 - val_loss: 4.4661 - val_metrics_pearsonr: 0.0327\n",
      "Epoch 1513/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.1683 - metrics_pearsonr: 0.0291 - val_loss: 4.4618 - val_metrics_pearsonr: 0.0327\n",
      "Epoch 1514/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.1642 - metrics_pearsonr: 0.0291 - val_loss: 4.4576 - val_metrics_pearsonr: 0.0326\n",
      "Epoch 1515/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.1600 - metrics_pearsonr: 0.0291 - val_loss: 4.4534 - val_metrics_pearsonr: 0.0326\n",
      "Epoch 1516/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.1559 - metrics_pearsonr: 0.0290 - val_loss: 4.4491 - val_metrics_pearsonr: 0.0326\n",
      "Epoch 1517/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.1517 - metrics_pearsonr: 0.0290 - val_loss: 4.4448 - val_metrics_pearsonr: 0.0325\n",
      "Epoch 1518/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.1476 - metrics_pearsonr: 0.0290 - val_loss: 4.4406 - val_metrics_pearsonr: 0.0325\n",
      "Epoch 1519/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.1435 - metrics_pearsonr: 0.0290 - val_loss: 4.4362 - val_metrics_pearsonr: 0.0325\n",
      "Epoch 1520/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 4.1393 - metrics_pearsonr: 0.0289 - val_loss: 4.4319 - val_metrics_pearsonr: 0.0324\n",
      "Epoch 1521/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.1352 - metrics_pearsonr: 0.0289 - val_loss: 4.4275 - val_metrics_pearsonr: 0.0324\n",
      "Epoch 1522/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 4.1311 - metrics_pearsonr: 0.0289 - val_loss: 4.4231 - val_metrics_pearsonr: 0.0324\n",
      "Epoch 1523/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.1270 - metrics_pearsonr: 0.0288 - val_loss: 4.4187 - val_metrics_pearsonr: 0.0323\n",
      "Epoch 1524/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.1229 - metrics_pearsonr: 0.0288 - val_loss: 4.4143 - val_metrics_pearsonr: 0.0323\n",
      "Epoch 1525/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 4.1188 - metrics_pearsonr: 0.0288 - val_loss: 4.4098 - val_metrics_pearsonr: 0.0323\n",
      "Epoch 1526/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.1147 - metrics_pearsonr: 0.0288 - val_loss: 4.4053 - val_metrics_pearsonr: 0.0323\n",
      "Epoch 1527/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.1106 - metrics_pearsonr: 0.0287 - val_loss: 4.4009 - val_metrics_pearsonr: 0.0322\n",
      "Epoch 1528/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.1065 - metrics_pearsonr: 0.0287 - val_loss: 4.3964 - val_metrics_pearsonr: 0.0322\n",
      "Epoch 1529/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.1025 - metrics_pearsonr: 0.0287 - val_loss: 4.3919 - val_metrics_pearsonr: 0.0322\n",
      "Epoch 1530/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.0984 - metrics_pearsonr: 0.0286 - val_loss: 4.3875 - val_metrics_pearsonr: 0.0321\n",
      "Epoch 1531/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.0944 - metrics_pearsonr: 0.0286 - val_loss: 4.3832 - val_metrics_pearsonr: 0.0321\n",
      "Epoch 1532/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.0904 - metrics_pearsonr: 0.0286 - val_loss: 4.3788 - val_metrics_pearsonr: 0.0321\n",
      "Epoch 1533/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.0864 - metrics_pearsonr: 0.0286 - val_loss: 4.3746 - val_metrics_pearsonr: 0.0321\n",
      "Epoch 1534/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.0824 - metrics_pearsonr: 0.0285 - val_loss: 4.3703 - val_metrics_pearsonr: 0.0320\n",
      "Epoch 1535/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 4.0784 - metrics_pearsonr: 0.0285 - val_loss: 4.3661 - val_metrics_pearsonr: 0.0320\n",
      "Epoch 1536/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 4.0745 - metrics_pearsonr: 0.0285 - val_loss: 4.3620 - val_metrics_pearsonr: 0.0320\n",
      "Epoch 1537/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.0705 - metrics_pearsonr: 0.0285 - val_loss: 4.3579 - val_metrics_pearsonr: 0.0319\n",
      "Epoch 1538/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 4.0665 - metrics_pearsonr: 0.0284 - val_loss: 4.3538 - val_metrics_pearsonr: 0.0319\n",
      "Epoch 1539/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 4.0626 - metrics_pearsonr: 0.0284 - val_loss: 4.3498 - val_metrics_pearsonr: 0.0319\n",
      "Epoch 1540/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.0586 - metrics_pearsonr: 0.0284 - val_loss: 4.3457 - val_metrics_pearsonr: 0.0319\n",
      "Epoch 1541/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.0547 - metrics_pearsonr: 0.0283 - val_loss: 4.3417 - val_metrics_pearsonr: 0.0318\n",
      "Epoch 1542/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.0507 - metrics_pearsonr: 0.0283 - val_loss: 4.3377 - val_metrics_pearsonr: 0.0318\n",
      "Epoch 1543/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.0467 - metrics_pearsonr: 0.0283 - val_loss: 4.3338 - val_metrics_pearsonr: 0.0318\n",
      "Epoch 1544/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.0428 - metrics_pearsonr: 0.0283 - val_loss: 4.3298 - val_metrics_pearsonr: 0.0317\n",
      "Epoch 1545/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.0389 - metrics_pearsonr: 0.0282 - val_loss: 4.3259 - val_metrics_pearsonr: 0.0317\n",
      "Epoch 1546/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.0350 - metrics_pearsonr: 0.0282 - val_loss: 4.3221 - val_metrics_pearsonr: 0.0317\n",
      "Epoch 1547/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.0311 - metrics_pearsonr: 0.0282 - val_loss: 4.3182 - val_metrics_pearsonr: 0.0316\n",
      "Epoch 1548/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.0272 - metrics_pearsonr: 0.0281 - val_loss: 4.3144 - val_metrics_pearsonr: 0.0316\n",
      "Epoch 1549/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.0233 - metrics_pearsonr: 0.0281 - val_loss: 4.3106 - val_metrics_pearsonr: 0.0316\n",
      "Epoch 1550/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.0195 - metrics_pearsonr: 0.0281 - val_loss: 4.3069 - val_metrics_pearsonr: 0.0316\n",
      "Epoch 1551/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.0157 - metrics_pearsonr: 0.0281 - val_loss: 4.3032 - val_metrics_pearsonr: 0.0315\n",
      "Epoch 1552/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 4.0119 - metrics_pearsonr: 0.0280 - val_loss: 4.2995 - val_metrics_pearsonr: 0.0315\n",
      "Epoch 1553/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.0082 - metrics_pearsonr: 0.0280 - val_loss: 4.2958 - val_metrics_pearsonr: 0.0315\n",
      "Epoch 1554/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 4.0044 - metrics_pearsonr: 0.0280 - val_loss: 4.2922 - val_metrics_pearsonr: 0.0314\n",
      "Epoch 1555/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 4.0007 - metrics_pearsonr: 0.0280 - val_loss: 4.2886 - val_metrics_pearsonr: 0.0314\n",
      "Epoch 1556/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.9970 - metrics_pearsonr: 0.0279 - val_loss: 4.2850 - val_metrics_pearsonr: 0.0314\n",
      "Epoch 1557/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 3.9933 - metrics_pearsonr: 0.0279 - val_loss: 4.2814 - val_metrics_pearsonr: 0.0313\n",
      "Epoch 1558/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.9897 - metrics_pearsonr: 0.0279 - val_loss: 4.2778 - val_metrics_pearsonr: 0.0313\n",
      "Epoch 1559/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 3.9860 - metrics_pearsonr: 0.0279 - val_loss: 4.2742 - val_metrics_pearsonr: 0.0313\n",
      "Epoch 1560/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.9823 - metrics_pearsonr: 0.0278 - val_loss: 4.2706 - val_metrics_pearsonr: 0.0313\n",
      "Epoch 1561/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.9786 - metrics_pearsonr: 0.0278 - val_loss: 4.2669 - val_metrics_pearsonr: 0.0312\n",
      "Epoch 1562/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.9750 - metrics_pearsonr: 0.0278 - val_loss: 4.2633 - val_metrics_pearsonr: 0.0312\n",
      "Epoch 1563/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.9713 - metrics_pearsonr: 0.0277 - val_loss: 4.2596 - val_metrics_pearsonr: 0.0312\n",
      "Epoch 1564/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.9676 - metrics_pearsonr: 0.0277 - val_loss: 4.2558 - val_metrics_pearsonr: 0.0311\n",
      "Epoch 1565/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.9640 - metrics_pearsonr: 0.0277 - val_loss: 4.2521 - val_metrics_pearsonr: 0.0311\n",
      "Epoch 1566/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.9603 - metrics_pearsonr: 0.0277 - val_loss: 4.2482 - val_metrics_pearsonr: 0.0311\n",
      "Epoch 1567/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.9566 - metrics_pearsonr: 0.0276 - val_loss: 4.2443 - val_metrics_pearsonr: 0.0311\n",
      "Epoch 1568/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.9529 - metrics_pearsonr: 0.0276 - val_loss: 4.2404 - val_metrics_pearsonr: 0.0310\n",
      "Epoch 1569/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.9492 - metrics_pearsonr: 0.0276 - val_loss: 4.2364 - val_metrics_pearsonr: 0.0310\n",
      "Epoch 1570/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.9455 - metrics_pearsonr: 0.0276 - val_loss: 4.2324 - val_metrics_pearsonr: 0.0310\n",
      "Epoch 1571/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.9418 - metrics_pearsonr: 0.0275 - val_loss: 4.2283 - val_metrics_pearsonr: 0.0310\n",
      "Epoch 1572/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.9381 - metrics_pearsonr: 0.0275 - val_loss: 4.2243 - val_metrics_pearsonr: 0.0309\n",
      "Epoch 1573/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.9344 - metrics_pearsonr: 0.0275 - val_loss: 4.2202 - val_metrics_pearsonr: 0.0309\n",
      "Epoch 1574/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.9308 - metrics_pearsonr: 0.0275 - val_loss: 4.2161 - val_metrics_pearsonr: 0.0309\n",
      "Epoch 1575/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.9271 - metrics_pearsonr: 0.0274 - val_loss: 4.2121 - val_metrics_pearsonr: 0.0308\n",
      "Epoch 1576/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.9234 - metrics_pearsonr: 0.0274 - val_loss: 4.2081 - val_metrics_pearsonr: 0.0308\n",
      "Epoch 1577/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.9198 - metrics_pearsonr: 0.0274 - val_loss: 4.2041 - val_metrics_pearsonr: 0.0308\n",
      "Epoch 1578/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.9162 - metrics_pearsonr: 0.0274 - val_loss: 4.2002 - val_metrics_pearsonr: 0.0308\n",
      "Epoch 1579/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.9126 - metrics_pearsonr: 0.0273 - val_loss: 4.1964 - val_metrics_pearsonr: 0.0307\n",
      "Epoch 1580/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.9090 - metrics_pearsonr: 0.0273 - val_loss: 4.1926 - val_metrics_pearsonr: 0.0307\n",
      "Epoch 1581/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.9054 - metrics_pearsonr: 0.0273 - val_loss: 4.1889 - val_metrics_pearsonr: 0.0307\n",
      "Epoch 1582/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.9018 - metrics_pearsonr: 0.0273 - val_loss: 4.1851 - val_metrics_pearsonr: 0.0307\n",
      "Epoch 1583/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.8982 - metrics_pearsonr: 0.0272 - val_loss: 4.1815 - val_metrics_pearsonr: 0.0306\n",
      "Epoch 1584/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.8946 - metrics_pearsonr: 0.0272 - val_loss: 4.1778 - val_metrics_pearsonr: 0.0306\n",
      "Epoch 1585/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.8910 - metrics_pearsonr: 0.0272 - val_loss: 4.1742 - val_metrics_pearsonr: 0.0306\n",
      "Epoch 1586/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.8874 - metrics_pearsonr: 0.0271 - val_loss: 4.1706 - val_metrics_pearsonr: 0.0306\n",
      "Epoch 1587/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.8839 - metrics_pearsonr: 0.0271 - val_loss: 4.1671 - val_metrics_pearsonr: 0.0305\n",
      "Epoch 1588/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.8803 - metrics_pearsonr: 0.0271 - val_loss: 4.1635 - val_metrics_pearsonr: 0.0305\n",
      "Epoch 1589/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.8768 - metrics_pearsonr: 0.0271 - val_loss: 4.1600 - val_metrics_pearsonr: 0.0305\n",
      "Epoch 1590/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.8733 - metrics_pearsonr: 0.0270 - val_loss: 4.1565 - val_metrics_pearsonr: 0.0304\n",
      "Epoch 1591/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.8698 - metrics_pearsonr: 0.0270 - val_loss: 4.1531 - val_metrics_pearsonr: 0.0304\n",
      "Epoch 1592/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.8663 - metrics_pearsonr: 0.0270 - val_loss: 4.1497 - val_metrics_pearsonr: 0.0304\n",
      "Epoch 1593/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.8628 - metrics_pearsonr: 0.0270 - val_loss: 4.1463 - val_metrics_pearsonr: 0.0304\n",
      "Epoch 1594/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.8594 - metrics_pearsonr: 0.0269 - val_loss: 4.1429 - val_metrics_pearsonr: 0.0303\n",
      "Epoch 1595/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.8560 - metrics_pearsonr: 0.0269 - val_loss: 4.1396 - val_metrics_pearsonr: 0.0303\n",
      "Epoch 1596/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.8525 - metrics_pearsonr: 0.0269 - val_loss: 4.1362 - val_metrics_pearsonr: 0.0303\n",
      "Epoch 1597/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.8492 - metrics_pearsonr: 0.0269 - val_loss: 4.1329 - val_metrics_pearsonr: 0.0303\n",
      "Epoch 1598/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.8458 - metrics_pearsonr: 0.0268 - val_loss: 4.1296 - val_metrics_pearsonr: 0.0302\n",
      "Epoch 1599/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.8424 - metrics_pearsonr: 0.0268 - val_loss: 4.1262 - val_metrics_pearsonr: 0.0302\n",
      "Epoch 1600/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.8390 - metrics_pearsonr: 0.0268 - val_loss: 4.1229 - val_metrics_pearsonr: 0.0302\n",
      "Epoch 1601/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.8356 - metrics_pearsonr: 0.0268 - val_loss: 4.1195 - val_metrics_pearsonr: 0.0301\n",
      "Epoch 1602/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.8323 - metrics_pearsonr: 0.0267 - val_loss: 4.1162 - val_metrics_pearsonr: 0.0301\n",
      "Epoch 1603/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.8289 - metrics_pearsonr: 0.0267 - val_loss: 4.1128 - val_metrics_pearsonr: 0.0301\n",
      "Epoch 1604/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.8256 - metrics_pearsonr: 0.0267 - val_loss: 4.1093 - val_metrics_pearsonr: 0.0301\n",
      "Epoch 1605/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.8222 - metrics_pearsonr: 0.0267 - val_loss: 4.1059 - val_metrics_pearsonr: 0.0300\n",
      "Epoch 1606/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.8188 - metrics_pearsonr: 0.0266 - val_loss: 4.1024 - val_metrics_pearsonr: 0.0300\n",
      "Epoch 1607/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.8155 - metrics_pearsonr: 0.0266 - val_loss: 4.0989 - val_metrics_pearsonr: 0.0300\n",
      "Epoch 1608/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.8121 - metrics_pearsonr: 0.0266 - val_loss: 4.0953 - val_metrics_pearsonr: 0.0300\n",
      "Epoch 1609/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 3.8087 - metrics_pearsonr: 0.0266 - val_loss: 4.0917 - val_metrics_pearsonr: 0.0299\n",
      "Epoch 1610/5000\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 3.8054 - metrics_pearsonr: 0.0266 - val_loss: 4.0881 - val_metrics_pearsonr: 0.0299\n",
      "Epoch 1611/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.8020 - metrics_pearsonr: 0.0265 - val_loss: 4.0845 - val_metrics_pearsonr: 0.0299\n",
      "Epoch 1612/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.7986 - metrics_pearsonr: 0.0265 - val_loss: 4.0809 - val_metrics_pearsonr: 0.0299\n",
      "Epoch 1613/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.7953 - metrics_pearsonr: 0.0265 - val_loss: 4.0773 - val_metrics_pearsonr: 0.0298\n",
      "Epoch 1614/5000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 3.7919 - metrics_pearsonr: 0.0265 - val_loss: 4.0737 - val_metrics_pearsonr: 0.0298\n",
      "Epoch 1615/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.7886 - metrics_pearsonr: 0.0264 - val_loss: 4.0701 - val_metrics_pearsonr: 0.0298\n",
      "Epoch 1616/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.7853 - metrics_pearsonr: 0.0264 - val_loss: 4.0666 - val_metrics_pearsonr: 0.0298\n",
      "Epoch 1617/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.7819 - metrics_pearsonr: 0.0264 - val_loss: 4.0630 - val_metrics_pearsonr: 0.0297\n",
      "Epoch 1618/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.7786 - metrics_pearsonr: 0.0264 - val_loss: 4.0595 - val_metrics_pearsonr: 0.0297\n",
      "Epoch 1619/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.7753 - metrics_pearsonr: 0.0263 - val_loss: 4.0560 - val_metrics_pearsonr: 0.0297\n",
      "Epoch 1620/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.7720 - metrics_pearsonr: 0.0263 - val_loss: 4.0526 - val_metrics_pearsonr: 0.0297\n",
      "Epoch 1621/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.7687 - metrics_pearsonr: 0.0263 - val_loss: 4.0492 - val_metrics_pearsonr: 0.0296\n",
      "Epoch 1622/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.7654 - metrics_pearsonr: 0.0263 - val_loss: 4.0458 - val_metrics_pearsonr: 0.0296\n",
      "Epoch 1623/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.7621 - metrics_pearsonr: 0.0262 - val_loss: 4.0424 - val_metrics_pearsonr: 0.0296\n",
      "Epoch 1624/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.7589 - metrics_pearsonr: 0.0262 - val_loss: 4.0391 - val_metrics_pearsonr: 0.0296\n",
      "Epoch 1625/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.7556 - metrics_pearsonr: 0.0262 - val_loss: 4.0357 - val_metrics_pearsonr: 0.0295\n",
      "Epoch 1626/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.7523 - metrics_pearsonr: 0.0262 - val_loss: 4.0324 - val_metrics_pearsonr: 0.0295\n",
      "Epoch 1627/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.7491 - metrics_pearsonr: 0.0261 - val_loss: 4.0292 - val_metrics_pearsonr: 0.0295\n",
      "Epoch 1628/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.7458 - metrics_pearsonr: 0.0261 - val_loss: 4.0259 - val_metrics_pearsonr: 0.0295\n",
      "Epoch 1629/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.7426 - metrics_pearsonr: 0.0261 - val_loss: 4.0227 - val_metrics_pearsonr: 0.0294\n",
      "Epoch 1630/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.7394 - metrics_pearsonr: 0.0261 - val_loss: 4.0195 - val_metrics_pearsonr: 0.0294\n",
      "Epoch 1631/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.7362 - metrics_pearsonr: 0.0260 - val_loss: 4.0163 - val_metrics_pearsonr: 0.0294\n",
      "Epoch 1632/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.7330 - metrics_pearsonr: 0.0260 - val_loss: 4.0131 - val_metrics_pearsonr: 0.0294\n",
      "Epoch 1633/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.7298 - metrics_pearsonr: 0.0260 - val_loss: 4.0099 - val_metrics_pearsonr: 0.0293\n",
      "Epoch 1634/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.7266 - metrics_pearsonr: 0.0260 - val_loss: 4.0068 - val_metrics_pearsonr: 0.0293\n",
      "Epoch 1635/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.7234 - metrics_pearsonr: 0.0260 - val_loss: 4.0036 - val_metrics_pearsonr: 0.0293\n",
      "Epoch 1636/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.7203 - metrics_pearsonr: 0.0259 - val_loss: 4.0005 - val_metrics_pearsonr: 0.0293\n",
      "Epoch 1637/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.7171 - metrics_pearsonr: 0.0259 - val_loss: 3.9974 - val_metrics_pearsonr: 0.0292\n",
      "Epoch 1638/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.7140 - metrics_pearsonr: 0.0259 - val_loss: 3.9942 - val_metrics_pearsonr: 0.0292\n",
      "Epoch 1639/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.7109 - metrics_pearsonr: 0.0259 - val_loss: 3.9911 - val_metrics_pearsonr: 0.0292\n",
      "Epoch 1640/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.7078 - metrics_pearsonr: 0.0258 - val_loss: 3.9880 - val_metrics_pearsonr: 0.0292\n",
      "Epoch 1641/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 3.7047 - metrics_pearsonr: 0.0258 - val_loss: 3.9848 - val_metrics_pearsonr: 0.0291\n",
      "Epoch 1642/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.7015 - metrics_pearsonr: 0.0258 - val_loss: 3.9817 - val_metrics_pearsonr: 0.0291\n",
      "Epoch 1643/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.6984 - metrics_pearsonr: 0.0258 - val_loss: 3.9785 - val_metrics_pearsonr: 0.0291\n",
      "Epoch 1644/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.6953 - metrics_pearsonr: 0.0257 - val_loss: 3.9754 - val_metrics_pearsonr: 0.0291\n",
      "Epoch 1645/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.6922 - metrics_pearsonr: 0.0257 - val_loss: 3.9722 - val_metrics_pearsonr: 0.0290\n",
      "Epoch 1646/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.6891 - metrics_pearsonr: 0.0257 - val_loss: 3.9690 - val_metrics_pearsonr: 0.0290\n",
      "Epoch 1647/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.6860 - metrics_pearsonr: 0.0257 - val_loss: 3.9657 - val_metrics_pearsonr: 0.0290\n",
      "Epoch 1648/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.6829 - metrics_pearsonr: 0.0257 - val_loss: 3.9625 - val_metrics_pearsonr: 0.0290\n",
      "Epoch 1649/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 3.6799 - metrics_pearsonr: 0.0256 - val_loss: 3.9593 - val_metrics_pearsonr: 0.0290\n",
      "Epoch 1650/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.6768 - metrics_pearsonr: 0.0256 - val_loss: 3.9560 - val_metrics_pearsonr: 0.0289\n",
      "Epoch 1651/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.6737 - metrics_pearsonr: 0.0256 - val_loss: 3.9528 - val_metrics_pearsonr: 0.0289\n",
      "Epoch 1652/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.6706 - metrics_pearsonr: 0.0256 - val_loss: 3.9495 - val_metrics_pearsonr: 0.0289\n",
      "Epoch 1653/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.6675 - metrics_pearsonr: 0.0255 - val_loss: 3.9462 - val_metrics_pearsonr: 0.0289\n",
      "Epoch 1654/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.6645 - metrics_pearsonr: 0.0255 - val_loss: 3.9430 - val_metrics_pearsonr: 0.0288\n",
      "Epoch 1655/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.6614 - metrics_pearsonr: 0.0255 - val_loss: 3.9397 - val_metrics_pearsonr: 0.0288\n",
      "Epoch 1656/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.6583 - metrics_pearsonr: 0.0255 - val_loss: 3.9365 - val_metrics_pearsonr: 0.0288\n",
      "Epoch 1657/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.6553 - metrics_pearsonr: 0.0255 - val_loss: 3.9333 - val_metrics_pearsonr: 0.0288\n",
      "Epoch 1658/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.6522 - metrics_pearsonr: 0.0254 - val_loss: 3.9301 - val_metrics_pearsonr: 0.0287\n",
      "Epoch 1659/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.6492 - metrics_pearsonr: 0.0254 - val_loss: 3.9269 - val_metrics_pearsonr: 0.0287\n",
      "Epoch 1660/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.6461 - metrics_pearsonr: 0.0254 - val_loss: 3.9238 - val_metrics_pearsonr: 0.0287\n",
      "Epoch 1661/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.6431 - metrics_pearsonr: 0.0254 - val_loss: 3.9206 - val_metrics_pearsonr: 0.0287\n",
      "Epoch 1662/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.6401 - metrics_pearsonr: 0.0253 - val_loss: 3.9175 - val_metrics_pearsonr: 0.0286\n",
      "Epoch 1663/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.6371 - metrics_pearsonr: 0.0253 - val_loss: 3.9144 - val_metrics_pearsonr: 0.0286\n",
      "Epoch 1664/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.6340 - metrics_pearsonr: 0.0253 - val_loss: 3.9113 - val_metrics_pearsonr: 0.0286\n",
      "Epoch 1665/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.6310 - metrics_pearsonr: 0.0253 - val_loss: 3.9082 - val_metrics_pearsonr: 0.0286\n",
      "Epoch 1666/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.6280 - metrics_pearsonr: 0.0253 - val_loss: 3.9052 - val_metrics_pearsonr: 0.0286\n",
      "Epoch 1667/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.6250 - metrics_pearsonr: 0.0252 - val_loss: 3.9021 - val_metrics_pearsonr: 0.0285\n",
      "Epoch 1668/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.6220 - metrics_pearsonr: 0.0252 - val_loss: 3.8991 - val_metrics_pearsonr: 0.0285\n",
      "Epoch 1669/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.6191 - metrics_pearsonr: 0.0252 - val_loss: 3.8961 - val_metrics_pearsonr: 0.0285\n",
      "Epoch 1670/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.6161 - metrics_pearsonr: 0.0252 - val_loss: 3.8931 - val_metrics_pearsonr: 0.0285\n",
      "Epoch 1671/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.6131 - metrics_pearsonr: 0.0251 - val_loss: 3.8902 - val_metrics_pearsonr: 0.0284\n",
      "Epoch 1672/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.6102 - metrics_pearsonr: 0.0251 - val_loss: 3.8872 - val_metrics_pearsonr: 0.0284\n",
      "Epoch 1673/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.6072 - metrics_pearsonr: 0.0251 - val_loss: 3.8842 - val_metrics_pearsonr: 0.0284\n",
      "Epoch 1674/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.6043 - metrics_pearsonr: 0.0251 - val_loss: 3.8813 - val_metrics_pearsonr: 0.0284\n",
      "Epoch 1675/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.6014 - metrics_pearsonr: 0.0251 - val_loss: 3.8784 - val_metrics_pearsonr: 0.0284\n",
      "Epoch 1676/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.5984 - metrics_pearsonr: 0.0250 - val_loss: 3.8754 - val_metrics_pearsonr: 0.0283\n",
      "Epoch 1677/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.5955 - metrics_pearsonr: 0.0250 - val_loss: 3.8725 - val_metrics_pearsonr: 0.0283\n",
      "Epoch 1678/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.5926 - metrics_pearsonr: 0.0250 - val_loss: 3.8696 - val_metrics_pearsonr: 0.0283\n",
      "Epoch 1679/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.5897 - metrics_pearsonr: 0.0250 - val_loss: 3.8667 - val_metrics_pearsonr: 0.0283\n",
      "Epoch 1680/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.5868 - metrics_pearsonr: 0.0249 - val_loss: 3.8638 - val_metrics_pearsonr: 0.0282\n",
      "Epoch 1681/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.5840 - metrics_pearsonr: 0.0249 - val_loss: 3.8609 - val_metrics_pearsonr: 0.0282\n",
      "Epoch 1682/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.5811 - metrics_pearsonr: 0.0249 - val_loss: 3.8580 - val_metrics_pearsonr: 0.0282\n",
      "Epoch 1683/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.5782 - metrics_pearsonr: 0.0249 - val_loss: 3.8550 - val_metrics_pearsonr: 0.0282\n",
      "Epoch 1684/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.5753 - metrics_pearsonr: 0.0249 - val_loss: 3.8521 - val_metrics_pearsonr: 0.0281\n",
      "Epoch 1685/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.5725 - metrics_pearsonr: 0.0248 - val_loss: 3.8492 - val_metrics_pearsonr: 0.0281\n",
      "Epoch 1686/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.5696 - metrics_pearsonr: 0.0248 - val_loss: 3.8462 - val_metrics_pearsonr: 0.0281\n",
      "Epoch 1687/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.5667 - metrics_pearsonr: 0.0248 - val_loss: 3.8433 - val_metrics_pearsonr: 0.0281\n",
      "Epoch 1688/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.5639 - metrics_pearsonr: 0.0248 - val_loss: 3.8403 - val_metrics_pearsonr: 0.0281\n",
      "Epoch 1689/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 3.5610 - metrics_pearsonr: 0.0248 - val_loss: 3.8373 - val_metrics_pearsonr: 0.0280\n",
      "Epoch 1690/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 3.5582 - metrics_pearsonr: 0.0247 - val_loss: 3.8344 - val_metrics_pearsonr: 0.0280\n",
      "Epoch 1691/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.5554 - metrics_pearsonr: 0.0247 - val_loss: 3.8314 - val_metrics_pearsonr: 0.0280\n",
      "Epoch 1692/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 3.5525 - metrics_pearsonr: 0.0247 - val_loss: 3.8284 - val_metrics_pearsonr: 0.0280\n",
      "Epoch 1693/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.5497 - metrics_pearsonr: 0.0247 - val_loss: 3.8254 - val_metrics_pearsonr: 0.0279\n",
      "Epoch 1694/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.5468 - metrics_pearsonr: 0.0246 - val_loss: 3.8225 - val_metrics_pearsonr: 0.0279\n",
      "Epoch 1695/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.5440 - metrics_pearsonr: 0.0246 - val_loss: 3.8195 - val_metrics_pearsonr: 0.0279\n",
      "Epoch 1696/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.5412 - metrics_pearsonr: 0.0246 - val_loss: 3.8165 - val_metrics_pearsonr: 0.0279\n",
      "Epoch 1697/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.5384 - metrics_pearsonr: 0.0246 - val_loss: 3.8136 - val_metrics_pearsonr: 0.0279\n",
      "Epoch 1698/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.5356 - metrics_pearsonr: 0.0246 - val_loss: 3.8106 - val_metrics_pearsonr: 0.0278\n",
      "Epoch 1699/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.5327 - metrics_pearsonr: 0.0245 - val_loss: 3.8077 - val_metrics_pearsonr: 0.0278\n",
      "Epoch 1700/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.5299 - metrics_pearsonr: 0.0245 - val_loss: 3.8048 - val_metrics_pearsonr: 0.0278\n",
      "Epoch 1701/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.5271 - metrics_pearsonr: 0.0245 - val_loss: 3.8019 - val_metrics_pearsonr: 0.0278\n",
      "Epoch 1702/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.5243 - metrics_pearsonr: 0.0245 - val_loss: 3.7990 - val_metrics_pearsonr: 0.0278\n",
      "Epoch 1703/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.5215 - metrics_pearsonr: 0.0245 - val_loss: 3.7961 - val_metrics_pearsonr: 0.0277\n",
      "Epoch 1704/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.5188 - metrics_pearsonr: 0.0244 - val_loss: 3.7932 - val_metrics_pearsonr: 0.0277\n",
      "Epoch 1705/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.5160 - metrics_pearsonr: 0.0244 - val_loss: 3.7904 - val_metrics_pearsonr: 0.0277\n",
      "Epoch 1706/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.5132 - metrics_pearsonr: 0.0244 - val_loss: 3.7875 - val_metrics_pearsonr: 0.0277\n",
      "Epoch 1707/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.5104 - metrics_pearsonr: 0.0244 - val_loss: 3.7847 - val_metrics_pearsonr: 0.0276\n",
      "Epoch 1708/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.5077 - metrics_pearsonr: 0.0244 - val_loss: 3.7819 - val_metrics_pearsonr: 0.0276\n",
      "Epoch 1709/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.5049 - metrics_pearsonr: 0.0243 - val_loss: 3.7791 - val_metrics_pearsonr: 0.0276\n",
      "Epoch 1710/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.5021 - metrics_pearsonr: 0.0243 - val_loss: 3.7763 - val_metrics_pearsonr: 0.0276\n",
      "Epoch 1711/5000\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 3.4994 - metrics_pearsonr: 0.0243 - val_loss: 3.7735 - val_metrics_pearsonr: 0.0276\n",
      "Epoch 1712/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.4967 - metrics_pearsonr: 0.0243 - val_loss: 3.7708 - val_metrics_pearsonr: 0.0275\n",
      "Epoch 1713/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.4939 - metrics_pearsonr: 0.0243 - val_loss: 3.7680 - val_metrics_pearsonr: 0.0275\n",
      "Epoch 1714/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.4912 - metrics_pearsonr: 0.0242 - val_loss: 3.7653 - val_metrics_pearsonr: 0.0275\n",
      "Epoch 1715/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.4885 - metrics_pearsonr: 0.0242 - val_loss: 3.7625 - val_metrics_pearsonr: 0.0275\n",
      "Epoch 1716/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.4858 - metrics_pearsonr: 0.0242 - val_loss: 3.7598 - val_metrics_pearsonr: 0.0275\n",
      "Epoch 1717/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.4831 - metrics_pearsonr: 0.0242 - val_loss: 3.7571 - val_metrics_pearsonr: 0.0274\n",
      "Epoch 1718/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.4804 - metrics_pearsonr: 0.0241 - val_loss: 3.7544 - val_metrics_pearsonr: 0.0274\n",
      "Epoch 1719/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.4777 - metrics_pearsonr: 0.0241 - val_loss: 3.7516 - val_metrics_pearsonr: 0.0274\n",
      "Epoch 1720/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.4750 - metrics_pearsonr: 0.0241 - val_loss: 3.7489 - val_metrics_pearsonr: 0.0274\n",
      "Epoch 1721/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.4723 - metrics_pearsonr: 0.0241 - val_loss: 3.7462 - val_metrics_pearsonr: 0.0274\n",
      "Epoch 1722/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.4696 - metrics_pearsonr: 0.0241 - val_loss: 3.7435 - val_metrics_pearsonr: 0.0273\n",
      "Epoch 1723/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.4670 - metrics_pearsonr: 0.0240 - val_loss: 3.7408 - val_metrics_pearsonr: 0.0273\n",
      "Epoch 1724/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.4643 - metrics_pearsonr: 0.0240 - val_loss: 3.7381 - val_metrics_pearsonr: 0.0273\n",
      "Epoch 1725/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.4616 - metrics_pearsonr: 0.0240 - val_loss: 3.7354 - val_metrics_pearsonr: 0.0273\n",
      "Epoch 1726/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.4590 - metrics_pearsonr: 0.0240 - val_loss: 3.7327 - val_metrics_pearsonr: 0.0272\n",
      "Epoch 1727/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 3.4563 - metrics_pearsonr: 0.0240 - val_loss: 3.7300 - val_metrics_pearsonr: 0.0272\n",
      "Epoch 1728/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.4537 - metrics_pearsonr: 0.0239 - val_loss: 3.7272 - val_metrics_pearsonr: 0.0272\n",
      "Epoch 1729/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.4511 - metrics_pearsonr: 0.0239 - val_loss: 3.7245 - val_metrics_pearsonr: 0.0272\n",
      "Epoch 1730/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.4484 - metrics_pearsonr: 0.0239 - val_loss: 3.7218 - val_metrics_pearsonr: 0.0272\n",
      "Epoch 1731/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.4458 - metrics_pearsonr: 0.0239 - val_loss: 3.7190 - val_metrics_pearsonr: 0.0271\n",
      "Epoch 1732/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.4432 - metrics_pearsonr: 0.0239 - val_loss: 3.7163 - val_metrics_pearsonr: 0.0271\n",
      "Epoch 1733/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.4405 - metrics_pearsonr: 0.0238 - val_loss: 3.7135 - val_metrics_pearsonr: 0.0271\n",
      "Epoch 1734/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.4379 - metrics_pearsonr: 0.0238 - val_loss: 3.7108 - val_metrics_pearsonr: 0.0271\n",
      "Epoch 1735/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.4353 - metrics_pearsonr: 0.0238 - val_loss: 3.7081 - val_metrics_pearsonr: 0.0271\n",
      "Epoch 1736/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.4327 - metrics_pearsonr: 0.0238 - val_loss: 3.7053 - val_metrics_pearsonr: 0.0270\n",
      "Epoch 1737/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.4301 - metrics_pearsonr: 0.0238 - val_loss: 3.7026 - val_metrics_pearsonr: 0.0270\n",
      "Epoch 1738/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.4274 - metrics_pearsonr: 0.0237 - val_loss: 3.6998 - val_metrics_pearsonr: 0.0270\n",
      "Epoch 1739/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.4248 - metrics_pearsonr: 0.0237 - val_loss: 3.6971 - val_metrics_pearsonr: 0.0270\n",
      "Epoch 1740/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.4222 - metrics_pearsonr: 0.0237 - val_loss: 3.6944 - val_metrics_pearsonr: 0.0270\n",
      "Epoch 1741/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.4196 - metrics_pearsonr: 0.0237 - val_loss: 3.6917 - val_metrics_pearsonr: 0.0269\n",
      "Epoch 1742/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.4170 - metrics_pearsonr: 0.0237 - val_loss: 3.6890 - val_metrics_pearsonr: 0.0269\n",
      "Epoch 1743/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.4145 - metrics_pearsonr: 0.0237 - val_loss: 3.6863 - val_metrics_pearsonr: 0.0269\n",
      "Epoch 1744/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.4119 - metrics_pearsonr: 0.0236 - val_loss: 3.6837 - val_metrics_pearsonr: 0.0269\n",
      "Epoch 1745/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.4093 - metrics_pearsonr: 0.0236 - val_loss: 3.6810 - val_metrics_pearsonr: 0.0269\n",
      "Epoch 1746/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.4067 - metrics_pearsonr: 0.0236 - val_loss: 3.6783 - val_metrics_pearsonr: 0.0268\n",
      "Epoch 1747/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.4041 - metrics_pearsonr: 0.0236 - val_loss: 3.6757 - val_metrics_pearsonr: 0.0268\n",
      "Epoch 1748/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.4016 - metrics_pearsonr: 0.0236 - val_loss: 3.6731 - val_metrics_pearsonr: 0.0268\n",
      "Epoch 1749/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3990 - metrics_pearsonr: 0.0235 - val_loss: 3.6704 - val_metrics_pearsonr: 0.0268\n",
      "Epoch 1750/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.3964 - metrics_pearsonr: 0.0235 - val_loss: 3.6678 - val_metrics_pearsonr: 0.0268\n",
      "Epoch 1751/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.3939 - metrics_pearsonr: 0.0235 - val_loss: 3.6652 - val_metrics_pearsonr: 0.0267\n",
      "Epoch 1752/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.3913 - metrics_pearsonr: 0.0235 - val_loss: 3.6626 - val_metrics_pearsonr: 0.0267\n",
      "Epoch 1753/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.3888 - metrics_pearsonr: 0.0235 - val_loss: 3.6601 - val_metrics_pearsonr: 0.0267\n",
      "Epoch 1754/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.3862 - metrics_pearsonr: 0.0234 - val_loss: 3.6575 - val_metrics_pearsonr: 0.0267\n",
      "Epoch 1755/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.3837 - metrics_pearsonr: 0.0234 - val_loss: 3.6549 - val_metrics_pearsonr: 0.0267\n",
      "Epoch 1756/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.3812 - metrics_pearsonr: 0.0234 - val_loss: 3.6524 - val_metrics_pearsonr: 0.0266\n",
      "Epoch 1757/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.3787 - metrics_pearsonr: 0.0234 - val_loss: 3.6498 - val_metrics_pearsonr: 0.0266\n",
      "Epoch 1758/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.3761 - metrics_pearsonr: 0.0234 - val_loss: 3.6473 - val_metrics_pearsonr: 0.0266\n",
      "Epoch 1759/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.3736 - metrics_pearsonr: 0.0233 - val_loss: 3.6448 - val_metrics_pearsonr: 0.0266\n",
      "Epoch 1760/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.3711 - metrics_pearsonr: 0.0233 - val_loss: 3.6423 - val_metrics_pearsonr: 0.0266\n",
      "Epoch 1761/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.3686 - metrics_pearsonr: 0.0233 - val_loss: 3.6397 - val_metrics_pearsonr: 0.0265\n",
      "Epoch 1762/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.3661 - metrics_pearsonr: 0.0233 - val_loss: 3.6372 - val_metrics_pearsonr: 0.0265\n",
      "Epoch 1763/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3636 - metrics_pearsonr: 0.0233 - val_loss: 3.6347 - val_metrics_pearsonr: 0.0265\n",
      "Epoch 1764/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3612 - metrics_pearsonr: 0.0232 - val_loss: 3.6322 - val_metrics_pearsonr: 0.0265\n",
      "Epoch 1765/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 3.3587 - metrics_pearsonr: 0.0232 - val_loss: 3.6296 - val_metrics_pearsonr: 0.0265\n",
      "Epoch 1766/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 3.3562 - metrics_pearsonr: 0.0232 - val_loss: 3.6271 - val_metrics_pearsonr: 0.0265\n",
      "Epoch 1767/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 3.3538 - metrics_pearsonr: 0.0232 - val_loss: 3.6246 - val_metrics_pearsonr: 0.0264\n",
      "Epoch 1768/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.3513 - metrics_pearsonr: 0.0232 - val_loss: 3.6221 - val_metrics_pearsonr: 0.0264\n",
      "Epoch 1769/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 3.3488 - metrics_pearsonr: 0.0232 - val_loss: 3.6195 - val_metrics_pearsonr: 0.0264\n",
      "Epoch 1770/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.3464 - metrics_pearsonr: 0.0231 - val_loss: 3.6170 - val_metrics_pearsonr: 0.0264\n",
      "Epoch 1771/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3439 - metrics_pearsonr: 0.0231 - val_loss: 3.6144 - val_metrics_pearsonr: 0.0264\n",
      "Epoch 1772/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 3.3415 - metrics_pearsonr: 0.0231 - val_loss: 3.6119 - val_metrics_pearsonr: 0.0263\n",
      "Epoch 1773/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.3390 - metrics_pearsonr: 0.0231 - val_loss: 3.6094 - val_metrics_pearsonr: 0.0263\n",
      "Epoch 1774/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.3366 - metrics_pearsonr: 0.0231 - val_loss: 3.6068 - val_metrics_pearsonr: 0.0263\n",
      "Epoch 1775/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.3341 - metrics_pearsonr: 0.0230 - val_loss: 3.6043 - val_metrics_pearsonr: 0.0263\n",
      "Epoch 1776/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.3317 - metrics_pearsonr: 0.0230 - val_loss: 3.6017 - val_metrics_pearsonr: 0.0263\n",
      "Epoch 1777/5000\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 3.3293 - metrics_pearsonr: 0.0230 - val_loss: 3.5992 - val_metrics_pearsonr: 0.0262\n",
      "Epoch 1778/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.3268 - metrics_pearsonr: 0.0230 - val_loss: 3.5967 - val_metrics_pearsonr: 0.0262\n",
      "Epoch 1779/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.3244 - metrics_pearsonr: 0.0230 - val_loss: 3.5941 - val_metrics_pearsonr: 0.0262\n",
      "Epoch 1780/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3220 - metrics_pearsonr: 0.0229 - val_loss: 3.5916 - val_metrics_pearsonr: 0.0262\n",
      "Epoch 1781/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3196 - metrics_pearsonr: 0.0229 - val_loss: 3.5891 - val_metrics_pearsonr: 0.0262\n",
      "Epoch 1782/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.3172 - metrics_pearsonr: 0.0229 - val_loss: 3.5866 - val_metrics_pearsonr: 0.0261\n",
      "Epoch 1783/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3147 - metrics_pearsonr: 0.0229 - val_loss: 3.5840 - val_metrics_pearsonr: 0.0261\n",
      "Epoch 1784/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.3123 - metrics_pearsonr: 0.0229 - val_loss: 3.5815 - val_metrics_pearsonr: 0.0261\n",
      "Epoch 1785/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.3099 - metrics_pearsonr: 0.0229 - val_loss: 3.5791 - val_metrics_pearsonr: 0.0261\n",
      "Epoch 1786/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.3075 - metrics_pearsonr: 0.0228 - val_loss: 3.5766 - val_metrics_pearsonr: 0.0261\n",
      "Epoch 1787/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.3051 - metrics_pearsonr: 0.0228 - val_loss: 3.5741 - val_metrics_pearsonr: 0.0261\n",
      "Epoch 1788/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.3027 - metrics_pearsonr: 0.0228 - val_loss: 3.5716 - val_metrics_pearsonr: 0.0260\n",
      "Epoch 1789/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.3003 - metrics_pearsonr: 0.0228 - val_loss: 3.5692 - val_metrics_pearsonr: 0.0260\n",
      "Epoch 1790/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.2979 - metrics_pearsonr: 0.0228 - val_loss: 3.5667 - val_metrics_pearsonr: 0.0260\n",
      "Epoch 1791/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.2956 - metrics_pearsonr: 0.0227 - val_loss: 3.5643 - val_metrics_pearsonr: 0.0260\n",
      "Epoch 1792/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.2932 - metrics_pearsonr: 0.0227 - val_loss: 3.5618 - val_metrics_pearsonr: 0.0260\n",
      "Epoch 1793/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.2908 - metrics_pearsonr: 0.0227 - val_loss: 3.5594 - val_metrics_pearsonr: 0.0259\n",
      "Epoch 1794/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.2884 - metrics_pearsonr: 0.0227 - val_loss: 3.5570 - val_metrics_pearsonr: 0.0259\n",
      "Epoch 1795/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.2861 - metrics_pearsonr: 0.0227 - val_loss: 3.5546 - val_metrics_pearsonr: 0.0259\n",
      "Epoch 1796/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.2837 - metrics_pearsonr: 0.0227 - val_loss: 3.5522 - val_metrics_pearsonr: 0.0259\n",
      "Epoch 1797/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.2813 - metrics_pearsonr: 0.0226 - val_loss: 3.5498 - val_metrics_pearsonr: 0.0259\n",
      "Epoch 1798/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.2790 - metrics_pearsonr: 0.0226 - val_loss: 3.5474 - val_metrics_pearsonr: 0.0259\n",
      "Epoch 1799/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2766 - metrics_pearsonr: 0.0226 - val_loss: 3.5450 - val_metrics_pearsonr: 0.0258\n",
      "Epoch 1800/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.2743 - metrics_pearsonr: 0.0226 - val_loss: 3.5427 - val_metrics_pearsonr: 0.0258\n",
      "Epoch 1801/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.2719 - metrics_pearsonr: 0.0226 - val_loss: 3.5403 - val_metrics_pearsonr: 0.0258\n",
      "Epoch 1802/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2696 - metrics_pearsonr: 0.0225 - val_loss: 3.5379 - val_metrics_pearsonr: 0.0258\n",
      "Epoch 1803/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.2673 - metrics_pearsonr: 0.0225 - val_loss: 3.5356 - val_metrics_pearsonr: 0.0258\n",
      "Epoch 1804/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.2650 - metrics_pearsonr: 0.0225 - val_loss: 3.5332 - val_metrics_pearsonr: 0.0257\n",
      "Epoch 1805/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.2626 - metrics_pearsonr: 0.0225 - val_loss: 3.5308 - val_metrics_pearsonr: 0.0257\n",
      "Epoch 1806/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.2603 - metrics_pearsonr: 0.0225 - val_loss: 3.5285 - val_metrics_pearsonr: 0.0257\n",
      "Epoch 1807/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.2580 - metrics_pearsonr: 0.0225 - val_loss: 3.5261 - val_metrics_pearsonr: 0.0257\n",
      "Epoch 1808/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.2557 - metrics_pearsonr: 0.0224 - val_loss: 3.5238 - val_metrics_pearsonr: 0.0257\n",
      "Epoch 1809/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.2534 - metrics_pearsonr: 0.0224 - val_loss: 3.5214 - val_metrics_pearsonr: 0.0257\n",
      "Epoch 1810/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.2511 - metrics_pearsonr: 0.0224 - val_loss: 3.5191 - val_metrics_pearsonr: 0.0256\n",
      "Epoch 1811/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.2488 - metrics_pearsonr: 0.0224 - val_loss: 3.5167 - val_metrics_pearsonr: 0.0256\n",
      "Epoch 1812/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.2465 - metrics_pearsonr: 0.0224 - val_loss: 3.5143 - val_metrics_pearsonr: 0.0256\n",
      "Epoch 1813/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.2442 - metrics_pearsonr: 0.0224 - val_loss: 3.5120 - val_metrics_pearsonr: 0.0256\n",
      "Epoch 1814/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2420 - metrics_pearsonr: 0.0223 - val_loss: 3.5096 - val_metrics_pearsonr: 0.0256\n",
      "Epoch 1815/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2397 - metrics_pearsonr: 0.0223 - val_loss: 3.5072 - val_metrics_pearsonr: 0.0255\n",
      "Epoch 1816/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.2374 - metrics_pearsonr: 0.0223 - val_loss: 3.5049 - val_metrics_pearsonr: 0.0255\n",
      "Epoch 1817/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2351 - metrics_pearsonr: 0.0223 - val_loss: 3.5025 - val_metrics_pearsonr: 0.0255\n",
      "Epoch 1818/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.2329 - metrics_pearsonr: 0.0223 - val_loss: 3.5001 - val_metrics_pearsonr: 0.0255\n",
      "Epoch 1819/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.2306 - metrics_pearsonr: 0.0222 - val_loss: 3.4978 - val_metrics_pearsonr: 0.0255\n",
      "Epoch 1820/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.2283 - metrics_pearsonr: 0.0222 - val_loss: 3.4954 - val_metrics_pearsonr: 0.0255\n",
      "Epoch 1821/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.2261 - metrics_pearsonr: 0.0222 - val_loss: 3.4930 - val_metrics_pearsonr: 0.0254\n",
      "Epoch 1822/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2238 - metrics_pearsonr: 0.0222 - val_loss: 3.4907 - val_metrics_pearsonr: 0.0254\n",
      "Epoch 1823/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.2216 - metrics_pearsonr: 0.0222 - val_loss: 3.4883 - val_metrics_pearsonr: 0.0254\n",
      "Epoch 1824/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.2193 - metrics_pearsonr: 0.0222 - val_loss: 3.4860 - val_metrics_pearsonr: 0.0254\n",
      "Epoch 1825/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.2171 - metrics_pearsonr: 0.0221 - val_loss: 3.4836 - val_metrics_pearsonr: 0.0254\n",
      "Epoch 1826/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.2148 - metrics_pearsonr: 0.0221 - val_loss: 3.4813 - val_metrics_pearsonr: 0.0254\n",
      "Epoch 1827/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.2126 - metrics_pearsonr: 0.0221 - val_loss: 3.4790 - val_metrics_pearsonr: 0.0253\n",
      "Epoch 1828/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.2103 - metrics_pearsonr: 0.0221 - val_loss: 3.4767 - val_metrics_pearsonr: 0.0253\n",
      "Epoch 1829/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.2081 - metrics_pearsonr: 0.0221 - val_loss: 3.4743 - val_metrics_pearsonr: 0.0253\n",
      "Epoch 1830/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.2058 - metrics_pearsonr: 0.0221 - val_loss: 3.4720 - val_metrics_pearsonr: 0.0253\n",
      "Epoch 1831/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.2036 - metrics_pearsonr: 0.0220 - val_loss: 3.4697 - val_metrics_pearsonr: 0.0253\n",
      "Epoch 1832/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.2014 - metrics_pearsonr: 0.0220 - val_loss: 3.4674 - val_metrics_pearsonr: 0.0252\n",
      "Epoch 1833/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.1992 - metrics_pearsonr: 0.0220 - val_loss: 3.4651 - val_metrics_pearsonr: 0.0252\n",
      "Epoch 1834/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.1969 - metrics_pearsonr: 0.0220 - val_loss: 3.4628 - val_metrics_pearsonr: 0.0252\n",
      "Epoch 1835/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.1947 - metrics_pearsonr: 0.0220 - val_loss: 3.4606 - val_metrics_pearsonr: 0.0252\n",
      "Epoch 1836/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.1925 - metrics_pearsonr: 0.0220 - val_loss: 3.4583 - val_metrics_pearsonr: 0.0252\n",
      "Epoch 1837/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1903 - metrics_pearsonr: 0.0219 - val_loss: 3.4560 - val_metrics_pearsonr: 0.0252\n",
      "Epoch 1838/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.1881 - metrics_pearsonr: 0.0219 - val_loss: 3.4538 - val_metrics_pearsonr: 0.0251\n",
      "Epoch 1839/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.1859 - metrics_pearsonr: 0.0219 - val_loss: 3.4515 - val_metrics_pearsonr: 0.0251\n",
      "Epoch 1840/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1837 - metrics_pearsonr: 0.0219 - val_loss: 3.4493 - val_metrics_pearsonr: 0.0251\n",
      "Epoch 1841/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.1815 - metrics_pearsonr: 0.0219 - val_loss: 3.4471 - val_metrics_pearsonr: 0.0251\n",
      "Epoch 1842/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1793 - metrics_pearsonr: 0.0218 - val_loss: 3.4448 - val_metrics_pearsonr: 0.0251\n",
      "Epoch 1843/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.1771 - metrics_pearsonr: 0.0218 - val_loss: 3.4426 - val_metrics_pearsonr: 0.0251\n",
      "Epoch 1844/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1749 - metrics_pearsonr: 0.0218 - val_loss: 3.4404 - val_metrics_pearsonr: 0.0250\n",
      "Epoch 1845/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.1727 - metrics_pearsonr: 0.0218 - val_loss: 3.4382 - val_metrics_pearsonr: 0.0250\n",
      "Epoch 1846/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1706 - metrics_pearsonr: 0.0218 - val_loss: 3.4360 - val_metrics_pearsonr: 0.0250\n",
      "Epoch 1847/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.1684 - metrics_pearsonr: 0.0218 - val_loss: 3.4337 - val_metrics_pearsonr: 0.0250\n",
      "Epoch 1848/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.1662 - metrics_pearsonr: 0.0217 - val_loss: 3.4315 - val_metrics_pearsonr: 0.0250\n",
      "Epoch 1849/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.1641 - metrics_pearsonr: 0.0217 - val_loss: 3.4293 - val_metrics_pearsonr: 0.0250\n",
      "Epoch 1850/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.1619 - metrics_pearsonr: 0.0217 - val_loss: 3.4271 - val_metrics_pearsonr: 0.0249\n",
      "Epoch 1851/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 3.1597 - metrics_pearsonr: 0.0217 - val_loss: 3.4249 - val_metrics_pearsonr: 0.0249\n",
      "Epoch 1852/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.1576 - metrics_pearsonr: 0.0217 - val_loss: 3.4227 - val_metrics_pearsonr: 0.0249\n",
      "Epoch 1853/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.1555 - metrics_pearsonr: 0.0217 - val_loss: 3.4205 - val_metrics_pearsonr: 0.0249\n",
      "Epoch 1854/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 3.1533 - metrics_pearsonr: 0.0216 - val_loss: 3.4183 - val_metrics_pearsonr: 0.0249\n",
      "Epoch 1855/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.1512 - metrics_pearsonr: 0.0216 - val_loss: 3.4161 - val_metrics_pearsonr: 0.0249\n",
      "Epoch 1856/5000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.1490 - metrics_pearsonr: 0.0216 - val_loss: 3.4139 - val_metrics_pearsonr: 0.0248\n",
      "Epoch 1857/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.1469 - metrics_pearsonr: 0.0216 - val_loss: 3.4117 - val_metrics_pearsonr: 0.0248\n",
      "Epoch 1858/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.1448 - metrics_pearsonr: 0.0216 - val_loss: 3.4095 - val_metrics_pearsonr: 0.0248\n",
      "Epoch 1859/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.1427 - metrics_pearsonr: 0.0216 - val_loss: 3.4073 - val_metrics_pearsonr: 0.0248\n",
      "Epoch 1860/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 3.1405 - metrics_pearsonr: 0.0215 - val_loss: 3.4051 - val_metrics_pearsonr: 0.0248\n",
      "Epoch 1861/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 3.1384 - metrics_pearsonr: 0.0215 - val_loss: 3.4029 - val_metrics_pearsonr: 0.0248\n",
      "Epoch 1862/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 3.1363 - metrics_pearsonr: 0.0215 - val_loss: 3.4006 - val_metrics_pearsonr: 0.0247\n",
      "Epoch 1863/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.1342 - metrics_pearsonr: 0.0215 - val_loss: 3.3984 - val_metrics_pearsonr: 0.0247\n",
      "Epoch 1864/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 3.1321 - metrics_pearsonr: 0.0215 - val_loss: 3.3962 - val_metrics_pearsonr: 0.0247\n",
      "Epoch 1865/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.1300 - metrics_pearsonr: 0.0215 - val_loss: 3.3940 - val_metrics_pearsonr: 0.0247\n",
      "Epoch 1866/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.1279 - metrics_pearsonr: 0.0215 - val_loss: 3.3918 - val_metrics_pearsonr: 0.0247\n",
      "Epoch 1867/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.1258 - metrics_pearsonr: 0.0214 - val_loss: 3.3896 - val_metrics_pearsonr: 0.0247\n",
      "Epoch 1868/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.1237 - metrics_pearsonr: 0.0214 - val_loss: 3.3874 - val_metrics_pearsonr: 0.0246\n",
      "Epoch 1869/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 3.1216 - metrics_pearsonr: 0.0214 - val_loss: 3.3853 - val_metrics_pearsonr: 0.0246\n",
      "Epoch 1870/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.1195 - metrics_pearsonr: 0.0214 - val_loss: 3.3831 - val_metrics_pearsonr: 0.0246\n",
      "Epoch 1871/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.1174 - metrics_pearsonr: 0.0214 - val_loss: 3.3809 - val_metrics_pearsonr: 0.0246\n",
      "Epoch 1872/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1153 - metrics_pearsonr: 0.0214 - val_loss: 3.3787 - val_metrics_pearsonr: 0.0246\n",
      "Epoch 1873/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.1132 - metrics_pearsonr: 0.0213 - val_loss: 3.3766 - val_metrics_pearsonr: 0.0246\n",
      "Epoch 1874/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.1111 - metrics_pearsonr: 0.0213 - val_loss: 3.3744 - val_metrics_pearsonr: 0.0245\n",
      "Epoch 1875/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.1090 - metrics_pearsonr: 0.0213 - val_loss: 3.3722 - val_metrics_pearsonr: 0.0245\n",
      "Epoch 1876/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.1070 - metrics_pearsonr: 0.0213 - val_loss: 3.3701 - val_metrics_pearsonr: 0.0245\n",
      "Epoch 1877/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.1049 - metrics_pearsonr: 0.0213 - val_loss: 3.3679 - val_metrics_pearsonr: 0.0245\n",
      "Epoch 1878/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.1028 - metrics_pearsonr: 0.0213 - val_loss: 3.3658 - val_metrics_pearsonr: 0.0245\n",
      "Epoch 1879/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.1007 - metrics_pearsonr: 0.0212 - val_loss: 3.3637 - val_metrics_pearsonr: 0.0245\n",
      "Epoch 1880/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.0987 - metrics_pearsonr: 0.0212 - val_loss: 3.3615 - val_metrics_pearsonr: 0.0244\n",
      "Epoch 1881/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.0966 - metrics_pearsonr: 0.0212 - val_loss: 3.3594 - val_metrics_pearsonr: 0.0244\n",
      "Epoch 1882/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.0945 - metrics_pearsonr: 0.0212 - val_loss: 3.3573 - val_metrics_pearsonr: 0.0244\n",
      "Epoch 1883/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.0925 - metrics_pearsonr: 0.0212 - val_loss: 3.3552 - val_metrics_pearsonr: 0.0244\n",
      "Epoch 1884/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.0904 - metrics_pearsonr: 0.0212 - val_loss: 3.3531 - val_metrics_pearsonr: 0.0244\n",
      "Epoch 1885/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.0884 - metrics_pearsonr: 0.0211 - val_loss: 3.3510 - val_metrics_pearsonr: 0.0244\n",
      "Epoch 1886/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.0863 - metrics_pearsonr: 0.0211 - val_loss: 3.3489 - val_metrics_pearsonr: 0.0243\n",
      "Epoch 1887/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.0843 - metrics_pearsonr: 0.0211 - val_loss: 3.3468 - val_metrics_pearsonr: 0.0243\n",
      "Epoch 1888/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.0822 - metrics_pearsonr: 0.0211 - val_loss: 3.3447 - val_metrics_pearsonr: 0.0243\n",
      "Epoch 1889/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.0802 - metrics_pearsonr: 0.0211 - val_loss: 3.3427 - val_metrics_pearsonr: 0.0243\n",
      "Epoch 1890/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.0782 - metrics_pearsonr: 0.0211 - val_loss: 3.3406 - val_metrics_pearsonr: 0.0243\n",
      "Epoch 1891/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.0761 - metrics_pearsonr: 0.0210 - val_loss: 3.3385 - val_metrics_pearsonr: 0.0243\n",
      "Epoch 1892/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.0741 - metrics_pearsonr: 0.0210 - val_loss: 3.3364 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1893/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.0721 - metrics_pearsonr: 0.0210 - val_loss: 3.3344 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1894/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.0701 - metrics_pearsonr: 0.0210 - val_loss: 3.3323 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1895/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.0681 - metrics_pearsonr: 0.0210 - val_loss: 3.3302 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1896/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.0660 - metrics_pearsonr: 0.0210 - val_loss: 3.3282 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1897/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.0640 - metrics_pearsonr: 0.0210 - val_loss: 3.3261 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1898/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.0620 - metrics_pearsonr: 0.0209 - val_loss: 3.3241 - val_metrics_pearsonr: 0.0242\n",
      "Epoch 1899/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.0600 - metrics_pearsonr: 0.0209 - val_loss: 3.3220 - val_metrics_pearsonr: 0.0241\n",
      "Epoch 1900/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.0580 - metrics_pearsonr: 0.0209 - val_loss: 3.3199 - val_metrics_pearsonr: 0.0241\n",
      "Epoch 1901/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.0560 - metrics_pearsonr: 0.0209 - val_loss: 3.3179 - val_metrics_pearsonr: 0.0241\n",
      "Epoch 1902/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.0541 - metrics_pearsonr: 0.0209 - val_loss: 3.3158 - val_metrics_pearsonr: 0.0241\n",
      "Epoch 1903/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.0521 - metrics_pearsonr: 0.0209 - val_loss: 3.3138 - val_metrics_pearsonr: 0.0241\n",
      "Epoch 1904/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.0501 - metrics_pearsonr: 0.0208 - val_loss: 3.3117 - val_metrics_pearsonr: 0.0241\n",
      "Epoch 1905/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.0481 - metrics_pearsonr: 0.0208 - val_loss: 3.3096 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1906/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.0461 - metrics_pearsonr: 0.0208 - val_loss: 3.3076 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1907/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.0441 - metrics_pearsonr: 0.0208 - val_loss: 3.3055 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1908/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.0422 - metrics_pearsonr: 0.0208 - val_loss: 3.3035 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1909/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.0402 - metrics_pearsonr: 0.0208 - val_loss: 3.3014 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1910/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 3.0382 - metrics_pearsonr: 0.0208 - val_loss: 3.2993 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1911/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 3.0363 - metrics_pearsonr: 0.0207 - val_loss: 3.2973 - val_metrics_pearsonr: 0.0240\n",
      "Epoch 1912/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.0343 - metrics_pearsonr: 0.0207 - val_loss: 3.2952 - val_metrics_pearsonr: 0.0239\n",
      "Epoch 1913/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.0324 - metrics_pearsonr: 0.0207 - val_loss: 3.2932 - val_metrics_pearsonr: 0.0239\n",
      "Epoch 1914/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.0304 - metrics_pearsonr: 0.0207 - val_loss: 3.2911 - val_metrics_pearsonr: 0.0239\n",
      "Epoch 1915/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.0284 - metrics_pearsonr: 0.0207 - val_loss: 3.2891 - val_metrics_pearsonr: 0.0239\n",
      "Epoch 1916/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.0265 - metrics_pearsonr: 0.0207 - val_loss: 3.2871 - val_metrics_pearsonr: 0.0239\n",
      "Epoch 1917/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 3.0245 - metrics_pearsonr: 0.0206 - val_loss: 3.2850 - val_metrics_pearsonr: 0.0239\n",
      "Epoch 1918/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.0226 - metrics_pearsonr: 0.0206 - val_loss: 3.2830 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1919/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.0207 - metrics_pearsonr: 0.0206 - val_loss: 3.2809 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1920/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 3.0187 - metrics_pearsonr: 0.0206 - val_loss: 3.2789 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1921/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 3.0168 - metrics_pearsonr: 0.0206 - val_loss: 3.2769 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1922/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 3.0148 - metrics_pearsonr: 0.0206 - val_loss: 3.2749 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1923/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.0129 - metrics_pearsonr: 0.0206 - val_loss: 3.2729 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1924/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 3.0110 - metrics_pearsonr: 0.0205 - val_loss: 3.2708 - val_metrics_pearsonr: 0.0238\n",
      "Epoch 1925/5000\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 3.0090 - metrics_pearsonr: 0.0205 - val_loss: 3.2688 - val_metrics_pearsonr: 0.0237\n",
      "Epoch 1926/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 3.0071 - metrics_pearsonr: 0.0205 - val_loss: 3.2668 - val_metrics_pearsonr: 0.0237\n",
      "Epoch 1927/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 3.0052 - metrics_pearsonr: 0.0205 - val_loss: 3.2648 - val_metrics_pearsonr: 0.0237\n",
      "Epoch 1928/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 3.0032 - metrics_pearsonr: 0.0205 - val_loss: 3.2629 - val_metrics_pearsonr: 0.0237\n",
      "Epoch 1929/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 3.0013 - metrics_pearsonr: 0.0205 - val_loss: 3.2609 - val_metrics_pearsonr: 0.0237\n",
      "Epoch 1930/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.9994 - metrics_pearsonr: 0.0205 - val_loss: 3.2589 - val_metrics_pearsonr: 0.0237\n",
      "Epoch 1931/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.9975 - metrics_pearsonr: 0.0204 - val_loss: 3.2569 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1932/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.9956 - metrics_pearsonr: 0.0204 - val_loss: 3.2549 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1933/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.9936 - metrics_pearsonr: 0.0204 - val_loss: 3.2530 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1934/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.9917 - metrics_pearsonr: 0.0204 - val_loss: 3.2510 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1935/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 2.9898 - metrics_pearsonr: 0.0204 - val_loss: 3.2490 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1936/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.9879 - metrics_pearsonr: 0.0204 - val_loss: 3.2471 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1937/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.9860 - metrics_pearsonr: 0.0203 - val_loss: 3.2451 - val_metrics_pearsonr: 0.0236\n",
      "Epoch 1938/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.9841 - metrics_pearsonr: 0.0203 - val_loss: 3.2432 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1939/5000\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 2.9822 - metrics_pearsonr: 0.0203 - val_loss: 3.2412 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1940/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.9803 - metrics_pearsonr: 0.0203 - val_loss: 3.2393 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1941/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.9784 - metrics_pearsonr: 0.0203 - val_loss: 3.2374 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1942/5000\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 2.9765 - metrics_pearsonr: 0.0203 - val_loss: 3.2354 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1943/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.9746 - metrics_pearsonr: 0.0203 - val_loss: 3.2335 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1944/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.9727 - metrics_pearsonr: 0.0202 - val_loss: 3.2316 - val_metrics_pearsonr: 0.0235\n",
      "Epoch 1945/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.9709 - metrics_pearsonr: 0.0202 - val_loss: 3.2296 - val_metrics_pearsonr: 0.0234\n",
      "Epoch 1946/5000\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 2.9690 - metrics_pearsonr: 0.0202 - val_loss: 3.2277 - val_metrics_pearsonr: 0.0234\n",
      "Epoch 1947/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.9671 - metrics_pearsonr: 0.0202 - val_loss: 3.2258 - val_metrics_pearsonr: 0.0234\n",
      "Epoch 1948/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.9652 - metrics_pearsonr: 0.0202 - val_loss: 3.2239 - val_metrics_pearsonr: 0.0234\n",
      "Epoch 1949/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.9634 - metrics_pearsonr: 0.0202 - val_loss: 3.2220 - val_metrics_pearsonr: 0.0234\n",
      "Epoch 1950/5000\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 2.9615 - metrics_pearsonr: 0.0202 - val_loss: 3.2200 - val_metrics_pearsonr: 0.0234\n",
      "Epoch 1951/5000\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 2.9596 - metrics_pearsonr: 0.0201 - val_loss: 3.2181 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1952/5000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.9578 - metrics_pearsonr: 0.0201 - val_loss: 3.2162 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1953/5000\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.9559 - metrics_pearsonr: 0.0201 - val_loss: 3.2143 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1954/5000\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 2.9541 - metrics_pearsonr: 0.0201 - val_loss: 3.2124 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1955/5000\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 2.9522 - metrics_pearsonr: 0.0201 - val_loss: 3.2105 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1956/5000\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 2.9504 - metrics_pearsonr: 0.0201 - val_loss: 3.2086 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1957/5000\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 2.9485 - metrics_pearsonr: 0.0201 - val_loss: 3.2067 - val_metrics_pearsonr: 0.0233\n",
      "Epoch 1958/5000\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 2.9467 - metrics_pearsonr: 0.0200 - val_loss: 3.2047 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1959/5000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 2.9449 - metrics_pearsonr: 0.0200 - val_loss: 3.2028 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1960/5000\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 2.9430 - metrics_pearsonr: 0.0200 - val_loss: 3.2009 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1961/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 2.9412 - metrics_pearsonr: 0.0200 - val_loss: 3.1990 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1962/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 2.9394 - metrics_pearsonr: 0.0200 - val_loss: 3.1971 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1963/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 2.9375 - metrics_pearsonr: 0.0200 - val_loss: 3.1952 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1964/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 2.9357 - metrics_pearsonr: 0.0199 - val_loss: 3.1933 - val_metrics_pearsonr: 0.0232\n",
      "Epoch 1965/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 2.9339 - metrics_pearsonr: 0.0199 - val_loss: 3.1914 - val_metrics_pearsonr: 0.0231\n"
     ]
    }
   ],
   "source": [
    "model,predicty,testy,r,p,weights=Auto_Transformer(vy,vx,6,[['transformer'],['fc',7]],test_size=0.2,valid_size=0.1,k_fold=5,task_mode='regression',if_best_mode='no',modelpath=None,encoder_deep=1,num_heads=1,key_dim=1,ifdropout='no',trans_dropout_rate=0.0,trans_units=256,trans_activation='tanh',embedding_num=None,if_weight_initialize='no',weight_initialize_method='TruncatedNormal',weight_initialize_parameter1=0.00,weight_initialize_parameter2=0.05,if_print_model='yes',loss_function='default',optimizer='Adam',metrics='Pearsonr',if_early_stopping=1000,learning_rate=0.0001,epochs=5000,batch_size=5000,ifrandom_split='yes',ifweight='no',ifmute='no',ifsave='yes',savepath='E:/huawei/huawei_gnss_wind_u_30min_press_k5_onestation_45',device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f567a-a1dd-44d8-ae75-32e5c3444498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmean(np.abs(testy-predicty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3ea65-a427-49f2-8c0a-8c13eb49f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testy.shape,predicty.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8da8d-a175-4d49-a95b-fe7772942950",
   "metadata": {},
   "outputs": [],
   "source": [
    "times=np.arange(3519)\n",
    "testy_u=testy\n",
    "predicty_u=predicty\n",
    "levels=[1000,925,850,700,600,500,400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96deff50-b780-48c5-b826-5a0b87e142ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times', 'levels')\n",
    "\n",
    "\n",
    "testy_u_da = xr.DataArray(\n",
    "    data=testy_u,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='testy_u' \n",
    ")\n",
    "\n",
    "\n",
    "predicty_u_da = xr.DataArray(\n",
    "    data=predicty_u,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_u'\n",
    ")\n",
    "\n",
    "testy_u_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_u_onestation_45.nc')\n",
    "predicty_u_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_u_onestation_45.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da782789-c599-4b53-b10c-c6c3133369fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "testy_u_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_testy_u_onestation_45.nc')\n",
    "predicty_u_file=xr.open_dataset('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_u_onestation_45.nc')\n",
    "testy_u=np.array(testy_u_file['testy_u'])\n",
    "predicty_u=np.array(predicty_u_file['predicty_u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f862ec-d92c-46f0-8cd2-402f35c377aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CDF匹配\n",
    "def Auto_cdf_matching(vx,vy):\n",
    "    import numpy as np\n",
    "    from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    if np.array(vx).ndim==1:\n",
    "        vx_cdf = (np.arange(len(vx)) +  1) / (len(vx))\n",
    "        vy_cdf = (np.arange(len(vy)) +  1) / (len(vy))\n",
    "        \n",
    "        spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx))\n",
    "        vx_interp = spl(vy_cdf)\n",
    "        \n",
    "        def func(x, a, b, c, d):\n",
    "            return a*x + b*x**2 + c*x**3 + d\n",
    "        \n",
    "        popt = curve_fit(func, vx_interp, np.sort(vy))[0]\n",
    "        \n",
    "        matched_vx = func(vx, *popt)\n",
    "    elif np.array(vx).ndim==2:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            vx_cdf = (np.arange(len(vx[:,i])) +  1) / (len(vx[:,i]))\n",
    "            vy_cdf = (np.arange(len(vy[:,i])) +  1) / (len(vy[:,i]))\n",
    "            \n",
    "            spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i]))\n",
    "            vx_interp = spl(vy_cdf)\n",
    "            \n",
    "            def func(x, a, b, c, d):\n",
    "                return a*x + b*x**2 + c*x**3 + d\n",
    "            \n",
    "            popt = curve_fit(func, vx_interp, np.sort(vy[:,i]))[0]\n",
    "            \n",
    "            matched_vx[:,i] = func(vx[:,i], *popt)\n",
    "    elif np.array(vx).ndim==3:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                vx_cdf = (np.arange(len(vx[:,i,j])) +  1) / (len(vx[:,i,j]))\n",
    "                vy_cdf = (np.arange(len(vy[:,i,j])) +  1) / (len(vy[:,i,j]))\n",
    "                \n",
    "                spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j]))\n",
    "                vx_interp = spl(vy_cdf)\n",
    "                \n",
    "                def func(x, a, b, c, d):\n",
    "                    return a*x + b*x**2 + c*x**3 + d\n",
    "                \n",
    "                popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j]))[0]\n",
    "                \n",
    "                matched_vx[:,i,j] = func(vx[:,i,j], *popt)\n",
    "    elif np.array(vx).ndim==4:\n",
    "        matched_vx=np.zeros((vx.shape[0],vx.shape[1],vx.shape[2],vx.shape[3]))\n",
    "        for i in range(vx.shape[1]):\n",
    "            for j in range(vx.shape[2]):\n",
    "                for k in range(vx.shape[3]):\n",
    "                    vx_cdf = (np.arange(len(vx[:,i,j,k])) +  1) / (len(vx[:,i,j,k]))\n",
    "                    vy_cdf = (np.arange(len(vy[:,i,j,k])) +  1) / (len(vy[:,i,j,k]))\n",
    "                    \n",
    "                    spl = InterpolatedUnivariateSpline(vx_cdf, np.sort(vx[:,i,j,k]))\n",
    "                    vx_interp = spl(vy_cdf)\n",
    "                    \n",
    "                    def func(x, a, b, c, d):\n",
    "                        return a*x + b*x**2 + c*x**3 + d\n",
    "                    \n",
    "                    popt = curve_fit(func, vx_interp, np.sort(vy[:,i,j,k]))[0]\n",
    "                    \n",
    "                    matched_vx[:,i,j,k] = func(vx[:,i,j,k], *popt)\n",
    "\n",
    "    return matched_vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd141a83-bd3f-4bf4-aa3a-53fc576e7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import Auto_paint_self\n",
    "np.random.seed(25)\n",
    "trainy,testy,trainx,testx = train_test_split(np.array(vy),vx,test_size=0.2,random_state=25)\n",
    "predicty_u=Auto_cdf_matching(np.array(predicty_u),trainy[np.random.randint(0,trainy.shape[0], predicty_u.shape[0]),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2b5b3-4679-4e1b-89c3-5a0b3d9e71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from metpy.calc import wind_direction,wind_speed\n",
    "from metpy.units import units\n",
    "u_rmse=np.zeros((predicty_u.shape[1]))\n",
    "u_mae=np.zeros((predicty_u.shape[1]))\n",
    "u_pearson=np.zeros((predicty_u.shape[1]))\n",
    "u_mape=np.zeros((predicty_u.shape[1]))\n",
    "for i in tqdm(range(predicty_u.shape[1])):\n",
    "    u_rmse[i]=mean_squared_error(testy_u[:,i],predicty_u[:,i])\n",
    "    u_pearson[i],_=pearsonr(testy_u[:,i],predicty_u[:,i])\n",
    "    u_mae[i]=mean_absolute_error(testy_u[:,i],predicty_u[:,i])\n",
    "    u_mape[i]=mean_absolute_percentage_error(testy_u[:,i],predicty_u[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312b1cf-880f-49cd-9c25-a78afc4f5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u_mae)\n",
    "print(np.nanmean(u_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2511a33f-1e5a-4bed-bade-a1a97d95a505",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(u_rmse)\n",
    "print(np.nanmean(u_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec04903-de35-4c66-92f3-c76447a7e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_p=np.sqrt(u_rmse)/(np.nanmax(testy_u,axis=0)-np.nanmin(testy_u,axis=0))\n",
    "#v_p=np.sqrt(v_rmse)/(np.nanmax(testy_v,axis=0)-np.nanmin(testy_v,axis=0))\n",
    "#wind_p=np.sqrt(wind_rmse)/(np.nanmax(np.sqrt(testy_u**2+testy_v**2),axis=0)-np.nanmin(np.sqrt(testy_u**2+testy_v**2),axis=0))\n",
    "print(u_p)\n",
    "print(np.nanmean(u_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1efbcb-42c8-49c3-ac71-f9e20cf8d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "dim_names = ('times', 'levels')\n",
    "\n",
    "predicty_u_da_cdf = xr.DataArray(\n",
    "    data=predicty_u,\n",
    "    coords={\n",
    "        'times': times,\n",
    "        'levels': levels\n",
    "    },\n",
    "    dims=dim_names,\n",
    "    name='predicty_u'\n",
    ")\n",
    "\n",
    "predicty_u_da.to_netcdf('E:/huawei/result/huawei_Transformer_30min_k5_gnss_to_wind_predicty_u_cdf_onestation_45.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d01d0e-dc73-40e8-a3c4-9373a1aa0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
